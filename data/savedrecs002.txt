FN Clarivate Analytics Web of Science
VR 1.0
PT P
PN CN109031114-A
TI Spring operating mechanism circuit breaker modeling and fault diagnosis method, involves performing fault diagnosis process according to deep belief network and softmax classifier combination of circuit fault diagnosis operation.
AU JI T
   YE X
   LI M
   WU Q
AE UNIV SOUTH CHINA TECHNOLOGY (UYSC-C)
GA 2018A4923E
AB    NOVELTY - The method involves establishing a signal transmitting system and a data collecting system by utilizing a current sensor and a data collecting card. An environment is set up to store data on LabVIEW (RTM: System-design platform and development environment for a visual programming language) at a computer end. Data obtained by simulation process is clustered by adopting K-mean clustering algorithm to form a standard base. Fault diagnosis process is performed by executing rapid template matching process according to deep belief network (DBN) and softmax classifier combination of circuit fault diagnosis operation.
   USE - Spring operating mechanism circuit breaker modeling and fault diagnosis method.
   ADVANTAGE - The method enables detecting actual error data by utilizing an emulation signal to perform effective fault diagnosis and rapid template matching process in a simple manner with less operation amount.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a spring operating mechanism circuit breaker modeling and fault diagnosis method. '(Drawing includes non-English language text)'
DC S01 (Electrical Instruments); T01 (Digital Computers)
MC S01-G10; S01-H07A; T01-J05B3; T01-J20B; T01-N01D; T01-N03A2
IP G01R-031/327
PD CN109031114-A   18 Dec 2018   G01R-031/327   201911   Pages: 16   Chinese
AD CN109031114-A    CN11147478    29 Sep 2018
PI CN11147478    29 Sep 2018
UT DIIDW:2018A4923E
ER

PT P
PN CN109036459-A
TI Method for detecting voice endpoint by utilizing computer device, involves judging whether step length is greater than one, and determining frame skip number of to-be-detected voice frame according to step length of each convolution layer.
AU LI C
   ZHU W
AE BAIDU ONLINE NETWORK TECHNOLOGY BEIJING (BIDU-C)
GA 2018A48053
AB    NOVELTY - The method involves setting a layer number of a convolution layer of a convolutional neural network for to-be-detected voice frame. Step-length of each convolution layer is set according to the layer number of the convolution layer. Judgment is made to check whether the step length is greater than one. A frame skip number of the to-be-detected voice frame is determined according to the step length of the each convolution layer. A maximum layer number of the convolution layer of the convolutional neural network is set. The step length of a layer of the convolution layer is set.
   USE - Method for detecting a voice endpoint by utilizing a computer device (claimed).
   ADVANTAGE - The method enables reducing calculation amount of a CPU in an electronic device such as a computer device so as to reduce power consumption of the electronic device.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for detecting a voice endpoint by utilizing a computer device
   (2) a computer-readable storage medium for storing a set of instructions for detecting a voice endpoint by utilizing a computer device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for detecting a voice endpoint by utilizing a computer device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J04B2; T01-S03; W04-V01; W04-V05
IP G10L-025/30; G10L-025/87; G06N-003/04
PD CN109036459-A   18 Dec 2018   G10L-025/30   201911   Pages: 19   Chinese
AD CN109036459-A    CN10959142    22 Aug 2018
PI CN10959142    22 Aug 2018
UT DIIDW:2018A48053
ER

PT P
PN CN109029974-A
TI One-dimensional convolutional neural network based planetary gearbox fault detecting method, involves training fault identification model, and identifying fault type of planetary gear box by using fault identification model.
AU LI D
   WANG H
   HUA W
   ZHAO Y
   YANG F
   LIN S
AE UNIV SHANGHAI ELECTRIC POWER (UYSI-C)
GA 2018A49613
AB    NOVELTY - The method involves obtaining a vibration signal of a planetary gear box, where the vibration signal is input to a fault identification model. The fault identification model is trained by using a one-dimensional convolution neural network, where the convolution neural network comprises an input layer, two convolutional layers, two pooling layers, a feature vector layer and an output layer. Fault type of the planetary gear box is identified by the fault identification model. Characteristic vector of a characteristic map is obtained to determine characteristic vector of the second pooling layer.
   USE - One-dimensional convolutional neural network based planetary gearbox fault detecting method.
   ADVANTAGE - The method enables realizing fault diagnosis of the planetary gear box in accurate and rapid manner.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a one-dimensional convolutional neural network based planetary gearbox fault detecting method. '(Drawing includes non-English language text)'
DC Q54 (Non-positive displacement fluid engines (i.e. driven by fluid); Miscellaneous motors and machines for producing mechanical power/thrust (F03B,D,G,H)); S02 (Engineering Instrumentation); T01 (Digital Computers)
MC S02-J01; S02-J03; T01-J04B2; T01-N01B3
IP G01M-013/02; G01M-015/02; F03D-017/00
PD CN109029974-A   18 Dec 2018   G01M-013/02   201911   Pages: 13   Chinese
AD CN109029974-A    CN10654805    22 Jun 2018
PI CN10654805    22 Jun 2018
UT DIIDW:2018A49613
ER

PT P
PN CN109011419-A
TI MEMS sensor based human-body action training method, involves collecting current user action data of body parts of user, and identifying and inputting user action data into action identification model to output action correction information.
AU LI F
AE CHONGQING DIANZHENG INFORMATION TECHNOLOGY CO LTD (CHON-Non-standard)
GA 2018A4672V
AB    NOVELTY - The method involves establishing standard action database and an action identification model based on multi-standard motion data (S1). Human body action in the multi-standard motion data is marked (S2) to generate marking action data. The marking action data is processed by adopting a deep learning algorithm to output a training result. An action identification model is corrected (S3) according to the training result. Current user action data of different body parts of a user is collected (S4) by multiple MEMS sensors. The current user action data is identified and input (S5) into the action identification model to output action correction information.
   USE - MEMS sensor based human-body action training method.
   ADVANTAGE - The method enables sending the action correction information to the user to grasp standard of own actions, thus improving user action guidance efficiency.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a MEMS sensor based human-body action training method. '(Drawing includes non-English language text)'
   Step for establishing standard action database and action identification model based on multi-standard motion data (S1)
   Step for marking human body action in multi-standard motion data to generate marking action data (S2)
   Step for correcting action identification model according to training result (S3)
   Step for collecting current user action data of different body parts of user by MEMS sensors (S4)
   Step for identifying and inputting user action data into action identification model to output action correction information (S5)
DC T01 (Digital Computers); V06 (Electromechanical Transducers and Small Machines)
MC T01-J05B4P; T01-J16C2; T01-J30A; V06-V01K1; V06-V04G; V06-V04R
IP A63B-024/00
PD CN109011419-A   18 Dec 2018   A63B-024/00   201911   Pages: 7   Chinese
AD CN109011419-A    CN10962360    22 Aug 2018
PI CN10962360    22 Aug 2018
UT DIIDW:2018A4672V
ER

PT P
PN CN109032671-A
TI Data parallel strategy based distributed deep learning method, involves converting training data of P-Model into Distort data type, and updating global neural network model parameter to reach precision desired value by training precision.
AU LI M
   HOU M
   ZHAN S
   DONG H
   WANG H
   XI R
   DONG L
AE UNIV ELECTRONIC SCI & TECHNOLOGY (UEST-C)
GA 2018A4888B
AB    NOVELTY - The method involves inputting a to-be-trained neural network model by a user based on PyTorch (RTM: open-source machine learning library for Python). A working node training parameter and a distributed training parameter are sent to a working node according to a communication threshold value in a P-Model. A global training parameter and a distributed training parameter are sent to a parameter server by an updated distribution algorithm P- Model. Training data of the P-Model is converted into a Distort data type. A global neural network model parameter is updated by a parameter server at each time to reach a precision desired value by training precision.
   USE - Data parallel strategy based distributed deep learning method.
   ADVANTAGE - The method enables effectively combining PyTorch (RTM: open-source machine learning library for Python) and Spark together, ensuring decoupling of bottom layer by PyTorch (RTM: open-source machine learning library for Python) distributed clusters, providing convenient training interface, and effectively realizing data parallel-based distributed training process.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a data parallel strategy based distributed deep learning system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a data parallel strategy based distributed deep learning system.
DC T01 (Digital Computers)
MC T01-F05F; T01-N01B3; T01-N01D3
IP G06F-009/38; G06N-003/04; G06N-003/08
PD CN109032671-A   18 Dec 2018   G06F-009/38   201911   Pages: 10   Chinese
AD CN109032671-A    CN10662859    25 Jun 2018
PI CN10662859    25 Jun 2018
UT DIIDW:2018A4888B
ER

PT P
PN CN109035231-A
TI Depth circulation based wheat fusarium head blight detecting method, involves collecting hyperspectral image pixels, and analyzing depth classification effect of circular neural network model corresponding to model accuracy and loss rate.
AU LI S
   JIN X
   XU G
   FU Y
   WANG S
   ZHU J
   FANG X
AE UNIV ANHUI AGRIC (UYAH-C)
GA 2018A48345
AB    NOVELTY - The method involves collecting wheat spike hyperspectral image pixels (S1). Under-sampling process of the wheat spike hyperspectral image pixel is performed to obtain an unbalanced data set and features of background, health and diseases for training a target data deep convolutional neural network model. A two-dimensional image of target data is remodeled (S2) to obtain a gray image. A depth circular neural network model is trained (S3) based on preprocessed data. Depth classification effect of the depth circular neural network model is analyzed (S4) corresponding to trained model accuracy and loss rate.
   USE - Depth circulation based wheat fusarium head blight detecting method.
   ADVANTAGE - The method enables utilizing wheat fusarium head blight high spectrum imaging technology so as to realize quick and non-destructive detection and improve testing accuracy of a wheat area classifying result.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a depth circulation based wheat fusarium head blight detecting method. '(Drawing includes non-English language text)'
   Step for collecting wheat spike hyperspectral image pixels (S1)
   Step for remodeling two-dimensional image of target data (S2)
   Step for training depth circular neural network model (S3)
   Step for analyzing depth classification effect of depth circular neural network model (S4)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2; T01-J10B2; T01-N01B3A; T04-D04
IP G06T-007/00; G06K-009/62; G06N-003/04
PD CN109035231-A   18 Dec 2018   G06T-007/00   201911   Pages: 9   Chinese
AD CN109035231-A    CN10805085    20 Jul 2018
PI CN10805085    20 Jul 2018
UT DIIDW:2018A48345
ER

PT P
PN CN109008961-A
TI Method for auxiliary nursing infant in service center, involves inputting to-be-recognized infant voice to infant voice recognition network model to obtain state tag, and sending state tag to client end to output.
AU LI X
   ZHAO Y
   CHEN J
AE ZHENGZHOU YUNHAI INFORMATION TECHNOLOGY (INEI-C)
GA 2018A54770
AB    NOVELTY - The method involves receiving training speech by a service center, where the training speech comprises infant voice. An infant voice recognition network model is obtained based on a training speech training deep learning network. To-be-recognized infant voice is input to the infant voice recognition network model to obtain a state tag. The state tag is sent to a client end to output. Operation prompt is prompted based on the state tag to obtain prompt information. The prompt information is sent to the client end. The prompt information is output by the client end.
   USE - Method for auxiliary nursing infant in a service center (claimed).
   ADVANTAGE - The method enables accurately identifying requirement of infant, and reducing infant nursing staff nursing load.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a service center
   (2) a device for auxiliary nursing infant in a service center
   (3) a system for auxiliary nursing infant in a service center
   (4) a readable storage medium for storing set of instruction for auxiliary nursing infant in a service center.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for auxiliary nursing infant in a service center. '(Drawing includes non-English language text)'
DC P31 (Diagnosis, surgery (A61B).); W04 (Audio/Video Recording and Systems)
MC W04-W05A
IP A61B-005/00
PD CN109008961-A   18 Dec 2018   A61B-005/00   201911   Pages: 15   Chinese
AD CN109008961-A    CN10643651    21 Jun 2018
PI CN10643651    21 Jun 2018
UT DIIDW:2018A54770
ER

PT P
PN CN109034281-A
TI Convolutional neural network based Chinese handwriting recognition accelerating method, involves testing classifiers of networks in test set to evaluate performance of classifiers and calculate calculation amount required for classifiers.
AU LI Z
   TENG N
   JIN M
   LU H
AE INST SEMICONDUCTORS CHINESE ACAD SCI (CBDT-C)
GA 2018A4846U
AB    NOVELTY - The method involves pre-processing handwriting character pictures data to classify a convolutional neural network (1). A convolutional neural network structure is constructed. Three classifiers are respectively added (2) into a shallow layer, a middle layer and a top layer. Network parameters are initialized. Loss functions of the classifiers are utilized (3) to guide network training for updating parameters of the shallow, middle and top layer networks and the classifiers. The loss functions of three classifiers are weighted (4) for function adjustment of parameters of the networks and the classifiers by using weighted loss function. The classifiers of the networks in a test set are tested (5) for evaluating performance of the classifiers and calculating calculation amount required for the classifiers.
   USE - Convolutional neural network based Chinese handwriting recognition accelerating method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network based Chinese handwriting recognition accelerating method. '(Drawing includes non-English language text)'
   Step for pre-processing handwriting character pictures data to classify convolutional neural network (1)
   Step for adding three classifiers into shallow layer, middle layer and top layer (2)
   Step for utilizing loss functions of classifiers to guide network training for updating parameters of shallow, middle and top layer networks and classifiers (3)
   Step for weighting loss functions of three classifiers for function adjustment of parameters of networks and classifiers by using weighted loss function (4)
   Step for testing classifiers of networks in test set for evaluating performance of classifiers and calculating calculation amount required for classifiers (5)
DC T01 (Digital Computers)
MC T01-J10B2A; T01-N01B3A
IP G06K-009/68; G06N-003/04; G06N-003/08
PD CN109034281-A   18 Dec 2018   G06K-009/68   201911   Pages: 12   Chinese
AD CN109034281-A    CN10789695    18 Jul 2018
PI CN10789695    18 Jul 2018
UT DIIDW:2018A4846U
ER

PT P
PN CN109009179-A
TI Deep belief network based isotope-labeled-tracer PET separation method, involves obtaining counting vector, and obtaining TAC reconstructed dynamic PET image sequence corresponding to first injected tracer and second injected tracers.
AU LIU H
   XU J
AE UNIV ZHEJIANG (UYZH-C)
GA 2018A5471P
AB    NOVELTY - The method involves obtaining a counting vector corresponding to different time. Dynamic counting sequence is generated under mixed double-tracer distribution condition of a first injected tracer and a second injected tracer. Dynamic PET image sequence is generated by using PET image reconstruction algorithm. The first injected tracer is divided into a training set and a testing set. A pixel point is extracted. A double-tracer PET reconstruction model is established. TAC reconstructed dynamic PET image sequence is obtained corresponding to the first injected tracer and the second injected tracer.
   USE - Deep belief network based isotope-labeled-tracer PET separation method.
   ADVANTAGE - The method enables realizing recovery of radioactive tracer single PET signal, and verifying validity of dual-tracer PET signal separation by the deep belief network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a deep belief network based isotope-labeled-tracer. '(Drawing includes non-English language text)'
DC P31 (Diagnosis, surgery (A61B).); S03 (Scientific Instrumentation); T01 (Digital Computers)
MC S03-G02B3; T01-J10B2; T01-N01B3A; T01-N01D1B; T01-N01E
IP A61B-006/00; A61B-006/03; G06T-007/187; G06T-007/00
PD CN109009179-A   18 Dec 2018   A61B-006/00   201911   Pages: 12   Chinese
AD CN109009179-A    CN10507876    02 Aug 2018
PI CN10507876    02 Aug 2018
UT DIIDW:2018A5471P
ER

PT P
PN CN109033947-A
TI Deep learning based road surface identifying method, involves training YOLO model, inputting image to be tested into trained YOLO model to calculate category probability and surrounding frame of target to identify road surface.
AU LIU J
   WEI X
   LI F
   YE Z
   LI J
   TANG Z
   ZHOU S
   WANG Y
   WU Y
AE UNIV BEIHANG (UNBA-C)
GA 2018A4855L
AB    NOVELTY - The method involves collecting road surface data to establish a structure data set. A YOLO model is established by reducing size of convolution kernels and increasing connection between different feature layers. The YOLO model is trained by using the structure data set. An image to be tested is input into the trained YOLO model to calculate category probability and a surrounding frame of a target to identify the road surface. Small range of convolution kernels are determined without increasing parameters. Photos and videos of the road surface are collected.
   USE - Deep learning based road surface identifying method.
   ADVANTAGE - The method enables performing road surface identification process by using the trained YOLO model with high accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based road surface identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J04B2; T01-J05B2B; T01-J10B2; T01-J21; T01-J30A; W04-W05A
IP G06K-009/00; G06K-009/62; G06N-003/04; G06N-003/08
PD CN109033947-A   18 Dec 2018   G06K-009/00   201911   Pages: 15   Chinese
AD CN109033947-A    CN10592958    11 Jun 2018
PI CN10592958    11 Jun 2018
UT DIIDW:2018A4855L
ER

PT P
PN CN109009074-A
TI Depth study based cardiac death auxiliary warning device, has model judging module provided with convolutional neural network model, and abnormity alarm module that sends alarm signal in time.
AU LIU X
   MA R
   XUE M
   TANG J
AE UNIV SHANGHAI ENG & TECHNOLOGY (USES-C)
GA 2018A54747
AB    NOVELTY - The device has an ECG acquisition module connected with a model judging module that is coupled with an image pre-processing module. An abnormity alarm module is connected with the model judging module. The ECG collecting module collects ECG data in real-time and sends the ECG data to the image pre-processing module. The image pre-processing module is placed in a sliding window region-of-interest (ROI) area. The model judging module is provided with a convolutional neural network model and adapted to judge whether abnormal ECG number count is greater than 1. The abnormity alarm module sends an alarm signal in time.
   USE - Depth study based cardiac death auxiliary warning device.
   ADVANTAGE - The device has high accuracy and high sensitivity.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating operations of a depth study based cardiac death auxiliary warning device. '(Drawing includes non-English language text)'
DC P31 (Diagnosis, surgery (A61B).); S05 (Electrical Medical Equipment); T01 (Digital Computers); T04 (Computer Peripheral Equipment); W05 (Alarms, Signalling, Telemetry and Telecontrol)
MC S05-D; T01-J10B2; T01-N01D1B; T01-N01E; T04-D02; T04-D03; T04-D04; W05-B07G5A
IP A61B-005/0402; A61B-005/0452; G06K-009/32; G06K-009/62
PD CN109009074-A   18 Dec 2018   A61B-005/0402   201911   Pages: 9   Chinese
AD CN109009074-A    CN10808839    19 Jul 2018
PI CN10808839    19 Jul 2018
UT DIIDW:2018A54747
ER

PT P
PN CN109034184-A
TI Deep learning-based equalizing ring detection and identification method involves collecting transmission line picture data in batches, automatic identification and positioning of pressure equalization ring.
AU LU S
   XIA L
   MO Z
   FENG P
   YAN Y
   CHEN J
   SHI Y
   HAN X
   PANG T
   LIU X
   LI D
AE YULIN POWER SUPPLY BUREAU GUANGXI POWER (CSPG-C)
   WUHAN JIAMINGKAIER ELECTRIC TECHNOLOGY (WUHA-Non-standard)
   WUHAN AROVER TECHNOLOGY CO LTD (WUHA-Non-standard)
GA 2018A5538F
AB    NOVELTY - The method involves preprocessing using the collected original equalization ring image as an image source. The equalization loop image sample is pre-processed. The convolutional neural network is used to extract multi-level features of the image to form a grading ring training map. The obtained grading ring training images are combined to form a sample set, and input into the detection model to be trained with an unsupervised forward propagation algorithm. The backward propagation algorithm alternates the method and adjusts the weight and offset parameters in the convolutional neural network, and finally determines the optimized model parameters. The detection network is initialized according to the optimized model parameters, and the transmission line picture data is collected in batches, automatic identification and positioning of the pressure equalization ring.
   USE - Deep learning-based equalizing ring detection and identification method.
   ADVANTAGE - The deep learning-based equalizing loop detection and recognition method can adapt to the demand of the equalizing loop detection and recognition under the complex background of non-specific angles, and achieve better use effect.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning-based equalizing ring detection and identification process. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-J10B1; T01-J10B2A; T01-N01B3; T01-N01D1B
IP G06K-009/62; G06N-003/04; G06N-003/08
PD CN109034184-A   18 Dec 2018   G06K-009/62   201911   Pages: 13   Chinese
AD CN109034184-A    CN10582294    07 Jun 2018
PI CN10582294    07 Jun 2018
UT DIIDW:2018A5538F
ER

PT P
PN CN109035169-A
TI Unsupervised/semi-supervised CT image reconstruction deep network training method, involves performing filter back projection algorithm to reconstruct CT image of de-noised CT unmeasured data for obtaining output result of deep network.
AU MENG D
   XIE Q
   ZHAO Q
   MA J
   GENG M
   DENG Y
AE UNIV XIAN JIAOTONG (UYXJ-C)
GA 2018A4835S
AB    NOVELTY - The method involves defining marked data loss function and non-marked data loss function of a deep network. CT unmeasured data is selected as an input of the deep network. Weighted addition process of the marked and non-marked data loss functions is realized. Unsupervised/semi-supervised network loss function is defined to update parameters of the deep network by performing gradient descent operation. A CT image is de-noised according to the updated deep network. Filter back projection algorithm is performed to reconstruct the CT image of the de-noised CT unmeasured data for obtaining an output result of the deep network.
   USE - Unsupervised/semi-supervised CT image reconstruction deep network training method.
   ADVANTAGE - The method enables improving CT image reconstruction deep network training accuracy by using non-marked data or marked data, increasing speed of CT image de-noise effect of the deep network and establishing an unmeasured data recovery model and a depth learning model so as to realize CT image reconstruction process.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating an unsupervised/semi-supervised ct image reconstruction deep network training method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E01B; T01-J10B1; T01-N01B3
IP G06T-005/00; G06N-003/04; G06N-003/08
PD CN109035169-A   18 Dec 2018   G06T-005/00   201911   Pages: 15   Chinese
AD CN109035169-A    CN10798715    19 Jul 2018
PI CN10798715    19 Jul 2018
UT DIIDW:2018A4835S
ER

PT P
PN CN109033390-A
TI Similar question sentence automatic generating method, involves judging whether expanded question sentence is similar question sentence by using deep learning model, and marking similar question sentence according to judging result.
AU PAN C
   YANG Z
   LIU Y
   WU Y
   CHEN Z
   HU X
   WEN L
AE SHENZHEN ZHUIYI TECHNOLOGY CO LTD (SHEN-Non-standard)
GA 2018A4869Q
AB    NOVELTY - The method involves obtaining an initial question sentence. The initial question sentence is inputted into a first deep learning model. Multiple expanding question sentences are outputted by the first deep learning model according to the initial question sentence. An expanded question sentence is generated according to the initial question sentence. Judgment is made to check whether the expanded question sentence is a similar question sentence by using a second deep learning model. The similar question sentence is marked according to a judging result.
   USE - Similar question sentence automatic generating method.
   ADVANTAGE - The method enables generating a similar question in an automatic manner by using a computer, saving human resources consumed by manual marking of the similar question, reducing cost of a robot and realizing high efficiency of generating the similar question and short consumption time.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a similar question sentence automatic generating device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a similar question sentence automatic generating method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B4P; T01-J11A1; T01-J30A
IP G06F-017/30; G06F-017/27
PD CN109033390-A   18 Dec 2018   G06F-017/30   201911   Pages: 11   Chinese
AD CN109033390-A    CN10856231    27 Jul 2018
PI CN10856231    27 Jul 2018
UT DIIDW:2018A4869Q
ER

PT P
PN CN109033971-A
TI Residual network concept based high-efficient pedestrian identification method, involves inputting training set into network model, fine-tuning verification data set, and storing trained model for testing accuracy of model.
AU PANG S
   QIAO S
   LI W
   YU S
   WANG L
AE UNIV CHINA PETROLEUM HUADONG (UYPE-C)
GA 2018A4854W
AB    NOVELTY - The method involves acquiring pedestrian pictures in a public data set. A convolutional neural network model is designed. A training set in the public data set is input into the network model for training, where the network model comprises an image pre-processing layer, a residual network module layer, a difference processing layer, a convergence layer and a connecting processing layer. A verification data set is fine-tuned after completing the training process to ensure accuracy of the model. A trained model is stored for testing accuracy of the model.
   USE - Residual network concept based high-efficient pedestrian identification method.
   ADVANTAGE - The method enables accurately identifying and classifying pedestrian pictures, improving recognition efficiency and increasing processing speed.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a residual network concept based high-efficient pedestrian identification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2A; T01-N01B3A; T04-D04
IP G06K-009/00; G06K-009/62; G06N-003/04; G06N-003/08
PD CN109033971-A   18 Dec 2018   G06K-009/00   201911   Pages: 10   Chinese
AD CN109033971-A    CN10673779    27 Jun 2018
PI CN10673779    27 Jun 2018
UT DIIDW:2018A4854W
ER

PT P
PN CN109009013-A
TI Intelligent wristband, has multiple sensors for measuring parameter information associated with wearer, and processor for generating classification information for representing health condition of wearer.
AU PENG L
AE PENG L (PENG-Individual)
GA 2018A5475U
AB    NOVELTY - The wristband has multiple sensors (111-114) for measuring parameter information associated with a wearer. A memory unit stores program. A processor (120) obtains multiple groups of parameter information related to the wearer from the sensors. The processor generates classification information for representing health condition of the wearer by using a diagnostic model based on a convolutional neural network according to matrix information. The sensors are provided with an acceleration measuring device. The first sensor and the second sensor for measuring heart rate. The third sensor measures blood. The fourth sensor measures temperature.
   USE - Intelligent wristband.
   DESCRIPTION OF DRAWING(S) - The drawing shows a perspective view of an intelligent wristband.
   Sensors (111-114)
   Processor (120)
DC B04 (Natural products and polymers. Including testing of body fluids (other than blood typing or cell counting), pharmaceuticals or veterinary compounds of unknown structure, testing of microorganisms for pathogenicity, testing of chemicals for mutagenicity or human toxicity and fermentative production of DNA or RNA. General compositions.); P31 (Diagnosis, surgery (A61B).); S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC B04-B04D5; B11-C08E8; B11-C11; B12-K04F; S05-D01G; T01-J05B2; T01-N01E
IP A61B-005/0205; A61B-005/11; A61B-005/145; A61B-005/01
PD CN109009013-A   18 Dec 2018   A61B-005/0205   201911   Pages: 9   Chinese
AD CN109009013-A    CN10656969    25 Jun 2018
PI CN10656969    25 Jun 2018
UT DIIDW:2018A5475U
ER

PT P
PN CN109033998-A
TI Convolutional neural network depth learning based remote sensing image feature marking method, involves obtaining output characteristic pattern, training convolution neural network, and splicing test result sets to obtain marking result.
AU SHI Z
   CHEN H
   FENG P
   WU X
   DAN T
AE UNIV BEIHANG (UNBA-C)
   BEIJING INST SATELLITE INFORMATION ENG (BEIJ-Non-standard)
GA 2018A48549
AB    NOVELTY - The method involves reading sensing data of a sample image that is divided into a training set and a test set. An original training image is cut into 321/asterisk321 size in a testing phase. An original test image is cut into 500/asterisk500 size to obtain a marked result according to original size of a classification chart. A convolutional neural network is constructed. An output characteristic pattern is obtained. The characteristic pattern is increased by 8 times by performing deconvolutional operation. An attention map is up-sampled by a sigmoid layer. The convolutional neural network is trained by a Caffe frame. Test result sets are spliced to obtain the marking result.
   USE - Convolutional neural network depth learning based remote sensing image feature marking method.
   ADVANTAGE - The method enables improving classification effect of a network ground object by using a depth monitoring mechanism, improving comprehensive performance of the training network, realizing automatic image classification of each pixel, reducing trouble of manual interpretation and accelerating decoding process to obtain refinement of the marking result.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network depth learning based remote sensing image feature marking method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J05B2; T01-J10B2; T01-J10B3A; T01-L02; T01-N01B3A; T01-N02B2
IP G06K-009/00; G06K-009/62
PD CN109033998-A   18 Dec 2018   G06K-009/00   201911   Pages: 13   Chinese
AD CN109033998-A    CN10721848    04 Jul 2018
PI CN10721848    04 Jul 2018
UT DIIDW:2018A48549
ER

PT P
PN CN109034374-A
TI Method for estimating relative depth sequence by using multi-scale densely connected convolutional network, involves outputting reconstructed depth map of increased multi-scale model to obtain depth sequence of high quality estimation.
AU SU F
AE SUZHOU ZHONGKE QIHUI SOFTWARE TECHNOLOGY (SUZH-Non-standard)
GA 2018A4844D
AB    NOVELTY - The method involves determining validity of input characteristic used in an ablation experiment analysis. Performance of context thread contribution in context of depth sequence estimation is checked. A multi-scale densely connected network is utilized to finish task. Local context information around point is determined by using a multi-scale model. A global structure is constructed to search a local structure in a large area near regression from the point. The multi-scale model is increased by using a dense net depth learning algorithm. A reconstructed depth map of the increased multi-scale model is outputted to obtain depth sequence of relative high quality estimation.
   USE - Method for estimating relative depth sequence by using a multi-scale densely connected convolutional network.
   ADVANTAGE - The method enables effectively searching a surrounding environment and network to determine depth information of different points, so that conversion problem of two-dimensional information to three-dimensional information can be avoided, thus improving sequence estimating accuracy.
DC T01 (Digital Computers)
MC T01-J10B2; T01-J16C2; T01-N01B3; T01-N03A2
IP G06N-003/04; G06N-003/08; G06K-009/62
PD CN109034374-A   18 Dec 2018   G06N-003/04   201911   Pages: 5   Chinese
AD CN109034374-A    CN10711047    03 Jul 2018
PI CN10711047    03 Jul 2018
UT DIIDW:2018A4844D
ER

PT P
PN CN109036465-A
TI Voice emotion recognition method, involves constructing fusion depth layer by convolution neural network, and comparing voice emotion recognition rate of two experiments by traditional convolution neural network and layer characteristics.
AU SUN L
   CHEN J
AE UNIV NANJING POSTS & TELECOM (UNPT-C)
GA 2018A4804X
AB    NOVELTY - The method involves converting speech data into a spectrogram wave. Data amplification treatment is performed of the spectrogram wave. A fusion depth layer is constructed by a convolution neural network. Voice emotion recognition rate of two experiments are compared by using the traditional convolution neural network and fusion depth layer characteristics, where sampling frequency of voice data is 16KHZ, voice data comprises seven emotions are angry, bored, disgust, fear, happiness, neutral and anxious. Data amplification process is performed by using a keras depth learning framework, where the data amplification process comprises random rotation image, horizontal translation, vertical translation, shear transform, image zoom and horizontal turning operation.
   USE - Voice emotion recognition method.
   ADVANTAGE - The method enables improving voice emotion recognition rate and identification accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a voice emotion recognition device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J04B2; T01-J10B3A; T01-N01B3; W04-V01; W04-V04A4; W04-V05
IP G10L-025/63; G10L-025/30; G06N-003/04; G06N-003/08
PD CN109036465-A   18 Dec 2018   G10L-025/63   201911   Pages: 12   Chinese
AD CN109036465-A    CN10685220    28 Jun 2018
PI CN10685220    28 Jun 2018
UT DIIDW:2018A4804X
ER

PT P
PN CN109036470-A
TI Voice distinguishing method applied to computer device, involves processing original voice data to be distinguished based on voice activity detection algorithm, and acquiring voice data to be distinguished by target.
AU TU H
AE PINGAN TECHNOLOGY SHENZHEN CO LTD (PING-C)
GA 2018A5530D
AB    NOVELTY - The voice distinguishing method involves processing (S10) the original voice data to be distinguished based on the voice activity detection algorithm, and acquiring the voice data to be distinguished by the target. The corresponding answer-seizure ratio (ASR) speech features are obtained (S20) based on the target to be distinguished voice data. The ASR speech feature is inputted (S30) into the pre-trained ASR-deep neural network (DNN) model to distinguish and obtain the target differentiation result.
   USE - Voice distinguishing method applied to computer device (claimed).
   ADVANTAGE - The speech distinguishing method can distinguish the target speech, and interfere the speech very well. The accurate speech distinction can be performed in the case where the speech data noise interference is very large.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) voice distinguishing device;
   (2) computer device; and
   (3) computer-readable storage medium storing instructions for voice distinguishing.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating voice distinguishing method. (Drawing includes non-English language text)
   Speech features (ASR)
   Step for processing the original voice data to be distinguished based on the voice activity detection algorithm (S10)
   Step for obtaining corresponding answer-seizure ratio (S20)
   Step for Step for inputting ASR speech feature (S30)
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J18; T01-S03; W04-V01; W04-V04A1; W04-V05
IP G10L-025/78; G10L-025/84; G10L-025/30; G10L-025/24; G10L-025/21; G10L-025/18
PD CN109036470-A   18 Dec 2018   G10L-025/78   201911   Pages: 21   Chinese
AD CN109036470-A    CN10561723    04 Jun 2018
PI CN10561723    04 Jun 2018
UT DIIDW:2018A5530D
ER

PT P
PN CN109035120-A
TI Big data security management system, has load weighing apparatus with CPU operation module and GPU operation module, where CPU operation module and GPU module operation module are respectively connected with database module.
AU WANG H
AE SHENZHEN HAINENG COMMUNICATION EQUIP CO (SHEN-Non-standard)
GA 2018A4836V
AB    NOVELTY - The system has an input module and a monitoring device connected between a CPU operation module and a GPU operation module. A recording module is provided with a camera and a memory. The monitoring device is provided with an infrared high definition camera and a magnetic card reading module. The magnetic card reading module collects staff information. A load weighing apparatus is connected with the CPU operation module and the GPU operation module to realize analyzing operation of a human. The CPU operation module and the GPU module operation module are respectively connected with a database module.
   USE - Big data security management system.
   ADVANTAGE - The system realizes human body pose recognition and skeletal recognition by utilizing the CPU operation module, and improves deep learning, and can be used structured data image in security management application.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a big data security management system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T05 (Counting, Checking, Vending, ATM and POS Systems)
MC T01-J05A; T01-J05B2B; T01-J05B4F; T01-J05B4M; T05-D01A
IP G06Q-050/26; G07C-009/00; G06N-099/00
PD CN109035120-A   18 Dec 2018   G06Q-050/26   201911   Pages: 5   Chinese
AD CN109035120-A    CN11280783    30 Oct 2018
PI CN11280783    30 Oct 2018
UT DIIDW:2018A4836V
ER

PT P
PN CN109035232-A
TI Depth learning based machine vision fusion sheet defect detecting method, involves performing sheet size defect detecting on clamping workpiece based on machine vision process to obtain results of clamp defect detection.
AU WANG J
   TANG T
   ZENG Q
AE UNIV GUILIN ELECTRONIC TECHNOLOGY (UYGE-C)
GA 2018A48344
AB    NOVELTY - The method involves collecting an image of a clamping workpiece. Sheet defect detection is performed on the clamping workpiece based on deep learning process. Sheet size defect detecting is performed on the clamping workpiece based on machine vision process to obtain results of clamp defect detection, where clip size defect comprises marking material and saw inclined four-type defect. A convolutional neural network model is designed and trained based on ResNet18 network to receive results of clamp defect detection in real-time. A measurement boundary is located based on image boundary pixel difference for measuring size of a sheet.
   USE - Depth learning based machine vision fusion sheet defect detecting method.
   ADVANTAGE - The method enables improving clamping quality detecting process based on machine vision so as to improve extracting characteristic detection accuracy, thus effectively improving clamping accuracy of defect detection.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a depth learning based machine vision fusion sheet defect detecting method. '(Drawing includes non-English language text)'
DC S03 (Scientific Instrumentation); T01 (Digital Computers)
MC S03-E04F; T01-J10B2
IP G06T-007/00; G06N-003/04; G01N-021/88
PD CN109035232-A   18 Dec 2018   G06T-007/00   201911   Pages: 8   Chinese
AD CN109035232-A    CN10815171    24 Jul 2018
PI CN10815171    24 Jul 2018
UT DIIDW:2018A48344
ER

PT P
PN CN109034386-A
TI Resource scheduler based deep learning system, has deep learning framework for executing learning program, and resource scheduler for allocating environment variable and recycling resource unit, such that deep learning process is completed.
AU WANG J
   LIU F
   WANG Y
   CAO R
   WANG X
AE CHINESE ACAD SCI COMPUTER NETWORK INFORM (CACN-C)
GA 2018A48445
AB    NOVELTY - The system has multiple high performance computing nodes provided with multiple graphics processors. Each graphics processor is provided with a resource scheduler i.e. Slurm resource scheduler and a deep learning framework i.e. TensorFlow (RTM: Open source software library) deep learning framework. The resource scheduler is utilized according to requirement of a user. Multiple resource units are selected from the high performance computing node. The resource scheduler allocates an environment variable to the user. The deep learning framework executes a deep learning program. The resource scheduler recycles an allocated resource unit, such that deep learning process is completed.
   USE - Resource scheduler based deep learning system.
   ADVANTAGE - The system enables realizes centralized management of the deep learning framework, and effectively improves operation efficiency of the deep learning framework.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a resource scheduler based deep learning method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a resource scheduler based deep learning method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J30A; T01-S03
IP G06N-003/08; G06N-003/063
PD CN109034386-A   18 Dec 2018   G06N-003/08   201911   Pages: 9   Chinese
AD CN109034386-A    CN10668856    26 Jun 2018
PI CN10668856    26 Jun 2018
UT DIIDW:2018A48445
ER

PT P
PN CN109033450-A
TI Method for lift equipment fault prediction based on deep learning, involves improving optimization model, lift fault information database updated in real time and real-time updated data entered into model to test accuracy of model.
AU WANG L
   JIANG H
AE UNIV TAIYUAN TECHNOLOGY (UYTL-C)
GA 2018A48686
AB    NOVELTY - The method involves counting the number of lift failures of various types. A sequence of events is constructed. A sequence of data records of lift fault types is arranged in order according to the time of occurrence of the fault. A Long Short Term Memory (LSTM) neural network is constructed. The time series and event sequence is trained using the dual LSTM neural network. The fusion background knowledge representation and historical influence representation is represented through a joint layer joint layer. The neural network model is continuously iteratively trained to get the optimal network model. The type of lift failure and the lift failure time are predicted by the fault type prediction layer and fault time prediction layer. The optimization model is improved. The lift fault information database is updated in real time. The real-time updated data is entered into model to test accuracy of the model. The model is improved based on the actual feedback.
   USE - Method for lift equipment fault prediction based on deep learning.
   ADVANTAGE - The method can assist the lift maintenance personnel to take relevant preventive measures as soon as possible. The occurrence of fault events are avoided.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart illustrating the method for lift equipment fault prediction based on deep learning. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-J05B4M; T01-N01B3A
IP G06F-017/30; G06N-003/04
PD CN109033450-A   18 Dec 2018   G06F-017/30   201911   Pages: 16   Chinese
AD CN109033450-A    CN10962887    22 Aug 2018
PI CN10962887    22 Aug 2018
UT DIIDW:2018A48686
ER

PT P
PN CN109029363-A
TI Deep learning based target distance measuring method, involves performing loss function of target distance model, and carrying out training process of target distance model when target distance model is tested.
AU WEI X
   ZHANG W
   LAN H
   WANG Z
   GUO J
   SUN W
AE QUANZHOU EQUIP MFG INST (QUAN-Non-standard)
GA 2018A55705
AB    NOVELTY - The method involves establishing target database under different distances. Loss function of a target distance model is performed. A training process of the target distance model is carried out when the target distance model is tested. Video information is captured from an appointed camera through a data acquisition source. A data collection object is contained with pedestrian, bicycle, motorcycle, automobile, bus, bird, cat and dog. Boundary frame-type information of a detected target is obtained. Video data is collected from a binocular vision camera.
   USE - Deep learning based target distance measuring method.
   ADVANTAGE - The method enables avoiding target ranging problem into regression problem by using a target detection algorithm model so as to realize better target detection function by a normal monocular camera to obtain target category information and target distance information to acquire depth information of an object and reduce hardware cost in an effective manner.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based target distance measuring method. '(Drawing includes non-English language text)'
DC S02 (Engineering Instrumentation); T01 (Digital Computers)
MC S02-B04; S02-B10; T01-J05B4F; T01-J07D3; T01-J30A
IP G01C-011/00
PD CN109029363-A   18 Dec 2018   G01C-011/00   201911   Pages: 15   Chinese
AD CN109029363-A    CN10562681    04 Jun 2018
PI CN10562681    04 Jun 2018
UT DIIDW:2018A55705
ER

PT P
PN CN109035221-A
TI Image recognition depth learning technology based macrostructure intelligent rating method, involves collecting macrostructure rating image database, and inputting test set for performing material macrostructure intelligent rating test.
AU WU C
   DU S
   WANG H
   LIN F
AE CHENGDU ADVANCED METALLIC MATERIALS IND (ANSH-C)
GA 2018A4834F
AB    NOVELTY - The method involves collecting macrostructure rating image database of different materials. Macro- structure image information is extracted. The macro- structure image information is pre-processed. Training set and validation set are set according to needed proportion. Deep neural network is trained according to the training set and the validation set. Testing of the deep neural network is initialized by using the training model. The test set is inputted for performing material macrostructure intelligent rating test.
   USE - Image recognition depth learning technology based macrostructure intelligent rating method.
DC T01 (Digital Computers)
MC T01-J05B4F; T01-J10B2A; T01-N01B3A
IP G06T-007/00; G06N-003/08
PD CN109035221-A   18 Dec 2018   G06T-007/00   201911   Pages: 8   Chinese
AD CN109035221-A    CN10751664    10 Jul 2018
PI CN10751664    10 Jul 2018
UT DIIDW:2018A4834F
ER

PT P
PN CN109034217-A
TI Image recognition depth learning technology based intelligent grain size evaluating method, involves initializing testing neural network, and inputting testing set into deep neural network for performing grain size evaluating operation.
AU WU C
   WANG H
   DU S
   ZHAO Z
AE CHENGDU ADVANCED METALLIC MATERIALS IND (ANSH-C)
GA 2018A4848M
AB    NOVELTY - The method involves establishing a multi-material grain size rating image database. Grain size image information is extracted. Image pre-processing operation is performed. The multi-material grain size rating image database is divided into a training set, a validation set and a testing set. A deep neural network is trained according to the training set and the validation set. A testing neural network is initialized by utilizing a training model. The testing set is input into the deep neural network for performing grain size evaluating operation.
   USE - Image recognition depth learning technology based intelligent grain size evaluating method.
   ADVANTAGE - The method enables increasing grain size evaluating precision.
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B4F; T01-J10B2A; T01-N01B3A; T04-D04
IP G06K-009/62; G06N-003/04
PD CN109034217-A   18 Dec 2018   G06K-009/62   201911   Pages: 6   Chinese
AD CN109034217-A    CN10751652    10 Jul 2018
PI CN10751652    10 Jul 2018
UT DIIDW:2018A4848M
ER

PT P
PN CN109034007-A
TI Convolutional neural network-based vegetation remote sensing image extraction optimization method, involves processing vegetation area to be extracted from sample block using trained model, and extracting vegetation area from sample block.
AU WU F
   JIANG H
   FU X
AE GEOVIS TECHNOLOGY BEIJING CO LTD (GEOV-Non-standard)
GA 2018A48542
AB    NOVELTY - The method involves selecting a vegetation area of an image for manual annotation so as to identify the type of the image, and marking original data of the image for a cutting block. The edges of the cutting block having less than 512 pixels are discarded, and a VGG16 network model is modified. A training model is utilized for training a sample so as to obtain a trained model. The vegetation area to be extracted from a sample block is processed using the trained model, and the vegetation area is extracted from the sample block.
   USE - Convolutional neural network-based vegetation remote sensing image extraction optimization method.
   ADVANTAGE - The vegetation area to be extracted from the sample block is processed using the trained model, and the vegetation area is extracted from the sample block, thus allowing efficient, accurate and automatic extraction of vegetation area while reducing the manual work.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network-based vegetation remote sensing image extraction optimization method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B2; T01-N01B3
IP G06K-009/00; G06N-003/04; G06N-003/08
PD CN109034007-A   18 Dec 2018   G06K-009/00   201911   Pages: 6   Chinese
AD CN109034007-A    CN10735084    06 Jul 2018
PI CN10735084    06 Jul 2018
UT DIIDW:2018A48542
ER

PT P
PN CN109034449-A
TI Deep learning and passenger behavior patterns based short-term bus passenger flow predicting method, involves extracting influence factors of bus passenger flow, and predicting bus passenger flow by using depth learning model.
AU WU W
   ZHOU W
   JIN W
   REN J
AE UNIV SOUTH CHINA TECHNOLOGY (UYSC-C)
GA 2018A4842N
AB    NOVELTY - The method involves recognizing and extracting influence factors of a bus passenger flow. Trip time, peak time, weather condition and day index of the bus passenger flow are selected as external factors. An IC card type is selected according to discrete index. Internal factors and external factors of a bus passenger are analyzed. Flow matrix is subdivided to re-construct a bus passenger flow data structure for an input sample. A historical passenger flow and the bus passenger flow of the external factors and the internal factors are obtained. The bus passenger flow is predicted by using a depth learning model.
   USE - Deep learning and passenger behavior patterns based short-term bus passenger flow predicting method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a deep learning and passenger behavior patterns based short-term bus passenger flow. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J04C; T01-J05A2; T01-J05B2B; T01-J30A; W04-W05A
IP G06Q-010/04; G06Q-050/30; G06F-017/16
PD CN109034449-A   18 Dec 2018   G06Q-010/04   201911   Pages: 44   Chinese
AD CN109034449-A    CN10614511    14 Jun 2018
PI CN10614511    14 Jun 2018
UT DIIDW:2018A4842N
ER

PT P
PN CN109034448-A
TI Semantic analysis and deep belief network based vehicle track prediction method, involves obtaining regression prediction result by utilizing extracted user track characteristic, and performing weight clustering process to optimize results.
AU XIAO Y
   ZHU Y
   DAI T
   WU X
   ZHU M
   CHENG C
AE UNIV CHONGQING POSTS & TELECOM (UCPT-C)
GA 2018A4842P
AB    NOVELTY - The method involves obtaining a data source. Number original information of a vehicle, a bayonet code and attribute of vehicle track information are obtained. Relevance between words is analyzed in sentence. A card language material library is established by using a sliding window. Data analysis process is performed by a deep belief network (DBN). A regression prediction model is established based on user track characteristic. A linear regression prediction result is obtained by utilizing the extracted user track characteristic. Weight clustering process is performed to optimize results.
   USE - Semantic analysis and DBN based vehicle track prediction method.
   ADVANTAGE - The method enables effectively improving a complex road network relation of actual traffic environment so as to improve trajectory prediction negative effect and prediction efficiency.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a semantic analysis and DBN based vehicle track prediction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J03; T01-J05B3; T01-J07D1; T01-J16C3; T01-N01A2; T01-N03A2
IP G06Q-010/04; G06Q-050/26; G06F-017/18; G08G-001/01
PD CN109034448-A   18 Dec 2018   G06Q-010/04   201911   Pages: 13   Chinese
AD CN109034448-A    CN10613127    14 Jun 2018
PI CN10613127    14 Jun 2018
UT DIIDW:2018A4842P
ER

PT P
PN CN109034215-A
TI Deep convolutional neural network-based safety helmet wear detecting method, involves determining size and category confidence score of bounding box where head of person who does not wear safety cap is located.
AU XIE L
   ZHANG G
   HUANG S
   WANG L
   DENG Q
AE UNIV CHINESE NORTHEASTERN (UYDB-C)
GA 2018A4848P
AB    NOVELTY - The method involves training a deep convolutional neural network with a training sample image (100). A to-be-detected image is input (101) to the trained convolutional neural network, where the trained deep convolutional neural network includes a basic network module, a convolution module, a top-down module and a prediction module. A detection result of the deep convolutional neural network is output (102). A bounding box satisfying preset condition is placed (103) on the to-be-detected image. Size and category confidence score of the bounding box is determined where a head of a person who does not wear a safety cap is located. Alarm message is sent (104) if the detection result includes type of bounding boxes satisfying the preset condition.
   USE - Deep convolutional neural network-based safety helmet wear detecting method.
   ADVANTAGE - The method enables accurately detecting whether the person wearing the helmet, improving detection performance of target image resolution by fusing a high layer characteristic pattern and a low level characteristic image.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep convolutional neural network-based safety helmet wear detecting method. '(Drawing includes non-English language text)'
   Step for training deep convolutional neural network (100)
   Step for inputting to-be-detected image to trained convolutional neural network (101)
   Step for outputting detection result of deep convolutional neural network (102)
   Step for placing bounding box satisfying preset condition on to-be-detected image (103)
   Step for sending alarm message (104)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J10B1; T01-J10B2; T01-J10D; T01-N01B3; T04-D04
IP G06K-009/62; G06N-003/04; G06N-003/08
PD CN109034215-A   18 Dec 2018   G06K-009/62   201911   Pages: 22   Chinese
AD CN109034215-A    CN10746776    09 Jul 2018
PI CN10746776    09 Jul 2018
UT DIIDW:2018A4848P
ER

PT P
PN CN109035146-A
TI Deep learning based low-quality image resolution detecting method, involves processing characteristics of high-resolution image by using reconstruction network to reconstruct high resolution image and restore information in original image.
AU YAN B
   MA C
   BARE B
AE UNIV FUDAN (UYFU-C)
GA 2018A4836A
AB    NOVELTY - The method involves extracting interference information characteristics in an image. One-dimensional noise variances are input to a characteristics extracting network. Interference information in the image is generated. Blur and noise characteristics in a fusion image are detected. A low resolution image is input to a characteristic converged network during dimension reduction process for learning characteristics of the image. Characteristics of a high-resolution image are processed by using an image reconstruction network to reconstruct the high resolution image and restore edge texture detail information in an original image.
   USE - Deep learning based low-quality image resolution detecting method.
   ADVANTAGE - The method enables utilizing information of the low-resolution image to reinforce supramolecular effect of an interference image, realizing image resolution detecting function in ideal conditions by using an experiment result, obtaining the low-resolution image from real conditions of the interference image by using unknown processes so as to generate a high resolution image in accordance with subjective visual quality.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of a decoder structure. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B3A; T01-J10D; T01-N01B3
IP G06T-003/40; G06N-003/04
PD CN109035146-A   18 Dec 2018   G06T-003/40   201911   Pages: 9   Chinese
AD CN109035146-A    CN10901714    09 Aug 2018
PI CN10901714    09 Aug 2018
UT DIIDW:2018A4836A
ER

PT P
PN CN109034248-A
TI Depth learning based noisy tag image classifying method, involves re-dividing baseline data set to obtain taxonomy dataset data, and training final classification model, and classifying noise label image according to classification model.
AU YANG G
   QIN X
   HE Y
   CHEN X
   CHEN H
   LU P
AE UNIV ELECTRONIC SCI & TECHNOLOGY (UEST-C)
GA 2018A4847Q
AB    NOVELTY - The method involves performing data purification on a semantic metadata set and an image data set to obtain a baseline data set. A word vector and an image vector are obtained. The baseline data set is trained based on a baseline model. Characteristic information of the baseline data set is extracted by the trained baseline model. Clustering is performed on the characteristic information by a hierarchical clustering to obtain a current data type. The baseline data set is re-divided based on the current data set to obtain a taxonomy dataset data. A final classification model is trained. A noise label image is classified according to the final classification model.
   USE - Depth learning based noisy tag image classifying method.
   ADVANTAGE - The method enables avoiding problem in applying to large data sets.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic illustration of a depth learning based noisy tag image classifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W04 (Audio/Video Recording and Systems)
MC T01-J05B2C; T01-J05B3; T01-J05B4F; T01-J10B2; T01-J16C3; T01-J30A; T04-D03A; T04-D04; T04-D07B1; T04-K03B; W04-W05A
IP G06K-009/62
PD CN109034248-A   18 Dec 2018   G06K-009/62   201911   Pages: 10   Chinese
AD CN109034248-A    CN10846627    27 Jul 2018
PI CN10846627    27 Jul 2018
UT DIIDW:2018A4847Q
ER

PT P
PN CN109034396-A
TI Method for processing advanced learning operation in distributed cluster by utilizing electronic device, involves performing deep learning training operation by cluster manager, and obtaining result of deep learning training operation.
AU YANG J
AE BEIJING BAIDU NETCOM SCI & TECHNOLOGY CO (BIDU-C)
GA 2018A4843W
AB    NOVELTY - The method involves determining whether current resource allowance satisfies resource requirement of deep learning training operation or not. The deep learning training operation is added to job queue corresponding to tenant group. The deep learning training operation is submitted to a cluster manager by using a cluster manager adapter corresponding to priority of job in the job queue. The deep learning training operation is performed by the cluster manager corresponding to managed distributed computing node. Result of the deep learning training operation is obtained.
   USE - Method for processing advanced learning operation in a distributed cluster by utilizing an electronic device (claimed).
   ADVANTAGE - The method enables improving processing efficiency of the deep learning training operation.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for processing advanced learning operation in a distributed cluster by using an electronic device
   (2) a computer readable storage medium for storing a set of instructions for processing advanced learning operation in a distributed cluster by utilizing an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for processing advanced learning operation in a distributed cluster by utilizing an electronic device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J05A2; T01-J30A; W04-W05A
IP G06N-099/00; G06Q-010/06; G06Q-030/06
PD CN109034396-A   18 Dec 2018   G06N-099/00   201911   Pages: 22   Chinese
AD CN109034396-A    CN10759278    11 Jul 2018
PI CN10759278    11 Jul 2018
UT DIIDW:2018A4843W
ER

PT P
PN CN109035171-A
TI Human face image restoration method, involves performing face image restoration process to obtain face symmetry axis, obtaining face image by reticulate pattern, and checking whether distance between left and right axis is in coverage area.
AU ZHANG D
   NI P
AE UNIV CHINA JILIANG (UYJA-C)
GA 2018A4835Q
AB    NOVELTY - The method involves extracting multiple key points by machine learning algorithm. Position information of the key point is output. Key point fitting process is performed. Spatial information of an original input image is obtained. A reticulate face image is divided into a background image by utilizing a deep neural network. A consecutive distance measurement value is counted. Face image restoration process is performed to obtain a face symmetry axis. The face image is obtained by a reticulate pattern. Judgment is made to check whether distance between left and right axis is in a textured coverage area.
   USE - Human face image restoration method.
   ADVANTAGE - The method enables inputting mesh face image, outputting a reticulate pattern of a clear human face image and improving visual effect of the image and reticulate face image identification accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a deep neural network. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B1; T01-J10B2; T01-J16C2; T04-D07F1
IP G06T-005/00; G06K-009/00; G06T-007/68; G06T-007/194
PD CN109035171-A   18 Dec 2018   G06T-005/00   201911   Pages: 12   Chinese
AD CN109035171-A    CN10867459    01 Aug 2018
PI CN10867459    01 Aug 2018
UT DIIDW:2018A4835Q
ER

PT P
PN CN109031472-A
TI Method for processing weather prediction data by interactive device, involves determining weather data associated with forecasting site, and performing deep learning training on weather data associated with site to obtain forecasting model.
AU ZHANG K
   CHU W
   SHI X
AE ALIBABA GROUP HOLDING LTD (ABAB-C)
GA 2018A4914S
AB    NOVELTY - The method involves determining multiple weather observation areas are associated with a forecast site according to set area division process. Weather data associated with the forecasting site is determined, where the weather data comprises meteorological observation features in multiple weather observation regions associated with the forecasting site at different observation times. Deep learning training is performed on the weather data associated with the forecasting site to obtain a weather forecasting model. A target observation characteristic and a related observation characteristic are determined.
   USE - Method for processing weather prediction data by an interactive device (claimed).
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for processing weather prediction data by an interactive
   (2) a method for providing interaction interface
   (3) a machine readable medium for storing a set of instructions for processing weather prediction data by an interactive.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for processing weather prediction data by an interactive device. '(Drawing includes non-English language text)'
DC S03 (Scientific Instrumentation); T01 (Digital Computers)
MC S03-D05; T01-J30A; T01-S03
IP G01W-001/10; G06N-003/04; G06N-003/08
PD CN109031472-A   18 Dec 2018   G01W-001/10   201911   Pages: 25   Chinese
AD CN109031472-A    CN10431354    09 Jun 2017
PI CN10431354    09 Jun 2017
UT DIIDW:2018A4914S
ER

PT P
PN CN109033433-A
TI Method for classifying emotion data of comment data based on convolutional neural network, involves using trained sentiment classification model, and subjecting classified review data to sentiment classification.
AU ZHENG K
   YAO H
   LI R
   LIU C
   DONG L
   KANG X
AE UNIV CHINA GEOSCIENCES WUHAN (UYCI-C)
GA 2018A4868L
AB    NOVELTY - The method involves obtaining (S1) a comment data set for training. The comment data set is preprocessed (S2), and the useless information is filtered out. The comment data set is processed (S3). The emotional keyword is extracted and background knowledge corresponding to the emotional keyword is obtained. A vector generation model is used (S4), a vector is generated for each of the emotional keyword and the background knowledge corresponding to each comment. The vector of the keyword is spliced (S5) to form a two-dimensional matrix of keywords. The keyword two-dimensional matrix of each comment and the background knowledge two-dimensional matrix are respectively spliced (S6) into a multi-channel two-dimensional matrix. An emotional classification model training is performed (S7). The trained sentiment classification model is used (S8), and the classified review data is subjected to sentiment classification.
   USE - Method for classifying emotion data of comment data based on convolutional neural network.
   ADVANTAGE - The accuracy of the emotional classification of the film evaluation data can be improved.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a review data sentiment classification system based on convolutional neural network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for classifying emotion data of comment data. (Drawing includes non-English language text)
   Step for obtaining a comment data set for training (S1)
   Step for preprocessing the comment data set (S2)
   Step for processing the comment data set (S3)
   Step for using a vector generation model (S4)
   Step for splicing vector of the keyword (S5)
   Step for respectively splicing the keyword two-dimensional matrix of each comment and the background knowledge two-dimensional matrix into a multi-channel two-dimensional matrix (S6)
   Step for performing an emotional classification model training (S7)
   Step for using trained sentiment classification model, and subjecting classified review data to sentiment classification (S8)
DC T01 (Digital Computers)
MC T01-J05B2; T01-J05B4P; T01-J11A1; T01-N01B3
IP G06F-017/30; G06F-017/27; G06N-003/04
PD CN109033433-A   18 Dec 2018   G06F-017/30   201911   Pages: 15   Chinese
AD CN109033433-A    CN10918698    13 Aug 2018
PI CN10918698    13 Aug 2018
UT DIIDW:2018A4868L
ER

PT P
PN CN109034127-A
TI Method for detecting spectral abnormality by utilizing electronic device, involves obtaining to-be-detected spectrum data, and judging whether to-be-detected spectrum data is abnormal according to calculated prediction error.
AU ZHOU H
   ZHENG S
   YANG X
AE CHINA ELECTRONICS TECHNOLOGY GROUP CORP (CETC-C)
GA 2018A4850W
AB    NOVELTY - The method involves obtaining sequence data and dividing obtained sequence data into a training set and a testing set. A wavelet convolution neural network is trained by using input samples in the training set, where the input detection samples in the test set are used to determine abnormal detection threshold associated with error distribution. To-be-detected spectrum data is obtained and input into the wavelet convolutional neural network to obtain a prediction result for calculating prediction error. Judgment is made to check whether the to-be-detected spectrum data is abnormal according to the calculated prediction error.
   USE - Method for detecting spectral abnormality by utilizing an electronic device (claimed).
   ADVANTAGE - The method enables utilizing wavelet transform and a convolutional neural network to reduce computational complexity, avoiding noise interference during spectrum anomaly detection process, and improving spectrum anomaly detection accuracy.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a device for detecting spectral abnormality by utilizing an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for detecting spectral abnormality by utilizing an electronic device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B1; T01-J04B2; T01-J10B2; T01-N01B3A; T01-N01D
IP G06K-009/00; G06N-003/04
PD CN109034127-A   18 Dec 2018   G06K-009/00   201911   Pages: 15   Chinese
AD CN109034127-A    CN11011051    31 Aug 2018
PI CN11011051    31 Aug 2018
UT DIIDW:2018A4850W
ER

PT P
PN CN109033995-A
TI Method for identifying user behavior, involves identifying user behavior category corresponding to original data according to filter parameters in convolutional neural network model.
AU ZHOU S
   GONG Y
   LI J
AE CHUMENWENWEN INFORMATION TECHNOLOGY CO (CHUM-Non-standard)
GA 2018A5554P
AB    NOVELTY - The method involves obtaining (101) an original data corresponding to user behavior. A convolutional neural network model is paired based on tagged data of a user behavior category. The raw data is inputted (102) to the convolutional neural network model. A user behavior category corresponding to the original data is identified according to filter parameters in the convolutional neural network model. The original data of a known user behavior category is marked. The descriptive data is obtained. The feature data in the tag data is extracted.
   USE - Method for identifying user behavior by intelligent wearable device e.g. smart watch.
   ADVANTAGE - The method of user behavior recognition is optimized by using primitive sensor data. The use of convolutional neural network models to identify user behavior is added, which reduces errors in identifying user behavior and can identify more complex user behaviors.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) an apparatus for identifying the user behavior; and
   (2) a non-transitory computer readable storage medium storing program for identifying user behavior.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart illustrating the method for identifying user behavior. (Drawing includes non-English language text)
   Step for obtaining the original data corresponding to user behavior (101)
   Step for inputting the raw data to the convolutional neural network model (102)
DC T01 (Digital Computers)
MC T01-J10B2A
IP G06K-009/00; G06N-003/04; G06N-003/08
PD CN109033995-A   18 Dec 2018   G06K-009/00   201911   Pages: 15   Chinese
AD CN109033995-A    CN10718089    29 Jun 2018
PI CN10718089    29 Jun 2018
UT DIIDW:2018A5554P
ER

PT P
PN CN109002885-A
TI Convolutional neural network pool unit, has pooled result output module for outputting each processed feature map through output channel corresponding to image source of feature map according to mapping relationship.
AU NIE L
   JIANG K
   WANG Z
AE JINAN INSPUR HIGH & NEW TECHNOLOGY INVES (INEI-C)
GA 2018A3446W
AB    NOVELTY - The unit has a pooled resource pool module provided with a mapping logic unit, a control logic unit and a pool calculation logic unit. An input module converts an externally input pool parameter to the mapping logic unit. The mapping logic unit maintains a mapping relationship between a feature map source and an input channel. A pool calculation unit performs pooling calculation processing on each feature map in a pool calculation logic group. A pooled result output module outputs each processed feature map through an output channel corresponding to an image source of a feature map according to the mapping relationship.
   USE - Convolutional neural network pool unit.
   ADVANTAGE - The unit independently designs and configures different pool parameter to re-definition function, and improves universality of the pool unit main body.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a convolutional neural network pool unit based pooling calculation method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a convolutional neural network pool unit. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J16C1
IP G06N-003/04
PD CN109002885-A   14 Dec 2018   G06N-003/04   201911   Pages: 12   Chinese
AD CN109002885-A    CN10818971    24 Jul 2018
PI CN10818971    24 Jul 2018
UT DIIDW:2018A3446W
ER

PT P
PN CN108937954-A
TI Method for monitoring continuous blood glucose, involves utilizing continuous blood glucose monitor blood glucose monitoring technology, and taking comparison result as sample, followed by performing continuous blood glucose monitoring.
AU XIE X
   WU J
   LIU C
   CHEN H
   HANG T
   HONG S
   CAI X
   XIAO S
   LIN D
   YANG C
   GU M
AE UNIV SUN YAT-SEN (UYSY-C)
GA 2018A07574
AB    NOVELTY - A continuous blood glucose monitoring method involves utilizing a continuous blood glucose monitor blood glucose monitoring technology to collect inaccurate blood glucose values ??from a single patient for period of time, measuring an accurate blood sugar level by performing a blood glucose monitoring method for multiple fingertip blood collection, performing blood glucose data collection on a large number of patients, taking the comparison result as sample, and subjecting the data to deep artificial learning correction, using an artificial intelligence automatic encoder technology by using the data collected by the sustainable blood glucose meter, training multi-layer neural network method, and using training result to correct the data measured by the sustainable blood glucose monitor, and performing continuous blood glucose monitoring, and correcting recorded blood glucose value using a numerical correction method by artificial intelligence training.
   USE - Method for monitoring continuous blood glucose.
   ADVANTAGE - The method enables monitoring continuous blood glucose in accurate and reliable manner.
   DETAILED DESCRIPTION - A continuous blood glucose monitoring method involves utilizing a continuous blood glucose monitor blood glucose monitoring technology to collect inaccurate blood glucose values ??from a single patient for period of time, measuring an accurate blood sugar level by performing a blood glucose monitoring method for multiple fingertip blood collection, correcting the blood glucose level measured by the continuous blood glucose monitor with the accurate blood glucose level, performing blood glucose data collection on a large number of patients, comparing the data of the continuous blood glucose monitoring of a large number of patients collected with the corrected results, taking the comparison result as sample, and subjecting the data to deep artificial learning correction, using an artificial intelligence automatic encoder technology by using the data collected by the sustainable blood glucose meter, deep learning, training multi-layer neural network method to obtain the training result, and using training result to correct the data measured by the sustainable blood glucose monitor, identifying continuous glucose monitor data front the patient and rule and correcting mode difference of the corrected result, preparing a blood glucose value by using continuous glucose monitoring technology and actual blood glucose level, and classifying the numerical difference pattern recognized by the artificial intelligence method into the blood glucose correction mode, after completing an artificial intelligence training, performing continuous blood glucose monitoring, and correcting recorded blood glucose value using a numerical correction method by artificial intelligence training.
DC B04 (Natural products and polymers. Including testing of body fluids (other than blood typing or cell counting), pharmaceuticals or veterinary compounds of unknown structure, testing of microorganisms for pathogenicity, testing of chemicals for mutagenicity or human toxicity and fermentative production of DNA or RNA. General compositions.); P31 (Diagnosis, surgery (A61B).); T01 (Digital Computers)
MC B04-B04D5; B11-C08; B11-C11; B12-K04G; T01-J06A
IP A61B-005/145; G06N-099/00
PD CN108937954-A   07 Dec 2018   A61B-005/145   201911   Pages: 8   Chinese
AD CN108937954-A    CN10370218    23 May 2017
PI CN10370218    23 May 2017
UT DIIDW:2018A07574
ER

PT P
PN CN106778682-A
TI Convolutional neural network model training method, involves evaluating cross entropy function according to human face image attribute judging result, and updating convolutional neural network model weighting parameter.
AU CHEN S
   YANG Q
AE XIAMEN ZHONGKONG BIOLOGICAL RECOGNITION (XIAM-Non-standard)
GA 201738608N
AB    NOVELTY - The method involves obtaining a human face image for obtaining human face image attribute judging result. A cross entropy function is evaluated according to the human face image attribute judging result. Convolutional neural network model weighting parameter is updated based on the attribute judging result. Alignment data of the human face image is obtained. Human face image quantizing process is performed. An image sheet of the convolutional neural network model is determined. Length of a pooling layer of the convolutional neural network model is determined.
   USE - Convolutional neural network model training method.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a convolutional neural network model training device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network model training method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-N01B3; T04-D04; T04-D07D3; T04-D07F1
IP G06K-009/00; G06K-009/62; G06N-003/04
PD CN106778682-A   31 May 2017   G06K-009/00   201749   Pages: 16   Chinese
AD CN106778682-A    CN10021101    11 Jan 2017
PI CN10021101    11 Jan 2017
CP CN106778682-A
      CN104850890-A   UNIV XIDIAN (UYXN)   FANG M, LUO X, PAN R, WANG Y, XIE K, TIAN Y, ZHENG H, LIU T
      CN105474234-A   XIAMEN ZKTECO INFORMATION TECHNOLOGY CO (XIAM-Non-standard)   CHEN S, CHE Q
      CN105631479-A   CHINESE ACAD SCI AUTOMATION INST (CAZD)   YANG Y, ZHANG W
      US20140288928-A1      
UT DIIDW:201738608N
ER

PT P
PN CN109034160-A
TI Convolutional neural network based digital instrument decimal point automatically identifying method, involves splicing LED character and decimal point convolutional neural network model recognition results.
AU CHEN Z
   WANG W
   GENG P
   MA W
AE JIANGSU DILUN INTELLIGENT TECHNOLOGY CO (JIAN-Non-standard)
GA 2018A48505
AB    NOVELTY - The method involves encapsulating decimal point sample pictures, where the decimal point sample pictures are divided into training and testing data packets for performing decimal point convolutional neural network model training test. A LED character convolutional neural network model is established after preprocessing a to-be-identified image by using a trained network model. Nine regions are input into the decimal point convolutional neural network model. A position of a decimal point is determined based on order of the decimal point to detect decimal point recognition success rate. LED character convolutional neural network model and decimal point convolutional neural network model recognition results are spliced.
   USE - Convolutional neural network based digital instrument decimal point automatically identifying method.
   ADVANTAGE - The method enables scaling a LED character image and the decimal point to perform region segmentation process and send the LED character image into a network model and converting regression positioning problem into classification problem so as to prevent LED character convolutional neural network model and decimal point convolutional neural network model recognition results from being interfered with each other and realize flexible network debugging process.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network based digital instrument decimal point automatically identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-J05B2; T01-J10B2A; T01-N01B3A; W01-A03B; W01-A06F7C; W01-A06G2
IP G06K-009/34; G06K-009/62; G06N-003/04
PD CN109034160-A   18 Dec 2018   G06K-009/34   201910   Pages: 11   Chinese
AD CN109034160-A    CN10734321    06 Jul 2018
PI CN10734321    06 Jul 2018
CP CN109034160-A
      CN101030258-A   UNIV ZHEJIANG TECHNOLOGY (UYZT)   SUI C, TANG Y, TONG J, WEI G, WANG T, LI D
      CN101079108-A   UNIV ZHEJIANG TECHNOLOGY (UYZT)   SUI C, TANG Y, TONG J, WEI G, WANG T, LI D
      CN105654130-A   CHENGDU BRAND BIG DATA TECHNOLOGY CO LTD (CHEN-Non-standard)   LIU S, YAO J, HE H, CHEN B, WU Y
      CN105809179-A   SHENZHEN INST ADVANCED TECHNOLOGY (CAAT)   GUO S, QIAO Y, YANG Z
      CN106529537-A   YIJIAHE TECHNOLOGY CO LTD (YIJI-Non-standard)   GE C, WANG F, LIN H, CHENG M, ZHAO W, QIU X, XU C
      CN106960208-A   HARBIN INST TECHNOLOGY (HAIT)   SU T, ZHOU S, ZHOU J, ZHOU T, LIU C
      CN108133216-A   WUHAN ZHONGYUANHUADIAN TECHNOLOGY CO LTD (WUHA-Non-standard)   CHEN L, MA L, CHENG L, FENG W, CAO H, MA J, ZHANG G
      US20090060396-A1      
CR CN109034160-A
      : "LED", ,relevantClaims[1-6],relevantPassages[38-41]
      : "", ,relevantClaims[1-6],relevantPassages[214-217]
UT DIIDW:2018A48505
ER

PT P
PN CN109034070-A
TI Method for blindly separating replacement aliasing image, involves subjecting optimized image characteristic map to point multiplication operation with replacement alias image to be detected to obtain image separating effect.
AU DUAN X
   LI F
   LIU Y
AE UNIV HENAN NORMAL (UYNR-C)
GA 2018A4852B
AB    NOVELTY - The method involves converting noisy permutation alias image of two known permutation area positions into an image. A noise-containing permutation area in the noisy permutation alias image of the known permutation region position is defined. A convolutional neural network is constructed. Two train values are input into a convolutional neural network for training to obtain the trained convolutional neural network. A permuted alias image to be detected is pre-processed. The permuted alias image is input into the trained convolutional neural network to obtain an image characteristic map. The image characteristic map is optimized. The optimized image characteristic map is subjected to point multiplication operation with a replacement alias image to be detected to obtain image separating effect.
   USE - Method for blindly separating a replacement aliasing image.
   ADVANTAGE - The method enables automatically extracting features of the replacement alias image by adopting the convolutional neural network so as to ensure stable extracted features, thus avoiding affect of human factors, and improving accuracy of image separation and simplifying separation process and improving separation speed.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a device for blindly separating a replacement aliasing image.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a device for blindly separating a replacement aliasing image. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E02B; T01-E04; T01-J03; T01-J10B1; T01-J10B2; T01-N01B3; T04-D04
IP G06K-009/00; G06K-009/62; G06N-003/04; G06N-003/08
PD CN109034070-A   18 Dec 2018   G06K-009/00   201910   Pages: 21   Chinese
AD CN109034070-A    CN10848315    27 Jul 2018
PI CN10848315    27 Jul 2018
UT DIIDW:2018A4852B
ER

PT P
PN CN109034155-A
TI Character detecting and identifying method, involves determining data set, where data set comprises character picture and character area position, and obtaining character information based on corrected character area picture.
AU FANG P
   XIA Y
   LV C
AE BAIZHUO NETWORK TECHNOLOGY CO LTD (BAIZ-Non-standard)
GA 2018A48508
AB    NOVELTY - The method involves determining a data set, where the data set comprises a character picture and a character area position. Manual annotation data is obtained. A training text region detection model is established by using a deep neural network. Text information is obtained according to a character area picture. A deep neural network training character recognition model is established. Character information is outputted. A corrected character area picture is obtained. Character information is obtained based on the corrected character area picture.
   USE - Character detecting and identifying method.
   ADVANTAGE - The method enables achieving automatic recognition and recording working, and greatly reducing labor cost.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a character detecting and identifying system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a character detecting and identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B2A; T01-N01B3
IP G06K-009/32; G06N-003/04; G06N-003/08
PD CN109034155-A   18 Dec 2018   G06K-009/32   201910   Pages: 9   Chinese
AD CN109034155-A    CN10818780    24 Jul 2018
PI CN10818780    24 Jul 2018
UT DIIDW:2018A48508
ER

PT P
PN CN109034050-A
TI Deep learning based identity card image text identifying method, involves selecting first image in target field as second image, inputting second image into model, and performing target field identifying function on second image.
AU FENG H
   PIAO A
   ZHANG Y
AE SF TECHNOLOGY CO LTD (SFTE-Non-standard)
GA 2018A4852V
AB    NOVELTY - The method involves performing image pre-processing function on a first image. The pre-processed first image is input into a first model. Target field detection function is performed on the first image by using the first model. Position information of the target field in the first image is obtained. The first image in the target field is selected as a second image according to the position information of the target field. The second image is input into a second model. Target field identifying function is performed on the second image to obtain text information of the target field in the second image.
   USE - Deep learning based identity card image text identifying method.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based identity card image text identifying device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based identity card image text identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J10B2; T01-J30A; W04-W05A
IP G06K-009/00; G06K-009/20
PD CN109034050-A   18 Dec 2018   G06K-009/00   201910   Pages: 10   Chinese
AD CN109034050-A    CN10813704    23 Jul 2018
PI CN10813704    23 Jul 2018
UT DIIDW:2018A4852V
ER

PT P
PN CN109036468-A
TI Method for identifying voice emotion e.g. angry, happy, timid or surprisingly of human, involves obtaining final human emotion identification result by using majority voting priority principle of six nucleic-PSVM classifiers.
AU HAN Z
   WANG J
   ZHANG L
   WANG D
   YANG Y
   WEI H
   ZHAO D
AE UNIV BOGHAI (UYBO-C)
GA 2018A4804V
AB    NOVELTY - The method involves obtaining an emotion signal. A voice signal in a corresponding emotion state is extracted. Pre-processing function is performed on the emotion signal, where the pre-processing function includes pre-emphasis, sub-frame windowing and endpoint detection function. A human emotion characteristic parameter is extracted. A voice emotion characteristic parameter is extracted from a pre-processed voice signal. The human emotion characteristic parameter is combined with the voice emotion characteristic parameter by using a deep belief network to obtain an integrated characteristic vector. A final human emotion identification result is obtained by using majority voting priority principle of six nucleic-PSVM classifiers.
   USE - Method for identifying voice emotion e.g. angry, happy, timid or surprisingly of human (all claimed) based on deep belief network and nuclear-PSVM.
   ADVANTAGE - The method enables realizing angry, happy, timid and surprisingly human basic emotion identification function, utilizing deep learning algorithm and a PSVM classifier, so that emotion information identification process can be detected closed to human emotion identification process, thus improving human emotion identification accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for identifying voice emotion of human based on deep belief network and nuclear-PSVM. '(Drawing includes non-English language text)'
DC W04 (Audio/Video Recording and Systems)
MC W04-V01; W04-V04A4; W04-V05
IP G10L-025/63; G10L-025/27; G10L-025/30; G10L-025/45; G10L-015/04; G10L-015/08
PD CN109036468-A   18 Dec 2018   G10L-025/63   201910   Pages: 10   Chinese
AD CN109036468-A    CN11311528    06 Nov 2018
PI CN11311528    06 Nov 2018
UT DIIDW:2018A4804V
ER

PT P
PN CN109034202-A
TI Deep belief network based avionic system mode identifying method, involves performing pattern recognition process on avionics operating data by using DBNC model, and reducing error of DBNC model based on pattern recognition.
AU HONG S
   SUN L
   LI H
   LUO M
AE UNIV BEIHANG (UNBA-C)
GA 2018A48492
AB    NOVELTY - The method involves establishing a DBNC model for setting model parameter initialization. A typical failure mode is selected to obtain historical fault data for the DBNC model from an avionic system. Connection weights and a node bias condition are optimized in the DBNC model through an artificial fish-swarm optimization mode. A training result of the DBNC model is evaluated, where a learning condition of the DBNC model is determined. Pattern recognition process is performed on avionics operating data by using the DBNC model. Error of the DBNC model is reduced based on pattern recognition.
   USE - Deep belief network based avionic system mode identifying method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep belief network based avionic system mode identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E01B; T01-J10B2A; T01-N01B3
IP G06K-009/62; G06N-003/00
PD CN109034202-A   18 Dec 2018   G06K-009/62   201910   Pages: 14   Chinese
AD CN109034202-A    CN10693984    29 Jun 2018
PI CN10693984    29 Jun 2018
UT DIIDW:2018A48492
ER

PT P
PN CN109035284-A
TI Deep learning based cardiac CT image segmentation method, involves performing image segmentation process on preset tissue region by pre-trained V-Net model to obtain segmentation image of tissue region corresponding to cardiac CT image.
AU HU Z
   MA H
   WU Y
   LIANG D
   YANG Y
   LIU X
   ZHENG H
AE SHENZHEN INST ADVANCED TECHNOLOGY (CAAT-C)
GA 2018A4832U
AB    NOVELTY - The method involves obtaining a user input cardiac CT image when a heart CT image segmentation request is received. The cardiac CT image is pre-processed to obtain a corresponding pre-processed image. Image segmentation process is performed on a preset tissue region by a pre-trained V-Net model to obtain a segmentation image of a cardiac tissue region corresponding to the cardiac CT image. The V- Net model is provided with a convolution kernel, an input layer, a compression layer and an output layer, where step length of the input layer is 1 and the output layer is 2.
   USE - Deep learning based cardiac CT image segmentation method.
   ADVANTAGE - The method enables improving image segmentation accuracy so as to obtain a segmented image with high precision so that safety operation is improved.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a deep learning based cardiac CT image segmentation device
   (2) a computer-readable storage medium for storing a set of instructions for segmenting cardiac CT image based on deep learning.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based cardiac ct image segmentation method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J05B2A; T01-J10B1; T01-J10B2; T01-J15X; T01-J30A; T01-S03
IP G06T-007/174
PD CN109035284-A   18 Dec 2018   G06T-007/174   201910   Pages: 11   Chinese
AD CN109035284-A    CN10685558    28 Jun 2018
PI CN10685558    28 Jun 2018
UT DIIDW:2018A4832U
ER

PT P
PN CN109034490-A
TI Method for predicting electric load, involves obtaining power load prediction result by deep learning method based on current power load data after normalization process and historical power load data.
AU HUANG S
   YIN H
   MENG A
   LIU Z
AE UNIV GUANGDONG TECHNOLOGY (UGTE-C)
GA 2018A4950J
AB    NOVELTY - The method involves acquiring (Step S1) current electric load data and historical electric load data. The current power load data and the historical power load data are normalized (Step S2). The power load prediction result is obtained (Step S3) by the deep learning method based on the current power load data after the normalization process and the historical power load data.
   USE - Method for predicting electric load.
   ADVANTAGE - The depth learning method is used to process the normalized current power load data and the historical power load data, and the power load prediction result is smoothly obtained, and considers the influence of the historical power load data on the future power load data, and the obtained power load. The prediction results are more accurate and can guide the power supply well, and there is no shortage of power supply or excessive power waste.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) a device for predicting power load;
   (2) a power load forecasting device; and
   (3) a computer-readable storage medium storing program for predicting electric load.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the process for predicting an electric load. (Drawing includes non-English language text)
   Step for acquiring current electric load data and historical electric load data acquiring current electric load data and historical electric load data (Step S1)
   Step for normalizing the current power load data and the historical power load data (Step S2)
   Step for obtaining power load prediction result by deep learning method based on current power load data after normalization process and historical power load data (Step S3)
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-D03; T01-J05A2A; T01-J05A2C; T01-J30A; T01-S03; W04-W05A
IP G06Q-010/04; G06Q-050/06
PD CN109034490-A   18 Dec 2018   G06Q-010/04   201910   Pages: 13   Chinese
AD CN109034490-A    CN10916228    13 Aug 2018
PI CN10916228    13 Aug 2018
UT DIIDW:2018A4950J
ER

PT P
PN CN109034204-A
TI Convolutional neural network based welding seam fault identifying method, involves training defect neural network by defining cost function, and sending to-be-identified welding seam image to neural network to identify type of defect.
AU JIANG H
   GAO J
   WANG X
   WANG Q
   XIA F
   HE S
   CHENG L
   LI H
   CHANG Y
AE UNIV XIAN JIAOTONG (UYXJ-C)
GA 2018A48490
AB    NOVELTY - The method involves establishing a pooling model, where the pooling model includes distribution of pool domain and characteristic of characteristic map. Maximum pool characteristic is determined corresponding to correction factor of a welding seam. A ReliefF algorithm is combined with a neural network as feature selection process for constructing a deep neural network with the feature selection process. A welding seam defect identification neural network is trained by defining cost function. To-be-identified welding seam image is sent to the trained deep neural network to identify type of welding seam defect.
   USE - Convolutional neural network based welding seam fault identifying method.
   ADVANTAGE - The method enables avoiding manual process of extracting characteristics of the welding seam so as to improve defect identification rate of a pre-convolution neural network model.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network based welding seam fault identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-N01B3; T01-N01D1B; T04-D04; T04-D07A
IP G06K-009/62; G06N-003/04; G06N-003/08
PD CN109034204-A   18 Dec 2018   G06K-009/62   201910   Pages: 11   Chinese
AD CN109034204-A    CN10709776    02 Jul 2018
PI CN10709776    02 Jul 2018
UT DIIDW:2018A48490
ER

PT P
PN CN109033738-A
TI Deep learning based drug activity prediction method, involves constructing drug activity data set for segmenting drug activity data set, and obtaining predicted result by ensuring predictive model of drug to-be-predicted.
AU KWON C
   FAN Y
   WANG F
   YUE Y
   LIN X
   LIU Y
AE UNIV HUNAN (UYHU-C)
GA 2018A4860S
AB    NOVELTY - The method involves constructing a drug activity data set for segmenting a drug activity data set. Data of the drug activity data is determined as a training set. Atomic features of the training set are extracted. A molecular structure of the training set is transformed into an adjacency matrix. A prediction model is constructed, where prediction model contains five layers. An output value is transmitted to a classifier for optimizing a loss function. A predicted model is obtained by iterative calculation. A predicted result is obtained by ensuring predictive model of the drug to-be-predicted.
   USE - Deep learning based drug activity prediction method.
   ADVANTAGE - The method enables ensuring complex metric by exchanging information between evidence and query molecule so as to achieve higher accuracy of prediction at low data.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning based drug activity prediction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J04E; T01-J30A; W04-W05A
IP G06F-019/00; G06N-003/08
PD CN109033738-A   18 Dec 2018   G06F-019/00   201910   Pages: 14   Chinese
AD CN109033738-A    CN10742486    09 Jul 2018
PI CN10742486    09 Jul 2018
UT DIIDW:2018A4860S
ER

PT P
PN CN109035779-A
TI Dense Net based motorway traffic flow prediction method, involves inputting single-dimensional traffic flow data, pre-processing single-dimensional traffic flow data, and prediction traffic flow by trained DenseNet network model.
AU LI D
   CHENG X
   WANG T
   LV H
   QIAN Z
   REN J
AE UNIV NANJING POSTS & TELECOM (UNPT-C)
GA 2018A4820U
AB    NOVELTY - The method involves inputting a single-dimensional traffic flow data. The single-dimensional traffic flow data is pre-processed. Traffic flow is predicted by a trained DenseNet network model. Traffic flow data is inputted. A training test unit is constructed. A single-dimensional time sequence is established. A training sample is obtained. An input part, a three dense part, a two transition part and an output part of a convolutional neural network model are constructed. Network parameters are updated in a single-cycle step. The training sample is processed.
   USE - Dense Net based motorway traffic flow prediction method.
   ADVANTAGE - The method enables automatically learning a flow data unit hidden relationship between flow rate so as to ensure better prediction effect.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a dense net based motorway traffic flow prediction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-N01A2; T01-N01B3A
IP G08G-001/01; G06Q-010/04; G06Q-050/26
PD CN109035779-A   18 Dec 2018   G08G-001/01   201910   Pages: 10   Chinese
AD CN109035779-A    CN11002046    30 Aug 2018
PI CN11002046    30 Aug 2018
UT DIIDW:2018A4820U
ER

PT P
PN CN109033321-A
TI Image and natural language feature extraction method involves forming matrix representing characteristics of entire statement with feature vectors of different words.
AU LI H
   DAN H
AE CHENGDU KUAIYAN TECHNOLOGY CO LTD (CHEN-Non-standard)
GA 2018A4871K
AB    NOVELTY - The method involves extracting the image feature for an input image by using a deep convolutional neural network. The image feature is a two-dimensional feature map. The feature of a corresponding region in the image is encoded with each feature vector. The image segmentation task is required to require location information of an object according to the natural language feature. The word is embedded for dimensionality reduction after encoding each word as a one-hot feature vector. The dimensionally reduced words are sequentially inputted into the neural network in the order of original sentence. For a t-th word in the sentence, the neural network learns the characteristic of the word. The semantic information of the word, the context information of the word and the entire statement are encoded with the feature of the word. A matrix representing the characteristics of the entire statement is formed with the feature vectors of different words.
   USE - Image and natural language feature extraction method.
   ADVANTAGE - The extraction of images and natural language facilitates implementation of keyword-based language indication image segmentation methods. The processing difficulty of the long sentence is reduced. The accuracy of object positioning and recognition is improved and the accuracy of the language indication image segmentation is improved.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic diagram of the principle of image and natural language feature extraction method. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-J04C; T01-J05B4P; T01-J10B1; T01-J10B2A; T01-J10D; T01-J16C3; T01-N01B3
IP G06F-017/30; G06N-003/04
PD CN109033321-A   18 Dec 2018   G06F-017/30   201910   Pages: 8   Chinese
AD CN109033321-A    CN10790480    18 Jul 2018
PI CN10790480    18 Jul 2018
UT DIIDW:2018A4871K
ER

PT P
PN CN109029989-A
TI Gearbox fault diagnosis method based on infrared thermal imaging, involves constructing convolutional neural network and inputting fault feature of test sample into Softmax classifier to realize identification of gearbox fault type.
AU LI Y
   WANG X
   DU X
   ZHU W
   WEI Y
   SI S
   FANG Y
AE UNIV NORTHWESTERN POLYTECHNICAL (UNWP-C)
GA 2018A4960R
AB    NOVELTY - The method involves obtaining infrared thermogram of the gear box under different working conditions by the thermal imager. The gear failure test structure and debug the gearbox system are installed. The temperature of the mechanical fault simulation test bench is initialized to the set temperature. The mechanical failure simulation test bench is preheated at 3000 rpm. The sample set of the infrared thermogram obtained is divided into a training sample set and a test sample set. The fault characteristics of the training samples are extracted. The convolutional layer is constructed. The normalized layer and activation layer are constructed. The convolutional neural network is constructed using the convolutional layer. The Softmax regression model is trained to minimize the loss function by continuous adjustment based on the hypothesis function. The fault feature of the test sample is inputted into the Softmax classifier model to realize the identification of the gearbox fault type.
   USE - Gearbox fault diagnosis method based on infrared thermal imaging.
   ADVANTAGE - The fault signature is entered into the Softmax classifier to automatically identify the different fault types of the gearbox.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a gearbox fault diagnosis method based on infrared thermal imaging. (Drawing includes non-English language text)
DC S03 (Scientific Instrumentation); T01 (Digital Computers)
MC S03-E01B; T01-N01B3A
IP G01M-013/02; G01N-025/72
PD CN109029989-A   18 Dec 2018   G01M-013/02   201910   Pages: 11   Chinese
AD CN109029989-A    CN11140317    28 Sep 2018
PI CN11140317    28 Sep 2018
UT DIIDW:2018A4960R
ER

PT P
PN CN109034196-A
TI Chinese food identification model generating method, involves obtaining image to be trained according to food picture obtained, and training obtained image to be trained by convolutional neural network model to obtain food recognition model.
AU LI Y
AE BEIJING JIANKANGYOUYI TECHNOLOGY CO LTD (BEIJ-Non-standard)
GA 2018A48498
AB    NOVELTY - The method involves obtaining corresponding number of food images of multiple food categories. The obtained food images are separately pre-processed. An image to be trained is obtained according to each food picture obtained after preprocessing is performed. The obtained image to be trained is trained by a convolutional neural network model i.e. primary residual Inception-ResNet-v2 model, to obtain a food recognition model. Gaussian filtering process is performed on the obtained food images. Image enhancement processing is performed on the food images obtained by Gaussian filtering process.
   USE - Chinese food identification model generating method.
   ADVANTAGE - The method enables reducing problem that the Chinese food does not currently realize corresponding identification scheme to a certain extent.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a Chinese food identification model generating device
   (2) a food identification device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a Chinese food identification model generating method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B1; T01-J10B2A; T01-N01B3; T04-D03; T04-D04
IP G06K-009/62; G06T-005/20
PD CN109034196-A   18 Dec 2018   G06K-009/62   201910   Pages: 15   Chinese
AD CN109034196-A    CN10645557    21 Jun 2018
PI CN10645557    21 Jun 2018
UT DIIDW:2018A48498
ER

PT P
PN CN109033172-A
TI Deep study and approximate target location image retrieval method, involves performing normalization process, and calculating characteristic vector of query image based on similarity score and characteristic vector of processed image.
AU LIAO K
   DENG X
   ZHENG Y
   TANG Z
   YUAN H
AE UNIV XIAN TECHNOLOGY (UYXT-C)
GA 2018A4875E
AB    NOVELTY - The method involves performing characteristic extraction and weighting process. An image in a convolutional neural network is extracted. An activation mapping local characteristic of the image is determined. Sliding window size is determined. A characteristic vector in blocks is determined to obtain local information in the image. Region division process is performed according to the characteristic vector of the image. The image is divided into multiple regions. A reference image is obtained in a database. A similarity score is calculated for inquiring an object area. Normalization process is performed. A characteristic vector of a query image is calculated based on similarity score and the characteristic vector of a processed image.
   USE - Deep study and approximate target location image retrieval method.
   ADVANTAGE - The method enables improving depth learning ability to optimize the image so as to improve image retrieval accuracy and reducing redundancy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a convolutional neural network. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E03; T01-J04C; T01-J05B4F; T01-J10B1; T01-J10B3A; T01-N03A2
IP G06F-017/30; G06N-003/04
PD CN109033172-A   18 Dec 2018   G06F-017/30   201910   Pages: 15   Chinese
AD CN109033172-A    CN10644333    21 Jun 2018
PI CN10644333    21 Jun 2018
UT DIIDW:2018A4875E
ER

PT P
PN CN109034190-A
TI Active sample dynamic selection strategy mining object detection system, has sample obtaining unit for obtaining labeled samples, and model training unit for selecting pseudo-labeled sample and manual marking sample training model.
AU LIN J
   WANG K
   WANG Q
   YAN X
   CHEN Z
AE GUANGZHOU SHENYU INFORMATION TECHNOLOGY (GUAN-Non-standard)
GA 2018A4849E
AB    NOVELTY - The system has a sample obtaining unit for obtaining small amount of labeled samples and large amount of unmarked samples. A model building and initializing unit establishes a depth learning object detection model and initializes the depth learning object detection model by small amount of labeled samples. A self-learning unit introduces a self-learning course to guide pseudo self-learning process to mine high-confidence samples. A model training unit selects a pseudo-labeled sample and manual marking sample training model to improve model performance.
   USE - Active sample dynamic selection strategy mining object detection system.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for an active sample dynamic selection strategy mining object detection method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of an active sample dynamic selection strategy mining object detection system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-J30A; T04-D04; T04-D07B
IP G06K-009/62
PD CN109034190-A   18 Dec 2018   G06K-009/62   201910   Pages: 16   Chinese
AD CN109034190-A    CN10623849    15 Jun 2018
PI CN10623849    15 Jun 2018
UT DIIDW:2018A4849E
ER

PT P
PN CN109040489-A
TI Method for distributing telecommunication service by using electronic device, involves obtaining calling cause type of incoming call, and distributing subscriber to customer service according to calling cause type.
AU LIU J
   WANG T
   SHI S
AE CHINA UNITED NETWORK COMMUNICATIONS CORP (CUNC-C)
GA 2018A4712W
AB    NOVELTY - The method involves updating a user relative feature value according to feedback problem. The feedback problem is classified by a user according to a characteristic value of the user. Calling cause type of incoming call is obtained. A subscriber is distributed to customer service according to the calling cause type. A deep learning algorithm is adopted for extracting a characteristic value corresponding to customer data. User call reason is classified corresponding to the updated feedback problem. Service personnel evaluation information and a processing result of the feedback problem are obtained.
   USE - Method for distributing telecommunication service by using an electronic device (claimed).
   ADVANTAGE - The method enables improving service distributing efficiency.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a telecommunication service distribution device
   (2) a computer readable storage medium for storing set of instructions for distributing telecommunication service by using an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for distributing telecommunication service by using an electronic device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-J16C2; T01-N01B3; T01-N01D; W01-B03; W01-C02B4
IP H04M-003/523
PD CN109040489-A   18 Dec 2018   H04M-003/523   201910   Pages: 16   Chinese
AD CN109040489-A    CN10872725    02 Aug 2018
PI CN10872725    02 Aug 2018
UT DIIDW:2018A4712W
ER

PT P
PN CN109040774-A
TI Method for extracting program information by terminal device and server, involves obtaining key frame images according to target program, inputting key frame images to depth learning model, and obtaining program information.
AU LIU R
AE UDITECH CO LTD (UDIT-Non-standard)
GA 2018A4706S
AB    NOVELTY - The method involves sending extracting strategy request of target program to a server. Extracting strategy request is determined by a task table for querying the target program in a database. A depth learning model is established corresponding to each task in a task list. Key frame images are obtained according to the target program. The key frame images are input to the depth learning model. Program information is obtained. Deep learning model of task is stored in a local memory. A download address is determined. Determination is made to check whether confidence degree is compared with characteristic information of a preset threshold value.
   USE - Method for extracting program information by a terminal device and a server (all claimed).
   ADVANTAGE - The method enables reducing extracting time and timeliness of program information.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a computer-readable storage medium for extracting program information by a terminal device and a server.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for extracting program information by a terminal device and a server. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W02 (Broadcasting, Radio and Line Transmission Systems); W03 (TV and Broadcast Radio Receivers); W04 (Audio/Video Recording and Systems)
MC T01-E01C; T01-H01A; T01-J05B4P; T01-N01B3; T01-N01D3; T01-S03; W02-F10K; W03-A16C5A; W04-W05A
IP H04N-021/232; H04N-021/234; H04N-021/432; H04N-021/44; H04N-021/266
PD CN109040774-A   18 Dec 2018   H04N-021/232   201910   Pages: 19   Chinese
AD CN109040774-A    CN10819132    24 Jul 2018
PI CN10819132    24 Jul 2018
UT DIIDW:2018A4706S
ER

PT P
PN CN109034153-A
TI Method for determining fidelity sample image during image rotation, involves determining rotated key information area image as fidelity sample image, and determining whether target external rectangle is overlapped with unknown pixel area.
AU MA W
   WANG Q
AE TAIKANG INSURANCE GROUP CO LTD (TAIK-Non-standard)
   TAIKANG ONLINE PROPERTY INSURANCE CO LTD (TAIK-Non-standard)
GA 2018A4850A
AB    NOVELTY - The method involves determining a minimum enclosing rectangle of a key information area after a sample image is rotated as a target external rectangle. An unknown pixel value region is determined. Fidelity boundary is determined according to a positional relationship between the target external rectangle and an unknown pixel region and according to overlap of the target external rectangle and the unknown pixel region. A rotated key information area image is determined as a fidelity sample image according to the determined fidelity boundary. Determination is made to check whether the target external rectangle is overlapped with an unknown pixel area.
   USE - Method for determining a fidelity sample image during an image rotation.
   ADVANTAGE - The method enables intercepting an unknown pixel value region after rotation process is performed to obtain the fidelity sample image so as to expand number of training samples, enrich sample features and improve recognition and generalization ability of deep learning algorithm model.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a device for determining a fidelity sample image during an image rotation.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for determining a fidelity sample image during an image rotation. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B1; T01-J10B2A; T01-J10B3A; T01-J16C2; T04-D02; T04-D04; T04-D07D5
IP G06K-009/32; G06K-009/66; G06T-005/00
PD CN109034153-A   18 Dec 2018   G06K-009/32   201910   Pages: 20   Chinese
AD CN109034153-A    CN10803980    20 Jul 2018
PI CN10803980    20 Jul 2018
UT DIIDW:2018A4850A
ER

PT P
PN CN109033521-A
TI Railway limiting gradient optimization decision making method, involves obtaining four-passage railway case information, and determining limit gradient recommended value of railway case according to number of outputs of limit slope value.
AU PU H
   ZHANG H
   LI W
   WANG L
   SONG Y
   LI X
   XIE J
   WANG J
   PENG X
   HU J
AE UNIV CENT SOUTH (UYCS-C)
GA 2018A4866K
AB    NOVELTY - The method involves constructing a deep convolutional neural network model (S1). The deep convolutional neural network model is trained (S2) based on a training data set and a verification data set. A constructed network model is trained (S3) by using the training data set. A verifying model is established based on the verification data set to perform a deep convolutional neural network model training and verification process. Four-passage railway case information is obtained (S4). A limit gradient recommended value of a railway case is determined (S5) corresponding to number of outputs of a limit slope value.
   USE - Railway limiting gradient optimization decision making method.
   ADVANTAGE - The method enables realizing high degree of automation, strong practicability, high operating efficiency and wide application range.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a railway limiting gradient optimization decision making method. '(Drawing includes non-English language text)'
   Step for constructing a deep convolutional neural network model (S1)
   Step for training the deep convolutional neural network model (S2)
   Step for training a constructed network model (S3)
   Step for obtaining four-passage railway case information (S4)
   Step for determining a limit gradient recommended value of a railway case (S5)
DC T01 (Digital Computers); X23 (Electric Railways and Signalling)
MC T01-J07D1; T01-J15B; T01-J15X; T01-N01B3; X23-X20
IP G06F-017/50; G06N-003/04
PD CN109033521-A   18 Dec 2018   G06F-017/50   201910   Pages: 16   Chinese
AD CN109033521-A    CN10658482    25 Jun 2018
PI CN10658482    25 Jun 2018
UT DIIDW:2018A4866K
ER

PT P
PN CN109034054-A
TI Deep learning model based harmonic multi-label classifying method, involves inputting sample data to pre-obtained model, classifying pre-processed training data, and obtaining classification result by using processed model.
AU QI L
   CHEN Q
   WANG H
AE UNIV NORTH CHINA ELECTRIC POWER (UYHD-C)
GA 2018A4852R
AB    NOVELTY - The method involves extracting different characteristic of the harmonic data from a full connection layer. Different harmonic signals are generated. Multiple harmonics are classified. A universal multi-label classification model is constructed based on harmonic LSTM. Data pre-processing operation is performed on sample data. The processed sample data is input into an LSTM model. Parameters of the LSTM model are adjusted. The sample data is input to the pre-obtained model. The pre-processed training data is classified. A classification result is obtained by using a processed model. Data samples are divided.
   USE - Deep learning model based harmonic multi-label classifying method.
   ADVANTAGE - The method enables improving power quality, adaptability, algorithm efficiency and harmonic classification and recognition accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a deep learning model based harmonic multi-label classifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B2A; T01-J30A
IP G06K-009/00; G06N-003/04; G06N-003/08
PD CN109034054-A   18 Dec 2018   G06K-009/00   201910   Pages: 8   Chinese
AD CN109034054-A    CN10819148    24 Jul 2018
PI CN10819148    24 Jul 2018
UT DIIDW:2018A4852R
ER

PT P
PN CN109034140-A
TI Deep learning structure based industrial control network signal abnormality detecting method, involves inputting splicing data into comparison network by calculating depth of nerve network, and detecting abnormal attack-type value.
AU QU H
   QIN J
   CHEN H
AE HARBIN INST TECHNOLOGY (HAIT-C)
GA 2018A4850K
AB    NOVELTY - The method involves obtaining selected portion marking data as training sample from industrial control network data. Training sample data normalization standardized operation is carried out to obtain calibration data. Pseudo sample values are added to form detection data by using a data enhancement algorithm after carrying out the normalization standardized operation. Splicing data is input into a comparison network by calculating depth of a nerve network to obtain normal data. An abnormal attack-type value is detected by a classifier according to detected abnormal value data.
   USE - Deep learning structure based industrial control network signal abnormality detecting method.
   ADVANTAGE - The method enables improving industrial control network signal abnormality detecting efficiency without manual intervention and avoiding distinguish difficulty of the normal data and the abnormal value data.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning structure based industrial control network signal abnormality detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-D03; T01-E01B; T01-E01C; T01-J05B2B; T01-J10B2; T01-N01B3
IP G06K-009/00; G06K-009/62; G06N-003/08
PD CN109034140-A   18 Dec 2018   G06K-009/00   201910   Pages: 11   Chinese
AD CN109034140-A    CN11072320    13 Sep 2018
PI CN11072320    13 Sep 2018
UT DIIDW:2018A4850K
ER

PT P
PN CN109033702-A
TI Convolutional neural network based power system transient voltage stability evaluation method, involves determining power system transient stable voltage by performing transient voltage stable evaluation of offline training model.
AU REN Z
   GONG Q
   WANG D
   ZHANG P
   ZHANG X
   LIU C
   DU Z
   ZHANG M
   LI S
   ZHENG B
   WANG B
   QIAO H
   WU L
AE STATE GRID SICHUAN ELECTRIC POWER CO ELE (SGCC-C)
   UNIV WUHAN (UYWU-C)
   STATE GRID CORP CHINA (SGCC-C)
GA 2018A4861T
AB    NOVELTY - The method involves performing offline training operation of convolutional neural network (CNN). Transient stable evaluation operation of off-line training model. Large amount data is obtained by presetting different operation mode and fault location. The large amount data is divided into training data and testing data. Fault data is pre-processed for acquiring dimensional feature and divided into training sample and testing sample. A dimensional input feature value is obtained and input to an off-line training model. Power system transient stable voltage is determined by performing CNN transient voltage stable evaluation of the offline training model.
   USE - CNN based power system transient voltage stability evaluation method.
   ADVANTAGE - The method enables increasing voltage stability evaluation accuracy to reduce error rate and test time.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a convolutional neural network based power system transient voltage stability evaluation method. '(Drawing includes non-English language text)'
DC S01 (Electrical Instruments); T01 (Digital Computers)
MC S01-H07A; T01-J15X; T01-N01B3A
IP G06F-017/50; G06N-003/04; G06N-003/08
PD CN109033702-A   18 Dec 2018   G06F-017/50   201910   Pages: 8   Chinese
AD CN109033702-A    CN10967613    23 Aug 2018
PI CN10967613    23 Aug 2018
UT DIIDW:2018A4861T
ER

PT P
PN CN109035315-A
TI SIFT characteristic and convolutional neural network characteristic fusion based remote sensing image registration method, involves performing to-be-registered image geometric transformation process and registered image re-sampling process.
AU SHAO Z
   LI C
   YANG K
   ZHOU W
AE UNIV WUHAN (UYWU-C)
GA 2018A48324
AB    NOVELTY - The method involves calculating similarity between characteristics to obtain a reference image. Initial matching registration image error elimination process is performed according to a geometrical characteristic point of consistency relation. A geometric transformation parameter of registration between to-be-estimated images is determined according to a correct matching point. To-be-registered image geometric transformation process is performed according to an estimated geometric transformation parameter. Registered image re-sampling process is performed.
   USE - SIFT characteristic and CNN characteristic fusion based remote sensing image registration method.
   ADVANTAGE - The method enables ensuring accurately expressing remote sensing image content so as to improve registration precision of the remote sensing image with higher adaptability.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a SIFT characteristic and convolutional neural network (CNN) characteristic fusion based remote sensing image registration system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a remote sensing image registration method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B1; T01-J10B2; T01-N01D1B; T01-N01D2; T04-D03; T04-D04
IP G06T-007/33; G06K-009/46; G06K-009/62; G06N-003/04
PD CN109035315-A   18 Dec 2018   G06T-007/33   201910   Pages: 10   Chinese
AD CN109035315-A    CN10987940    28 Aug 2018
PI CN10987940    28 Aug 2018
UT DIIDW:2018A48324
ER

PT P
PN CN109034192-A
TI Deep learning based track-train body vibration status predicting method, involves converting irregularity data into track irregularity image sample, and inputting image sample is input to CNN model for predicting vibration state of model.
AU TENG F
   LI Y
   LI T
AE UNIV SOUTHWEST JIAOTONG (UYSJ-C)
GA 2018A4849C
AB    NOVELTY - The method involves converting two-dimensional track irregularity data into RGB image data to construct a training set. A CNN model is established. The training set is input to the CNN model for training the CNN model. The track irregularity data is converted into a track irregularity image sample. The track irregularity image sample is input to the trained CNN model for predicting a vibration state of the CNN model. Train body vibrating vertical acceleration irregularity data is extracted. A vertical acceleration absolute mean and standard deviation are calculated. A characteristic matrix is obtained.
   USE - Deep learning based track-train body vibration status predicting method.
   ADVANTAGE - The method enables effectively reducing modeling complexity to provide original track irregularity data for training of the CNN, and automatically extracting track-train body feature of a vibration state classification task so as to avoid complex feature extraction and selection process.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a track-train body. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E03; T01-E04; T01-J04C; T01-J05B2; T01-J10B2; T01-J30A; T04-D04; T04-D08
IP G06K-009/62; G06N-003/04; G06N-003/08
PD CN109034192-A   18 Dec 2018   G06K-009/62   201910   Pages: 7   Chinese
AD CN109034192-A    CN10637027    20 Jun 2018
PI CN10637027    20 Jun 2018
UT DIIDW:2018A4849C
ER

PT P
PN CN109034134-A
TI Multi-task deep convolutional neural network based vehicle abnormal driving behavior detecting method, involves judging whether driver is in abnormal state, and transmitting alarm when driver is in abnormal state according to statistic data.
AU WANG D
   HUANG Q
AE SHENZHEN NIOU TECHNOLOGY CO LTD (SHEN-Non-standard)
GA 2018A4850Q
AB    NOVELTY - The method involves collecting a driver face image. The collected image is pre-processed. Edge characteristic of face characteristic points for the pre-processed image is extracted by adopting canny edge detection algorithm. Human face abnormal behavior, face orientation abnormal behavior and other characteristics are detected from the pre-processed image according to driving abnormal behavior detection algorithm. Judgment is made to check whether a driver is in an abnormal state according to statistic data. An alarm is transmitted when the driver is in the abnormal state according to the statistic data.
   USE - Multi-task deep convolutional neural network based vehicle abnormal driving behavior detecting method.
   ADVANTAGE - The method enables establishing a multi-task depth learning face detection model to extract human face feature orientation and human face other features, and rapidly and accurately detecting abnormal driving behavior according to extracted characteristic.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a multi-task deep convolutional neural network based vehicle abnormal driving behavior detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-F02; T01-J03; T01-J07D1; T01-J10B2; T01-N01D1B; T04-D03
IP G06K-009/00; G06K-009/46; G06N-003/04
PD CN109034134-A   18 Dec 2018   G06K-009/00   201910   Pages: 10   Chinese
AD CN109034134-A    CN11031072    03 Sep 2018
PI CN11031072    03 Sep 2018
UT DIIDW:2018A4850Q
ER

PT P
PN CN109036412-A
TI Voice awakening method, involves judging whether confidence degree is compared with preset threshold based on field voice data, and obtaining user instruction when confidence degree is less than preset threshold.
AU WANG H
   YAN J
   ZHANG H
   CHEN X
   MA D
   LI X
AE SUZHOU Q-DREAMER NETWORK TECHNOLOGY CO (SUZH-Non-standard)
GA 2018A4805X
AB    NOVELTY - The method involves extracting acoustic characteristic information corresponding to scene voice data. The acoustic characteristic information is input to a deep neural network classification model corresponding to live voice data to obtain posterior probability information of field voice data. Confidence degree of the field voice data is calculated according to the posterior probability information. Judgment is made to check whether the confidence degree is compared with a preset threshold based on the field voice data. A voice recording device is awakened when the confidence degree is greater than the preset threshold. A user instruction is obtained when the confidence degree is less than the preset threshold.
   USE - Voice awakening method.
   ADVANTAGE - The method enables effectively improving awakening performance due to noise so as to obtain original data such as speed, pitch and volume so as to ensure better wake-up system simulation adaptability to different speakers.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a voice awakening system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a voice awakening method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J05B2; T01-J16B; W04-V01
IP G10L-015/22; G10L-015/16; G10L-015/20
PD CN109036412-A   18 Dec 2018   G10L-015/22   201910   Pages: 11   Chinese
AD CN109036412-A    CN11081600    17 Sep 2018
PI CN11081600    17 Sep 2018
UT DIIDW:2018A4805X
ER

PT P
PN CN109035242-A
TI Deep learning based HF-ERW welding state image detecting method, involves calculating loss value of image classification model, and inputting HF-ERW welding state image into image classification model to obtain classification result.
AU WANG H
   WEI F
   CHAI C
   WANG X
   GUO J
AE UNIV CHANGAN (UCHA-C)
GA 2018A4833U
AB    NOVELTY - The method involves establishing an image classification model based on a convolutional neural network (CNN). Weld quality state marking process is performed on sample image data in a HF-ERW welding state image data set to generate an HF-ERW welding quality state data set. The sample image data is input into the image classification model for training process. Parameters of the image classification model after each training session is adjusted. A loss value of the image classification model is calculated according to classification result of the sample image data. A HF-ERW welding state image to be detected is input into the image classification model to obtain classification result.
   USE - Deep learning based HF-ERW welding state image detecting method.
   ADVANTAGE - The method enables improving HF-ERW welding state image detecting precision.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based HF-ERW welding state image detecting device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning based HF-ERW welding state image detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04A; T01-J05B2; T01-J07B; T01-J10B1; T01-J10B2; T01-N01B3; T04-D04
IP G06T-007/00; G06K-009/62; G06N-003/04
PD CN109035242-A   18 Dec 2018   G06T-007/00   201910   Pages: 16   Chinese
AD CN109035242-A    CN10903938    09 Aug 2018
PI CN10903938    09 Aug 2018
UT DIIDW:2018A4833U
ER

PT P
PN CN109039727-A
TI Method for monitoring message queue by using electronic device based on deep learning, involves inputting real-time monitoring data to prediction model, and judging whether performing processing of alarm for message queue.
AU WANG R
   HU J
   LIU Y
AE BANK CHINA CO LTD (BANK-Non-standard)
GA 2018A4731E
AB    NOVELTY - The method involves pre-processing historical monitoring data of a message queue within predetermined time period. A single hidden layer neural network machine learning algorithm is applied to obtain a prediction model for predicting speed of the message queue according to the pre-processed history monitoring data. Real-time monitoring data of current message queue is acquired. The real-time monitoring data is input to the prediction model to obtain predicted speed of current message queue. Judgment is made to check whether performing processing of an alarm for the current message queue according to the predicted speed of the current message queue.
   USE - Method for monitoring message queue by using electronic device (claimed) based on deep learning.
   ADVANTAGE - The method enables effectively improving reliability and accuracy of message queue monitoring to avoid leakage and invalid warning alarm message queue.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a system for monitoring message queue by using electronic device based on deep learning
   (2) a computer-readable storage medium for storing a set of instructions for monitoring message queue by using electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for monitoring message queue by using electronic device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J16C2; T01-N02B2; T01-S03
IP H04L-012/24; H04L-012/801; H04L-029/06
PD CN109039727-A   18 Dec 2018   H04L-012/24   201910   Pages: 24   Chinese
AD CN109039727-A    CN10818214    24 Jul 2018
PI CN10818214    24 Jul 2018
UT DIIDW:2018A4731E
ER

PT P
PN CN109034899-A
TI Method for estimating article residual value, involves generating user characteristic of return item by using data of return item, and entering article characteristic into learning neural network to obtain residual value of return item.
AU WU B
   ZHAO N
   ZHAO Y
   WEI X
   HAN L
   HE X
   MEI T
   YI J
   ZHOU B
AE BEIJING JINGDONG SHANGKE INFORMATION TEC (JDOF-C)
   BEIJING JINGDONG CENTURY TRADING CO LTD (JDOF-C)
GA 2018A4841W
AB    NOVELTY - The method involves generating user characteristic of a return item by using returned user data of the return item. A user characteristic and an article characteristic are entered into an input depth learning neural network to obtain residual value of the return item. An opinion of the user characteristics of the return item is generated to obtain opinion data by a return user of the return item. Natural language process is performed on a return text by a return user. Depth characteristic extraction process is performed to return a photo shot by the return user to obtain user opinion of understand characteristics of the return item.
   USE - Method for estimating article residual value.
   ADVANTAGE - The method enables considering user factors and item factors, and estimating article residual value.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a device for estimating article residual value.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for estimating article residual value. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J16C3; T01-N01A2C; T01-N01B3
IP G06Q-030/02; G06Q-030/00
PD CN109034899-A   18 Dec 2018   G06Q-030/02   201910   Pages: 16   Chinese
AD CN109034899-A    CN10831981    26 Jul 2018
PI CN10831981    26 Jul 2018
UT DIIDW:2018A4841W
ER

PT P
PN CN109034159-A
TI Method for extracting image information of mobile terminal, involves determining document type of electronic image, determining structural information of electronic image, and outputting document type of image and structural information.
AU WU G
   GAO D
   LI J
   ZHANG L
   WU W
AE BEIJING SINOVOICE TECHNOLOGY CO LTD (BEIJ-Non-standard)
GA 2018A48506
AB    NOVELTY - The method involves training a predetermined model according to a training sample and depth learning algorithm, where the predetermined model includes a text line detecting model, a text line recognition model and a document classification model. An electronic image of document text is obtained. The trained predetermined model is loaded into an AI chip. The electronic image is input into the predetermined model. A document type of the electronic image is determined. Structural information of the electronic image is determined. The document type of the electronic image and the structural information are output.
   USE - Method for extracting image information of a mobile terminal (claimed).
   ADVANTAGE - The method improving extracting accuracy and robustness of the image information in real-time.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for extracting image information of a mobile terminal
   (2) a computer-readable storage medium for storing a set of instructions to execute a method for extracting image information of a mobile terminal.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for extracting image information of a mobile terminal. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B1; T01-J05B2; T01-J10B2A; T01-J16C2; T01-J30A; T01-S03; T04-D02; T04-D04
IP G06K-009/34; G06K-009/62
PD CN109034159-A   18 Dec 2018   G06K-009/34   201910   Pages: 16   Chinese
AD CN109034159-A    CN10523909    28 May 2018
PI CN10523909    28 May 2018
UT DIIDW:2018A48506
ER

PT P
PN CN109036503-A
TI ECG diagnosis report generating system, has correction module for performing modification process, and report generation module for generating reports corresponding to statistical information of fastest heart rate and slowest rate.
AU XIAO H
   LI Q
   LUO Y
   MU F
   QU S
   ZHANG X
AE XILAN TECHNOLOGY BEIJING CO LTD (XILA-Non-standard)
GA 2018A4804B
AB    NOVELTY - The system has a ST-T change counting module and a heart rate counting module for generating cardiac rhythm type information, block/arrest information and premature beat type statistical information according to original ECG data and convolutional neural network model. A comprehensive correction module is configured to perform modification process on the cardiac rhythm type information and the block/arrest information by a doctor through a correction tracking module. A report generation module is configured to generate reports corresponding to a report template and statistical information of fastest heart rate and slowest rate.
   USE - ECG diagnosis report generating system.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a ECG diagnosis report generating method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of an ECCG diagnosis report generating system. '(Drawing includes non-English language text)'
DC S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S05-G02G; T01-J03; T01-N01E1
IP G16H-015/00; G16H-050/20
PD CN109036503-A   18 Dec 2018   G16H-015/00   201910   Pages: 9   Chinese
AD CN109036503-A    CN10770726    13 Jul 2018
PI CN10770726    13 Jul 2018
UT DIIDW:2018A4804B
ER

PT P
PN CN109035274-A
TI Background estimation and U-shaped convolutional neural network based document image binarization method, involves performing segmentation processing on background subtraction image, and performing binarization processing in output result.
AU XIONG W
   WANG X
   FENG C
   LIU H
   LI M
   XIONG Z
   JIN J
   WANG C
   JIA X
   TONG L
   GUAN L
AE UNIV HUBEI TECHNOLOGY (UYHI-C)
GA 2018A48333
AB    NOVELTY - The method involves performing grayscale preprocessing on a color document image to obtain a grayscale image. Image enhancement processing is performed on the grayscale image to obtain an enhanced image. Stroke width conversion processing is performed on the enhanced image. Morphological closing operation is performed on the image. Background of a document image is estimated to obtain a background estimation map. Absolute difference between the enhanced image and the background estimation map is calculated. Absolute difference images are inverted to obtain a background subtraction image. Segmentation processing is performed on the background subtraction image. Binarization processing is performed in an output result to achieve image binarization.
   USE - Background estimation and U-shaped convolutional neural network based document image binarization method.
   ADVANTAGE - The method enables significantly improving binarization effect of a document image in complex background, and realizing low-quality document image binarization in complex backgrounds such as slender strokes, ink infiltration stains on the page, uneven illumination and low contrast.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a background estimation and U-shaped convolutional neural network based document image binarization method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04D; T01-J10B1; T01-J10B2; T01-J10B3A; T01-J10B3B; T01-N01D2; T04-D08
IP G06T-007/12; G06T-005/00; G06T-007/194; G06T-003/40; G06N-003/04
PD CN109035274-A   18 Dec 2018   G06T-007/12   201910   Pages: 10   Chinese
AD CN109035274-A    CN10964338    23 Aug 2018
PI CN10964338    23 Aug 2018
UT DIIDW:2018A48333
ER

PT P
PN CN109034143-A
TI Video amplification and depth learning based face expression identification method, involves inputting pre-processed data to convolutional neural network model, and extracting feature data to perform micro-expression recognition task.
AU XU D
   LIU R
AE UNIV YUNNAN (UYUN-C)
GA 2018A4850G
AB    NOVELTY - The method involves amplifying action amplitude of micro-expression video data by adopting interference cancelation video amplification technology (S1). The video data is divided (S2) into video frame images. An image sequence is extracted corresponding to the micro-expression according to a micro-emotion tag in a data set to form a current data set. Face cropping preprocessing operation is performed (S3) on the processed video. Pre-processed data is input (S4) to a convolutional neural network model. Micro-expression feature data is extracted to perform micro-expression recognition task.
   USE - Video amplification and depth learning based face expression identification method.
   ADVANTAGE - The method enables increasing amplitude of expression movement by performing video amplification operation for eliminating interference on a complete data set and effectively improving accuracy of micro-expression recognition based on full classification of emotional tags.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a video amplification and depth learning based face expression identification method. '(Drawing includes non-English language text)'
   Step for amplifying action amplitude of micro-expression video data by adopting interference cancelation video amplification technology (S1)
   Step for dividing video data into video frame images (S2)
   Step for performing face cropping preprocessing operation on processed video (S3)
   Step for inputting pre-processed data to convolutional neural network model (S4)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2; T01-J10B2A; T01-N01B3; T04-D03; T04-D07F1; T04-K03B
IP G06K-009/00; G06N-003/04
PD CN109034143-A   18 Dec 2018   G06K-009/00   201910   Pages: 10   Chinese
AD CN109034143-A    CN11293854    01 Nov 2018
PI CN11293854    01 Nov 2018
UT DIIDW:2018A4850G
ER

PT P
PN CN109034076-A
TI Automatic sample mechanical fault signal clustering method, involves classifying and training deep neural network model by clustering training samples to establish automatic mechanical fault signal clustering model.
AU YANG Y
AE UNIV TIANJIN POLYTECHNIC (UYTI-Non-standard)
GA 2018A48526
AB    NOVELTY - The method involves obtaining an initial training sample, where the initial training sample includes multiple initial training sample pairs. Wavelet packet transform process is performed on multiple time domain vibration signals of the initial training sample to obtain a training sample wavelet packet energy vector, where the training sample wavelet packet energy vector includes a wavelet packet energy vector of each time domain vibration signal of the initial training sample. Unsupervised training classification process is performed on the wavelet packet energy vector of the training sample. Each initial training sample pair is updated. A deep neural network model is classified and trained by clustering training samples to establish automatic mechanical fault signal clustering model.
   USE - Automatic sample mechanical fault signal clustering method.
   ADVANTAGE - The method enables obtaining initial training sample to automatically update type label of the cluster training sample without manual operation so as to automatically extract feature of the training sample to classify a fault signal, thus increasing working efficiency, reducing implementation cost and signal classification error caused by individual differences, and hence realizing wide range of application.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for an automatic sample mechanical fault signal clustering system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an automatic sample mechanical fault signal clustering method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2; T01-J05B3; T01-J10B2; T01-N01B3; T01-N03A2; T04-D04
IP G06K-009/00; G06K-009/62; G06N-003/04
PD CN109034076-A   18 Dec 2018   G06K-009/00   201910   Pages: 18   Chinese
AD CN109034076-A    CN10861166    01 Aug 2018
PI CN10861166    01 Aug 2018
UT DIIDW:2018A48526
ER

PT P
PN CN109034183-A
TI Method for detecting target by electronic device, involves obtaining characteristic patterns, performing characteristic pattern fusion process, obtaining fusion feature map, and obtaining target detection result based on fusion feature map.
AU YAO Y
   DONG Y
   BAI H
   XIONG F
AE BEIJING FACEALL TECHNOLOGY CO LTD (BEIJ-Non-standard)
GA 2018A4849L
AB    NOVELTY - The method involves processing an image sample corresponding to a convolutional neural network. Two characteristic patterns are obtained. A characteristic pattern fusion process is performed. A fusion feature map is obtained. A target detection result is obtained corresponding to the fusion feature map, where the target detection result comprises target type and target position. Target size is determined corresponding to the target feature map. The target property map is processed to obtain a characteristic map of the target size. The target feature map is divided. An original image in the image sample is extracted.
   USE - Method for detecting target by an electronic device (claimed).
   ADVANTAGE - The method enables enhancing adaptability in a target fusion process and realizing strong detection capability of small objects.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for detecting target by an electronic device
   (2) a computer-readable storage medium for storing set of instruction for detecting target by an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for detecting target by an electronic device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-S03; T04-D04; T04-D07D5
IP G06K-009/62; G06N-003/04
PD CN109034183-A   18 Dec 2018   G06K-009/62   201910   Pages: 14   Chinese
AD CN109034183-A    CN10581085    07 Jun 2018
PI CN10581085    07 Jun 2018
UT DIIDW:2018A4849L
ER

PT P
PN CN109034147-A
TI Natural language deep learning based optical character recognition optimization method, involves performing word identification optimization process to combine connected areas of word, and converting single word into structured documents.
AU YAO Y
AE SHANGHAI WIZLAWGIC INFORMATION TECHNOLOGY CO LTD (SHAN-Non-standard)
GA 2018A5538Q
AB    NOVELTY - The method involves reading an original document in form of a grayscale image to obtain a gray matrix. Gray image clustering process is performed on the grayscale image to divide the grayscale image into multiple layers. A text area in the image is identified by performing layer-by-layer process to obtain pre-processed feature layer and connected area data. Word identification optimization process is performed to combine connected areas of a word. A single word is recognized and converted into structured documents by using a convolution neural network. A main contribution of a connected region is detected.
   USE - Natural language deep learning based optical character recognition optimization method.
   ADVANTAGE - The method enables outputting the structured document with high accuracy.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a natural language deep learning based optical character recognition optimization system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a natural language deep learning based optical character recognition optimization system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J05B3; T01-J10B2A; T01-J16C3; T01-N01B3; T01-N01D2; T01-N03A2; T04-D02A; T04-D04
IP G06K-009/20; G06K-009/34; G06K-009/62; G06N-003/04
PD CN109034147-A   18 Dec 2018   G06K-009/20   201910   Pages: 22   Chinese
AD CN109034147-A    CN11057725    11 Sep 2018
PI CN11057725    11 Sep 2018
UT DIIDW:2018A5538Q
ER

PT P
PN CN109035327-A
TI Deep learning based panoramic camera pose estimation method, involves building network structure by performing small scale random gradient descent process, predicting panoramic camera posture, and obtaining rotation matrix of world.
AU YING X
   ZHANG D
   SHI Y
   TONG X
   WEN J
   ZHA H
AE UNIV PEKING (UYPK-C)
GA 2018A4831T
AB    NOVELTY - The method involves collecting a panoramic picture of a city area. Image data is processed. The panoramic picture is converted into a perspective projection. The panoramic picture texture is mapped on a surface of a unit sphere. A virtual pinhole model camera is placed at a center part of the sphere. An image and a rotation matrix of a model are generated by using different rotation rendering technology and texture mapping technology. A network structure is designed with two parallel outputs. The network structure is built by performing small scale random gradient descent process. A panoramic camera posture is predicted in a given single panoramic image. A rotation matrix of a world is obtained by the camera.
   USE - Deep learning based panoramic camera pose estimation method.
   ADVANTAGE - The method enables improving robustness.
   DESCRIPTION OF DRAWING(S) - The drawing shows a front view illustrating a deep learning based panoramic camera pose estimation method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J10B3A; T01-N01B3; W04-M01S; W04-W05A
IP G06T-007/70; G06T-003/00; G06T-003/60
PD CN109035327-A   18 Dec 2018   G06T-007/70   201910   Pages: 10   Chinese
AD CN109035327-A    CN10658881    25 Jun 2018
PI CN10658881    25 Jun 2018
UT DIIDW:2018A4831T
ER

PT P
PN CN109034460-A
TI Method for predicting passenger flow congestion degree in scenic spot, involves establishing grid passenger flow congestion degree model by utilizing convolutional neural network algorithm to predict congestion level of passenger flow.
AU YU C
   HONG J
   CHEN Y
AE SHENZHEN HEXUN HUAGU INFORMATION TECHNOL (SHEN-Non-standard)
GA 2018A4842D
AB    NOVELTY - The method involves obtaining a scenic spot map. Grid division is performed con the scenic spot map in a real-time manner. Position information of a tourist spot is obtained to determine passenger flow of each grid. A grid passenger flow congestion degree model is established by utilizing a convolutional neural network algorithm through scenic grid historical passenger flow data to predict a congestion level of the passenger flow of each grid. Position information and information reporting time of a first mobile terminal in the scenic spot map are obtained. Position information and the information reporting time of first and second mobile terminals are eliminated to obtain position information of tourist in a scenic spot.
   USE - Method for predicting a passenger flow congestion degree in a scenic spot.
   ADVANTAGE - The method enables predicting the congestion level of the passenger flow in the scenic spot according to the scenic spot map and the position information of the tourists, preventing occurrence of scenic security accidents based on the prediction of the congestion level and providing personalized services for tourists to enhance experience of tourists.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for predicting a passenger flow congestion degree in a scenic spot
   (2) a computer readable storage medium for storing a set of programs for predicting a passenger flow congestion degree in a scenic spot
   (3) a system for predicting a passenger flow congestion degree in a scenic spot.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for predicting a passenger flow congestion degree in a scenic spot. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-N01A2
IP G06Q-010/04; G06Q-050/12
PD CN109034460-A   18 Dec 2018   G06Q-010/04   201910   Pages: 14   Chinese
AD CN109034460-A    CN10711677    03 Jul 2018
PI CN10711677    03 Jul 2018
UT DIIDW:2018A4842D
ER

PT P
PN CN109034111-A
TI Deep learning based driver hand off steering wheel detecting method, involves determining triggering requirement of wheel is satisfied, and obtaining warning information to remind driver if triggering requirement of wheel is satisfied.
AU YU G
   ZHANG L
   WANG Y
   NIU H
   ZHANG Y
AE UNIV BEIHANG (UNBA-C)
GA 2018A48518
AB    NOVELTY - The method involves collecting an image of a driver operating steering wheel. Latitude and longitude and speed information of a vehicle is obtained. Steering wheel operation amount information is obtained by using a depth learning-based operator detection algorithm. Determination is made to check whether warning signal triggering requirement of the steering wheel is satisfied or not by combining the steering wheel operation amount information with the latitude and longitude and speed information of the vehicle. Warning information is obtained to remind the driver if the warning signal triggering requirement of the steering wheel is satisfied.
   USE - Deep learning based driver hand off steering wheel detecting method.
   ADVANTAGE - The method enables timely detecting behavior of the driver operating the steering wheel through real-time detection, warning and communication functions during driving process and reminding the driver to timely correct the steering wheel so as to realize better steering wheel operating behavior, thus reducing occurrence of traffic accidents and improving traffic efficiency.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based driver hand off steering wheel detecting system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning based driver hand off steering wheel detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J07D1; T01-J10B2; T01-J30A
IP G06K-009/00; G06K-009/62; G06N-003/08
PD CN109034111-A   18 Dec 2018   G06K-009/00   201910   Pages: 12   Chinese
AD CN109034111-A    CN10940987    17 Aug 2018
PI CN10940987    17 Aug 2018
UT DIIDW:2018A48518
ER

PT P
PN CN109034034-A
TI Reinforcement learning algorithm based optimized convolutional neural network vein identification method, involves constructing network search model, and determining vein recognition according to convolutional neural network output.
AU YU M
   XIE Q
   ZHANG C
AE GUANGZHOU MELOW INFORMATION TECHNOLOGY (GUAN-Non-standard)
GA 2018A4853A
AB    NOVELTY - The method involves constructing a network search model. Network topology structure is constructed. Policy item of maximum probability value is calculated. Memory of current network is updated. Return evaluation module is established. Strategy probability matrix is calculated. Convolution network evaluation module is constructed. User registration vein image is inputted to the convolutional network model to generate characteristic vector. Convolutional network model characteristic extraction is performed. Vein recognition is determined according to convolutional neural network output.
   USE - Reinforcement learning algorithm based optimized convolutional neural network vein identification method.
   ADVANTAGE - The method enables obtaining vein identification accurately.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a reinforcement learning algorithm based optimized convolutional neural network vein identification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E03; T01-E04; T01-J04B2; T01-J04C; T01-J10B2A; T01-J16C2; T01-N01B3; T01-N03A2
IP G06K-009/00; G06K-009/62; G06N-003/04
PD CN109034034-A   18 Dec 2018   G06K-009/00   201910   Pages: 13   Chinese
AD CN109034034-A    CN10787418    12 Jul 2018
PI CN10787418    12 Jul 2018
UT DIIDW:2018A4853A
ER

PT P
PN CN109031200-A
TI Deep learning based sound source spatial orientation detecting method, involves inputting binaural sound signals with unknown sound source direction, and outputting predicted value of sound source spatial orientation by neural network model.
AU YU S
   ZHONG X
   GU Z
AE UNIV SOUTH CHINA TECHNOLOGY (UYSC-C)
GA 2018A4921D
AB    NOVELTY - The method involves obtaining binaural sound signals of spatial orientation by utilizing a head dual-microphone system for training depth neural network models. Iterative training process is performed on the depth neural network models to obtain a classifier with optimal parameters. The binaural sound signals with unknown sound source direction are input to trained depth neural network model. A predicted value of sound source spatial orientation is output by the depth neural network model. An artificial head is placed on a turntable. Two microphones are fixed at an ear canal end of the artificial head.
   USE - Deep learning based sound source spatial orientation detecting method.
   ADVANTAGE - The method enables simplifying hardware installing process, obtaining large neural network information, improving prediction accuracy to a level of human behavior experiment.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a depth neural network model. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W06 (Aviation, Marine and Radar Systems)
MC T01-N01B3; W06-A03F
IP G01S-005/18
PD CN109031200-A   18 Dec 2018   G01S-005/18   201910   Pages: 10   Chinese
AD CN109031200-A    CN10504609    24 May 2018
PI CN10504609    24 May 2018
UT DIIDW:2018A4921D
ER

PT P
PN CN109035292-A
TI Deep learning based moving target object detecting method, involves performing target detection process on transverse spliced sub-image by utilizing trained deep learning target detection model, and obtaining target detecting frame.
AU YU X
   ZHAO X
   LI D
   LI Z
   ZHU M
   PAN X
AE BEIJING ICE TECH CO LTD (BEIJ-Non-standard)
GA 2018A4832N
AB    NOVELTY - The method involves inputting or collecting a video image. A moving object on the video image is detected. A foreground area is obtained. Outer expanding processing process is performed on the foreground area to obtain position of an outer expanded foreground area and a corresponding sub-image. The sub-image is scaled to fixed height. A scaled sub-image is transversely spliced to obtain a transverse spliced sub-image. Target detection process is performed on the transverse spliced sub-image by utilizing a trained deep learning target detection model. A target detecting frame is obtained.
   USE - Deep learning based moving target object detecting method.
   ADVANTAGE - The method enables detecting a moving target object in a rapid manner with high detection accuracy.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based moving target object detecting device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based moving target object detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J10B2; T01-J10B3A; T01-J30A; W04-W05A
IP G06T-007/20; G06T-007/194; G06T-003/40; G06N-003/08
PD CN109035292-A   18 Dec 2018   G06T-007/20   201910   Pages: 10   Chinese
AD CN109035292-A    CN11010626    31 Aug 2018
PI CN11010626    31 Aug 2018
UT DIIDW:2018A4832N
ER

PT P
PN CN109032071-A
TI Deep learning network based real-time numerical control machine kinematic error factors identifying method, involves inputting error value of depth-collecting circular movement error track pattern to trained learning identifying network.
AU YU Y
   DU L
   PENG X
   XU L
AE UNIV CHONGQING TECHNOLOGY (UYQG-C)
GA 2018A4902G
AB    NOVELTY - The method involves establishing a numerical control machine tool circular movement error trace theory model. Error factors are calculated corresponding to an error trace theory sample. A numerical value of the error factor is changed according to different types of the error factor. A numerical machine tool circular movement error track depth learning identifying network is established based on a deep convolutional neural network through offline corresponding to the error trace theory sample. An error value of a depth-collecting circular movement error track pattern is input to the trained depth learning identifying network for identifying numerical control machine tool movement error factors.
   USE - Deep learning network based real-time numerical control machine kinematic error factors identifying method.
   ADVANTAGE - The method enables identifying numerical control machine kinematic error factors in a convenient manner so as to improve error factor identifying efficiency and error factor accuracy and reduce error factor identifying time by satisfying testing requirements.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning network based real-time numerical control machine kinematic error factors identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T06 (Process and Machine Control)
MC T01-J07B; T06-A04A3; T06-A07B
IP G05B-019/401; G06N-003/04; G06N-003/08
PD CN109032071-A   18 Dec 2018   G05B-019/401   201910   Pages: 16   Chinese
AD CN109032071-A    CN10936010    16 Aug 2018
PI CN10936010    16 Aug 2018
UT DIIDW:2018A4902G
ER

PT P
PN CN109033294-A
TI Hybrid recommendation method for incorporating content information, involves supplementing score matrix using obtained output data, and obtaining predicted score by recommendation algorithm.
AU ZHANG B
   GAO W
   YUE L
   SUN X
   FENG G
AE UNIV NORTHEAST NORMAL (UYNO-C)
GA 2018A4872A
AB    NOVELTY - The method involves converting the content information into a collection of content information words vector. The loss function of the node j in the neural network in the scoring matrix is obtained, according to the forward propagation algorithm. The weight matrix and the offset vector are adjusted by using the loss function to obtain an optimal value of the weight matrix and the offset vector, according to the back propagation algorithm. The content information word vector is integrated into the neural network to obtain output data of the neural network. The score matrix is supplemented using the obtained output data, and the predicted score is obtained by the recommendation algorithm.
   USE - Hybrid recommendation method for incorporating content information.
   ADVANTAGE - The distributed dense vector representation is obtained from content text and is combine with scoring data, so as to incorporate a noise reduction self-encoder using deep learning techniques, and focus on learning a hidden feature representation from a scoring matrix to reconstruct a scoring matrix for prediction. Hence the recommendation effect is improved.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram illustrating the operations of hybrid recommendation method. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-J05B4P; T01-N01A; T01-N01D2
IP G06F-017/30; G06Q-030/06; G06N-003/04; G06N-003/08
PD CN109033294-A   18 Dec 2018   G06F-017/30   201910   Pages: 11   Chinese
AD CN109033294-A    CN10771617    13 Jul 2018
PI CN10771617    13 Jul 2018
UT DIIDW:2018A4872A
ER

PT P
PN CN109040729-A
TI Method for correcting image white balance by terminal, involves obtaining direction of light source corresponding to target sub-images, and performing white balance emendation process according to mixing light and light source.
AU ZHANG G
AE OPPO GUANGDONG MOBILE COMMUNICATION CO (GDOP-C)
GA 201900058N
AB    NOVELTY - The method involves dividing a target image to obtain multiple target sub-images. Direction of a light source is obtained corresponding to each target sub-image. White balance emendation process is performed according to a mixing light scene and the light source. White balance correction process is performed by the target image according to the light source. The light source is determined according to a number of target sub-images. A convolutional neural network model is input into learning images to obtain a predetermined machine learning model.
   USE - Method for correcting image white balance by a terminal (claimed).
   ADVANTAGE - The method enables improving image white balance correction effect under the mixing light scene.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) an image white balance correcting device
   (2) a computer-readable storage medium for storing a set of instructions for performing an image white balance correcting device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for correcting image white balance by a terminal. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J10B1; T01-S03; W04-P01D1
IP H04N-009/64; H04N-009/73
PD CN109040729-A   18 Dec 2018   H04N-009/64   201910   Pages: 21   Chinese
AD CN109040729-A    CN10934706    16 Aug 2018
PI CN10934706    16 Aug 2018
UT DIIDW:201900058N
ER

PT P
PN CN109034205-A
TI Semi-supervised depth learning based direct-type image classifying method, involves preparing semi- supervised image data set, and determining test image label or test data set by using identification precision of trained model.
AU ZHANG Y
   GONG Y
   SHI W
   CHENG D
   TAO X
AE UNIV XIAN JIAOTONG (UYXJ-C)
GA 2018A4848Y
AB    NOVELTY - The method involves preparing semi- supervised image data set, where training data is divided into training data set and validation data set. The universal deep neural network image classification model is established. Network model parameter is stored. The criteria are established based on the Min direct pushing semi-supervised deep convolutional neural network model. Judgment is made to check whether circulating time reaches maximum cycle times. Test image label or test data set is determined by using identification precision of the trained model.
   USE - Semi-supervised depth learning based direct-type image classifying method.
   ADVANTAGE - The method enables ensuring better portability.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view illustrating a semi-supervised depth learning based direct-type image classifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B2; T01-N01B3A
IP G06K-009/62; G06N-003/04; G06N-003/08
PD CN109034205-A   18 Dec 2018   G06K-009/62   201910   Pages: 18   Chinese
AD CN109034205-A    CN10713131    29 Jun 2018
PI CN10713131    29 Jun 2018
UT DIIDW:2018A4848Y
ER

PT P
PN CN109040605-A
TI Method for guiding photography by using mobile terminal, involves obtaining significant target area from selected body region, indicating main body region, and determining target shooting area based on preset picture mode.
AU ZHANG Y
   ZHENG W
AE BEIJING DAJIA INTERNET INFORMATION TECHN (BEIJ-Non-standard)
GA 2018A4710P
AB    NOVELTY - The method involves obtaining a shooting target in an image indication scene based on a pre-trained convolutional neural network. A target area in a reminding image is determined. The convolutional neural network is trained according to a set of mark sample images. Each marked sample images are marked with a significance target area. The significant target area is obtained from a selected body region corresponding to the sample image. The main body region is indicated according to a target shooting area. The target shooting area is determined based on a preset picture mode. A user is prompted to complete patterning successfully.
   USE - Method for guiding photography by using a mobile terminal (claimed).
   ADVANTAGE - The method enables improving shooting guiding accuracy.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for guiding photography by using a mobile terminal
   (2) a non transitory computer-readable storage medium for storing a set of instructions for guiding photography by using a mobile terminal.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for guiding photography by using a mobile terminal. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-S03; W04-M01D; W04-X01K5E
IP H04N-005/232; G06N-003/04
PD CN109040605-A   18 Dec 2018   H04N-005/232   201910   Pages: 24   Chinese
AD CN109040605-A    CN11307419    05 Nov 2018
PI CN11307419    05 Nov 2018
UT DIIDW:2018A4710P
ER

PT P
PN CN109034044-A
TI Convolutional neural network based pedestrian image re-identifying method, involves training fusion convolutional neural network, extracting local feature of test pedestrian image, and determining final characteristic of pedestrian image.
AU ZHANG Z
   SI T
   LIU S
AE UNIV TIANJIN NORMAL (UYTI-Non-standard)
GA 2018A48531
AB    NOVELTY - The method involves constructing a fusion convolutional neural network by using depth pre-training learning model (S1). A pedestrian image of a training set is pre-processed (S2). The pre-processed training pedestrian image is input to the fusion convolutional neural network. Integral characteristics of the pedestrian image is determined (S3) based on a convolution activation map. The integral characteristics of the pedestrian image is optimized (S4) by using a dynamic triple loss function. Local feature is obtained and optimized (S5) by using a cross-entropy loss function. The fusion convolutional neural network is trained (S6) corresponding to the local features of the input image set. Local feature of a test pedestrian image is extracted (S7). Final characteristic of the test pedestrian image is determined (S8, S9).
   USE - Convolutional neural network based pedestrian image re-identifying method.
   ADVANTAGE - The method enables fully utilizing a convolutional neural network, learning integral feature and local feature of the pedestrian image, combining characteristics to the pedestrian image and improving pedestrian identified matching accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network based pedestrian image re-identifying method. '(Drawing includes non-English language text)'
   Step for constructing fusion convolutional neural network by using depth pre-training learning model (S1)
   Step for pre-processing pedestrian image of training set (S2)
   Step for determining integral characteristics of pedestrian image (S3)
   Step for optimizing integral characteristics of pedestrian image (S4)
   Step for obtaining and optimizing (S5)
   Step for training fusion convolutional neural network corresponding to local features of input image set (S6)
   Step for extracting local feature of test pedestrian image (S7)
   Step for determining final characteristic of test pedestrian image (S8, S9)
DC T01 (Digital Computers)
MC T01-J04B2; T01-J10B1; T01-J10B2; T01-N01B3A
IP G06K-009/00; G06N-003/04; G06N-003/08
PD CN109034044-A   18 Dec 2018   G06K-009/00   201910   Pages: 13   Chinese
AD CN109034044-A    CN10800511    20 Jul 2018
PI CN10615191    14 Jun 2018
   CN10800511    20 Jul 2018
UT DIIDW:2018A48531
ER

PT P
PN CN109035808-A
TI Deep learning based traffic light switching method, involves calculating duration of traffic light by using pre-trained algorithm model, and switching traffic light of crossroad according to calculated duration of traffic light.
AU ZHAO Y
AE SHANGHAI PHICOMM COMMUNICATION CO LTD (SHFX-C)
GA 2018A48205
AB    NOVELTY - The method involves performing obtaining and monitoring process of a frame image according to captured current video information. Duration of traffic light is calculated by using a pre-trained algorithm model. The traffic light of a crossroad is switched according to the calculated duration of the traffic light. A main structure of the pre-trained algorithm model is formed. A training data set is trained according to the pre-trained algorithm model. A result of objective function is obtained through proper training time and reference adjustment. Establishment process of the pre-trained algorithm model is completed.
   USE - Deep learning based traffic light switching method.
   ADVANTAGE - The method enables effectively improving traffic running efficiency, reducing congestion phenomenon and cost, and realizing accurate detection of light with high reliability.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based traffic light switching system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based traffic light switching method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T07 (Traffic Control Systems)
MC T01-J04A; T01-J30A; T07-C
IP G08G-001/07; G08G-001/081; G08G-001/08
PD CN109035808-A   18 Dec 2018   G08G-001/07   201910   Pages: 11   Chinese
AD CN109035808-A    CN10801597    20 Jul 2018
PI CN10801597    20 Jul 2018
UT DIIDW:2018A48205
ER

PT P
PN CN109034246-A
TI Roadbed moisture state determining method, involves inputting training sample input into deep belief network model, where deep belief network model is unsupervised and trained to establish moisture state prediction model.
AU ZHENG J
   TENG X
AE UNIV CHINA MINING & TECHNOLOGY BEIJING (UYMB-C)
GA 2018A4847R
AB    NOVELTY - The method involves determining an output of a moisture state prediction model as a moisture state of a target roadbed. A water state prediction model is established by adapting gammatone filter bank cepstrum coefficient algorithm and deep belief network model algorithm. A training sample is obtained, where the training sample is provided with multiple training data. The training data is selected as a gammatone filter bank cepstrum coefficient vector of a water state. The training sample is input into a deep belief network model, where the deep belief network model is unsupervised and trained to establish the moisture state prediction model.
   USE - Roadbed moisture state determining method.
   ADVANTAGE - The method enables avoiding human intervention and manual experience processing staff dependence, and improving high efficiency and reducing error caused due to individual difference effectively to realize accurate and reliable detection of the moisture state of the roadbed.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a roadbed moisture state determining system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a roadbed moisture state determining method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E01B; T01-J10B2; T01-J16C1; T01-N01A2; T01-N01B3; T04-D04
IP G06K-009/62; G06N-003/06; G06N-003/08; G06Q-010/04
PD CN109034246-A   18 Dec 2018   G06K-009/62   201910   Pages: 19   Chinese
AD CN109034246-A    CN10844761    27 Jul 2018
PI CN10844761    27 Jul 2018
UT DIIDW:2018A4847R
ER

PT P
PN CN109019210-A
TI Convolutional neural network based lifting rope system health monitoring system, has lifting container whose top end is connected with steel wire rope, and upper computer for receiving collected rope state by mobile wireless sensor network.
AU ZHOU P
   ZHOU G
   ZHU Z
   SUN Y
   TANG C
   HAO B
   SHU X
   LI W
   PENG Y
   CAO G
   HE Z
   JIANG F
AE UNIV CHINA MINING & TECHNOLOGY XUZHOU (UYMT-C)
GA 2018A52251
AB    NOVELTY - The system has a lifting container (3) whose top end is connected with a steel wire rope (4). An image collecting system collects a rope state. An upper computer receives the collected rope state by a mobile wireless sensor network and obtains image data to realize deep excavation for performing a fault analyzing and warning state monitoring process. A CCD camera is connected with an acquisition card and vertically fixed to an optical axis. The acquisition card, a light source and a memory are connected with a controller.
   USE - Convolutional neural network based lifting rope system health monitoring system.
   ADVANTAGE - The system replaces manual inspection and realizes automatic rope collecting-learning-prediction-warning operation in an effective manner.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a convolutional neural network based lifting rope system health monitoring method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a convolutional neural network based lifting rope system health monitoring system. '(Drawing includes non-English language text)'
   Roller (1)
   Lifting cable wire (2)
   Lifting container (3)
   Steel wire rope (4)
DC Q38 (Hoisting; Lifting; Hauling; Trucks (B66)); T01 (Digital Computers); T04 (Computer Peripheral Equipment); X25 (Industrial Electric Equipment)
MC T01-C03C; T01-J10B2; T01-N02B2B; T04-D04; X25-F04A
IP B66B-005/00; G06K-009/62; G06N-003/04; G06N-003/08
PD CN109019210-A   18 Dec 2018   B66B-005/00   201910   Pages: 12   Chinese
AD CN109019210-A    CN10694764    29 Jun 2018
PI CN10694764    29 Jun 2018
UT DIIDW:2018A52251
ER

PT P
PN CN109002829-A
TI Method for realizing color image half-tone processing based on data reduction and convolutional neural networks, involves selecting test sample from color halftone images, and inputting reverse color halftone image to neural networks.
AU WANG Y
   XU K
   ZHENG H
   LUO X
AE UNIV XIDIAN (UYXN-C)
GA 2018A3448C
AB    NOVELTY - The method involves obtaining a training label set, a training sample set, a test label set and a test sample set. Color images are selected from a database. Dimension reduction function is performed on the training sample set and the training label set by using principal component analysis process. Convolutional neural networks (CNNs) is constructed. A weight matrix of the CNNs is obtained. The CNNs is trained. The training sample set and the training label set are input into the CNNs after completing dimension reduction function. A test sample is selected from color halftone images. The trained CNNs is optimized. A reverse color halftone image is input to the trained CNNs to obtain a color halftone image.
   USE - Method for realizing color image half-tone processing based on data reduction and CNNs for document printing and document scanning field.
   ADVANTAGE - The method enables color image half-tone processing function in an efficient manner.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for realizing color image half-tone processing based on data reduction and CNNs. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B4F; T01-J10B2; T01-J10B3A; T01-J10B3B; T01-N01B3A; T01-N01D2
IP G06K-009/46; G06K-009/62; G06N-003/04
PD CN109002829-A   14 Dec 2018   G06K-009/46   201910   Pages: 10   Chinese
AD CN109002829-A    CN10801770    20 Jul 2018
PI CN10801770    20 Jul 2018
UT DIIDW:2018A3448C
ER

PT P
PN CN109002358-A
TI Deep reinforcement learning based mobile terminal software adapting optimal scheduling method, involves updating weight parameter until mobile device obtains stable software optimized scheduling scheme according to environmental change.
AU XIAO L
   DAI C
   XU D
   JIANG D
   TANG Y
AE UNIV XIAMEN (UYXI-C)
GA 2018A3459R
AB    NOVELTY - The method involves establishing connection between a mobile terminal device and a surrounding edge computing device through a wireless network. A deep convolutional neural network is constructed by the mobile terminal device. Weight parameter of a network is initialized. Wireless channel bandwidth between a mobile device and the surrounding edge computing device is calculated. Software optimization scheme is randomly selected by the mobile device. The weight parameter are updated until the mobile device obtains stable software optimized scheduling scheme according to environmental change.
   USE - Deep reinforcement learning based mobile terminal software adapting optimal scheduling method.
   ADVANTAGE - The method enables reducing energy consumption of the mobile device, processing delay and energy loss of software task on the mobile device, estimating bandwidth of the mobile device to the edge device dynamic wireless link, using depth enhanced learning algorithm to evaluate time delay and energy consumption feedback information, predicting wireless channel model of the mobile device to the edge device, CPU computing resource and memory resource occupancy model of the mobile device, and improving user experience.
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-F02C1; T01-F02C2; T01-F05F; T01-J16C2; T01-J20C; T01-N01B3; T01-N03; W01-A06C4
IP G06F-009/50; G06N-003/04
PD CN109002358-A   14 Dec 2018   G06F-009/50   201910   Pages: 7   Chinese
AD CN109002358-A    CN10811580    23 Jul 2018
PI CN10811580    23 Jul 2018
UT DIIDW:2018A3459R
ER

PT P
PN CN108985001-A
TI Pharmaceutical formulation predicting method, involves checking and adjusting pharmaceutical formulation model, and predicting same type of pharmaceutical formulation by using pharmaceutical formulation predicting process.
AU OUYANG D
   YANG Y
   HAN R
   SU Y
AE OUYANG D (OUYA-Individual)
GA 2018A19726
AB    NOVELTY - The method involves establishing a pharmaceutical formulation in an information database. Pharmaceutical formulation preparation data in the information database is divided into two parts, where the first part is used as a training set sample and the second part is used as a verifying set sample. A pharmaceutical formulation model is established by performing depth learning process according to the training set sample. The pharmaceutical formulation model is checked and adjusted through the verifying set sample. Same type of the pharmaceutical formulation is predicted by using the pharmaceutical formulation predicting process.
   USE - Pharmaceutical formulation predicting method.
   ADVANTAGE - The method enables improving efficiency of the pharmaceutical development without consume laboratory equipment, completely realizing the prediction of pharmaceutical formulation research by a computer platform, shortening pharmaceutical development period and reducing cost of the pharmaceutical development.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of a pharmaceutical formulation predicting system. '(Drawing includes non-English language text)'
DC B04 (Natural products and polymers. Including testing of body fluids (other than blood typing or cell counting), pharmaceuticals or veterinary compounds of unknown structure, testing of microorganisms for pathogenicity, testing of chemicals for mutagenicity or human toxicity and fermentative production of DNA or RNA. General compositions.); T01 (Digital Computers)
MC B11-C08; B11-C11; B12-K04E1; T01-J04E; T01-J05B4P; T01-J30A
IP G06F-019/00
PD CN108985001-A   11 Dec 2018   G06F-019/00   201910   Pages: 8   Chinese
AD CN108985001-A    CN10429823    05 Jun 2017
PI CN10429823    05 Jun 2017
UT DIIDW:2018A19726
ER

PT P
PN CN108932567-A
TI Predicting multi-energy consumption index of cement calcining process based on convolutional neural network involves selecting 12 input variables related to energy consumption of cement sintering process, performing normalization process.
AU HAO X
   YANG Y
   ZHAO Y
   YANG L
   HE Y
   GUO T
   WANG Z
AE UNIV YANSHAN (UYAN-C)
GA 2018994299
AB    NOVELTY - Predicting multi-energy consumption index of cement calcining process based on convolutional neural network involves selecting 12 input variables related to energy consumption of cement sintering process, performing normalization process for the selected variable data where variable data is processed as input data according to time sequence, performing convolution pooling and full-join calculation on input variable data, performing convolution operation on input data, pooling input data which is subjected to the convolution operation, and performing output after multiple convolution pooling and subjecting data to full join operation to complete CNN predictive model forward training, using back-propagation technique to update weight parameter to improve the prediction accuracy.
   USE - Method for predicting multi-energy consumption index of cement calcining process based on convolutional neural network.
   ADVANTAGE - The method enables to predict multi-energy consumption index of cement calcining process based on convolutional neural network is capable of reflecting actual condition comprehensive energy consumption and provides planning scheduling basis for cement burning process.
   DETAILED DESCRIPTION - Calculating the first-order moment estimation and second-order moment estimation of gradient, designing independent adaptive learning rate for different parameters to update weight of the convolution layer and minimizing complete parameter fine-tuning to output error and using unit power consumption CNN model trained for cement sintering system and real-time prediction of ton coal consumption.
TF TECHNOLOGY FOCUS - INSTRUMENTATION AND TESTING - Preferred Process: The multi-energy consumption index of cement firing process based on convolutional neural network is predicted by analyzing the process flow of the whole cement burning process, determining the main energy source in the production process, selecting 12 input variables related to energy consumption, and selecting from the database of the cement burning system. The relevant variable data is extracted, and then selected variables are normalized, where second step is characterixed by convoluting variable data of the input layer in different directions, where longitudinal convolution extracts features between variables, and the horizontal convolution extracts data features of same variable at different times. After each convolution calculation, pooling operation is performed to reduce the operation parameters, and third step is characterixed by calculating gradient of exponential moving average, calculating gradient and gradient mean for deviation correction by using exponential moving average. The variable data of the input layer is subjected to convolution operations in different directions in second step is operated by using n1 convolution kernels to perform longitudinal convolution on the input layer variable data, and the longitudinal convolution is calculated as ai,j equals to function of f of addition of (wmxi,j and bm), where m equals to 1, 2-n1 Where xi,j is used to represent i-th row and j-th column elements of the input layer data, wm is convolution kernel weight, bm is offset term of convolution kernel; ai,j is i-th row of convolution data and f represents activation function, calculating input layer data by using convolution kernel and then activating by relu function, after activation, n1 neurons are output, and each neuron contains data matrix, where n1 neurons are averaged, where specific formula represents as follows pi/q,j equals to summation of a by using function of i and j in which i and j equals to 0 and using function of D and F, and is multiplicated by 1/q, where q represents size of the pooled area, ai,j convolutional layer outputs neurons in the i-th row and j-th column element, D and F are single neuron data matrix length and width, due to pooled kernel is vertical pooling, where length of the neuron matrix decreases, pi/q,j represents i/q row j column elements of the pooling layer output neuron matrix elements, using neuron output after two convolutions as input of the connection layer, and the connection layer integrates feature information which is represented by the elements of all the neuron matrix into the neurons of the connection layer, and sets the number of connected layer neurons. The step third is also characterized by determining back propagation learning parameter, where back propagation algorithm learning rate is alpha, and determining first moment estimation attenuation index beta 1, second moment estimation attenuation index beta 2, time is t, and objective function f(theta) Where beta 1 and beta 2 have value range of 0, 1, where theta parameter is vector containing forward training weights and offsets, after determining the parameters alpha 1, beta 1, beta 2 and given objective function f(theta), initializing first moment vector m which equals to 0, second moment vector v which equals to 0, and time step t which equals to 0, calculating first moment estimate and second moment estimate of error gradient of the energy consumption prediction index, and correcting parameters, using the exponential decay correction value of gradient mt of previous moment and exponential decay correction value of square gradient vt of previous moment to update the theta parameter until the error is less than the set threshold, updating model parameter by using previously obtained parameter, and calculating formul as theta(t) equals to substraction of theta(t-1) and multiplication of a and vector m(t) divided by addition of root of vector v(t) and epsilon (1), updating iteration each parts, that is, time step t plus 1, updating gradient of the parameter theta obtained by the objective function on time step, first moment estimate mt of update deviation, and the second-order original moment estimate vt, and then calculating first-order moment estimate of deviation correction and using second-order moment estimate of deviation correction to update parameter theta of the model with value which is calculated above until the error is less than set threshold. Preferred Condition: The expression formula of activation function represents as f(x) equals to max (0, x).
DC L02 (Refractories, ceramics, cement - includes manufacturing methods, limes, soil preparation for (road) building, magnesias and slags, cements, mortars, concretes, abrasives, thermal or acoustic insulation (non)oxide ceramics and ceramic composites, but not brick making, concrete mixers or casting or pottersâ€™ wheels (C04).); T01 (Digital Computers)
MC L02-A04; L02-A08; L02-C; T01-E01B; T01-E03; T01-J04B2; T01-J04D; T01-J05B4P; T01-N01A2; T01-N01B3A
IP G06Q-010/04; G06Q-050/04; G06N-003/04; C04B-007/44
PD CN108932567-A   04 Dec 2018   G06Q-010/04   201910   Pages: 14   Chinese
AD CN108932567-A    CN10910130    10 Aug 2018
PI CN10910130    10 Aug 2018
UT DIIDW:2018994299
ER

PT P
PN CN108921910-A
TI Convolution neural network based JPEG compression encoding image restoring method, involves obtaining fixed image quality factor, obtaining step size of high definition image, and obtaining restored image by characteristic decoding unit.
AU CHEN Y
   ZHENG B
   TIAN X
AE UNIV ZHEJIANG (UYZH-C)
GA 201898174W
AB    NOVELTY - The method involves obtaining fixed image quality factor. JPEG compression encoding of distorted image is realized. Step size of a high definition image is obtained. Distorted image is divided into multiple image block groups. A telescopic convolutional neural network model is constructed, where the telescopic convolutional neural network model comprises image characteristic encoding unit. A linear characteristic mapping unit is connected with an image characteristic decoding unit. Restored image is obtained by the image characteristic decoding unit.
   USE - Convolution neural network based JPEG compression encoding image restoring method.
   ADVANTAGE - The method enables improving subjective image quality.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolution neural network based jpeg compression encoding image restoring method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J10B1; T01-J10D
IP G06T-009/00; G06N-003/04; G06N-003/08
PD CN108921910-A   30 Nov 2018   G06T-009/00   201910   Pages: 11   Chinese
AD CN108921910-A    CN10853338    30 Jul 2018
PI CN10853338    30 Jul 2018
UT DIIDW:201898174W
ER

PT P
PN CN108920850-A
TI Convolutional neural network-based flexo pressure predicting method, involves establishing static contact state between plate cylinder and central impression cylinder, and realizing printing pressure of transmission and storage data.
AU LIAO K
   LI C
   WU J
AE UNIV XIAN TECHNOLOGY (UYXT-C)
GA 201898200S
AB    NOVELTY - The method involves establishing a static contact state between a plate cylinder and a central impression cylinder. A local finite element model is utilized for studying an influence of characteristics of printing plate on printing pressure. Surface pressure values of different printing plates are collected on FCI300 satellite flexo printing machine. Model parameters are optimized for determining appropriate pressure prediction model. A printing pressure prediction is performed by a computer in a prepress paste section. MATLAB (RTM: High-level technical computing language and interactive environment) prediction pressure value is imported into corresponding read-write card to realize printing pressure of transmission and storage data.
   USE - Convolutional neural network-based flexo pressure predicting method.
   ADVANTAGE - The method enables automatically realizing data predicting into an electronic tag of corresponding the plate cylinder for subsequent printing so as to save manual writing process.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram illustrating a convolutional neural network-based flexo pressure predicting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J15X
IP G06F-017/50; G06N-003/04; G06K-017/00
PD CN108920850-A   30 Nov 2018   G06F-017/50   201910   Pages: 16   Chinese
AD CN108920850-A    CN10745170    09 Jul 2018
PI CN10745170    09 Jul 2018
UT DIIDW:201898200S
ER

PT P
PN CN108830152-A
TI Deep learning network and artificial feature based pedestrian detecting method, involves starting two threads at same time, and determining and outputting output result in form of rectangular frame of target according to detection result.
AU CHEN D
   YE D
AE BEIJING HONGYUN ZHISHENG TECHNOLOGY CO (BEIJ-Non-standard)
GA 201912424N
AB    NOVELTY - The method involves processing image data of a human face corresponding to threshold range. A detection result of an effective deep learning network is determined as a valid detection result when the detection result satisfies corresponding strategy, where detection results of an overlapped area of the human face and an upper body detection result rectangle frame of the human face are more than 85% of detection result of side face or positive face of a rectangle frame area. Two threads are started at same time. An output result is determined and output in form of a rectangular frame of a target according to the detection result.
   USE - Deep learning network and artificial feature based pedestrian detecting method.
   ADVANTAGE - The method enables performing parallel calculation and manual detection functions by accelerating the threads so as to reduce calculation time, realizing high process accuracy by using a deep learning network and artificial feature combined way, reducing false detection rate and increasing robustness effect.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning network and artificial feature based pedestrian detecting system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning network and artificial feature based pedestrian detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J10B2; T01-N01B3; W04-W05A
IP G06K-009/00; G06N-003/08
PD CN108830152-A   16 Nov 2018   G06K-009/00   201910   Pages: 14   Chinese
AD CN108830152-A    CN10426439    07 May 2018
PI CN10426439    07 May 2018
UT DIIDW:201912424N
ER

PT P
PN CN108829810-A
TI Health-oriented sentiment text classifying method, involves performing classifying process of text data, inputting test result of training set into current training set, and establishing training model based on current training set.
AU CHEN L
   LI Q
   CHEN Q
   XU A
   CHEN Y
   LIU W
   CHEN S
AE DONGGUAN DATA SCI SOFTWARE TECHNOLOGY CO (DONG-Non-standard)
   GUANGDONG ELECTRONIC INFORMATION ENG RES (GUAN-Non-standard)
GA 201912420H
AB    NOVELTY - The method involves processing healthy opinion text data in uniform format. A word order is scrambled by performing shuffle process. Words are randomly deleted by drop process. Healthy opinion text data is recombined into word sequence. A word vector and a code word vector are obtained by using a word to vector model according to a word segmentation result. A neural network feature is extracted by using a deep neural network. Classifying process of health sentiment text data is performed. A test result of a training set is inputted into a current training set. A training model is established based on the current training set.
   USE - Health-oriented sentiment text classifying method.
   ADVANTAGE - The method enables effectively improving accuracy and spread ability of text classification, avoiding need to use external information, and achieving regression tasks.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a training model. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E01A; T01-J05B2; T01-J05B4P; T01-J11A1; T01-N01A2C; T01-N01B3A
IP G06F-017/30; G06F-017/27; G06N-003/08
PD CN108829810-A   16 Nov 2018   G06F-017/30   201910   Pages: 9   Chinese
AD CN108829810-A    CN10582880    08 Jun 2018
PI CN10582880    08 Jun 2018
UT DIIDW:201912420H
ER

PT P
PN CN108829723-A
TI Accurate food ingredients identifying method, involves collecting food information by deep convolution neural network model after being optimized, and determining whether food images in tagged food image database are specific sized images.
AU GAO Z
   DANG W
   CHANG C
AE UNIV TIANJIN (UTIJ-C)
   TIANJIN KEYUAN TECHNOLOGY CO LTD (TIAN-Non-standard)
GA 201912549C
AB    NOVELTY - The method involves obtaining food images. A label is set in a tagged food image database. A deep convolution neural network model on a cloud platform is constructed according to food name. A processing model structure and a parameter are optimized. Food information is collected by the deep convolution neural network model after being optimized, where the food information comprises food type, number and/or a position of food in a containing space. Determination is made to check whether the food images in the tagged food image database are 256/asterisk256 sized images.
   USE - Accurate food ingredients identifying method.
   ADVANTAGE - The method enables realizing diet record timely recommending function so as to send out diet plan or instruction information to a user according to physical condition information of the user, so that visual user interface is established.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a binary complex network-based food recommending method
   (2) a binary complex network and depth learning based interactive intelligent refrigerator health service facilitating method
   (3) a binary complex network and depth learning based interactive intelligent refrigerator health service terminal.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a binary complex network and depth learning based interactive intelligent refrigerator health service terminal. '(Drawing includes non-English language text)'
DC S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S05-G02G3; S05-G02G4; T01-J04B2; T01-J05B4F; T01-J12; T01-N01D3A; T01-N01E1
IP G06F-017/30; G16H-020/60
PD CN108829723-A   16 Nov 2018   G06F-017/30   201910   Pages: 20   Chinese
AD CN108829723-A    CN10432243    08 May 2018
PI CN10432243    08 May 2018
UT DIIDW:201912549C
ER

PT P
PN CN108830185-A
TI Multi-task cooperative learning behavior identification and location method, involves constructing multi-channel binding behavior recognition convolutional neural network, and loading cooperative learning advanced network weight model file.
AU HAO Z
AE SICHUAN TONGZHI TECHNOLOGY CO LTD (SICH-Non-standard)
GA 201912446V
AB    NOVELTY - The method involves constructing a multi-channel binding behavior recognition convolutional neural network (S1). An action identification training weight value model is obtained (S2) by using the convolutional neural network. An action recognition and action task cooperative learning depth network is constructed (S3) on a basis of the convolutional neural network. Pedestrian identification and location data is obtained (S4) by using the action recognition and action task cooperative learning depth network. A multi-task cooperative learning advanced network weight model file is loaded (S5) to obtain a behavior identification and location result.
   USE - Multi-task cooperative learning behavior identification and location method.
   ADVANTAGE - The method enables improving multi-task cooperative learning ability, enhancing identification robustness and accuracy and combining a video data set to an image data set so as to increase information diversity of a training set, thus reducing energy consumption rate of video data, and hence omitting data by autonomous learning algorithm set for a marking work and reducing workload.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a multi-task cooperative learning behavior identification and location method. '(Drawing includes non-English language text)'
   Step for constructing multi-channel binding behavior recognition convolutional neural network (S1)
   Step for obtaining action identification training weight value model by using convolutional neural network (S2)
   Step for constructing action recognition and action task cooperative learning depth network on basis of convolutional neural network (S3)
   Step for obtaining pedestrian identification and location data by using action recognition and action task cooperative learning depth network (S4)
   Step for loading multi-task cooperative learning advanced network weight model file to obtain behavior identification and location result (S5)
DC T01 (Digital Computers)
MC T01-F02; T01-J10B2A; T01-J10B3A; T01-J16C2; T01-N01B3; T01-N01D2
IP G06K-009/00; G06K-009/62; G06N-003/04
PD CN108830185-A   16 Nov 2018   G06K-009/00   201910   Pages: 22   Chinese
AD CN108830185-A    CN10523779    28 May 2018
PI CN10523779    28 May 2018
UT DIIDW:201912446V
ER

PT P
PN CN108829900-A
TI Deep learning based method for retrieving human face image by terminal, involves storing target human face images in database according to partial attribute feature vector comparison result.
AU SHI F
   WANG B
   LONG G
AE CHENGDU SHIGUANTIANXIA TECHNOLOGY CO LTD (CHEN-Non-standard)
GA 2019124196
AB    NOVELTY - The method involves inputting a to-be searched face image through a multi-task local shared convolutional neural network model. Characteristic vector of the to-be searched face image is determined. Feature vectors of the to-be searched face image are calculated. Attribute feature vector, image identification feature vector and attribute feature vector of the to-be searched face image are stored in a database. Global properties feature vector comparison result and partial attribute feature vector comparison result are obtained. Target human face images are stored in a database according to the global properties feature vector comparison result and partial attribute feature vector comparison result.
   USE - Deep learning based method for retrieving human face image by a terminal (claimed).
   ADVANTAGE - The method enables effectively reducing face image retrieval probability.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a terminal
   (2) a deep learning based device for retrieving human face image by a terminal.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E01C; T01-E03; T01-E04; T01-F02; T01-J04C; T01-J05B4F; T01-J10B2; T01-J10B3A; T01-J10E; T01-N01B3; T01-N03A2; T04-D07F1
IP G06F-017/30; G06K-009/00
PD CN108829900-A   16 Nov 2018   G06F-017/30   201910   Pages: 19   Chinese
AD CN108829900-A    CN10856269    31 Jul 2018
PI CN10856269    31 Jul 2018
UT DIIDW:2019124196
ER

PT P
PN CN108830143-A
TI Deep learning based video analysis system, has video analysis depth learning server for transmitting identification model to video analyzing terminal to update first identification model into second identification model.
AU WANG Y
   ZENG Y
   NIE Y
AE SHENZHEN ZDS-T SMART SECURITY TECHNOLOGY (SHEN-Non-standard)
GA 201912424X
AB    NOVELTY - The system has a camera communicatively connected with a video analyzing terminal that is communicatively connected with a video management server. A video analysis depth learning server is connected with the video analyzing terminal and the video management server. The video analysis depth learning server trains a neural network to obtain a first identification model. The camera obtains and transmits fire protection monitoring point video data to the video analyzing terminal. The video analysis depth learning server transmits an identification model to the video analyzing terminal to update the first identification model into a second identification model.
   USE - Deep learning based video analysis system.
   ADVANTAGE - The system has strong practicability and high utilization rate, and improves image recognition accuracy, avoids false or missing phenomenon.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a deep learning based video analysis system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W05 (Alarms, Signalling, Telemetry and Telecontrol)
MC T01-J10B1; T01-J10B2A; T01-N01B3; T01-N01D1B; T01-N01D3; T01-N02B2; T04-D04; W05-B02B
IP G06K-009/00; G06K-009/62; G08B-017/12
PD CN108830143-A   16 Nov 2018   G06K-009/00   201910   Pages: 9   Chinese
AD CN108830143-A    CN10415478    03 May 2018
PI CN10415478    03 May 2018
CP CN108830143-A
      CN106845410-A   UNIV XIAN SCI & TECHNOLOGY (UYXI-Non-standard)   DENG J, QIN X, WANG W
      CN107808139-A   UNIV ELECTRONIC SCI & TECHNOLOGY (UEST)   GAO J, GAN Z
UT DIIDW:201912424X
ER

PT P
PN CN108830155-A
TI Deep learning based cardiac coronary artery identifying method, involves performing pyramid fusion process, and obtaining cardiac coronary artery segmentation and identifying vessel map by performing bilinear interpolation process.
AU XU B
   LIANG X
   WANG X
   YE D
AE BEIJING HONGYUN ZHISHENG TECHNOLOGY CO (BEIJ-Non-standard)
GA 201912591Q
AB    NOVELTY - The method involves performing segmentation and identification of a cardiac blood vessel in a training sample. A cardiac blood vessel characteristic picture is output to a pyramid module. The cardiac blood vessel characteristic picture is received by the pyramid module in a neural network for segmentation and identification. Pyramid fusion process is performed to output different scales of the cardiac blood vessel characteristic picture to a deconvolution layer in the neural network. A cardiac coronary artery segmentation and identifying vessel map is obtained by performing bilinear interpolation process.
   USE - Deep learning based cardiac coronary artery identifying method.
   ADVANTAGE - The method enables eliminating classification imbalance problem due to large difference between a background pixel and a vessel pixel proportion, and effectively avoiding interference introduced by a texture similar to vascular in an image background, and improving segmentation accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based cardiac coronary artery identifying method. '(Drawing includes non-English language text)'
DC B04 (Natural products and polymers. Including testing of body fluids (other than blood typing or cell counting), pharmaceuticals or veterinary compounds of unknown structure, testing of microorganisms for pathogenicity, testing of chemicals for mutagenicity or human toxicity and fermentative production of DNA or RNA. General compositions.); T01 (Digital Computers)
MC B11-C08J; B11-C11; B12-K04G2B; T01-J05B2; T01-J10B1; T01-J10B2; T01-N01B3
IP G06K-009/00; G06N-003/04; G06N-003/08; G06T-007/194
PD CN108830155-A   16 Nov 2018   G06K-009/00   201910   Pages: 11   Chinese
AD CN108830155-A    CN10441544    10 May 2018
PI CN10441544    10 May 2018
UT DIIDW:201912591Q
ER

PT P
PN CN108820233-A
TI Fixed wing unmanned aerial vehicle visual landing guidance method involves controlling autonomous landing of vehicle by calculating position change information between feature points that can match each other in adjacent multi-frame images.
AU YUAN B
   GUO J
AE UNIV XIJING (UNXJ-C)
GA 2019124189
AB    NOVELTY - The method involves using three-dimensional (3D) convolutional neural network (CNN) to extract adjacent multi-frame images from video captured by imaging equipment during landing phase of fixed-wing unmanned aerial vehicle. The autonomous landing of the unmanned aerial vehicle is controlled by calculating the position change information between the feature points that can match each other in the adjacent multi-frame images.
   USE - Fixed wing unmanned aerial vehicle visual landing guidance method.
   ADVANTAGE - The algorithm of the guidance process is realized without the aid of ground auxiliary signs and does not depend on the operating environment, so as to greatly improve the reliability of visual landing guidance of fixed-wing unmanned aerial vehicle.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating the fixed wing unmanned aerial vehicle visual landing guidance process. (Drawing includes non-English language text)
DC T01 (Digital Computers); W06 (Aviation, Marine and Radar Systems)
MC T01-J07D3; W06-B01B; W06-B15U
IP B64D-045/08
PD CN108820233-A   16 Nov 2018   B64D-045/08   201910   Pages: 12   Chinese
AD CN108820233-A    CN10730693    05 Jul 2018
PI CN10730693    05 Jul 2018
UT DIIDW:2019124189
ER

PT P
PN CN108829692-A
TI Convolutional neural network-based flower image searching method, involves extracting similar flower images based on preliminary search result, and utilizing preliminary search result as search result to complete image searching process.
AU ZOU L
   JIN L
   ZHANG S
   LI C
   CHEN T
   LI X
   XIONG Z
   YANG W
AE UNIV HUAZHONG SCI & TECHNOLOGY (UYHZ-C)
GA 201912421X
AB    NOVELTY - The method involves establishing a flower image data set. Flower images are processed based on random image transformation operation. A VGG16-based VGG-F flower classifying deep convolutional neural network model is constructed. Parameters of the neural network model are optimized based on an Adam optimization algorithm. Characteristic vectors of a to-be-inquired image and the flower image data set are extracted using a fully-connection layer of the neural network model. HSV color distribution characteristic vectors of to-be-queried flower image and a preliminary search result are obtained. Similar flower images are extracted based on the preliminary search result. The preliminary search result is utilized as a search result to complete flower image searching process.
   USE - Convolutional neural network-based flower image searching method.
   ADVANTAGE - The method enables realizing flower image searching process in effective and accurate manner.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a convolutional neural network-based flower image searching method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B4F; T01-J10B2; T01-J10B3B; T01-N01D1B; T01-N03A2
IP G06F-017/30; G06K-009/46; G06K-009/62; G06N-003/04; G06N-003/08
PD CN108829692-A   16 Nov 2018   G06F-017/30   201910   Pages: 11   Chinese
AD CN108829692-A    CN10312552    09 Apr 2018
PI CN10312552    09 Apr 2018
UT DIIDW:201912421X
ER

PT P
PN US2018373927-A1; TW625678-B1; TW201905757-A; US10282601-B2
TI Method for recognizing gesture of hand, involves detecting moving track of hand in second block and recognizing gesture of hand according to moving track.
AU YANG J
   TSAI T
   CHUANG C
   KUO C
AE HON HAI PRECISION IND CO LTD (HONH-C)
   HON HAI PRECISION IND CO LTD (HONH-C)
GA 201903459G
AB    NOVELTY - The method involves obtaining (600) an image that comprises a hand and image depth information. A static object comprised in the image is filtered (602). The hand coordinate information is obtained (604) and establishes a first block comprising the hand based on the hand coordinate information. The depth information of each pixel of the first block is obtained (606) and counts number of pixels of each depth level. The hand depth information is obtained (608) according to counting result and establishes a second block according to the hand depth information. A moving track of the hand in the second block is detected (610) and recognizes a gesture of the hand according to the moving track.
   USE - Method for recognizing gesture of hand.
   ADVANTAGE - The recognizing module recognizes the gesture of the hand according to the detected moving track and the gesture library. The first establishing module establishes characteristic values of the hand through the deep learning algorithm and obtains the hand coordinate information according to the characteristic values. The first filtering module filter the static objects comprised by the image through a Gaussian mixture module (GMM) to retain the motion objects.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for an electronic device for recognizing gesture of hand.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a gesture recognition method in electronic device.
   Step for obtaining image (600)
   Step for filtering static object (602)
   Step for obtaining hand coordinate information (604)
   Step for obtaining depth information (606)
   Step for obtaining hand depth information (608)
   Step for detecting moving track of hand (610)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B1; T01-J10B2A; T01-J10B3; T01-J16C2; T04-D03; T04-D04
IP G06K-009/00; G06K-009/40; G06K-009/46; G06K-009/62; G06T-007/223; G06T-007/55; G06K-009/78; G06F-003/01
PD US2018373927-A1   27 Dec 2018   G06K-009/00   201910   Pages: 11   English
   TW625678-B1   01 Jun 2018   G06K-009/62   201910      Chinese
   US10282601-B2   07 May 2019   G06K-009/62   201933      English
AD US2018373927-A1    US652698    18 Jul 2017
   TW625678-B1    TW120799    21 Jun 2017
   TW201905757-A    TW120799    21 Jun 2017
   US10282601-B2    US652698    18 Jul 2017
FD  US10282601-B2 Previous Publ. Patent US2018373927
PI TW120799    21 Jun 2017
CP    US10282601-B2
      US20110291926-A1      
      US20120093360-A1      
      US20130278504-A1      
      US20140177909-A1      
      US20170090584-A1      
      TW201426413-A   IND TECHNOLOGY RES INST (ITRI)   LIN H, WANG H, DONG S
      TW201619752-A   WISTRON CORP (WIST)   YANG J, LIN H, SHEN T, KAO M
UT DIIDW:201903459G
ER

PT P
PN CN109033089-A
TI Emotion analyzing method, involves fusing first feature data with second feature data by prediction model, and obtaining emotional classification result of user session according to fused feature data.
AU CHE T
   GAO W
   HE X
   LIU X
AE BEIJING JINGDONG SHANGKE INFORMATION TEC (JDOF-C)
   BEIJING JINGDONG CENTURY TRADING CO LTD (JDOF-C)
GA 2018A4877H
AB    NOVELTY - The method involves performing feature extraction for user session. Extracted user session features are inputted into a preset first prediction model and a second prediction model. First feature data in the first prediction model is inputted into the second prediction model. First feature data is fused with second feature data by the second prediction model. Emotional classification result of user session is obtained according to fused feature data based on convolutional neural network, where classification result of the first prediction model is less than classification result of the second prediction model.
   USE - Emotion analyzing method.
   ADVANTAGE - The method enables migrating knowledge in the first prediction model to the second prediction model by adopting migration learning process, so that the second prediction model obtains better classification results.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) an emotion analyzing device
   (2) a computer readable storage medium for storing set of instructions for an emotion analyzing method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an emotion analyzing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J05B4P; T01-J11A1; T01-N01A
IP G06F-017/27; G06N-003/04; G06Q-030/00
PD CN109033089-A   18 Dec 2018   G06F-017/27   201909   Pages: 12   Chinese
AD CN109033089-A    CN11037201    06 Sep 2018
PI CN11037201    06 Sep 2018
UT DIIDW:2018A4877H
ER

PT P
PN CN109034632-A
TI Depth-based learning model security risk evaluating method, involves constructing depth learning model, obtaining final model safety situation, and determining reference and numerical index according to depth learning model.
AU CHU Y
   WANG Q
   LI C
   WEI L
   LUAN L
   XIA L
   SHEN J
   YU H
   GAO D
   ZHANG Y
AE UNIV HARBIN ENGINEERING (UHEG-C)
GA 2018A49475
AB    NOVELTY - The method involves obtaining a to-be-measured target depth learning model. An original sample image is extracted from an original sample set. Sample image format requirements of the target depth learning model are determined. An original sample image is predicted. Sample image is obtained. Probability distribution of each class is obtained. A to-be-measured target depth learning model is calculated. A measuring target learning model is determined. Depth of the measuring target learning model is obtained. A model security risk evaluation result is output. A depth learning model is constructed according to a measured against safety index. A final model safety situation is obtained. A reference and numerical index is determined according to the depth learning model.
   USE - Depth-based learning model security risk evaluating method.
   ADVANTAGE - The method enables evaluating security risk by using an effective depth learning model.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a depth-based learning model security risk evaluating method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05A2; T01-J30A; T01-L02
IP G06N-003/08; G06Q-010/06
PD CN109034632-A   18 Dec 2018   G06Q-010/06   201909   Pages: 10   Chinese
AD CN109034632-A    CN10877437    03 Aug 2018
PI CN10877437    03 Aug 2018
UT DIIDW:2018A49475
ER

PT P
PN CN109034210-A
TI Multi-size pyramid network ultra-feature fusion based target location detection method, involves determining multi-task loss function of bounding box by multi-class classifier, and realizing image classification and target location function.
AU HUANG S
   GUO X
   FU G
   JIANG Z
   MEN A
AE ACAD BROADCASTING SCI SARFT (BROA-Non-standard)
   UNIV BEIJING POSTS & TELECOM (UBPT-C)
GA 2018A5538E
AB    NOVELTY - The method involves extracting different feature information of a multi-scale characteristic graph by utilizing a deep convolutional neural network. Dimension procession operation is performed on layered multi-scale characteristic graph according to pooling operation and deconvolution operation. A multi-size pyramid network model is constructed. A target candidate frame is constructed according to the multi- scale characteristic graph. Feature extraction process is performed on the multi-size pyramid network model. Multi-task loss function of a bounding box is determined by a multi- class classifier. Image classification and target location function are realized.
   USE - Multi-size pyramid network ultra-feature fusion based target location detection method.
   ADVANTAGE - The method enables improving feature extraction capability of a target and characteristic expression ability by utilizing the deep convolutional network, preventing gradient disappearance, effectively training and extracting a convolution neural network to realize target detection, increasing detecting precision of an algorithm to obtain optimized target detection result.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a multi-size pyramid network ultra-feature fusion based target location detection method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-F02A; T01-F03; T01-J04B2; T01-J05B2; T01-J10B2; T04-D03; T04-D04; T04-E
IP G06K-009/62; G06K-009/46
PD CN109034210-A   18 Dec 2018   G06K-009/62   201909   Pages: 9   Chinese
AD CN109034210-A    CN10721716    04 Jul 2018
PI CN10721716    04 Jul 2018
UT DIIDW:2018A5538E
ER

PT P
PN CN109033107-A
TI Method for retrieving image by utilizing computer device, involves obtaining fusion position information, and comparing characteristic vector of search image with characteristic vector stored in database to obtain image of searching result.
AU LAI H
AE TENCENT TECHNOLOGY SHENZHEN CO LTD (TNCT-C)
   UNIV SUN YAT-SEN (UYSY-C)
GA 2018A48776
AB    NOVELTY - The method involves inputting a search image into a convolutional neural network. An output result is input to a middle layer of the convolutional neural network. A characteristic pattern of a retrieved image is obtained. Fusion position information of the characteristic pattern is obtained. The fusion position information is input into the convolutional neural network. A characteristic vector of the search image is output. The characteristic vector of the search image is compared with a characteristic vector stored in a database to obtain an image of the searching result.
   USE - Method for retrieving image by utilizing a computer device (claimed).
   ADVANTAGE - The method enables increasing image retrieving precision.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for retrieving image by utilizing a computer device
   (2) a storage medium for storing a set of instructions for retrieving image by utilizing a computer device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for retrieving image by utilizing a computer device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E01C; T01-J05B4F; T01-J10E; T01-N03A2
IP G06F-017/30; G06N-003/04; G06N-003/08
PD CN109033107-A   18 Dec 2018   G06F-017/30   201909   Pages: 16   Chinese
AD CN109033107-A    CN10433984    09 Jun 2017
PI CN10433984    09 Jun 2017
UT DIIDW:2018A48776
ER

PT P
PN CN109034228-A
TI Differential privacy and relevance propagation level based image classifying method, involves utilizing optimal parameters of convolutional neural network as image classification result based on hierarchical correlation propagation.
AU LI S
   CHEN H
   LI Z
AE UNIV SHAANXI NORMAL (UNSN-C)
GA 2018A4848A
AB    NOVELTY - The method involves determining a grayscale image data set, where the grayscale image dataset includes grayscale image data and a classification label corresponding to the grayscale image data. A correlation matrix of the gray image data set is established based on hierarchical correlation propagation. A noise average correlation matrix is established. The grayscale image data set is divided into a training set and a test set. Disturbed batch data is obtained after loop iteration of the grayscale image data set. Cross entropy loss function is established based on the disturbed batch data. Optimal parameters of a convolutional neural network are utilized as image classification result based on differential privacy and hierarchical correlation propagation.
   USE - Differential privacy and relevance propagation level based image classifying method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a differential privacy and relevance propagation level based image classifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J05B2; T01-J10B2; T01-N01B3A; T04-D03A; T04-D04
IP G06K-009/62; G06N-003/04
PD CN109034228-A   18 Dec 2018   G06K-009/62   201909   Pages: 21   Chinese
AD CN109034228-A    CN10781097    17 Jul 2018
PI CN10781097    17 Jul 2018
UT DIIDW:2018A4848A
ER

PT P
PN CN109033561-A
TI Mine ventilation system disaster resistance evaluating method, involves inputting BP neural network by evaluation value of lowest layer evaluation index, and establishing BP neural network through deep learning training technique.
AU LIU Y
   TIAN Z
   SUN M
   REN Y
   XUE J
   YUAN L
   YU G
   DUAN C
   CHEN B
   DENG D
   YU Y
   GUO Z
   DING Y
AE PINGAN COAL MINING ENG TECHNOLOGY INST (HUAI-C)
   UNIV INNER MONGOLIA SCI & TECHNOLOGY (UYIN-C)
   HUAINAN MINING GROUP CO LTD (HUAI-C)
GA 2018A4865J
AB    NOVELTY - The method involves obtaining an evaluation value of a mine ventilation system at a lowest layer evaluation index. A BP neural network is input by the evaluation value of the lowest layer evaluation index. A disaster resistance level of the mine ventilation system output by the BP neural network is obtained, where the BP neural network is a sample set with different evaluation values of the lowest layer evaluation index and corresponding anti-disaster resistance capability level. The BP neural network is established through deep learning training technique.
   USE - Mine ventilation system disaster resistance evaluating method.
   ADVANTAGE - The method enables carrying a comprehensive evaluation and prediction of the disaster resistance capability of the mine ventilation system during the catastrophe period by constructing an evaluation model based the BP neural network so to achieve operability evaluation process and improve reliability, stability and strain capacity of the mine ventilation system during catastrophe period, so that comprehensive support capability of the mine ventilation system during the catastrophe period is improved, thus reducing casualties of personnel during the catastrophe period.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a mine ventilation system disaster evaluating device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a mine ventilation system disaster resistance evaluating method. '(Drawing includes non-English language text)'
DC S01 (Electrical Instruments); T01 (Digital Computers)
MC S01-H07A; T01-J15X; T01-N01B3
IP G06F-017/50; G06N-003/04; G06N-003/08
PD CN109033561-A   18 Dec 2018   G06F-017/50   201909   Pages: 19   Chinese
AD CN109033561-A    CN10731200    05 Jul 2018
PI CN10731200    05 Jul 2018
UT DIIDW:2018A4865J
ER

PT P
PN CN109033169-A
TI Multi-weighing conversion and convolutional neural network based mobile traffic flow data classification method, involves obtaining flow data to-be identified, and obtaining classifying result after pre-processing sample data of classifier.
AU QIN Z
   ZU J
   JI L
AE UNIV SOUTHEAST (UYSE-C)
GA 2018A4875H
AB    NOVELTY - The method involves pre-processing marked sample data of a classifier. A convolutional neural network model is established. Marked sample data is stored according to a HTTP request and a response message. A class label is generated based on a request message and the response message. Fixed size format of a two-dimensional character array is obtained by adopting a multi-level weighing conversion algorithm. Normalization processing of a two-dimensional integer array is performed. Flow data to-be identified is obtained. A corresponding classifying result is obtained after pre-processing marked sample data of the classifier.
   USE - Multi-weighing conversion and convolutional neural network based mobile traffic flow data classification method.
   ADVANTAGE - The method enables avoiding need of selected features so as to automatically find enhanced features with high classification accuracy and practicability.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a multi-weighing conversion and convolutional neural network based mobile traffic flow data classification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J05B4P
IP G06F-017/30; G06N-003/04
PD CN109033169-A   18 Dec 2018   G06F-017/30   201909   Pages: 10   Chinese
AD CN109033169-A    CN10640682    21 Jun 2018
PI CN10640682    21 Jun 2018
UT DIIDW:2018A4875H
ER

PT P
PN CN109035267-A
TI Deep learning based image target extracting method, involves constructing synthetic image set, reducing output feature map scale, performing area pixel representing process, and performing foreground matting result obtaining process.
AU QUAN H
   SHEN Z
AE UNIV EAST CHINA NORMAL (UYEN-C)
GA 2018A48339
AB    NOVELTY - The method involves constructing a synthetic image set. A foreground image data set is constructed from a specific website. Format of a foreground image is collected. A background image is obtained from a background image set according to a random background image. A landscape image scaling factor generating process is performed. A background area pixel representing process is performed. A natural image data set is constructed. Natural image with clear foreground object target is selected. An output of multiple convolutional layers is normalized for performing a batch processing process. An output feature map scale is reduced. An image result predicting process is performed. The predicting process is divided into low resolution prediction and high resolution prediction. A foreground matting result obtaining process is performed.
   USE - Deep learning based image target extracting method.
   ADVANTAGE - The method enables avoiding data collecting uneven quality, defining structure of network and loss function to ensure quality and performance of learning model depth and realizing automatic image target extraction process to obtain fine image result of foreground target.
   DESCRIPTION OF DRAWING(S) - The drawing shows a photographic view illustrating a deep learning based image target extracting method.
DC T01 (Digital Computers)
MC T01-J05B2B; T01-J10B2; T01-J10B3A; T01-N01B3
IP G06T-007/12; G06N-003/04; G06N-003/08
PD CN109035267-A   18 Dec 2018   G06T-007/12   201909   Pages: 14   Chinese
AD CN109035267-A    CN10649490    22 Jun 2018
PI CN10649490    22 Jun 2018
UT DIIDW:2018A48339
ER

PT P
PN CN109034370-A
TI Method for simplifying convolutional neural network based on feature mapping pruning, involves re-training network to complete simplification of convolution layer, and simplifying next convolution layer until all layers are streamlined.
AU RUI T
   ZHOU Y
   ZOU J
   YANG C
   YUAN H
   WANG D
   LI H
   LU M
   TIAN H
   YIN Q
   AI Y
   ZHANG F
AE UNIV PLA ARMY ENG (UYPL-Non-standard)
GA 2018A5537V
AB    NOVELTY - The method involves dividing a classification task into multiple classes. A network convolution layer is trained by using a convolutional neural network. Input data of the convolution layer is mapped to output characteristics. A feature map is indexed according to Fisher quasi-test. An index of the feature map is measured to generate a correct classification result attribute. A convolution kernel is determined corresponding to the convolution layer. Gradable value groups are obtained according to index calculation operation. Indexing value groups are ordered from big to small to obtain an indexing sequence. A mutation point of a slope of the indexing sequence is determined. A network is re-trained until the network resumes performance before pruning to complete simplification of the convolution layer. Next convolution layer is simplified until all convolution layers are streamlined.
   USE - Method for simplifying a convolutional neural network based on feature mapping pruning.
   ADVANTAGE - The method enables retraining the network until the network resumes performance, obtaining an efficient network model without sacrificing performance, satisfying application requirements of the convolutional neural network with limited storage resources, effectively removing feature mapping of the network for performance improvement, reducing network scale, maintaining network performance, and increasing running speed of the network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for simplifying convolutional neural network based on feature mapping pruning. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J05B2
IP G06N-003/04
PD CN109034370-A   18 Dec 2018   G06N-003/04   201909   Pages: 12   Chinese
AD CN109034370-A    CN10678956    27 Jun 2018
PI CN10678956    27 Jun 2018
UT DIIDW:2018A5537V
ER

PT P
PN CN109032935-A
TI Phantom-go-rule based chessboard game perfect software model predicting method, involves generating loss function number of chessboard, and predicting position of chessboard according to loss function number of chessboard.
AU WANG J
   WANG Z
   PAN J
   CHI S
   GAO Q
   ZHOU T
AE UNIV CHINESE NORTHEASTERN (UYDB-C)
GA 2018A4881C
AB    NOVELTY - The method involves generating non-perfect information of a chess board. The non-perfect information of the chess board is sorted to obtain phantom-go-rules. The sorted information of the chessboard is extracted to obtain 243-dimensional Feature and an 81-dimensional label. A deep neural network is established. Weight initialization process is performed on the deep neural network by using momentum algorithm optimization process. Loss function number of the chessboard is generated. Position of the chessboard is predicted according to the loss function number of the chessboard.
   USE - Phantom-go-rule based chessboard game perfect software model predicting method.
   ADVANTAGE - The method enables obtaining optimal strategy of a chessboard game when opponent deviates from equalization strategy so as to avoid limitation of dual zero-sum game and multi-player game.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a phantom-go-rule based chessboard game perfect software model predicting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J15X; T01-J20C; T01-N03; W04-X02B1
IP G06F-011/36; G06F-017/50; G06N-003/04
PD CN109032935-A   18 Dec 2018   G06F-011/36   201909   Pages: 18   Chinese
AD CN109032935-A    CN10766850    13 Jul 2018
PI CN10766850    13 Jul 2018
UT DIIDW:2018A4881C
ER

PT P
PN CN109034365-A
TI Deep learning model training method, involves calculating loss value between prediction target and real target of training sample data, and adjusting depth learning model according to calculated loss value back propagation parameters.
AU WANG X
   LIU M
   XIAN J
AE UNIV ELECTRONIC SCI & TECHNOLOGY (UEST-C)
GA 2018A4844L
AB    NOVELTY - The method involves acquiring training sample data. Prediction target of the training sample data is obtained by using a set of loss functions based on a pre-established deep learning model and the training sample data. A loss value between the prediction target and a real target of the training sample data is calculated by each of the set of loss functions. A depth learning model is adjusted according to the calculated loss value back propagation parameters. Random value parameter is imparted corresponding to the depth learning model. The parameter in the deep learning model is adjusted according to the calculated loss value of each round.
   USE - Deep learning model training method.
   ADVANTAGE - The method enables realizing deep learning model training process in an accurate and efficient manner.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning model training device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning model training method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04A; T01-J07B; T01-J30A
IP G06N-003/02
PD CN109034365-A   18 Dec 2018   G06N-003/02   201909   Pages: 11   Chinese
AD CN109034365-A    CN10742536    06 Jul 2018
PI CN10742536    06 Jul 2018
UT DIIDW:2018A4844L
ER

PT P
PN CN109036376-A
TI Method for synthesizing voice in Minnan language, involves estimating synthesized spectral envelope and fundamental frequency parameters, and synthesizing corresponding speech signals.
AU WU J
   HE X
   TANG X
   GUO H
   SONG Y
AE UNIV NANJING SCI & TECHNOLOGY (UNSC-C)
GA 2018A55313
AB    NOVELTY - The method involves acquiring (100) corpus data to be synthesized. The corpus data is labeled to obtain training corpus data. A fundamental frequency parameter and a spectrum envelope in the training corpus data are obtained (200). The fundamental frequency parameter is trained (300) by using a hidden Markov model to obtain a single Gaussian hidden Markov model. A context-dependent restricted Boltzmann machine model training is performed (400) on the spectral envelope according to the single Gaussian hidden Markov model and the fundamental frequency parameter, and obtaining limited Boltzmann machine training data. A Gaussian fitting is performed (500) on the limited Boltzmann machine model training data to obtain a Gaussian model on a spectral envelope line. The synthesized spectral envelope and the fundamental frequency parameters are estimated (600) buy the Gaussian model, and the corresponding speech signals are synthesized.
   USE - Method for synthesizing voice in Minnan language.
   ADVANTAGE - The combination of hidden Markov model and restricted Boltzmann machine model improves the speech accuracy of Minnan synthesis. The accuracy is too smooth and high in spectrum modeling, and improves the sound quality of synthesized speech.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for synthesizing a voice in the Minnan language. (Drawing includes non-English language text)
   Step for acquiring corpus data to be synthesized (100)
   Step for obtaining a fundamental frequency parameter and a spectrum envelope in the training corpus data (200)
   Step for training the fundamental frequency parameter by using a hidden Markov model to obtain a single Gaussian hidden Markov model (300)
   Step for performing a context-dependent restricted Boltzmann machine model training (400)
   Step for performing a Gaussian fitting on the limited Boltzmann machine model training data (500)
   Step for estimating the synthesized spectral envelope and the fundamental frequency parameters (600)
DC W04 (Audio/Video Recording and Systems)
MC W04-V01; W04-V02; W04-V04C1; W04-V05
IP G10L-013/08; G10L-013/10; G10L-015/14; G10L-015/183; G10L-025/18; G10L-025/24
PD CN109036376-A   18 Dec 2018   G10L-013/08   201909   Pages: 12   Chinese
AD CN109036376-A    CN11206551    17 Oct 2018
PI CN11206551    17 Oct 2018
UT DIIDW:2018A55313
ER

PT P
PN CN109035812-A
TI Method for controlling traffic signal lamp by utilizing computer device, involves controlling traffic switching time of traffic signal lamp of preset road sections according to combined traffic state and Q-matrix.
AU WU Z
AE PING AN TECHNOLOGY SHENZHEN CO LTD (PING-C)
GA 2018A55342
AB    NOVELTY - The method involves performing depth learning process on traffic environment training data based on Q-Learning algorithm to establish a Q-matrix corresponding to a combined traffic state and combined intersection behavior. Total revenue of the combined traffic state of multiple preset road sections obtained by selecting the combined intersection behavior in the combined traffic state is determined based on Q-value in the Q-matrix. A traffic state of the preset road sections is obtained at preset period when current time is preset time. Traffic switching time of a traffic signal lamp of the preset road sections is controlled according to the combined traffic state and the Q-matrix.
   USE - Method for controlling a traffic signal lamp by utilizing a computer device (claimed).
   ADVANTAGE - The method enables training a Q-Learning algorithm model for realizing data modeling process, establishing the Q-matrix of traffic jam corresponding to selection action of traffic signal switching time, realizing control process of traffic signal lamp based on a reinforcement learning result of the Q-matrix during traffic jam, improving traffic condition by changing traffic switching time of traffic signal lamp and relieving traffic jam state.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for controlling a traffic signal lamp by utilizing a computer device
   (2) a storage medium for storing a set of instructions to control a traffic signal lamp by utilizing a computer device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for controlling a traffic signal lamp by utilizing a computer device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B4P; T01-J21C; T01-J30A
IP G08G-001/07; G06N-099/00
PD CN109035812-A   18 Dec 2018   G08G-001/07   201909   Pages: 18   Chinese
AD CN109035812-A    CN11029041    05 Sep 2018
PI CN11029041    05 Sep 2018
UT DIIDW:2018A55342
ER

PT P
PN CN109035253-A
TI Deep learning automatic image mapping method guided by semantic segmentation information, involves training deep learning model with collected data set to obtain trained deep learning model and performing direct input into model.
AU XU H
   LIU J
   CHEN J
   LI W
AE CHANGSHA PANODUX IMAGING TECHNOLOGY CO (CHAN-Non-standard)
GA 201900049Q
AB    NOVELTY - The method involves collecting (S1) a data set of an image to be scanned. A deep learning model for automatic image mapping is constructed (S2). The deep learning model is trained (S3) with the collected data set to obtain a trained deep learning model. The direct input is made (S4) into the trained deep learning model to quickly obtain the foreground target image for the image to be mapped. The deep learning model comprises a semantic segmentation sub-network, a fully connected conditional adjoining sub-network, and an automatic image mapping sub-network. The segmented image output is divided by the sub-network with the full-connection condition, and the morphological operation is combined to obtain a ternary graph. The ternary map is corrected by information such as color and gradient. The foreground target image is obtained by the classical Bayesian map algorithm based on the ternary map and the image to be mapped.
   USE - Deep learning automatic image mapping method guided by semantic segmentation information.
   ADVANTAGE - The map algorithm can automatically extract the foreground target, and eliminate the complicated user interaction operation. The method has the advantages of completely automatic drawing process, simple and convenient operation, short drawing time and high precision of the drawing.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the deep learning automatic image mapping method guided by semantic segmentation information. (Drawing includes non-English language text)
   Step for collecting a data set of an image to be scanned (S1)
   Step for constructing deep learning model for automatic image mapping (S2)
   Step for training deep learning model with the collected data set to obtain a trained deep learning model (S3)
   Step for performing direct input into the trained deep learning model to quickly obtain the foreground target image for the image to be mapped (S4)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-J10B3B; T01-J16A; T01-J16C3; T01-J30A; T04-D04; T04-D08; T04-E
IP G06T-007/10; G06K-009/62
PD CN109035253-A   18 Dec 2018   G06T-007/10   201909   Pages: 7   Chinese
AD CN109035253-A    CN10724358    04 Jul 2018
PI CN10724358    04 Jul 2018
UT DIIDW:201900049Q
ER

PT P
PN CN109033505-A
TI Deep learning based ultra-rapid cooling temperature control method, involves determining activation function by adopting optimizing algorithm is Adam algorithm, completing data accumulation process, and determining expansion function.
AU ZHANG T
   TIAN Y
   WANG B
   ZHANG Z
   LI J
   LI Y
   WANG Z
   WANG G
AE UNIV CHINESE NORTHEASTERN (UYDB-C)
GA 2018A4866X
AB    NOVELTY - The method involves initially collecting influence factors and temperature controlling factors under field or laboratory test conditions. Cooling process data is pre-processed by adopting main component analysis function. Large weight influence factor is sent to an input layer unit and an output layer unit. Cooling time of a steel plate is set according to requirements. A neural network frame is established. Activation function is determined by adopting optimizing algorithm is Adam algorithm. Data accumulation process is completed. Timing expansion function is determined.
   USE - Deep learning based ultra-rapid cooling temperature control method.
   ADVANTAGE - The method enables fully processing the cooling process data to ensure segmental cooling hit, fully considering cooling effect factor model to increase accuracy and robustness of cooling control model after rolling, effectively reducing system online debugging time, learning cost and development period and determining whether lower hit rate reaches 96.3%.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based ultra-rapid cooling temperature control method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J15X; T01-N01B3A
IP G06F-017/50; G06N-003/04
PD CN109033505-A   18 Dec 2018   G06F-017/50   201909   Pages: 13   Chinese
AD CN109033505-A    CN10603507    06 Jun 2018
PI CN10603507    06 Jun 2018
UT DIIDW:2018A4866X
ER

PT P
PN CN109019335-A
TI Depth learning based hoisting safety distance detecting method, involves determining central point coordinates of worker and hook, and performing hoisting safety distance monitoring process based on vertical projection point.
AU ZHAO X
   ZHANG Y
   ZHANG M
   YANG Z
AE UNIV DALIAN TECHNOLOGY (UYDA-C)
GA 2018A5221W
AB    NOVELTY - The method involves fixing a tower crane on a monitoring device for obtaining a boom position (1). Data collecting process is performed (2) by deep learning algorithm. A detection model is trained (3) to locate workers and hooks in an image. Left upper corner and right lower corner point coordinates are displayed (4). Pixel length of the hook in the image is calculated (5) according to positioning information in a detection result. Pixel distance between the hook and the worker is calculated. Central point coordinates of the worker and hook are determined. Hoisting safety distance monitoring process is performed (6) based on a vertical projection point.
   USE - Depth learning based hoisting safety distance detecting method.
   ADVANTAGE - The method enables effectively reducing workers and hook identifying and locating problem in the image so as to realize safety distance detection process with high precision.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a depth learning based hoisting safety distance detecting method. '(Drawing includes non-English language text)'
   Step for fixing a tower crane on monitoring device for obtaining boom position (1)
   Step for performing data collecting process by deep learning algorithm (2)
   Step for training detection model to locate workers and hooks in image (3)
   Step for displaying left upper corner and right lower corner point coordinates (4)
   Step for calculating pixel length of hook in image according to positioning information in detection result (5)
   Step for performing hoisting safety distance monitoring process based on vertical projection point (6)
DC Q38 (Hoisting; Lifting; Hauling; Trucks (B66)); T01 (Digital Computers); X25 (Industrial Electric Equipment)
MC T01-J10B3A; T01-J16C2; T01-J30A; X25-F05
IP B66C-013/16; B66C-023/88
PD CN109019335-A   18 Dec 2018   B66C-013/16   201909   Pages: 12   Chinese
AD CN109019335-A    CN11027136    04 Sep 2018
PI CN11027136    04 Sep 2018
UT DIIDW:2018A5221W
ER

PT P
PN CN109002629-A
TI Multiphase flow simulation and visualization convolutional neural network structure, has generation network formed with analysis layer, and up-sampling convolution kernel is adapted to generate visible or analog data during recovery process.
AU CAI X
AE SUZHOU HUIDE SIMULATION TECHNOLOGY CO (SUZH-Non-standard)
GA 2018A3751S
AB    NOVELTY - The structure has an analyzing network divided into multi-layer structure to represent multi-scale characteristics of a multi-phase flow visualization system. A generation network is matched with a structure of the analysis network. The generation network is formed with an analysis layer for recovering middle layer data in recovery process by recursive mode. An up-sampling convolution kernel is adapted to generate visible or analog data during recovery process. The convolution kernel acts in local range if different time frames are associated with preset frames.
   USE - Multiphase flow simulation and visualization convolutional neural network structure.
   ADVANTAGE - The structure selects proper convolution kernel function to generate kernel function for approximating common multi-phase flow system function with high precision, operates the analyzing network and the generation network in parallel manner after training the neural network, and realizes large scale rapid calculation and visualization of a multi-phase flow system.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a convolutional neural network based on multi-phase flow simulation and visualization method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network based on multi-phase flow simulation and visualization method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J15H
IP G06F-017/50; G06N-003/04; G06N-003/08
PD CN109002629-A   14 Dec 2018   G06F-017/50   201909   Pages: 11   Chinese
AD CN109002629-A    CN10860971    01 Aug 2018
PI CN10860971    01 Aug 2018
UT DIIDW:2018A3751S
ER

PT P
PN CN109003282-A
TI Image processing method, involves dividing characteristic region by binary mask output based on output of binary mask, performing first dynamic image fusion by image frame, and obtaining second dynamic image.
AU CHEN G
AE BOE TECHNOLOGY GROUP CO LTD (BOEG-C)
GA 2018A3437Y
AB    NOVELTY - The method involves obtaining a static image by a characteristic region. The characteristic region is divided by a binary mask output based on output of binary mask. First dynamic image fusion is performed by an image frame. A second dynamic image is obtained. The static image is processed by a deep convolutional neural network. Extracted semantic feature layer is formed using a preset optimizing network. An optimization network is established by characteristic learning under scale merging and interpolation processing. The optimized network is trained to a feature area. Dynamic image decomposition is performed in an image frame sequence.
   USE - Image processing method.
   ADVANTAGE - The method enables improving display effect of image fusion.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) an image processing device
   (2) a computer storage medium for storing set of instructions for processing an image.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an image processing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E01C; T01-J05B2A; T01-J10B1; T01-J10B2; T01-J16C3; T01-N01B3; T04-J01
IP G06T-007/11; G06T-005/50
PD CN109003282-A   14 Dec 2018   G06T-007/11   201909   Pages: 15   Chinese
AD CN109003282-A    CN10847581    27 Jul 2018
PI CN10847581    27 Jul 2018
UT DIIDW:2018A3437Y
ER

PT P
PN CN109002855-A
TI Method for identifying fermentation degree of black tea based on convolutional neural network, involves determining black tea fermentation degree by using identification module of supervisory control and data acquisition system.
AU CHEN H
   SUN C
   ZHOU X
   TANG Z
AE CHANGSHA XIANGFENG INTELLIGENT EQUIP CO (CHAN-Non-standard)
GA 2018A3447P
AB    NOVELTY - The method involves collecting a black tea fermentation picture by using a supervisory control and data acquisition (SCADA). A black tea production line is selected as a training set of 8000 four fermentation stages of a convolutional neural network (CNN). CNN training process is performed, where a structure of the CNN is formed with an input layer, a convolution layer, a pool layer, a connecting layer and an output layer. Black tea fermentation degree is determined by using a black tea fermentation degree identification module of the SCADA system to perform continuous fermentation of black tea.
   USE - Method for identifying fermentation degree of black tea based on a convolutional neural network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of a method for identifying fermentation degree of black tea based on a convolutional neural network. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J10B2; T01-N01B3
IP G06K-009/62; G06N-003/04
PD CN109002855-A   14 Dec 2018   G06K-009/62   201909   Pages: 10   Chinese
AD CN109002855-A    CN10803331    20 Jul 2018
PI CN10803331    20 Jul 2018
UT DIIDW:2018A3447P
ER

PT P
PN CN109002774-A
TI Convolutional neural network-based fatigue monitoring device, has face location unit provided with image collecting module, and image collecting module, image pre-processing module, and detecting and locating module connected together.
AU DONG D
   ZHANG X
   HUANG Y
   WAN Y
   MU G
   ZHU K
   SU X
AE UNIV TSINGHUA TIANJIN ADVANCED EQUIP RES (UYQI-C)
GA 2018A3449U
AB    NOVELTY - The device has a face locating unit, a characteristic extracting unit, a calculating and analyzing unit and an output unit orderly connected together. The face location unit is provided with an image collecting module i.e. high definition camera, an image pre-processing module, and a detecting and locating module. The image collecting module, the image pre-processing module, and the detecting and locating module are orderly connected together. The characteristic extracting unit is provided with a convolution processing module and a state detecting module. A learning module is connected with the state detecting module.
   USE - Convolutional neural network-based fatigue monitoring device.
   ADVANTAGE - The device uses a neural network for locating human face characteristic point, and improves accuracy of fatigue recognition through input of large amount of data and adjustment of network parameters.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a convolutional neural network-based fatigue monitoring method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a convolutional neural network-based fatigue monitoring device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W05 (Alarms, Signalling, Telemetry and Telecontrol)
MC T01-E01A; T01-G11B; T01-J04B2; T01-J10B2A; T01-N01B3; T01-N02B2; W05-B07E
IP G06K-009/00; G06K-009/46; G06N-003/04; G08B-021/06
PD CN109002774-A   14 Dec 2018   G06K-009/00   201909   Pages: 11   Chinese
AD CN109002774-A    CN10687882    28 Jun 2018
PI CN10687882    28 Jun 2018
UT DIIDW:2018A3449U
ER

PT P
PN CN109003260-A
TI CT image pulmonary nodules detecting method, involves acquiring electronic computer tomography scanning CT image, and performing probability values fusion processing operation to obtain candidate classification result of saving area.
AU DOU Q
   LIU Q
   CHEN H
AE SHENZHEN IMSIGHT MEDICAL TECHNOLOGY CO (SHEN-Non-standard)
GA 2018A3438G
AB    NOVELTY - The method involves acquiring an electronic computer tomography scanning CT image. CT image pixel division processing operation is performed through a three-dimensional convolutional neural pixel pre-divided network to obtain a CT image. Connecting domain probability is determined to obtain a candidate nodule area corresponding to a probabilistic marking. A prediction model is established by using a different three-dimensional convolutional neural network classifier corresponding to the candidate nodule area. Probability values are obtained corresponding to the candidate nodule area. Probability values fusion processing operation is performed to obtain a candidate classification result of a saving area. CT image sub-area division processing operation is performed.
   USE - CT image pulmonary nodules detecting method.
   ADVANTAGE - The method enables realizing automatic CT image detecting technology, and improving CT image pulmonary nodules detecting precision.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a CT image pulmonary nodules detecting device
   (2) a readable storage medium for storing a set of instructions for detecting CT image pulmonary nodules.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a CT image pulmonary nodules detecting method. '(Drawing includes non-English language text)'
DC S03 (Scientific Instrumentation); T01 (Digital Computers)
MC S03-E06B3A; T01-J05B2; T01-J10B1; T01-J10B2; T01-J10B3A; T01-N01E
IP G06T-007/00; G06T-007/11; G06T-007/187; G06T-003/40
PD CN109003260-A   14 Dec 2018   G06T-007/00   201909   Pages: 15   Chinese
AD CN109003260-A    CN10695624    28 Jun 2018
PI CN10695624    28 Jun 2018
UT DIIDW:2018A3438G
ER

PT P
PN CN109003304-A
TI Depth learning technology based camera angle movement detecting system, has verification input module determining whether abnormality is present in camera angle, and result output module obtaining identification result of normal angle.
AU FANG C
   GAO Y
   ZHOU Q
AE NANJING YUNJITANG INFORMATION TECHNOLOGY (NANJ-Non-standard)
GA 2018A3437D
AB    NOVELTY - The system has a learning unit provided with a sample input module, a sample labeling module and a neural network training module. A verification unit is provided with a verification input module, a deep learning model and a result output module. The sample input module inputs a sample of a container image for training. The sample labeling module labels the image as a positive sample of normal angle and a negative sample of angle abnormality. The verification input module inputs the image of the container to be verified. The verification input module determines whether abnormality is present in the camera angle. The result output module obtains an identification result of the normal angle.
   USE - Depth learning technology based camera angle movement detecting system.
   ADVANTAGE - The system automatically identifies the abnormal angle of the camera by using the deep learning technology, and reduces driver's cheating behavior by moving the camera angle.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a depth learning based camera angle movement detecting method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a depth learning technology based camera angle movement detecting system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W02 (Broadcasting, Radio and Line Transmission Systems); W05 (Alarms, Signalling, Telemetry and Telecontrol)
MC T01-N01B3; W02-F01A5; W05-B05
IP G06T-007/73; G06N-003/04; G08G-001/017; H04N-007/18; G08B-025/10
PD CN109003304-A   14 Dec 2018   G06T-007/73   201909   Pages: 8   Chinese
AD CN109003304-A    CN10766323    12 Jul 2018
PI CN10766323    12 Jul 2018
UT DIIDW:2018A3437D
ER

PT P
PN CN109002844-A
TI Deep learning-based diabetic retinal image classification method, involves inputting extracted image to convolutional neural network after completing classification function, and outputting expression vector of retina image.
AU GAO J
   WU Y
AE UNIV HARBIN SCI & TECHNOLOGY (UYHS-C)
GA 2018A34480
AB    NOVELTY - The method involves collecting a three-dimensional retina image. Data of the three-dimensional retina image is input to a template generation module. Noise variance median filtering process is performed on the three-dimensional retina image by using a median filtering module. Pre-processing and characteristic extraction function is performed on the three-dimensional retina image to obtain an extracted image. The extracted image is classified. The extracted image is input to convolutional neural network after completing classification function. An expression vector of the three-dimensional retina image is output by using a deep neural network.
   USE - Deep learning-based diabetic retinal image classification method.
   ADVANTAGE - The method enables improving retinal image classification effect, classification precision and classification accuracy in an effective manner.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning-based diabetic retinal image classification method. '(Drawing includes non-English language text)'
DC B04 (Natural products and polymers. Including testing of body fluids (other than blood typing or cell counting), pharmaceuticals or veterinary compounds of unknown structure, testing of microorganisms for pathogenicity, testing of chemicals for mutagenicity or human toxicity and fermentative production of DNA or RNA. General compositions.); T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC B11-C08J; B11-C11; B12-K04G; T01-J05B2; T01-J10B1; T01-J10B2; T01-N01B3; T04-D03A; T04-D04
IP G06K-009/46; G06K-009/62; G06T-005/00; G06T-007/00
PD CN109002844-A   14 Dec 2018   G06K-009/62   201909   Pages: 5   Chinese
AD CN109002844-A    CN10706344    02 Jul 2018
PI CN10706344    02 Jul 2018
UT DIIDW:2018A34480
ER

PT P
PN CN109003280-A
TI Double-channel vascular intima ultrasonic image blood vessel dividing method, involves combining test set image with original image to form two-channel image, and determining intimal boundary of segmented blood vessel by segmentation model.
AU GUO S
   WU Y
   QIAO Y
   REN L
   LIANG W
   HUANG M
AE UNIV SOUTH CHINA TECHNOLOGY (UYSC-C)
GA 2018A34380
AB    NOVELTY - The method involves performing anisotropic diffusion filtering process on a training sample set image. The filtered training sample set image is combined with an original image to form a two-channel training sample set image. A depth learning segmentation model is established. The training set image is input into the depth learning segmentation model by using neighborhood gradient maximum pool. The anisotropic diffusion filtering process is performed on a test set image. The filtered test set image is combined with the original image to form a two-channel test set image. Intimal boundary of segmented blood vessel is determined by the trained depth learning segmentation model.
   USE - Double-channel vascular intima ultrasonic image blood vessel dividing method.
   ADVANTAGE - The method enables accurately and effectively extracting intimal area of the blood vessel.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a double-channel vascular intima ultrasonic image blood vessel dividing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B1; T01-J10B2; T01-J30A; T04-D07D3
IP G06T-007/11; G06N-003/04
PD CN109003280-A   14 Dec 2018   G06T-007/11   201909   Pages: 10   Chinese
AD CN109003280-A    CN10734361    06 Jul 2018
PI CN10734361    06 Jul 2018
UT DIIDW:2018A34380
ER

PT P
PN CN109002927-A
TI Recurrent neural network based oilfield exploration prediction method, involves obtaining training data of recurrent neural network, and inputting annual base data into recursion neural network model to generate prediction output.
AU HE J
   ZHANG Y
   LIU C
   SUI G
   LI L
   SHENG Q
   GAO S
   WANG X
AE CHINA PETROLEUM & CHEM CORP (SNPC-C)
   SINOPEC SHENGLI OILFIELD CO GEOPHYSICAL (SNPC-C)
GA 2018A3445T
AB    NOVELTY - The method involves obtaining basic data of a recursive neural network. The basic data is pre-processed. Preliminary process is performed on the basic data. An internal relation is established between the basic data to generate integrated data. A recursive neural network model is established. Training data of a recurrent neural network is obtained. Annual base data is input into the recursion neural network model to generate a prediction output. Well exploration degree is calculated. Accumulated deposit number is determined, where original base data includes format and order. The original base data is screened.
   USE - Recurrent neural network based oilfield exploration prediction method.
   ADVANTAGE - The method enables realizing accurate prediction of oil field exploration.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a recurrent neural network based oilfield exploration prediction method. '(Drawing includes non-English language text)'
DC H01 (Obtaining crude oil and natural gas - including exploration, drilling, well completion, production and treatment. General off-shore platform and drilling technology is included together with the treatment of tar sands and oil shales (C10G, E21B).); T01 (Digital Computers)
MC H01-A; T01-E01A; T01-J05B4P; T01-N01A2; T01-N01B3
IP G06Q-010/04; G06Q-050/02; G06N-003/08
PD CN109002927-A   14 Dec 2018   G06Q-010/04   201909   Pages: 10   Chinese
AD CN109002927-A    CN10855341    30 Jul 2018
PI CN10855341    30 Jul 2018
UT DIIDW:2018A3445T
ER

PT P
PN CN109003231-A
TI Method for enhancing image in display device, involves obtaining illumination pattern, inputting image to be processed and illumination pattern into image enhancement neural network model, and outputting enhanced image.
AU HE Y
AE GUANGZHOU SHIYUAN ELECTRONICS TECHNOLOGY (GUAZ-C)
GA 2018A34395
AB    NOVELTY - The method involves constructing an image enhancement neural network model. An illumination pattern is obtained corresponding to an image to be processed. The image to be processed and the illumination pattern are input into the image enhancement neural network model. The enhanced image is output. A training set is constructed, where the training set comprises multiple sets of training data and each set of training data includes an original image. The convolutional neural network model is trained by using the training set to obtain an image enhanced neural network model.
   USE - Method for enhancing an image in a display device (claimed).
   ADVANTAGE - The method enables constructing the image enhancement neural network model to remove illumination changes in the image to be processed according to the input illumination layer, thus improving enhancement effect of the image.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for enhancing an image in a display device
   (2) a computer storage medium for storing a set of instructions for enhancing an image in a display device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for enhancing an image in a display device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B1; T01-L02; T01-N01B3
IP G06T-005/00
PD CN109003231-A   14 Dec 2018   G06T-005/00   201909   Pages: 12   Chinese
AD CN109003231-A    CN10596553    11 Jun 2018
PI CN10596553    11 Jun 2018
UT DIIDW:2018A34395
ER

PT P
PN CN109003274-A
TI Pulmonary tuberculosis and tumor diagnosis differentiating method, involves inputting pre-processed CT image into deep convolutional neural network to perform tuberculosis-tumor differentiation process, where diagnostic result is outputted.
AU HUANG W
   XUE Y
   HU L
   HE J
   NI H
   PENG G
   ZHU J
   WU Y
AE UNIV GUANGZHOU (UNGZ-C)
GA 2018A34385
AB    NOVELTY - The method involves collecting a CT image to-be-identified. Possible tuberculosis and tumor parts are extracted from the CT image to-be -identified. Preset marking template of the pulmonary tuberculosis part and the tumor part is obtained. Marked CT image to-be-identified is pre-processed. The pre-processed CT image to-be-identified is inputted into a trained deep convolutional neural network for performing tuberculosis and tumor differentiation process, where diagnostic result is outputted. Gaussian filtering process is performed on the CT image to-be-identified.
   USE - Pulmonary tuberculosis and tumor diagnosis differentiating method.
   ADVANTAGE - The method enables accurately improving doctor accuracy in judging tuberculosis and lung tumors to avoid irreparable damage, and reducing noise so as to improve contrast.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a pulmonary tuberculosis and tumor diagnosis differentiating device
   (2) a computer readable storage medium for storing set of instructions for a pulmonary tuberculosis and tumor diagnosis differentiating method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a pulmonary tuberculosis and tumor diagnosis differentiating method. '(Drawing includes non-English language text)'
DC S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S05-D02A1; S05-D06; S05-D08A; T01-J10B2; T01-N01E1
IP G06T-007/00; G06N-003/04; G16H-030/20; G16H-050/20
PD CN109003274-A   14 Dec 2018   G06T-007/00   201909   Pages: 13   Chinese
AD CN109003274-A    CN10852410    27 Jul 2018
PI CN10852410    27 Jul 2018
UT DIIDW:2018A34385
ER

PT P
PN CN109002771-A
TI Recursive neural network-based remote sensing image classification method, involves performing flattening processing operation, inputting image block sequence, and classifying recursive neural network to obtain final classification result.
AU HUO L
   TANG P
   ZHENG K
AE CHINESE ACAD SCI EMOTE SENSING & DIGITAL (CAYS-C)
GA 2018A3449V
AB    NOVELTY - The method involves sampling a to be classified remote sensing image according to sample sampling strategy. A quantization value of the remote sensing image is re-mapped. Spatial resolution range is obtained according to the remote sensing image. Space window size of serialized process sequence is set according to selected space. An image block is identified in four directions. A flattening processing operation is performed on the image block. Flattened image block sequence are input into a recurrent neural network. A recursive neural network is classified to obtain a final classification result.
   USE - Recursive neural network-based remote sensing image classification method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a recursive neural network-based remote sensing image classification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2; T01-J10B2; T01-J10D; T04-D03; T04-D04
IP G06K-009/00; G06K-009/46; G06K-009/62; G06N-003/04; G06N-003/08
PD CN109002771-A   14 Dec 2018   G06K-009/00   201909   Pages: 9   Chinese
AD CN109002771-A    CN10666413    26 Jun 2018
PI CN10666413    26 Jun 2018
UT DIIDW:2018A3449V
ER

PT P
PN CN109003240-A
TI Parallel CNN based on multi-scale image de-noising method, involves constructing multi-scale parallel convolutional neural network model, and inputting noise image to image denoising model after outputting image.
AU JIA X
   CHAI H
   GUO Y
   HUANG Y
   ZHAO B
   LING L
   MA T
AE UNIV ANHUI SCI & TECHNOLOGY (UYLG-C)
GA 2018A3438Y
AB    NOVELTY - The method involves constructing a multi-scale parallel convolutional neural network model. Multi-scale parallel training parameters of the convolutional neural network model are obtained. A training unit is constructed. Mean square error and loss functions are determined. The loss functions are minimized by the multi-scale parallel convolutional neural network model to obtain an image denoising model. A noise image is inputted to the image denoising model after outputting the image. The noise image is inputted. Characteristic fusion is determined.
   USE - Parallel CNN based on multi-scale image de-noising method.
   ADVANTAGE - The method enables retaining edge information and detail information of the image to remove noise so as to improve structure similarity of the image to obtain a high quality noise-removing image.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view illustrating an operation of a parallel CNN based on multi-scale image de-noising method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B1; T01-N01B3
IP G06T-005/00; G06N-003/04; G06N-003/08; G06T-005/50
PD CN109003240-A   14 Dec 2018   G06T-005/00   201909   Pages: 13   Chinese
AD CN109003240-A    CN10777558    16 Jul 2018
PI CN10777558    16 Jul 2018
UT DIIDW:2018A3438Y
ER

PT P
PN CN109002766-A
TI Facial expression recognition method, involves performing to-be-identified image face detection process, and determining face region input depth by pre-training separable convolution neural network to obtain identification result.
AU JING X
   ZHU Y
   HUANG H
   TIAN L
AE UNIV BEIJING POSTS & TELECOM (UBPT-C)
GA 2018A3741R
AB    NOVELTY - The method involves obtaining a to-be identified image. To-be-identified image face detection process is performed. Detected human face region intercepting process is performed. Face region input depth is determined by a pre-training separable convolution neural network to obtain expression identification result. Weight parameter of the convolutional neural network is obtained. Face region convolution processing operation is carried out. Fusion analysis convolution result is obtained. Sensitivity of each neuron layer is calculated according to a rear propagation algorithm.
   USE - Facial expression recognition method.
   ADVANTAGE - The method enables reducing calculation amount in expression recognition process.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a facial expression recognition device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a facial expression recognition method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J10B2A; T04-D04; T04-D07D3; T04-D07F1
IP G06K-009/00; G06K-009/62
PD CN109002766-A   14 Dec 2018   G06K-009/00   201909   Pages: 25   Chinese
AD CN109002766-A    CN10649059    22 Jun 2018
PI CN10649059    22 Jun 2018
UT DIIDW:2018A3741R
ER

PT P
PN CN109003271-A
TI Depth YOLO learning algorithm based wire harness connector cable quality detecting method, involves conveying qualified to-be-detected wire harness connector product to qualified product area if system detects qualified product.
AU LI H
AE JIANGSU ZHUOSHU INTELLIGENT MFG CO LTD (JIAN-Non-standard)
GA 2018A3754B
AB    NOVELTY - The method involves obtaining a product sample. Sample images of multiple wire harness connectors are obtained. The obtained sample images are labeled for marking a defective area on each sample image to form a complete data set. Iterative training operation is executed on the marked sample images by using a deep learning YOLO algorithm. A cylinder in a wire harness connector locating mechanism is triggered by a sensor to locate a to-be-detected wire harness connector on a center line position of a conveyor belt. A qualified to-be-detected wire harness connector product is conveyed to a qualified product area if a system detects a qualified product.
   USE - Depth YOLO learning algorithm based wire harness connector cable quality detecting method.
   ADVANTAGE - The method enables utilizing enhanced depth learning YOLO algorithm to increase detecting precision and detecting efficiency, increasing detecting speed to reach 45FPS on GPU for TITAN and avoiding need of pause during product transfer process so as to realize defects detection process with strong applicability.
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-J16C2; T01-J30A; T01-L03; T04-D04
IP G06T-007/00; G06K-009/62
PD CN109003271-A   14 Dec 2018   G06T-007/00   201909   Pages: 5   Chinese
AD CN109003271-A    CN10822680    25 Jul 2018
PI CN10822680    25 Jul 2018
UT DIIDW:2018A3754B
ER

PT P
PN CN109003251-A
TI Method for purifying air based on image detection, involves arranging dual-camera subassembly on high-adaptive dust-removing push-pull window, and capturing position of push-pull window to obtain left and right side scene images.
AU LI J
AE LI J (LIJJ-Individual)
GA 2018A3438N
AB    NOVELTY - The method involves providing a high-adaptive dust-removing push-pull window to purify air, where the high-adaptive dust-removing sliding window comprises an SD memory device to store two height thresholds and parameters of a deep neural network identification mode. A dual-camera subassembly is arranged on a wall of the high-adaptive dust-removing push-pull window, where the dual-camera subassembly includes two cameras. Position of the high-adaptive dust-removing push-pull window is captured by using the cameras to obtain a left side scene image and a right side scene image.
   USE - Method for purifying air based on image detection.
   ADVANTAGE - The method enables improving dust removal efficiency of a household device and air purifying efficiency.
   DESCRIPTION OF DRAWING(S) - The drawing shows a front view of a high-adaptive dust-removing push-pull window.
DC Q48 (Blinds, shutters, doors and windows (E06B)); T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T04-K03D
IP G06T-007/00; G06T-007/11; E06B-003/46; E06B-007/28
PD CN109003251-A   14 Dec 2018   G06T-007/00   201909   Pages: 9   Chinese
AD CN109003251-A    CN10099797    01 Feb 2018
PI CN10099797    01 Feb 2018
CP CN109003251-A
      CN103471512-A   CHINA TRIUMPH INT ENG CO LTD (CHNB)   WANG C, LIU L, LIU X, ZHANG R, PENG S
      CN103973957-A   SHANGHAI BAYUNSHUI SCI & TECHNOLOGY DEV CO LTD (SHAN-Non-standard)   DONG H, SU Z, WANG C
      CN104929496-A   UNIV WUHAN TECHNOLOGY (WUHT)   DONG K, LIU D, LI H, JI Y, CHEN Z, TUO X, ZHANG L, ZHOU C
      CN106708084-A   CHINESE ACAD SCI AUTOMATION INST (CAZD)   ZENG Y, ZHAO F, WANG G
CR CN109003251-A
      : "", ,relevantClaims[1-8],relevantPassages[609-613]
UT DIIDW:2018A3438N
ER

PT P
PN CN109002863-A
TI Compact convolutional neural network-oriented resource limited system, has compact module for selecting each branch single convolutional layer, where compact module reduces input of each branch of channel number of convolution kernel layers.
AU LI Y
   ZHANG D
   WU Z
   LI X
AE UNIV SUN YAT-SEN FOSHAN SHUNDE RES INST (UYSY-C)
   SYSU-CMU SHUNDE INT JOINT RES INST (SYSU-Non-standard)
   UNIV SUN YAT-SEN (UYSY-C)
GA 2018A3741F
AB    NOVELTY - The system has an original input, a feature convolution structure, multiple micro-structures and an average pooling layer sequentially connected together. The micro-structure formed with a middle layer and a maximum pool layer by a setting module. The middle layer is connected to the maximum pool layer by ReLU. A compact module performs multi-scale filtering, multi-position pooling, filter decomposition and parameter reduction. The compact module selects an each branch single convolutional layer that is replaced by a multi-layer convolution kernel. The compact module reduces input of each branch of channel number of the convolution kernel layers.
   USE - Compact convolutional neural network-oriented resource limited system.
   ADVANTAGE - The system can strengthen abstract representation of an input image, which improves recognition efficiency and resource limited, and appropriately reduces network depth of a computer system so as to reduce computer resource consumption.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a compact convolutional neural network-oriented resource limited method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J10B1; T01-J10B2A; T01-J10B3A; T01-J16C2; T04-D04
IP G06K-009/66; G06N-003/04
PD CN109002863-A   14 Dec 2018   G06K-009/66   201909   Pages: 8   Chinese
AD CN109002863-A    CN10682103    27 Jun 2018
PI CN10682103    27 Jun 2018
UT DIIDW:2018A3741F
ER

PT P
PN CN109002767-A
TI Method for verifying human face image based on deep learning, involves calculating similarity of human faces to be verified based on human face feature information, and obtaining verification result of human faces to be verified.
AU LI Y
   CHEN X
   FU Q
   JIN H
   YANG M
   CAI L
   LIU C
AE EVERSEC BEIJING TECHNOLOGY CO LTD (EVER-Non-standard)
GA 2018A34500
AB    NOVELTY - The method involves constructing a first image set based on multiple first images. A second image set is constructed based on multiple second images. A human face detection model is trained according to the first image set. A feature extraction model is trained according to the second image set. A to-be-detected human face image is input into the human face detection model. Human face images to be verified are extracted. A corrected face images to be verified is processed by using the feature extraction model. Human face feature information in the human face images to-be-verified is extracted. Similarity of human faces to be verified is calculated based on the human face feature information. A verification result of human faces to be verified is obtained.
   USE - Method for verifying a human face image based on deep learning.
   ADVANTAGE - The method enables accurately detecting the human face image so as to improve application range and human face recognition accuracy in effective manner.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a system for verifying a human face image based on deep learning.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for verifying a human face based on deep learning. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W04 (Audio/Video Recording and Systems)
MC T01-J04A; T01-J10B1; T01-J10B2A; T01-J30A; T04-D03; T04-D04; T04-D07F1; W04-W05A
IP G06K-009/00; G06K-009/46; G06K-009/62
PD CN109002767-A   14 Dec 2018   G06K-009/00   201909   Pages: 15   Chinese
AD CN109002767-A    CN10650388    22 Jun 2018
PI CN10650388    22 Jun 2018
UT DIIDW:2018A34500
ER

PT P
PN CN109002755-A
TI Face image based age estimation model construction method, involves performing face detection process on images, taking image feature set as input, taking age tag set as output, and establishing regression model to obtain estimation model.
AU PENG J
   LI F
   LI Z
   WANG J
   ZHANG Y
   ZHU X
   TANG W
AE UNIV NORTHWEST (UYXB-C)
GA 2018A34508
AB    NOVELTY - The method involves performing face detection process on multiple images. A part of the image is intercepted as a face image. Multiple face images are stored as an original face image set. Multiple human face images are divided into two groups. LBP features of each human face image are extracted in a first image set to obtain a first LBP feature of each human face image. The first image feature set is taken as input. A first age tag set is taken as output. An XGBoost regression model is trained to obtain a first age estimation model. A second image feature set is taken as input. A second age tag set is taken as output. The XGBoost regression model is established to obtain a second age estimation model.
   USE - Face image based age estimation model construction method.
   ADVANTAGE - The method enables effectively reducing color difference caused by influence of Inception-V3 deep convolutional neural network, avoiding estimated convolution layer parameter error caused by problem of keeping texture information, and adopting a distributed learning algorithm and the Inception-V3 depth convolutional neural network by the depth tag, and improving feasibility and effectiveness of theoretical analysis and experimental verification process by using transfer learning pair data for network tuning.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a face image based age estimation method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a face image based age estimation model construction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J10B2; T01-J10B3B; T01-J16C2; T04-D03; T04-D04; T04-D07F1; T04-D08; T04-K03B
IP G06K-009/00; G06K-009/46; G06K-009/62
PD CN109002755-A   14 Dec 2018   G06K-009/00   201909   Pages: 16   Chinese
AD CN109002755-A    CN10563826    04 Jun 2018
PI CN10563826    04 Jun 2018
UT DIIDW:2018A34508
ER

PT P
PN CN109002834-A
TI Multi-modality characteristic based fine-grained image classifying method, involves combining monitoring target of detection network with monitoring target of network training time, and obtaining visual characteristics of image.
AU QI G
   XU H
   XU K
AE UNIV SOUTHEAST (UYSE-C)
GA 2018A34488
AB    NOVELTY - The method involves determining identification field and image data set field. A classification label corresponding to visual properties of human construction set is obtained according to a to-be-classified image. Synonym word and context word are extracted from existing synonym and context vocabulary. A low-dimension vector expression of the classification label is obtained in a knowledge base space. Domain text of the to-be-classified image is extracted from encyclopedia text by using a search engine. A monitoring target of a detection network is combined with a monitoring target of network training time. Visual characteristics of the to-be-classified image are obtained through an entire network.
   USE - Multi-modality characteristic based fine-grained image classifying method.
   ADVANTAGE - The method enables designing a depth learning model to learn characteristics of different layers of the to-be-classified image by the detection network and a classifying network, and combining the to-be-classified image with semantic vector expression of the classification label so as to improve accuracy of fine-grained image classification.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a multi-modality characteristic based fine-grained image classifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J05B4F; T01-J10B1; T01-J10B2; T01-J16A; T01-J16C3; T01-N01B3; T01-N02B2; T01-N03A2
IP G06K-009/62; G06F-017/30; G06N-003/04
PD CN109002834-A   14 Dec 2018   G06K-009/62   201909   Pages: 12   Chinese
AD CN109002834-A    CN10627958    15 Jun 2018
PI CN10627958    15 Jun 2018
UT DIIDW:2018A34488
ER

PT P
PN CN109002761-A
TI Deep convolutional neural network based pedestrian recognition monitoring system, has identification monitoring device determining whether measured pedestrian image is target pedestrian image according to target pedestrian feature.
AU QU W
   XU Z
   WANG J
   XIAO Z
   LIAO J
   QIU Z
   WAN Z
AE UNIV SUN YAT-SEN XINHUA COLLEGE (UYSY-C)
GA 2018A34505
AB    NOVELTY - The system has a video collecting device collecting a measured pedestrian image. A pedestrian database stores a target pedestrian image. An identification monitoring device identifies the measured pedestrian image from the video collecting device and obtains the target pedestrian image from the pedestrian database, and applies a deep convolutional neural network to learn target pedestrian features by using the target pedestrian image. The identification monitoring device determines whether the measured pedestrian image is the target pedestrian image according to the target pedestrian feature.
   USE - Deep convolutional neural network based pedestrian recognition monitoring system.
   ADVANTAGE - The system effectively reduces adverse influence of multiple recognition robustness factor to improve similarity pedestrian target matching accuracy rate.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of a deep convolutional neural network based pedestrian recognition monitoring system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B4F; T01-J10B2A; T01-J10E; T01-N01B3; T01-N02B2B
IP G06K-009/00; G06K-009/62; G06N-003/04; G06N-003/08
PD CN109002761-A   14 Dec 2018   G06K-009/00   201909   Pages: 15   Chinese
AD CN109002761-A    CN10604209    13 Jun 2018
PI CN10604209    13 Jun 2018
UT DIIDW:2018A34505
ER

PT P
PN CN109002857-A
TI Deep learning based automatic video style transformation and generating method, involves performing user preferences analyzing operation, and updating deep learning framework for establishing feedback learning model.
AU SHE Y
   CHEN Y
AE UNIV XIAMEN (UYXI-C)
GA 2018A3447M
AB    NOVELTY - The method involves performing training operation in a style model by utilizing a deep learning framework. Style processing parameter of the style model is obtained by utilizing a product identification module. A to-be-processed user video and user video request are obtained. Type of to-be-processed video is automatically identified by utilizing the product identification module. Rendering operation is performed in style processing parameter. User preferences analyzing operation is performed. The deep learning framework is updated for establishing a feedback learning model.
   USE - Deep learning based automatic video style transformation and generating method.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based automatic video style transformation and generating system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based automatic video style transformation and generating method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W03 (TV and Broadcast Radio Receivers); W04 (Audio/Video Recording and Systems)
MC T01-J10B2; T01-J30A; W03-A16C5; W03-A18A6; W04-W05A
IP G06K-009/62; H04N-021/466
PD CN109002857-A   14 Dec 2018   G06K-009/62   201909   Pages: 10   Chinese
AD CN109002857-A    CN10812471    23 Jul 2018
PI CN10812471    23 Jul 2018
UT DIIDW:2018A3447M
ER

PT P
PN CN109001679-A
TI Convolutional neural network based indoor sound source region localization method, involves obtaining classification result and visualizing final test results with tensorboard tool.
AU SUN H
   ZHANG X
   WANG S
   XU J
   ZHAI B
AE UNIV HEBEI TECHNOLOGY (UYHT-C)
GA 2018A3475B
AB    NOVELTY - The method involves building a signal model is in an unstructured indoor environment. The single fixed sound source is set in a two-dimensional space for an array consisting of microphones. The sound signal received by each microphone. The Gaussian white noise is added to the sound signal. The attenuation model of sound energy is constructed indicates that the microphone is received at the distance. The test sample is predicted by the trained convolutional neural network model. The test of convolutional neural networks is performed. The classification result is obtained in the location of the area to which the sound source belongs in the indoor to-be-positioned area. The final test results are visualized with the tensorboard tool.
   USE - Convolutional neural network based indoor sound source region localization method.
   ADVANTAGE - The accuracy of sound source area location is improved. The complexity of the network model is reduced.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of the convolutional neural network.
DC T01 (Digital Computers); W06 (Aviation, Marine and Radar Systems)
MC T01-J05B2; W06-A03F
IP G01S-005/20
PD CN109001679-A   14 Dec 2018   G01S-005/20   201909   Pages: 17   Chinese
AD CN109001679-A    CN10611930    14 Jun 2018
PI CN10611930    14 Jun 2018
UT DIIDW:2018A3475B
ER

PT P
PN CN109002529-A
TI Audio searching method, involves searching character code of target audio in preset audio library, searching known audio according to Hamming distance between character codes of target audio, and obtaining audio retrieval result.
AU WANG C
AE XIAMEN MEITUZHIJIA TECHNOLOGY CO LTD (XIAM-Non-standard)
GA 2018A3455W
AB    NOVELTY - The method involves extracting multiple audio characteristics of target audio to obtain target audio characteristic combination. The target audio characteristic combination is input into a pre-training depth learning model to obtain predetermined number of depth characteristic vectors. Each depth characteristic vector is converted to obtain multiple binary character codes corresponding to the target audio according to a preset threshold value. A character code of the target audio is searched in a preset audio library, where the preset audio library is included with multiple known audios and multiple character codes corresponding to the known audio. The known audio is searched according to Hamming distance between character codes of the target audio. An audio retrieval result is obtained.
   USE - Audio searching method.
   ADVANTAGE - The method enables searching audio corresponding to audio characteristic in an effective manner, realizing audio retrieval process without affecting audio length in an effective manner, and improving audio searching efficiency.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for an audio searching device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an audio searching method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-C08A; T01-G01A; T01-J05B3; T01-J30A; W04-V01; W04-V05; W04-W05A
IP G06F-017/30; G10L-025/18; G10L-025/24
PD CN109002529-A   14 Dec 2018   G06F-017/30   201909   Pages: 14   Chinese
AD CN109002529-A    CN10781178    17 Jul 2018
PI CN10781178    17 Jul 2018
UT DIIDW:2018A3455W
ER

PT P
PN CN109002037-A
TI Deep learning based multi-robot cooperation path following method, involves connecting speed conversion module with speed command receiving module and aerial robot speed vector and driving cooperative motion of robot group.
AU WANG H
   DING B
   LIU H
   GENG M
   SHI P
   ZHOU X
   LI Y
AE UNIV PLA NAT DEFENCE TECHNOLOGY (UNDT-C)
GA 2018A34673
AB    NOVELTY - The method involves receiving a signal mark by a cooperative identification decision module. A ground classification label probability vector or a fusion classification label probability vector is obtained. Classification label probability vector conversion process is performed. A speed conversion module is connected with a speed command receiving module and an aerial robot speed vector through a connection channel to a ground robot. Cooperative motion of a robot group is driven according to a velocity vector.
   USE - Deep learning based multi-robot cooperation path following method.
   ADVANTAGE - The method enables improving accuracy of route identification.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a multi-robot cooperation path following method. '(Drawing includes non-English language text)'
DC T06 (Process and Machine Control)
MC T06-B01A; T06-D07B
IP G05D-001/02
PD CN109002037-A   14 Dec 2018   G05D-001/02   201909   Pages: 22   Chinese
AD CN109002037-A    CN10680721    27 Jun 2018
PI CN10680721    27 Jun 2018
UT DIIDW:2018A34673
ER

PT P
PN CN109002890-A
TI Method for modeling convolutional neural network by electronic device, involves utilizing parameters by neurons of convolutional layer, and testing trained convolutional neural network model by using test data set.
AU WANG Y
   TANG W
   SHI S
AE UNIV BEIHANG (UNBA-C)
GA 2018A3446S
AB    NOVELTY - The method involves training (S1) a pre-constructed convolutional neural network model i.e. DeepID network model, by using a training data set to obtain a trained convolutional neural network model. Parameters of a convolution kernel are randomly set when constructing the convolutional neural network model. The parameters are utilized by neurons of a convolutional layer to connect with neurons of a previous layer. The trained convolutional neural network model is tested (S2) by using a test data set.
   USE - Method for modeling a convolutional neural network by an electronic device (claimed).
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for modeling a convolutional neural network by an electronic device
   (2) a non-transitory computer-readable storage medium for storing set of instruction for modeling a convolutional neural network by an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for modeling convolutional neural network by electronic device. '(Drawing includes non-English language text)'
   Step for training pre-constructed convolutional neural network model by using training data set to obtain trained convolutional neural network model (S1)
   Step for testing trained convolutional neural network model by using test data set (S2)
DC T01 (Digital Computers)
MC T01-J04B2; T01-N01B3A; T01-S03
IP G06N-003/08; G06N-003/04
PD CN109002890-A   14 Dec 2018   G06N-003/08   201909   Pages: 15   Chinese
AD CN109002890-A    CN10759256    11 Jul 2018
PI CN10759256    11 Jul 2018
UT DIIDW:2018A3446S
ER

PT P
PN CN109002711-A
TI Deep learning-based malicious code determination system, has report generation module for obtaining homologous database information, and browser end for configuring malicious code uploaded executable files.
AU WU Y
   JIANG Y
   ZOU F
AE UNIV SHANGHAI JIAOTONG (USJT-C)
GA 2018A3451C
AB    NOVELTY - The system has a server end provided with a homologous database module, an automatic shelling module and a visualization module. An automatic module is provided with a shell module. The visualization module configures a shell-less visual processing malicious code sample. A depth learning module extracts abstract characteristic of a convolutional neural network and learns sequence of a door circulation unit neural network. A report generation module obtains homologous database information. A browser end configures homologous determine report generated malicious code uploaded executable files.
   USE - Deep learning-based malicious code determination system.
   ADVANTAGE - The system has better system universality and rationality, and ensures homologous judging ability of random malicious code.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning-based malicious code determination method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of a malicious code determination system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B4P; T01-J12C; T01-N01B3; T01-N01D3; T01-N02B1B; T01-N02B3; T01-N03A1
IP G06F-021/56; G06N-003/04
PD CN109002711-A   14 Dec 2018   G06F-021/56   201909   Pages: 12   Chinese
AD CN109002711-A    CN10564657    04 Jun 2018
PI CN10564657    04 Jun 2018
UT DIIDW:2018A3451C
ER

PT P
PN CN109002847-A
TI Index deep belief network based axial piston pump multi-fault diagnosis method, involves establishing time-domain, frequency-domain and time-frequency domain indicator data set to acquire test sample for finally determining fault type.
AU XIANG J
   WANG S
   JIANG Y
   ZHONG Y
AE UNIV WENZHOU (UYWE-Non-standard)
GA 2018A3447W
AB    NOVELTY - The method involves pre-defining fault modes of various types of axial piston pumps and received an original vibration signal (S1). Time domain statistic analysis operation is performed (S2) on the original vibration signal to perform frequency domain metric analysis and time-frequency domain energy analysis operations to establish indicator data set corresponding to the pre-defining fault modes. Training samples of the pre-defining failure modes are acquired (S3) by utilizing time domain indicators, frequency domain indicators and time-frequency domain indicators. Time-domain, frequency-domain and time-frequency domain indicator data set are established (S4) for a to-be-monitored fault signal to acquire test sample for finally determining fault type.
   USE - Index deep belief network based axial piston pump multi-fault diagnosis method.
   ADVANTAGE - The method enables effectively solving multi-fault identification problem of an axial plunger pump.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an index deep belief network based axial piston pump multi-fault diagnosis method. '(Drawing includes non-English language text)'
   Step for pre-defining fault modes of various types of axial piston pumps (S1)
   Step for performing time domain statistic analysis operation (S2)
   Step for acquiring training samples of pre-defining failure modes (S3)
   Step for establishing time-domain, frequency-domain and time-frequency domain indicator data set (S4)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J03; T01-J10B2; T01-N01B3A; T04-D04
IP G06K-009/62
PD CN109002847-A   14 Dec 2018   G06K-009/62   201909   Pages: 17   Chinese
AD CN109002847-A    CN10725071    04 Jul 2018
PI CN10725071    04 Jul 2018
UT DIIDW:2018A3447W
ER

PT P
PN CN109002769-A
TI Deep neural network-based cow face alignment method, involves outputting coordinates of cow face key point by cow face key point positioning model, and aligning cow face according to coordinates of cow face key points in positioning model.
AU XIE S
AE DEEPFINCH HENGJI TECHNOLOGY CO LTD (DEEP-Non-standard)
GA 2018A3449X
AB    NOVELTY - The method involves pre-processing calibrated sample data for normalizing sample data. An image of the sample data is simultaneously scaled to obtain resolution size. A cow face key point positioning model is trained through a convolutional neural network. A to-be-located cow face image is located by using a trained bull face key point. Coordinates of a cow face key point in the to-be-located cow face image are output by the cow face key point positioning model. A cow face is aligned according to the coordinates of the cow face key points in the cow face key point positioning model. The cow face image is collected as a training sample and a testing sample.
   USE - Deep neural network-based cow face alignment method.
   ADVANTAGE - The method enables eliminating cow face different pose problems caused by preset shooting angle in shooting process, improving milk cow identification accuracy according to face recognition of facial action of milk cow and cow face, age and scene analysis.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep neural network-based cow face alignment system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep neural network-based cow face alignment method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-D03; T01-J10B2A; T01-J10B3A; T01-N01B3A; T04-D03; T04-D04; T04-D07D5; T04-D07F1
IP G06K-009/00; G06K-009/46; G06K-009/62; G06T-003/00; G06T-003/40
PD CN109002769-A   14 Dec 2018   G06K-009/00   201909   Pages: 12   Chinese
AD CN109002769-A    CN10652912    22 Jun 2018
PI CN10652912    22 Jun 2018
UT DIIDW:2018A3449X
ER

PT P
PN CN109003141-A
TI Outdoor media value evaluation method, involves determining predetermined static information of outdoor media in static attribute data module, and displaying outdoor media feeding value evaluation of chart data.
AU YANG C
AE YANG C (YANG-Individual)
GA 2018A34418
AB    NOVELTY - The method involves determining predetermined static information of outdoor media in a static attribute data module. An image of an outdoor media area is collected by using an image collecting module. The image is transmitted to an information extracting module. Traffic information in current image statistics of people is extracted based on image recognition algorithm of a convolutional neural network. The statistics of people and the traffic information are received by an information aggregation module. Service quality evaluation parameter of media advertisement period is obtained by a credit evaluation module. Outdoor media audience data is received by a media evaluation module generating module. Outdoor media feeding value evaluation of chart data is displayed.
   USE - Outdoor media value evaluation method.
   ADVANTAGE - The method enables quantifying metric of traditional media value and reaction medium value changes in time and achieving high practical value and high popularization value.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an outdoor media value evaluation method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J03; T01-J10B2A; T01-N01A2C; T01-N01D1B
IP G06Q-030/02; G06K-009/00
PD CN109003141-A   14 Dec 2018   G06Q-030/02   201909   Pages: 17   Chinese
AD CN109003141-A    CN10851680    30 Jul 2018
PI CN10851680    30 Jul 2018
UT DIIDW:2018A34418
ER

PT P
PN CN109002827-A
TI Vehicle component state identifying method, involves obtaining to-be-identified picture of vehicle components, identifying state of vehicle component according to to-be identified image, and obtaining output state of vehicle component.
AU YANG W
   LI Z
   ZHU L
   ZHANG D
AE DONGXIA DATONG BEIJING MANAGEMENT CONSUL (DONG-Non-standard)
GA 2018A3448E
AB    NOVELTY - The method involves obtaining a to-be-identified picture of vehicle components. A pre-processing to-be-identified picture is received. A to-be identified picture input pre-trained recognition model is established according to feature extraction information. State of a vehicle component is identified according to to-be identified image. Output state of the vehicle component is obtained. A training set is created. The training set is included with positive training set and negative training set. Deep learning identification model is created. Identification correct rate of the deep learning identification model is determined.
   USE - Vehicle component state identifying method.
   ADVANTAGE - The method enables identifying state of vehicle components in quick and accurate manner so as to improve processing and maintenance efficiency.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a vehicle component state identifying device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a vehicle component state identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J07D1; T01-J10B2A; T01-J30A; T04-D03; T04-D04
IP G06K-009/46; G06K-009/62
PD CN109002827-A   14 Dec 2018   G06K-009/46   201909   Pages: 13   Chinese
AD CN109002827-A    CN10596748    11 Jun 2018
PI CN10596748    11 Jun 2018
UT DIIDW:2018A3448E
ER

PT P
PN CN108994088-A
TI Principal component analysis dimension reduction based deep belief network hydraulic automatic gage control systems cylinder fault diagnosing method, involves constructing deep belief network model to operate control systems cylinder.
AU YANG Z
AE UNIV WUHAN SCI & TECHNOLOGY (UWSC-C)
GA 2018A3653M
AB    NOVELTY - The method involves collecting data by setting a sensor to collect hydraulic automatic gage control systems (HAGC) cylinder parameter signal under on a working state. Principal component analysis (PCA) calculation processing operation is performed according to set length to generate sample data based on PCA dimension reduction. Single -dimensional data is obtained corresponding to the working state of the HAGC cylinder. A characteristic signal is obtained. Deep belief network (DBN) training process is performed. A DBN model is constructed to operate a HAGC cylinder after processing the PCA dimension reduction for diagnosing fault according to test data.
   USE - PCA dimension reduction based DBN network HAGC cylinder fault diagnosing method.
   ADVANTAGE - The method enables improving adaptability and fault diagnosing efficiency.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a PCA dimension reduction based DBN network HAGC cylinder fault diagnosing device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a principal component analysis dimension reduction based deep belief network hydraulic automatic gage control systems cylinder fault diagnosing method. '(Drawing includes non-English language text)'
DC P51 (Rolling, drawing, extruding (B21B, C).); T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B4P; T01-J10B2; T01-N01B3A; T04-D04
IP B21B-038/00; G06K-009/62; G06N-003/04; G06N-003/08
PD CN108994088-A   14 Dec 2018   B21B-038/00   201909   Pages: 9   Chinese
AD CN108994088-A    CN10598042    12 Jun 2018
PI CN10598042    12 Jun 2018
UT DIIDW:2018A3653M
ER

PT P
PN CN109003223-A
TI Method for processing image in electronic device, involves dividing feature image set into two feature image subsets, and combining feature images with same original resolution to form feature image set of original resolution.
AU YU D
   WANG C
AE BEIJING ZIJIETIAODONG NETWORK TECHNOLOGY (BEIJ-Non-standard)
GA 2018A3439C
AB    NOVELTY - The method involves inputting a to-be-processed image to a convolutional neural network to obtain a feature image pyramid of the image, where the feature image pyramid comprises features of an image layer of original resolution. Transformation resolution is performed for the feature image pyramid to obtain a feature image set corresponding to the feature image pyramid, where feature images in the feature image set have same resolution. The feature image set is divided into two feature image subsets, where the feature image subsets comprise feature image with different original resolutions. The feature images with same original resolution are combined to form the feature image set of original resolution.
   USE - Method for processing an image in an electronic device (claimed).
   ADVANTAGE - The method enables improving accuracy of the convolutional neural network.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for processing an image in an electronic device
   (2) a computer readable storage medium for storing a set of instructions for processing an image in an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for processing an image in an electronic device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B3A; T01-J10D
IP G06T-003/00
PD CN109003223-A   14 Dec 2018   G06T-003/00   201909   Pages: 21   Chinese
AD CN109003223-A    CN10767342    13 Jul 2018
PI CN10767342    13 Jul 2018
UT DIIDW:2018A3439C
ER

PT P
PN CN109002881-A
TI FPGA based depth neural network fixed-point calculating method, involves quantizing entire values in filter of neural network as index power, and performing displacement and adding operation on image data to obtain convolution result.
AU YU F
   ZHANG J
   JING L
AE ZHENGZHOU YUNHAI INFORMATION TECHNOLOGY (INEI-C)
GA 2018A34471
AB    NOVELTY - The method involves performing fixed-point processing on image data. Floating point number in the image data is converted into fixed point number. Entire values in a filter of a neural network are quantized as an index power. Displacement and adding operation is performed on the image data after performing filter treatment and quantization operation to obtain a convolution result. The floating point number in the image data is converted into preset precision numbers. Values of the filter are gradually quantized in index power.
   USE - FPGA based depth neural network fixed-point calculating method.
   ADVANTAGE - The method enables making the deep neural network convolution process in a dot product operation for relatively inexpensive shift addition operation, and is realized the shift addition operation on the FPGA device based on the logic unit to fundamentally make the neural network in the operation process for dependent hardware, thus expanding parallelism of neural network unit on the FPGA device, calculation efficiency and energy consumption ratio.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a FPGA based depth neural network fixed-point calculating device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a FPGA based depth neural network fixed-point calculating method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); U13 (Integrated Circuits)
MC T01-E02A; T01-E02B; T01-E04; T01-F06; T01-J04A; T01-J04B2; T01-J10B1; T01-J10B2; T04-D03; T04-D04; U13-C04C
IP G06N-003/04; G06N-003/08; G06K-009/62
PD CN109002881-A   14 Dec 2018   G06N-003/04   201909   Pages: 10   Chinese
AD CN109002881-A    CN10690696    28 Jun 2018
PI CN10690696    28 Jun 2018
UT DIIDW:2018A34471
ER

PT P
PN CN109002889-A
TI Mobile device self-adapting iterative convolutional neural network model compressing method, involves evaluating compression end of convolutional neural network model, and selecting model with highest accuracy as compression model.
AU YU Z
   MA S
AE UNIV SOUTH CHINA TECHNOLOGY (UYSC-C)
GA 2018A3446T
AB    NOVELTY - The method involves performing data pre-processing operation according to training data. A to-be-compressed convolutional neural network is trained according to the pre-processed data based on the training data. A convolution neural network model with highest accuracy is selected as a to-be-compressed model. A to-be-compressed convolutional neural network model is compressed by performing adaptive iterative convolutional neural network model compression process. A compression end of a convolutional neural network model is evaluated. A model with highest accuracy is selected as a compression model.
   USE - Mobile device self-adapting iterative convolutional neural network model compressing method.
   ADVANTAGE - The method enables adaptively adjusting quantization scale, and determining parameters. The method enables improving model adaptive iterative compression accuracy, and supporting common convolutional neural network model compression process. The method enables compressing the convolutional neural network model to a specific digit according to requirement so as to efficiently compress the convolutional neural network model.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a mobile device self-adapting iterative convolutional neural network model. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-J04B2; T01-J05B4P; T01-N01B3; W01-A02A
IP G06N-003/08
PD CN109002889-A   14 Dec 2018   G06N-003/08   201909   Pages: 12   Chinese
AD CN109002889-A    CN10715248    03 Jul 2018
PI CN10715248    03 Jul 2018
UT DIIDW:2018A3446T
ER

PT P
PN CN109000876-A
TI Automatic encoder depth learning algorithm based flexible thin plate structure impact load identification method, involves processing impulse response data of SNS fiber to realize identification of position and intensity of impact load.
AU ZENG J
   YUAN H
   PAN X
   HUANG J
   CHEN M
   SI Y
   HE W
AE UNIV NANJING AERONAUTICS & ASTRONAUTICS (UNUA-C)
GA 2018A34954
AB    NOVELTY - The method involves designing a distributed coreless-single mode optical fiber sensor layout. A distributed sensor SNS fiber thin plate structure impact load monitoring system is constructed. Dynamic signals of impulse response are monitored and collected in real-time. Impact test data is recorded to generate a sample database by performing impact test on different positions and different energies. Plate structure impact sample base data is pre-processed. An automatic encoder is selected as a deep learning model to construct a network structure and train a learning neural network. Impulse response data of an SNS fiber is processed by using the trained model to realize identification of position and intensity of an impact load.
   USE - Distributed SNS multi-mode interference type optical fiber sensor and automatic encoder depth learning algorithm based flexible thin plate structure impact load identification method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a flexible thin plate structure. '(Drawing includes non-English language text)'
DC S02 (Engineering Instrumentation); T01 (Digital Computers); V07 (Fibre-optics and Light Control)
MC S02-J04A1; S02-J08; T01-J05B2B; T01-J05B4P; T01-J16C2; T01-N01B3A; T01-N01D; T01-N02B2B; V07-F01A1F; V07-N01
IP G01M-007/08
PD CN109000876-A   14 Dec 2018   G01M-007/08   201909   Pages: 15   Chinese
AD CN109000876-A    CN10399621    28 Apr 2018
PI CN10399621    28 Apr 2018
UT DIIDW:2018A34954
ER

PT P
PN CN109002853-A
TI Crop species and pest type combination identification method, involves extracting crop species characteristics, and obtaining first crop species evaluation value based on second crop species evaluation value and Bayesian probability value.
AU ZHANG C
   LI Y
   LU J
AE NINGXIA ZHIQI LIANSHAN TECHNOLOGY CO LTD (NING-Non-standard)
GA 2018A3741G
AB    NOVELTY - The method involves extracting crop species characteristics by using a preset depth full convolutional neural network. A crop species feature map is obtained. A pest type feature map is obtained by extracting pest type characteristics. A first pest type evaluation value is obtained by calculating the pest type map based on a preset multi-example learning fusion model. A Bayesian probability value of the crop species is obtained according to a preset training set and the first pest type evaluation value. A second pest type evaluation value is obtained according to the first pest type evaluation value and the pest type Bayesian probability value. A second crop species evaluation value is obtained based on the first crop species evaluation value and the crop species Bayesian probability value.
   USE - Crop species and pest type combination identification method.
   ADVANTAGE - The method enables increasing demand for training data for achieving high accuracy identification of crop types and types of pests and diseases.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a crop species and pest type combination identification device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a crop species and pest type combination identification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B2; T01-J16A; T01-N01B3
IP G06K-009/62; G06N-003/04
PD CN109002853-A   14 Dec 2018   G06K-009/62   201909   Pages: 15   Chinese
AD CN109002853-A    CN10788917    18 Jul 2018
PI CN10788917    18 Jul 2018
UT DIIDW:2018A3741G
ER

PT P
PN CN109003286-A
TI Depth learning and laser radar-based road segmentation method, involves performing pixel level matching process to image data, and correcting boundary part between targets by utilizing point cloud image of laser radar.
AU ZHANG C
   SUN H
   ZHANG W
AE UNIV SUZHOU AUTOMOBILE RES INST TSINGHUA (UYSU-Non-standard)
GA 2018A3437U
AB    NOVELTY - The method involves performing model training process to an end-to-end neural network. Image data of an input end is processed by the training model to obtain a road segmentation result. Pixel level matching process is performed to image data collected by a laser radar three- dimensional space calibration and image collecting module. A boundary part between targets is corrected by utilizing a point cloud image of a laser radar. Road image data is collected under various conditions. Road edge features are learned by utilizing a linear convolution layer.
   USE - Depth learning and laser radar-based road segmentation method.
   ADVANTAGE - The method enables realizing segmentation of lane lines in an accurate manner and achieving precise road division effect.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a depth learning and laser radar-based road segmentation method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J10B2; T01-J21; T01-N01B3
IP G06T-007/13; G06T-007/11; G06N-003/08; G06N-003/04; G06K-009/00
PD CN109003286-A   14 Dec 2018   G06T-007/13   201909   Pages: 7   Chinese
AD CN109003286-A    CN10836073    26 Jul 2018
PI CN10836073    26 Jul 2018
UT DIIDW:2018A3437U
ER

PT P
PN CN109002745-A
TI Deep learning and tracking technology based real-time lane line detecting method, involves predicting position of lane line in frame by executing Kalman tracking algorithm, and re-detecting lane line by key frame image.
AU ZHANG L
   WANG Z
   GAO Z
AE WUHAN AISIMBA TECHNOLOGY CO LTD (WUHA-Non-standard)
GA 2018A3450G
AB    NOVELTY - The method involves establishing a training data set. Related parameter of a convolutional neural network is determined. Training process is performed on a SegNet model based on a Full Convolutional Network (FCN) for realizing target segmentation process based on mass data. Image pre-processing and de-noising process are performed for dividing an interested area. A lane line is detected by using the SegNet model and a first key frame image. A position of the lane line is predicted in a frame by executing Kalman tracking algorithm. A lane line is re-detected by a second key frame image.
   USE - Deep learning and tracking technology based real-time lane line detecting method.
   ADVANTAGE - The method enables increasing lane line detection speed, improving image classification accuracy rate and lane line detection accuracy and effectively removing road shadow, reflection and natural artificial noise or interference.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning and tracking technology based real-time lane line detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B1; T01-J10B2; T01-J16C2; T01-N01B3
IP G06K-009/00; G06K-009/66; G06N-003/04
PD CN109002745-A   14 Dec 2018   G06K-009/00   201909   Pages: 6   Chinese
AD CN109002745-A    CN10418031    06 Jun 2017
PI CN10418031    06 Jun 2017
UT DIIDW:2018A3450G
ER

PT P
PN CN109005060-A
TI Depth-learning application optimization framework based hierarchical heterogeneous distributed system utilizing method, involves performing task assignment in distributed system, and protecting user sensitive data by encryption module.
AU ZHANG Z
   MA R
   HUA Y
   SONG T
   GUAN H
AE UNIV SHANGHAI JIAOTONG (USJT-C)
GA 2018A3389D
AB    NOVELTY - The method involves providing an operation preparing period and a preset operation period, where depth neural network training is performed in the operation preparing stage. Task assignment process for various types of devices in a distributed system is performed in the operation stage. User sensitive data is protected by a data encryption module. The depth-neural network training is selected with different emphasis based on a deep neural network model. A needed neural network is established with sufficient computing capacity of a computing node. The depth neural network model is provided with a network structure and network layers.
   USE - Deep-learning application optimization framework based hierarchical heterogeneous distributed system utilizing method.
   ADVANTAGE - The method enables improving user experience based on the data encryption module of the neural network, performing privacy protection on the user sensitive data with low calculation cost and storage cost, improving user data security and reducing system response time.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a depth-learning application optimization framework based hierarchical heterogeneous distributed system utilizing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-D01; T01-N01A; T01-N01B3; T01-N01D; T01-N02B1B; W01-A05A; W01-A06A; W01-A06D; W01-A06F
IP H04L-012/24; H04L-029/06; H04L-029/08; G06N-003/04
PD CN109005060-A   14 Dec 2018   H04L-012/24   201909   Pages: 9   Chinese
AD CN109005060-A    CN10870834    02 Aug 2018
PI CN10870834    02 Aug 2018
UT DIIDW:2018A3389D
ER

PT P
PN CN109002715-A
TI Convolutional neural network based method for identifying malicious software, involves establishing convolutional neural network according to weighting parameter and malware probability and non-malicious probability of neural network.
AU ZHAO L
   SHI W
   LI D
   HUANG T
AE UNIV NORTHEASTERN QINHUANGDAO (UYDB-C)
GA 2018A34518
AB    NOVELTY - The method involves executing sample software for obtaining operation code and authority information, where type of the sample software is malicious software and non-malicious software. Operation code conversion is performed after pre-processing the operation code to the authority information. Data of mixed input convolutional neural network is selected as a feature matrix. Judgment is made to check whether accuracy of malware probability of a convolutional neural network reaches a set value. A convolutional neural network is established according to a weighting parameter and malware probability and non-malicious probability of the convolutional neural network.
   USE - Convolutional neural network based method for identifying malicious software.
   ADVANTAGE - The method enables realizing malicious software identification with high identification precision and simple operation.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a convolutional neural network based malicious software identification system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a convolutional neural network based method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-D02; T01-J12C; T01-N02B1B; T01-N02B3; T01-N03
IP G06F-021/56
PD CN109002715-A   14 Dec 2018   G06F-021/56   201909   Pages: 11   Chinese
AD CN109002715-A    CN10730246    05 Jul 2018
PI CN10730246    05 Jul 2018
UT DIIDW:2018A34518
ER

PT P
PN CN109002807-A
TI SSD neural network based driving scene vehicle detecting method, involves collecting front image and input into final training model, and adopting suppression algorithm to remove excess detection frame for obtaining detection result.
AU ZHAO M
   SUN D
   JIA J
AE UNIV CHONGQING (UYCQ-C)
GA 2018A3448X
AB    NOVELTY - The method involves constructing data set and divided the data set into knife training set and test set. SqueezeNet is utilized as feature extraction network according to Caffe deep learning framework. To-be-detected six convolutional layers of the SqueezeNet network are selected to merge with a position regression layer and a category confidence discriminant layer for completing construction operation of a training network model. The training network model is initialized to establish a pre-training model. Multiple rounds of training operation are performed on the prepared data set by utilizing the pre-training model to establish a final training model. A front image is collected and input into the final training model. Non-maximum suppression algorithm is adopted to remove excess detection frame for obtaining detection result.
   USE - SSD neural network based driving scene vehicle detecting method.
   ADVANTAGE - The method enables accurately detecting vehicle target to improve environmental sensing capability of intelligent drive automobile.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a SSD neural network based driving scene vehicle detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J07D1; T01-J10B2; T01-N01B3A; T04-D04
IP G06K-009/00; G06K-009/62; G06N-003/04
PD CN109002807-A   14 Dec 2018   G06K-009/00   201909   Pages: 9   Chinese
AD CN109002807-A    CN10846201    27 Jul 2018
PI CN10846201    27 Jul 2018
UT DIIDW:2018A3448X
ER

PT P
PN CN109002764-A
TI Traffic sign image recognition model constructing method, involves geometrically correcting distorted traffic sign in to-be processed image by spatial transformation network, and outputting name of traffic sign by full-connection layer.
AU ZHAO X
   LIU Z
   GAO T
   XU J
   DONG M
   SHEN C
   FAN X
   YANG N
   LIN S
   LIAN X
   CHEN T
   WANG R
   ZHANG F
AE UNIV CHANGAN (UCHA-C)
GA 2018A34502
AB    NOVELTY - The method involves extracting portions of multiple original images. A traffic sign image set is obtained. A traffic sign label set is obtained. The traffic sign image set is selected as an input. The traffic sign label set is selected as an output for training an image recognition model. A traffic sign recognition model is obtained, where image recognition model comprises an image correction layer, a convolutional layer, a SPP layer, a first full-connection layer, a Softmax layer and a second full-connection layer. Distorted traffic sign is geometrically corrected in a to-be processed image by a spatial transformation network. A location of the traffic sign is output by the Softmax layer. A name of the traffic sign is output by the second full-connection layer.
   USE - Traffic sign image recognition model constructing method.
   ADVANTAGE - The method enables avoiding traffic sign recognition issues caused by distortion and deformation, and improving traffic sign recognition rate, establishing a traffic sign region extracting model on a ZF convolutional neural network, and setting extraction areas of four different scales for traffic sign area extraction, which improves traffic sign recognition accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a photograph of a traffic sign image recognition model.
DC T01 (Digital Computers)
MC T01-J10B2A; T01-N01B3
IP G06K-009/00; G06N-003/04
PD CN109002764-A   14 Dec 2018   G06K-009/00   201909   Pages: 12   Chinese
AD CN109002764-A    CN10628664    19 Jun 2018
PI CN10628664    19 Jun 2018
UT DIIDW:2018A34502
ER

PT P
PN CN109002463-A
TI Depth measurement model based text detection method, involves setting threshold value, calculating average distance between character in text line region, training depth measurement model, and filtering tested image to obtain text area.
AU ZHAO Y
   GANG Y
   LI W
   LIU S
   CHEN S
   XIONG X
   LIANG K
   ZHOU Y
   YANG Y
   HAO Y
   LIU J
   KANG R
AE GUIZHOU POWER GRID CORP INFORMATION (CSPG-C)
   UNIV NANJING (UNAJ-C)
   NANJING NARI INFORMATION & COMMUNICATION (SGCC-C)
GA 2018A3457F
AB    NOVELTY - The method involves capturing an input image by using a MSER detection algorithm for obtaining character level of a candidate region. A training data set is constructed in the character level according to a marked character area. A deep neural network is trained by using a classifier for classifying candidate character of the candidate area. A center point of the candidate area is selected. A small threshold value is set. Average distance between character is calculated in a text line region. A depth measurement model is trained. A tested image is filtered to obtain a final text area.
   USE - Depth measurement model based text detection method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a depth measurement model. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04A; T01-J05B4P; T01-J10B1; T01-J10B2; T01-N01B3
IP G06F-017/30; G06K-009/62
PD CN109002463-A   14 Dec 2018   G06F-017/30   201909   Pages: 14   Chinese
AD CN109002463-A    CN10568042    05 Jun 2018
PI CN10568042    05 Jun 2018
UT DIIDW:2018A3457F
ER

PT P
PN CN109003029-A
TI Deep learning based intelligent storehouse inspection method, involves transmitting two-dimension code content information to database, and determining type and number of hazardous chemicals in warehouse according to received data.
AU ZHENG Q
   WU J
   CHENG S
   YANG B
   LUO Z
   WENG D
   DAI L
   ZENG C
AE UNIV FUZHOU (UFZU-C)
GA 2018A3443N
AB    NOVELTY - The method involves collecting image data based on multi-thread technology. The image data is transmitted to an intelligent trolley terminal. The image data is received by a server. Two-dimensional code and marked chemical product information are identified based on deep learning detection algorithm. Angle information is transmitted to the intelligent trolley terminal. A two-dimension code content information reading process is performed. The two-dimension code content information is transmitted to a database. Type and number of hazardous chemicals in a warehouse are determined according to the received data.
   USE - Deep learning based intelligent storehouse inspection method.
   ADVANTAGE - The method enables reducing production cost.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of an intelligent storehouse. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); T05 (Counting, Checking, Vending, ATM and POS Systems)
MC T01-F02C3; T01-J05B4F; T01-N01A2; T01-N01B3; T01-N01D1B; T01-N01D2; T01-N01D3; T04-A03B1; T05-G03
IP G06Q-010/08; G07C-001/20; G06K-017/00
PD CN109003029-A   14 Dec 2018   G06Q-010/08   201909   Pages: 17   Chinese
AD CN109003029-A    CN10799888    20 Jul 2018
PI CN10799888    20 Jul 2018
UT DIIDW:2018A3443N
ER

PT P
PN CN109002926-A
TI High-accuracy photovoltaic power generation prediction model establishing method, involves overlapping BP neural network on last layer of DBN for supervised training, where BP neural network propagates error information.
AU ZHOU H
   ZHANG Y
   YANG L
   ZHENG X
   LIU Q
   WEI D
   GE S
AE UNIV CHINA JILIANG (UYJA-C)
GA 2018A3445U
AB    NOVELTY - The method involves utilizing a deep belief network for performing prediction. Layer-by-layer training data of restricted Boltzmann machines is processed. The deep belief network is tuned by adopting a BP algorithm. Time, current, voltage, temperature and different units of generating power data are processed. A RBM reconstruction error is reduced. A BP neural network is overlapped on a last layer of a DBN for supervised training, where the BP neural network propagates error information from top to bottom to the layer of RBM. A DBN network is tuned. The deep belief network is realized based on a spark computing framework.
   USE - High-accuracy photovoltaic power generation prediction model establishing method.
   ADVANTAGE - The method enables evaluating reliability of the prediction algorithm, and improving single host running efficiency and results.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a high-accuracy photovoltaic power generation prediction model establishing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); X15 (Non-Fossil Fuel Power Generating Systems)
MC T01-N01A2; T01-N01B3; T01-N02B1B; X15-A08
IP G06Q-010/04; G06Q-050/06; G06N-003/04
PD CN109002926-A   14 Dec 2018   G06Q-010/04   201909   Pages: 9   Chinese
AD CN109002926-A    CN10839539    27 Jul 2018
PI CN10839539    27 Jul 2018
UT DIIDW:2018A3445U
ER

PT P
PN CN109003219-A
TI Image information hiding method, involves generating multi-phase digital hologram of watermark image, and inserting pixels of multi-phase digital hologram of watermark image into pixels of corresponding position of host image.
AU ZOU W
   ZHUANG Z
   JIAO S
   LUO H
   XU C
AE UNIV SHENZHEN (UYSZ-C)
GA 2018A3439D
AB    NOVELTY - The method involves obtaining a host image pixel tolerance information hiding capacity matrix by weighting preset ratio according to a pixel intensity value and significance of a host image. A multi-phase digital hologram of a watermark image is generated according to a watermark image and the host image pixel tolerance information hiding capacity matrix. Pixels of the multi-phase digital hologram of the watermark image are inserted into pixels of a corresponding position of the host image. Significant extraction process is performed on the host image by adopting a deep learning mode.
   USE - Image information hiding method.
   ADVANTAGE - The method enables improving quality of decrypting watermark image.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) an image information decoding method
   (2) an image information decoding device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an image information hiding method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); V07 (Fibre-optics and Light Control)
MC T01-D01; T01-D02A; T01-J10B1; T01-J10D; T01-J12C; T01-J30A; T01-N02B1B; V07-F02C; V07-M
IP G06T-001/00; G06F-021/60
PD CN109003219-A   14 Dec 2018   G06T-001/00   201909   Pages: 14   Chinese
AD CN109003219-A    CN10792079    18 Jul 2018
PI CN10792079    18 Jul 2018
UT DIIDW:2018A3439D
ER

PT P
PN CN109003672-A
TI Deep learning based early lung cancer detection and classification integrated device, has model self-learning case database for receiving detection result to update server detection system when doctor confirms incorrect detection result.
AU ZOU W
   GAO C
   WANG Y
AE BEIJING RUIKEBANG TECHNOLOGY CO LTD (BEIJ-Non-standard)
GA 2018A3754V
AB    NOVELTY - The device has an early lung cancer detection case storage device connected with a hospital PACS system, where the early lung cancer detection case storage device is provided with a diagnosed case library module and a model self-learning cases base module. The early lung cancer detection case storage device sends detecting result to the diagnosed case library module and the hospital PACS system when a doctor confirms correct detection result after detection is completed. A model self-learning case database receives detection result uploaded by the doctor to update a server detection system when the doctor confirms incorrect detection result.
   USE - Deep learning based early lung cancer detection and classification integrated device.
   ADVANTAGE - The device reduces lack of data due to layered characteristics of CT images, and determines nodular information lost by network detection, and assists doctors in lung cancer diagnosis to reduce misdiagnosis.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based early lung cancer detection and classification integrated system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of a deep learning based early lung cancer detection and classification integrated device. '(Drawing includes non-English language text)'
DC S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S05-G02G3; S05-G02G9; T01-J05B2; T01-J05B4M; T01-J10B2; T01-N01B3; T01-N01D3; T01-N01E1
IP G16H-050/20; G16H-050/70; G06T-007/00; G06T-007/10
PD CN109003672-A   14 Dec 2018   G16H-050/20   201909   Pages: 17   Chinese
AD CN109003672-A    CN10776622    16 Jul 2018
PI CN10776622    16 Jul 2018
UT DIIDW:2018A3754V
ER

PT P
PN CN108972494-A
TI Humanoid manipulator gripping controlling system, has control module controlling 21-degrees-of-freedom five-finger imitating human mechanical arm according to different control modes to finish grasping of target object.
AU CHAO Y
   XIAO N
AE UNIV SOUTH CHINA TECHNOLOGY (UYSC-C)
GA 2018A2707E
AB    NOVELTY - The system has a device module comprising a 21-degrees-of-freedom five-finger imitating human mechanical arm, a 6-freedom mechanical arm, data gloves, a camera and a virtual simulation platform. A data obtaining module is connected with the camera to collect a grasping target picture and sensor data from the data gloves. A data processing module processes collected image data to identify a type and position of a to-be-grabbed object by generating a corresponding grasping plan. A control module controls the 6-freedom mechanical arm movement and the 21-degrees-of-freedom five-finger imitating human mechanical arm according to different control modes to finish grasping of a target object.
   USE - Humanoid manipulator gripping controlling system.
   ADVANTAGE - The system combines depth learning target identification and five-finger-imitating mechanism manual grasping control by emulating a virtual hand to timely display humanoid manipulator grasping control effect in intelligent and intuitive manner.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a humanoid manipulator gripping controlling system data processing method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a humanoid manipulator gripping controlling system data processing method. '(Drawing includes non-English language text)'
DC P62 (Hand tools, cutting (B25, B26).); T01 (Digital Computers); T06 (Process and Machine Control); X25 (Industrial Electric Equipment)
MC T01-J07B; T01-J10B2; T06-D07B; X25-A03E
IP B25J-003/00; B25J-009/16
PD CN108972494-A   11 Dec 2018   B25J-003/00   201909   Pages: 20   Chinese
AD CN108972494-A    CN10650621    22 Jun 2018
PI CN10650621    22 Jun 2018
UT DIIDW:2018A2707E
ER

PT P
PN CN108983187-A
TI EWC based online radar target recognition method, involves obtaining Fisher information matrix of data in range image training data, and obtaining correct target for each category as EWC-based online radar target recognition result.
AU CHEN B
   LIU Y
AE UNIV XIDIAN (UYXN-C)
GA 2018A2012A
AB    NOVELTY - The method involves determining batch original radar high-resolution off-image training data and batch original radar high-resolution range image test data. A target class of the batch original radar high-resolution range image training data and the batch original radar high-resolution range image test data is determined. A convolutional neural network model is established. A trained convolutional neural network is obtained according to the batch original radar high resolution image training data. A Fisher information matrix of data in the batch original radar high-resolution range image training data is obtained according to the trained convolutional neural network. A correct target for each category is obtained as an EWC-based online radar target recognition result.
   USE - EWC based online radar target recognition method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an EWC based online radar target recognition method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W06 (Aviation, Marine and Radar Systems)
MC T01-J10D; T01-N01B3A; W06-A04
IP G01S-007/41
PD CN108983187-A   11 Dec 2018   G01S-007/41   201909   Pages: 19   Chinese
AD CN108983187-A    CN10757440    11 Jul 2018
PI CN10757440    11 Jul 2018
UT DIIDW:2018A2012A
ER

PT P
PN CN108982508-A
TI Template matching and depth learning characteristic based plastic package IC chip defect detecting method, involves extracting pin region image in learning architecture to realize IC chip pin defect detection and classification.
AU CUI M
   ZHOU W
   ZHONG Y
   WU Y
AE JIANGSU VOCATIONAL COLLEGE AGRIC & FORES (JIAN-Non-standard)
GA 2018A2028P
AB    NOVELTY - The method involves carrying out an image collection and a IC chip image collecting process in a plastic packing process. A normal chip image and a defect image collected chip image are obtained for realizing an image pre- processing. Noise interference of characteristic information is filtered for performing a template matching and defect detection process. A IC chip positioning template and a character location template are established by using normal chip image acquisition. A pin region image is extracted in input trained pin depth of a defect recognition learning architecture to realize a IC chip pin defect detection and classification.
   USE - Template matching and depth learning characteristic based plastic package IC chip defect detecting method.
   ADVANTAGE - The method enables realizing IC chip character defect detection during plastic package in effective manner, finishing defect classification of the pin, increasing plastic package IC chip defect detecting accuracy and satisfying online detection requirement of IC chip in the plastic package.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram illustrating a template matching and depth learning characteristic based plastic package IC chip defect detecting method. '(Drawing includes non-English language text)'
DC A89 (Photographic, laboratory equipment, optical - including electrophotographic, thermographic uses.); S03 (Scientific Instrumentation); U11 (Semiconductor Materials and Processes)
MC A09-C; A12-E04; A12-E07C; S03-E04F; U11-D01A; U11-F01B3
IP G01N-021/88
PD CN108982508-A   11 Dec 2018   G01N-021/88   201909   Pages: 13   Chinese
AD CN108982508-A    CN10500001    23 May 2018
PI CN10500001    23 May 2018
UT DIIDW:2018A2028P
ER

PT P
PN CN108985442-A
TI Handwriting model training method involves using erroneous word training sample to train adjusted Chinese handwriting recognition model, and updating and adjusting weight and offset of Chinese handwriting recognition model.
AU GAO L
   ZHOU G
AE PINGAN TECHNOLOGY SHENZHEN CO LTD (PING-Non-standard)
GA 2018A33484
AB    NOVELTY - The method involves obtaining (S10) the standard Chinese character training sample, using the normative Chinese character training convolutional neural network and updating the convolutional nerve based on the batch gradient descent backward propagation algorithm. A non-canonical Chinese character training sample is obtained (S20) and the normative Chinese character recognition model is trained by using the non-canonical Chinese character, and the weight and offset of the text recognition model is updated in the specification by using a backward gradient propagation algorithm. A sample of the Chinese character is obtained (S30) to be tested and an error word whose recognition result does not match the real result is updated. The erroneous word training sample is used (S40) to train the adjusted Chinese handwriting recognition model, and the weight and offset of the Chinese handwriting recognition model are updated and adjusted.
   USE - Handwriting model training method.
   ADVANTAGE - The target Chinese handwriting recognition model with high recognition rate of handwriting can be obtained by adopting the handwritten model training method.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) a handwriting recognition method;
   (2) a handwriting model training device;
   (3) a computer device; and
   (4) a computer-readable storage medium storing instruction for handwriting model training.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a process of handwriting model training. (Drawing includes non-English language text)
   Step for obtaining the standard Chinese character training sample, using the normative Chinese character training convolutional neural network and updating the convolutional nerve based on the batch gradient descent backward propagation algorithm (S10)
   Step for obtaining non-canonical Chinese character training sample and training the normative Chinese character recognition model by using the non-canonical Chinese character, and updating the weight and offset of the text recognition model in the specification by using a backward gradient propagation algorithm (S20)
   Step for obtaining sample of the Chinese character to be tested and updating an error word whose recognition result does not match the real result (S30)
   Step for using erroneous word training sample is to train the adjusted Chinese handwriting recognition model, and updating and adjusting the weight and offset of the Chinese handwriting recognition model (S40)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2A; T01-N01B3; T01-S03; T04-D02; T04-D07A; T04-D07E
IP G06N-003/04; G06N-003/08; G06K-009/34
PD CN108985442-A   11 Dec 2018   G06N-003/04   201909   Pages: 24   Chinese
AD CN108985442-A    CN10564639    04 Jun 2018
PI CN10564639    04 Jun 2018
UT DIIDW:2018A33484
ER

PT P
PN CN108985444-A
TI Node inhibition based convolutional neural network pruning method, involves re-activating node of layer in network structure, removing corresponding node, and re-training network structure through sample data set to obtain final network.
AU GE Y
   GAO F
   LU S
   ZHANG Y
   LU J
AE UNIV ZHEJIANG TECHNOLOGY (UYZT-C)
GA 2018A1961X
AB    NOVELTY - The method involves reading a network weight file and a network configuration file to obtain an initial network structure. A target sample image is read. Node inhibition on network nodes in a neural network layer by layer is performed. Impact of node inactivation based on network loss function is calculated. The initial network structure is copied. Another network structure is obtained. A node from the last layer in a network structure set is selected. The node of the last layer in the network structure is re-activated. A corresponding node is removed. The network structure is re-trained through a sample data set to obtain a final network.
   USE - Node inhibition based convolutional neural network pruning method.
   ADVANTAGE - The method enables realizing compression and acceleration of the neural network, reducing calculation amount and a parameter number of the neural network, improving speeding up operation of the neural network, and reducing difficult application problems of deep learning in a real-scene.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a neural network structure. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2B; T01-N01D2
IP G06N-003/04; G06N-003/08
PD CN108985444-A   11 Dec 2018   G06N-003/04   201909   Pages: 6   Chinese
AD CN108985444-A    CN10765274    12 Jul 2018
PI CN10765274    12 Jul 2018
UT DIIDW:2018A1961X
ER

PT P
PN CN108985217-A
TI Deep space network based traffic sign identification method, involves determining image characteristics as characteristics of traffic signs, where traffic signs are classified by utilizing sotfmax classifier.
AU HOU Z
   ZHU J
   LIN E
   MO Y
   WANG T
   LIN J
AE UNIV CHANGZHOU (UNCZ-C)
GA 2018A1967E
AB    NOVELTY - The method involves extracting characteristics of a converted image at different stages of a network layer by utilizing an enhanced VGG network, where characteristics of different stages are fused. Variety of traffic sign image characteristics is determined. Smaller size convolution kernel is utilized to obtain detailed image characteristics for expression in the deep learning network layer by the enhanced VGG network. Spatial pyramid pooling process is performed on fusion characteristics to obtain specified size characteristics vector. Traffic signs in different classifiers are identified. Image characteristics are determined as characteristics of traffic signs, where traffic signs are classified by utilizing a sotfmax classifier.
   USE - Deep space network based traffic sign identification method.
   ADVANTAGE - The method enables effectively extracting image information by a space conversion network, and processing merged image features to obtain feature information of a traffic sign image by spatial pyramid process, and improving accuracy of identifying traffic sign images on basis of enhancing network characteristics.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep space network based traffic sign identification system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of a deep space network based traffic sign identification system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J10B2; T01-J10D; T01-N01B3; T04-D03
IP G06K-009/00; G06N-003/04; G06N-003/08
PD CN108985217-A   11 Dec 2018   G06K-009/00   201909   Pages: 20   Chinese
AD CN108985217-A    CN10751516    10 Jul 2018
PI CN10751516    10 Jul 2018
UT DIIDW:2018A1967E
ER

PT P
PN CN108983228-A
TI Far neural network based RCS near-far field conversion method, involves obtaining neural network by adjusting neural network control parameters, and inputting near-field RCS data into neural network to obtain far-field RCS data.
AU HU W
   LIU Y
   ZHANG W
   SUN J
   LV X
AE BEIJING INST TECHNOLOGY (BEIT-C)
GA 2018A20118
AB    NOVELTY - The method involves selecting neural network according to near-field measurement of radar echo data. A feed-forward neural network is selected if the radar echo data is single frequency point data. A convolutional neural network is selected if the radar echo data is multi-frequency data. Near-field RCS data and corresponding far-field RCS data are obtained as training samples. The neural network is obtained by adjusting neural network control parameters to satisfy error requirements. The near-field RCS data is input into the neural network in actual transformation to obtain the far-field RCS data.
   USE - Far neural network based RCS near-far field conversion method.
   ADVANTAGE - The method enables reducing numerical error caused by algorithm due to implementation of discrete.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a far neural network based RCS near-far field conversion method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W06 (Aviation, Marine and Radar Systems)
MC T01-E01B; T01-N01B3; W06-A04E3A; W06-A04H3
IP G01S-013/89; G01S-007/40
PD CN108983228-A   11 Dec 2018   G01S-013/89   201909   Pages: 10   Chinese
AD CN108983228-A    CN10752556    10 Jul 2018
PI CN10752556    10 Jul 2018
UT DIIDW:2018A20118
ER

PT P
PN CN108983320-A
TI Coastal typhoon extreme wind speed based numerical weather forecasting-artificial intelligent coupling prediction method, involves inputting data of friction speed to neural network, obtaining peak factor, and calculating maximum wind speed.
AU HUANG M
   XU Q
   WANG Y
   LOU W
   WU L
AE UNIV ZHEJIANG (UYZH-C)
GA 2018A20091
AB    NOVELTY - The method involves arranging an indicator in a target grid position. Average wind speed and square root speed are calculated. Initial and boundary conditions of an outermost-layer in a target grid position local region model are detected. A target position and friction speed are detected based on an artificial intelligence deep neural network model. A neuron number of hidden layer is determined by using a trial neural network model. Data of the friction speed is input to a deep neural network for training the deep neural network. A peak factor is obtained by using actual measurement. Maximum wind speed is calculated.
   USE - Coastal typhoon extreme wind speed based numerical weather forecasting-artificial intelligent coupling prediction method.
   ADVANTAGE - The method enables inputting mid-scale meteorological numerical mode analysis data and objective geographic information, detecting atmospheric complex physical processes, and predicting average wind speed and root mean square wind speed at a specific target location by using atmospheric motion equation simulation so as to reduce shortcoming problem of mathematical statistical prediction and artificial intelligent coupling predicting process.
   DESCRIPTION OF DRAWING(S) - The drawing shows a graphical view illustrating relationship between average wind speed and prediction time for predicting coastal typhoon extreme wind speed based numerical weather forecasting-artificial intelligent coupling. '(Drawing includes non-English language text)'
DC S02 (Engineering Instrumentation); S03 (Scientific Instrumentation); T01 (Digital Computers)
MC S02-G02; S03-D05; T01-J03; T01-N01B3
IP G01W-001/10; G01P-005/00
PD CN108983320-A   11 Dec 2018   G01W-001/10   201909   Pages: 14   Chinese
AD CN108983320-A    CN10306812    08 Apr 2018
PI CN10306812    08 Apr 2018
UT DIIDW:2018A20091
ER

PT P
PN CN108984775-A
TI Method for monitoring public opinion based on commodity reviews, involves obtaining unlabeled data from database and input data into neural network to obtain classification result is automatically stored in database.
AU HUANG W
   LI L
   LIN Y
   ZOU W
   XIA J
   XU L
AE NANJING XINBEI JINFU TECHNOLOGY CO LTD (NANJ-Non-standard)
   XYZ INSURANCE AGENT CO LTD (XYZI-Non-standard)
GA 2018A3351A
AB    NOVELTY - The method involves training the neural network according to the previously created neural network training parameter document. The batch size, learning rate and number of learning in the training parameter file are provided according to the neural network and other parameters. The review data is obtained from the database as neural network training data. The unlabeled data is obtained from the database and input the data into the neural network to obtain the classification result. The classification result is automatically stored in the database, the classification result is sampled, and the passed data is checked.
   USE - Method for monitoring public opinion based on commodity reviews.
   ADVANTAGE - The method combines various deep learning algorithms and innovative data processing methods, and the discrimination of negative comments and the detection of negative comment points enable enterprises to maintain a corporate image. The method can effectively transform unstructured comment data into structured, analyzable structured data.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a commodity review-based public opinion monitoring system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart illustrating the method for monitoring public opinion based on commodity reviews. (Drawing includes non-English language text)
   Step for combining the public comment data into a corpus (101)
   Step for constructing neural network (102)
   Step for using the page operation script to log into the e-commerce platform (103)
   Step for selecting the category for the question (104)
   Step for obtaining two-dimensional matrix of dimensions length (105)
DC T01 (Digital Computers)
MC T01-J05B2B; T01-J05B4P; T01-N01A2C; T01-N01A2F; T01-N01B3; T01-N01D2; T01-N02B2
IP G06F-017/30; G06N-003/04; G06N-003/08
PD CN108984775-A   11 Dec 2018   G06F-017/30   201909   Pages: 14   Chinese
AD CN108984775-A    CN10818724    24 Jul 2018
PI CN10818724    24 Jul 2018
UT DIIDW:2018A3351A
ER

PT P
PN CN108985343-A
TI Deep neural network based automobile damage detection method, involves performing fusion evaluation on damage detection result of appearance component, and outputting damage component and confidence value of automobile.
AU HUANG X
AE DEEPFINCH HENGJI TECHNOLOGY CO LTD (DEEP-Non-standard)
GA 2018A1964C
AB    NOVELTY - The method involves obtaining an automobile damage detection picture at an angle. An appearance component of the automobile damage detection picture is detected. A position and a type of the appearance component are determined. Damage detection is performed on the appearance component by utilizing a deep convolutional neural network. A fusion evaluation is performed on a damage detection result of the appearance component. A damage component and a confidence value of an automobile are outputted. A segmentation operation is performed on the automobile damage detection picture by utilizing a segmentation algorithm. A divided position and a type of the appearance component in the automobile are determined.
   USE - Deep neural network based automobile damage detection method.
   ADVANTAGE - The method enables obtaining extremely high accuracy and recall rate, ensuring convenient and simple utilization and improving the efficiency of promotion and automobile damage detection.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep neural network based automobile damage detection system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep neural network based automobile damage detection method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J07D1; T01-J10B2; T04-D03; T04-D04
IP G06K-009/62; G06K-009/46
PD CN108985343-A   11 Dec 2018   G06K-009/62   201909   Pages: 11   Chinese
AD CN108985343-A    CN10653240    22 Jun 2018
PI CN10653240    22 Jun 2018
UT DIIDW:2018A1964C
ER

PT P
PN CN108985276-A
TI Method for designing vision AI algorithm system using camera device, involves sending selected recognition rule to cloud server, and controlling cloud server for receiving processed video frame corresponding to recognition rule.
AU HUANG Z
   HUANG D
   SU Y
   CHEN Y
   HU W
   YU X
AE DDPAI SHENZHEN TECHNOLOGY CO LTD (DDPA-Non-standard)
GA 2018A1965X
AB    NOVELTY - The method involves executing triggering algorithm and identification algorithm based on deep learning algorithm for designing a cloud server. Triggering rule is sent to a camera device by the cloud server corresponding to the triggering algorithm. A user developed interface is provided for developing a visual application of an image pickup apparatus. The triggering rule and recognition rules are displayed on the user developed interface for selecting triggering rule and recognition rules by a developer. The selected triggering rule is sent to the image pickup apparatus. The selected recognition rule is sent to the cloud server. The cloud server is controlled by the identification algorithm for receiving processed a video frame corresponding to the recognition rule.
   USE - Method for designing vision AI algorithm system using a camera device.
   ADVANTAGE - The method enables reducing development cost and development staff intensity, and satisfying developers requirement.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a device for designing vision AI algorithm system using a camera device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for designing vision AI algorithm system using a camera device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W02 (Broadcasting, Radio and Line Transmission Systems)
MC T01-J10B2A; T01-J16C2; T01-N01B3; T01-N01D1B; T01-N01D3; W02-F01
IP G06K-009/00; H04N-007/18
PD CN108985276-A   11 Dec 2018   G06K-009/00   201909   Pages: 15   Chinese
AD CN108985276-A    CN10955633    21 Aug 2018
PI CN10955633    21 Aug 2018
UT DIIDW:2018A1965X
ER

PT P
PN CN108984576-A
TI Method for acquiring patent document based on convolutional neural network, involves obtaining second patent document corresponding to first object drawing, and displaying second patent document.
AU LI Y
AE GUANGZHOU JICHUANG JIAHE INTELLECTUAL (GUAN-Non-standard)
GA 2018A3358A
AB    NOVELTY - The method involves acquiring (S101) a preset image database, and inputting an image in preset image database into a preset convolutional neural network for trained convolutional neural network model. The predetermined convolutional neural network is provided with linear map and nonlinear map including multiple convolution layers. A target image is obtained (S102), and the image recognition is performed on the target image by using the trained convolutional neural network model. A name of the subject object is obtained in the target image. A first patent document is searched (S103) corresponding to the keyword in a preset patent database. The gradation processing is performed (S104) on the target image. The first target drawing that matches the target image is obtained after performing the gradation processing. A second patent document corresponding to the first object drawing is obtained (S105), and the second patent document is displayed.
   USE - Method for acquiring patent document based on convolutional neural network.
   ADVANTAGE - The image is recognized by the improved convolutional neural network with increased width. The target object is accurately identified in the target image, the accuracy of the retrieval is improved, and the probability of false detection is reduced.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a patent document acquisition system based on a convolutional neural network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart illustrating the process for acquiring patent document based on convolutional neural network. (Drawing includes non-English language text)
   Step for acquiring preset image database, and inputting image in preset image database into preset convolutional neural network for trained convolutional neural network model (S101)
   Step for obtaining target image, and performing image recognition on target image by using trained convolutional neural network model (S102)
   Step for searching first patent document corresponding to the keyword in preset patent database (S103)
   Step for performing gradation processing on target image (S104)
   Step for obtaining second patent document corresponding to first object drawing (S105)
DC T01 (Digital Computers)
MC T01-J04B2; T01-J05B4F; T01-J10B1; T01-J10B2A; T01-N01A2G; T01-N01D2; T01-N03A2
IP G06F-017/30; G06K-009/00; G06K-009/20
PD CN108984576-A   11 Dec 2018   G06F-017/30   201909   Pages: 16   Chinese
AD CN108984576-A    CN10123760    07 Feb 2018
PI CN10123760    07 Feb 2018
UT DIIDW:2018A3358A
ER

PT P
PN CN108985285-A
TI Machine identification based method for obtaining patent for product, involves performing edge contour extraction on subject object in product information image by combining canny operator and morphological operation.
AU LI Y
AE GUANGZHOU JICHUANG JIAHE INTELLECTUAL (GUAN-Non-standard)
GA 2018A3354U
AB    NOVELTY - The method involves performing (S103) a combined search in the preset patent database to obtain a corresponding first search result. A corresponding image library is selected (S104) according to the product name. The product information image is matched by using the image library and based on color feature extraction convolutional neural network. A template image is obtained in the image library that has the highest similarity with a subject object in the product information image. The edge contour extraction is performed (S105) on the subject object in the product information image by combining a canny operator and a morphological operation to obtain a contour image of the subject object. The features of the contour image are extracted (S106), the feature matching is performed on the drawings in the first retrieval result based on characteristics of the contour image, and the drawing matching the contour image and a corresponding patent document is obtained.
   USE - Machine identification based method for obtaining patent for product.
   ADVANTAGE - The consumer can judge the competitiveness of the commercial home to which the product belongs in comparison with the competitiveness of the product on the product according to the obtained patent retrieval result. The technical optimal problems of different commercial tenants on the same type of products can be judged by checking and analyzing the patent retrieval results.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a machine identification based system for obtaining patent for product.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the machine identification based method for obtaining patent for product. (Drawing includes non-English language text)
   Step for obtaining product information image (S101)
   Step for performing combined search in the preset patent database to obtain corresponding first search result (S103)
   Step for selecting corresponding image library according to the product name (S104)
   Step for performing edge contour extraction on the subject object in the product information image by combining canny operator and morphological operation to obtain contour image of the subject object (S105)
   Step for extracting features of the contour image, performing feature matching on the drawings in the first retrieval result based on characteristics of the contour image, and obtaining drawing matching the contour image and corresponding patent document (S106)
DC T01 (Digital Computers)
MC T01-J05B4P; T01-J10B2; T01-J10B3B; T01-N01A2G; T01-N01D2; T01-N03A2
IP G06K-009/20; G06K-009/46; G06Q-030/06; G06Q-050/18
PD CN108985285-A   11 Dec 2018   G06K-009/20   201909   Pages: 19   Chinese
AD CN108985285-A    CN10122957    07 Feb 2018
PI CN10122957    07 Feb 2018
UT DIIDW:2018A3354U
ER

PT P
PN CN108985899-A
TI CNN-LFM model based score data recommendation method, involves outputting unidentified marking to update implicit semantic model, and inputting image into network model to extract image features and parameters of image when gradient is zero.
AU LIANG C
   FAN R
   LU W
   ZHAO S
   WANG B
AE UNIV HEFEI TECHNOLOGY (UYHE-C)
GA 2018A1951U
AB    NOVELTY - The method involves constraining potential characteristics of an item based on image features and parameters. Potential features of a user and the potential characteristics of the item are obtained for predicting user unknown rating of the item based on the potential characteristics of the item and the potential characteristics of the user. A loss function is generated according to unknown score to calculate gradient in loss function. Judgment is made to check whether the gradient is zero. Unidentified marking is output to update a convolutional neural network model and an implicit semantic model. An image is input into the convolutional neural network model to extract image features and parameters of the image when the gradient is zero.
   USE - CNN-LFM model based score data recommendation method.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a CNN-LFM model based score data recommendation device
   (2) a storage medium for storing a set of instructions for processing score data recommendation based on CNN-LFM model.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a CNN-LFM model based score data recommendation method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J16C3; T01-N01A
IP G06Q-030/06; G06N-003/04; G06N-003/08
PD CN108985899-A   11 Dec 2018   G06Q-030/06   201909   Pages: 13   Chinese
AD CN108985899-A    CN10766937    13 Jul 2018
PI CN10766937    13 Jul 2018
UT DIIDW:2018A1951U
ER

PT P
PN CN108985229-A
TI Method for replacing intelligent advertisement based on deep neural network, involves overlaying pre-prepared advertisement content in advertisement area.
AU LIU Y
   WEI S
AE BEIJING GUOMENG TECHNOLOGY CO LTD (BEIJ-Non-standard)
GA 2018A33554
AB    NOVELTY - The method involves importing (S1) a live video. An advertisement area in the video is identified (S2) by using an identification network based on an instance segmentation model. The instance segmentation model includes a Mask-RCNN architecture. The pre-prepared advertisement content in the advertisement area is overlaid (S3). The video file edited is exported (S4) and sent to the user. The characteristic extraction is performed based on convolutional neural network CNN network feature extraction in the video image.
   USE - Method for replacing intelligent advertisement based on a deep neural network.
   ADVANTAGE - The method makes depth neural network algorithm used in the audio advertisement identification, completely realizes the precise recognition and replacement of sporting event advertisement position.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for the intelligent advertisement replacing device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart illustrating a method for replacing intelligent advertisement based on deep neural network. (Drawing includes non-English language text)
   Step for importing a live video (S1)
   Step for identifying an advertisement area in the video by using an identification network based on an instance segmentation model (S2)
   Step for overlaying the pre-prepared advertisement content in the advertisement area (S3)
   Step for exporting and sending the video file edited to the user (S4)
DC T01 (Digital Computers)
MC T01-J10B2A; T01-J30D; T01-N01A2C; T01-N01B; T01-N01D2
IP G06K-009/00; G06K-009/46; G06N-003/04
PD CN108985229-A   11 Dec 2018   G06K-009/00   201909   Pages: 11   Chinese
AD CN108985229-A    CN10780765    17 Jul 2018
PI CN10780765    17 Jul 2018
UT DIIDW:2018A33554
ER

PT P
PN CN108985346-A
TI Current image retrieval method for combining low-level image features and CNN (convolutional neural network) features, involves calculating similarity of fusion features by using block distance to obtain search results.
AU LIU Y
   HU D
   WANG F
AE XIAMEN ANTUWEI INFORMATION TECHNOLOGY CO LTD (XIAM-Non-standard)
GA 2018A3348L
AB    NOVELTY - The method involves extracting features of the CNN intermediate layer and extracting low-level image features. The fusion features are obtained by fusion of low-level image features and CNN intermediate layer features. The similarity of the fusion features is calculated by using the block distance to obtain the search results.
   USE - Current image retrieval method for combining low-level image features and convolutional neural network features.
   ADVANTAGE - The image similarity is calculated by using the intermediate layer features of the convolutional neural network and the low-level feature vectors of the traditional image in order to further improve the retrieval efficiency. The retrieval accuracy is considerably improved compared with the retrieval method using the traditional low-level features.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart of similarity calculation and sorting process. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-J04A; T01-J10B1; T01-J10B2; T01-N03A2
IP G06K-009/62
PD CN108985346-A   11 Dec 2018   G06K-009/62   201909   Pages: 12   Chinese
AD CN108985346-A    CN10662663    25 Jun 2018
PI CN10662663    25 Jun 2018
UT DIIDW:2018A3348L
ER

PT P
PN CN108985192-A
TI Multi-task deep convolutional neural network based video smoke recognizing method, involves transmitting 6-channel image to testing network, and performing forward propagating process of network to determine current frame as smoke frame.
AU LU X
   HU Y
AE UNIV SOUTHEAST (UYSE-C)
GA 2018A19683
AB    NOVELTY - The method involves constructing a smoke video recognizing data set. The smoke video recognizing data set is included with smoke video and non-smoke video. Collected video is captured into a video clip. Two continuous frames of the video clip are picked as a sample by using sample enhancing process. Enhancement data is obtained as a training set of a convolutional neural network. The smoke video and the non-smoke video are intercepted to obtain the video clip. Corresponding parameter of a fully connecting layer and a softmax classifier is counted. A reverse convolutional network part is ignored. A current frame and a previous frame of the video are tested from a normalized frame when the normalized frame is converted into 6-channel image. The 6-channel image is transmitted to a testing network. Forward propagating process of the network is performed to determine the current frame as a smoke frame.
   USE - Multi-task deep convolutional neural network based video smoke recognizing method.
   ADVANTAGE - The method enables realizing single-frame image static characteristic extracting process by the convolutional neural network with dynamic features between the adjacent frames to learn multi-tasks, improving smoke video recognizing and safety performance in fire pre-warning process and application range of the video clip and simplifying recognizing process of the video clip.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a multi-task deep convolutional neural network based video smoke recognizing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-F02; T01-J10B2A; T01-N01B3A; T01-N01D1B
IP G06K-009/00; G06K-009/62
PD CN108985192-A   11 Dec 2018   G06K-009/00   201909   Pages: 13   Chinese
AD CN108985192-A    CN10692696    29 Jun 2018
PI CN10692696    29 Jun 2018
UT DIIDW:2018A19683
ER

PT P
PN CN108985366-A
TI Convolution depth network based type-B ultrasonic image recognition algorithm, has set of instructions for storing trained neural network with data, selecting ultrasonic image as to be identified input, and obtaining identification result.
AU PANG B
   SUN X
   WANG J
   CAO D
AE WUHAN LANDING MEDICAL HI-TECH CO LTD (WUHA-Non-standard)
GA 2018A1963Q
AB    NOVELTY - The algorithm has set of instructions for capturing (S1) an ultrasound mode image and a doctor diagnostic result as an image tag. The ultrasonic mode image is obtained in a sample set to train a neural network (S2). The trained neural network is stored with data. The ultrasonic image is selected as to be identified input. An identification result is obtained according to output vector (S3). A deep neural network is selected as a multi-layer convolution depth neural network, where the multi-layer convolution depth neural network comprises an input layer, a convolution layer and an output layer.
   USE - Convolution depth network based type-B ultrasonic image recognition algorithm.
   ADVANTAGE - The algorithm has set of instructions training a complementary model by directly digitizing image pixel as input, effectively realizing a recognition and reconstruction operation of the image, and improving intelligent recognition degree.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolution depth network based type-b ultrasonic image recognition algorithm. '(Drawing includes non-English language text)'
   Step for capturing an ultrasound mode image and a doctor diagnostic result (S1)
   Step for obtaining ultrasonic mode image (S2)
   Step for obtaining identification result according to output vector (S3)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E01B; T01-J04B2; T01-J10B1; T01-J10B2A; T04-D04; T04-K03B
IP G06K-009/62; G06N-003/04
PD CN108985366-A   11 Dec 2018   G06K-009/62   201909   Pages: 6   Chinese
AD CN108985366-A    CN10733678    06 Jul 2018
PI CN10733678    06 Jul 2018
UT DIIDW:2018A1963Q
ER

PT P
PN CN108986185-A
TI Method for amplifying image data based on deep learning, involves processing intersection of region of interest of foreground image and background image by using superpixel method to fuse and generate augmented merged image.
AU QIN S
   ZHOU L
   XU S
AE ZHEJIANG SHENMOU TECHNOLOGY CO LTD (ZHEJ-Non-standard)
GA 2018A3343Q
AB    NOVELTY - The method involves pre-processing the foreground picture and the background picture to obtain a pre-processed foreground picture. The foreground image is automatically or manually labeled to form annotation information of the foreground image, where the annotation information includes a region of interest of the foreground image. The annotation information of the foreground picture is applied to the preprocessed foreground picture. The intersection of the region of interest of the foreground image and the background image are processed by using the superpixel method to fuse and generate the augmented merged image.
   USE - Method for amplifying image data based on deep learning.
   ADVANTAGE - The depth learning-based image data augmentation method combines images by using a deep learning model, and generates a large amount of training data of the same quality by using a limited number of natural images, thus saves time and cost. The method for amplifying image data based on deep learning effectively serves the training process of deep learning.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart illustrating a method for amplifying image data based on deep learning. (Drawing includes non-English language text)
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J05B4F; T01-J10B2; T01-J10C5; T01-J30A; W04-W05A
IP G06T-011/60; G06T-007/11
PD CN108986185-A   11 Dec 2018   G06T-011/60   201909   Pages: 9   Chinese
AD CN108986185-A    CN10861945    01 Aug 2018
PI CN10861945    01 Aug 2018
UT DIIDW:2018A3343Q
ER

PT P
PN CN108985361-A
TI Method for implementing malicious traffic detection based on deep learning, involves using malicious traffic detection model to detect real-time network traffic, and implementing malicious traffic detection.
AU QU W
AE BEIJING JINQING YUNHUA TECHNOLOGY CO LTD (BEIJ-Non-standard)
GA 2018A39497
AB    NOVELTY - The method involves obtaining (S101) a traffic session for malicious code through dynamic sandbox technology. The traffic session of the malicious code is mapped (S102) into a genetic map and the feature of the map is extracted. The map features of the traffic session are clustered. The clustering result is labeled with a malicious code family. A preset deep learning model is trained (S103) with the genetic map of the labeled malicious code family to establish a malicious traffic detection model. The malicious traffic detection model is used (S104) to detect real-time network traffic, and malicious traffic detection is implemented.
   USE - Method for implementing malicious traffic detection based on deep learning.
   ADVANTAGE - The high robustness, fast, accurate, low false positive rate, and cross-platform detection are provided.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a device for implementing malicious traffic detection based on deep learning.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the method for implementing malicious traffic detection based on deep learning. (Drawing includes non-English language text)
   Step for obtaining traffic session for malicious code through dynamic sandbox technology (S101)
   Step for mapping traffic session of malicious code into genetic map and extracting feature of map (S102)
   Step for training preset deep learning model with genetic map of labeled malicious code family to establish malicious traffic detection model (S103)
   Step for using malicious traffic detection model to detect real-time network traffic, and implementing malicious traffic detection (S104)
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J05B3; T01-J10B2; T01-N01B3; T01-N02B3; T01-N03A2; W04-W05A
IP G06K-009/62; G06N-003/04; G06N-003/08; H04L-029/06
PD CN108985361-A   11 Dec 2018   G06K-009/62   201909   Pages: 19   Chinese
AD CN108985361-A    CN10708037    02 Jul 2018
PI CN10708037    02 Jul 2018
UT DIIDW:2018A39497
ER

PT P
PN CN108983973-A
TI Gesture-identification based dexterous myoelectric artificial hand controlling method, involves performing gesture recognition prediction, and controlling human myoelectric artificial hand synchronization to complete gesture action.
AU SONG A
   HU X
   ZENG H
   XU B
   LI H
AE UNIV SOUTHEAST (UYSE-C)
GA 2018A1996A
AB    NOVELTY - The method involves collecting surface electromyogram signal data of a user forearm by using a multi-channel array type myoelectric sensor. User hand motion is determined. A surface electromyogram signal of the user with multiple gestures within preset time is obtained. A neural network model is trained based on depth learning-based gesture recognition prediction algorithm. Real-time gesture recognition prediction is performed. Human myoelectric artificial hand synchronization is controlled to complete gesture action according to a gesture prediction result.
   USE - Gesture-identification based dexterous myoelectric artificial hand controlling method.
   ADVANTAGE - The method enables using a Tensorflow (RTM: open-source software library) machine learning framework to learn weights and perform visual analysis, performing surface electromyography signal acquisition on the user, improving comprehensive prediction accuracy of eight gestures and deeply optimizing a real-time gesture prediction result.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a gesture-identification based dexterous myoelectric artificial hand controlling method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B2A
IP G06F-003/01; G06K-009/62
PD CN108983973-A   11 Dec 2018   G06F-003/01   201909   Pages: 10   Chinese
AD CN108983973-A    CN10716880    03 Jul 2018
PI CN10716880    03 Jul 2018
UT DIIDW:2018A1996A
ER

PT P
PN CN108986124-A
TI Multi-scale characteristic convolutional neural network retinal vascular image segmentation method, involves optimizing model parameter, and performing pixel-level retinal vessel segmentation process to obtain vessel segmentation image.
AU TANG C
   ZHENG T
   QIU Y
AE UNIV TIANJIN (UTIJ-C)
GA 2018A1946P
AB    NOVELTY - The method involves pre-processing a retinal image. Restricted contrast adaptive histogram equalization process and gamma brightness adjustment process are performed. Data amplification process is performed on retinal image data. An experimental image is segmented into multiple sub-blocks. A retinal vessel dividing network is constructed. A space pyramid cavity tank is subjected into a coder-decoder structure convolutional neural network. Model parameters are optimized in multiple iterations. Pixel-level retinal vessel segmentation process is automatically performed to obtain a vessel segmentation image.
   USE - Multi-scale characteristic convolutional neural network retinal vascular image segmentation method.
   ADVANTAGE - The method enables automatically extracting and dividing retinal blood vessels, and improving anti-interference ability of blood vessel shadow and tissue deformation factors and vessel segmentation mean accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a multi-scale characteristic convolutional neural network retinal vascular image segmentation method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B1; T01-J10B2; T01-N02B1B; T04-D04
IP G06T-007/12; G06K-009/62; G06N-003/04; G06T-005/40
PD CN108986124-A   11 Dec 2018   G06T-007/12   201909   Pages: 14   Chinese
AD CN108986124-A    CN10635753    20 Jun 2018
PI CN10635753    20 Jun 2018
UT DIIDW:2018A1946P
ER

PT P
PN CN108984523-A
TI Deep learning model-based commodity comment emotion analysis method, involves updating parameters of dynamic convolutional neural network by stochastic gradient descent algorithm to obtain emotion classification model, and labeling test set.
AU TANG H
   GONG Q
   LEI M
   MU H
   WANG X
AE UNIV CHONGQING POSTS & TELECOM (UCPT-C)
GA 2018A1983P
AB    NOVELTY - The method involves marking one-star and two-star evaluations in commodity comment data as a positive comment (S1). Four-star and five-star evaluations are marked as a negative comment. An emotional element dictionary and an emotion characteristic vector are constructed (S2). A word vector is obtained according to a word sequence. The word vector is corrected to form a text vector. A dynamic convolutional neural network model is constructed (S3). Parameters of the dynamic convolutional neural network are updated by a BP algorithm and a stochastic gradient descent algorithm to obtain an emotion classification model. A test set is labeled.
   USE - Deep learning model-based commodity comment emotion analysis method.
   ADVANTAGE - The method enables combining the dynamic convolutional neural network to improve classification model generalization capability and ensure classification effect.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning model-based commodity comment emotion analysis method. '(Drawing includes non-English language text)'
   Step for marking one-star and two-star evaluations in commodity comment data as positive comment (S1)
   Step for constructing emotional element dictionary and emotion characteristic vector (S2)
   Step for constructing dynamic convolutional neural network model (S3)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2; T01-J10B2; T01-J11A1; T01-N01A2F; T01-N01B3A; T04-D04
IP G06F-017/27; G06K-009/62; G06N-003/08
PD CN108984523-A   11 Dec 2018   G06F-017/27   201909   Pages: 11   Chinese
AD CN108984523-A    CN10695687    29 Jun 2018
PI CN10695687    29 Jun 2018
UT DIIDW:2018A1983P
ER

PT P
PN CN108985448-A
TI Neural network standard representation frame structure, has packaging module for encapsulating security information and identity authentication information of neural network for converting neural network into model.
AU TIAN Y
   CHEN G
   SHI Y
   WANG Y
AE UNIV PEKING (UYPK-C)
GA 2018A1961V
AB    NOVELTY - The structure has an operation module for obtaining neural network input converted interoperable representation format. A compact representation module converts the interoperable representation format into a serialized format through a compression algorithm. A coding and decoding expression module performs presentation format encoding and decoding process by neural network compression algorithm. A packaging module encapsulates security information and identity authentication information of the neural network for converting the neural network into a model, where the neural networks comprises a convolutional neural network, circulating neural network, generating against network or automatic encoder neural network.
   USE - Neural network standard representation frame structure.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a neural network standard representation frame structure. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-D02; T01-J11E; W01-A02A
IP G06N-003/063; G06N-003/04
PD CN108985448-A   11 Dec 2018   G06N-003/063   201909   Pages: 11   Chinese
AD CN108985448-A    CN10575097    06 Jun 2018
PI CN10575097    06 Jun 2018
UT DIIDW:2018A1961V
ER

PT P
PN CN108985254-A
TI Laser-based tracking method for trailer truck, involves determining whether vehicle head and vehicle hanger belong to same truck and outputting entire vehicle tracking result.
AU WANG C
AE SHANGHAI TRUNKTECH CO LTD (SHAN-Non-standard)
GA 2018A3354Y
AB    NOVELTY - The method involves obtaining a point cloud data using a laser scanner. The depth learning method is used to train the component models of the tracked trucks such as the front model and the vehicle hanging model, to identify the clustering results and the truck components. The vehicle head (1) and vehicle hanger (2) of the identified truck are tracked using the kalman filter to predict and update the motion state of the vehicle head and vehicle hanger. The determination is made on whether the vehicle head and vehicle hanger belong to the same truck and the entire vehicle tracking result is outputted.
   USE - Laser-based tracking method for trailer truck.
   ADVANTAGE - The tracking and identification of the trailer truck is realized, and the recognition accuracy is high.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of the laser-based tracking device.
   Vehicle head (1)
   Vehicle hanger (2)
   Connecting portion (3)
   Reference points (4,5)
DC T01 (Digital Computers); U22 (Pulse Generation and Manipulation)
MC T01-J05B3; T01-J07D1; T01-J10B2A; T01-J30A; U22-G01A1B
IP G06K-009/00; G06K-009/62
PD CN108985254-A   11 Dec 2018   G06K-009/00   201909   Pages: 8   Chinese
AD CN108985254-A    CN10863983    01 Aug 2018
PI CN10863983    01 Aug 2018
UT DIIDW:2018A3354Y
ER

PT P
PN CN108985149-A
TI Method for recognizing person image in terminal device e.g. cell phone, involves pairing limb component images of different parts of identified limb components and identifying image of each character in multi-person image to be recognized.
AU WANG Y
   WANG J
   XIAO J
AE PINGAN TECHNOLOGY SHENZHEN CO LTD (PING-Non-standard)
GA 2018A3355L
AB    NOVELTY - The method involves obtaining (S500) a multi-person image to be identified. Each limb component image is identified (S504) from the multi-person image to be recognized according to a preset limb component learning model of the character. The limb component image includes a head image, a neck image, a torso image, a hand image, and a foot image. The limb component images of different parts of the identified limb components are paired according to a preset limb component vector rule, and image of each character is identified (S506) in the multi-person image to be recognized.
   USE - Method for recognizing person image in terminal device such as cell phone, computer and server (claimed).
   ADVANTAGE - The images of individual characters in multi-person image are effectively recognized.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) a server; and
   (2) a computer readable storage medium storing instructions for recognizing person image.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the person image recognition method. (Drawing includes non-English language text)
   Step for obtaining multi-person image to be identified (S500)
   Step for performing deep learning on each of limb component images (S502)
   Step for identifying limb component image from multi-person image to be recognized (S504)
   Step for identifying image of each character in multi-person image to be recognized (S506)
   Step for performing abnormal value mark on palm portion of first type of hand image of preset number of proportions in pre-sampled hand image (S508)
DC T01 (Digital Computers)
MC T01-J10B2A; T01-N01B3; T01-N02A3C; T01-S03
IP G06K-009/00
PD CN108985149-A   11 Dec 2018   G06K-009/00   201909   Pages: 16   Chinese
AD CN108985149-A    CN10554263    01 Jun 2018
PI CN10554263    01 Jun 2018
UT DIIDW:2018A3355L
ER

PT P
PN CN108984724-A
TI Method for improving accuracy of sentiment classification of attribute by using high-dimensional representation, involves entering comment text to be processed into trained deep neural network model to obtain polarity of comment text.
AU XIE J
   WU H
   LI L
AE KAIERBOTE INFORMATION TECHNOLOGY KUNSHAN CO LTD (KAIE-Non-standard)
GA 2018A3351J
AB    NOVELTY - The method involves considering the specific attribute sentiment classification model based on high-dimensional representation as a black box function, the output of the function is a vector, which represents the probability that the input text belongs to each category label, the training objective minimizes the loss function. The Adagrad optimization function can be used, all the parameters of the matrix and the vector are evenly distributed. The Bi-LSTM is adopted in the training process, in order to avoid over-fitting. The comment text is entered to be processed into the trained deep neural network model to obtain the comment text for a specific attribute.
   USE - Method for improving accuracy of sentiment classification of attribute by using high-dimensional representation.
   ADVANTAGE - The two-way long-term and short-term memory neural network is used to encode the representations of the clauses obtained in the previous step to obtain the final representation of the entire sentence. The information related to a specific attribute is captured from three different dimensions of words, clauses and sentences, and finally the accuracy of the emotion classification of the specific attribute is improved.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the method for improving accuracy of sentiment classification of attribute by using high-dimensional representation. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-J05B2; T01-J05B4B; T01-J11A1; T01-N01B3; T01-N01D
IP G06F-017/30; G06F-017/27; G06N-003/04
PD CN108984724-A   11 Dec 2018   G06F-017/30   201909   Pages: 16   Chinese
AD CN108984724-A    CN10754022    10 Jul 2018
PI CN10754022    10 Jul 2018
UT DIIDW:2018A3351J
ER

PT P
PN CN108986047-A
TI Method for reducing image noise, involves selecting model parameters with recovery loss to determine final depth-up framework, and realizing image denoising using final depth enhancement framework model.
AU XIONG Z
   CHEN C
   TIAN X
   WU F
AE UNIV CHINA SCI & TECHNOLOGY (UCST-C)
GA 2018A33447
AB    NOVELTY - The method involves constructing (1) a paired training data set and a verification data set according to the obtained natural image and the additive noise sampled in the Gaussian distribution of the known variance, and preprocessing the training data set. The convolutional neural network is used (2) as the Boosting unit, and the deepening framework model is built based on the symbiotic organisms search (SOS) algorithm. The pre-processed training data set is used (3) to train the deep lifting framework model and adjust the corresponding model parameters. The verification data set is used (4) to adjust the superparameter and the optimized hyperparameters of the trained depth-lifting framework model. The verification data set is used to verify the deep-lifting framework model. The model parameters with recovery loss are selected to determine the final depth-up framework. The image denoising is realized (5) using the final depth enhancement framework model.
   USE - Method for reducing image noise.
   ADVANTAGE - The method improves image noise reduction performance.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the method for reducing image noise. (Drawing includes non-English language text)
   Step for constructing paired training data set (1)
   Step for using convolutional neural network (2)
   Step for using pre-processed training data set (3)
   Step for using verification data set (4)
   Step for realizing image denoising (5)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B1; T01-J10B3A; T01-N01B3; T01-N01D1B; T01-N03A2; T04-D07D3
IP G06T-005/00; G06N-003/04
PD CN108986047-A   11 Dec 2018   G06T-005/00   201909   Pages: 11   Chinese
AD CN108986047-A    CN10782106    13 Jul 2018
PI CN10782106    13 Jul 2018
UT DIIDW:2018A33447
ER

PT P
PN CN108986117-A
TI Video image cutting method, involves determining segmentation region, and determining segmented video image of image to-be-segmented according to segmentation region, and controlling terminal to display segmented video image.
AU ZENG W
   LIU H
   WANG S
   WANG H
   LIU Q
   NIE R
   LI Q
   LI J
AE BEIJING YOUKU TECHNOLOGY CO LTD (BEIJ-Non-standard)
GA 2018A1946V
AB    NOVELTY - The method involves identifying a target object in an image to-be-segmented by utilizing deep learning algorithm, where the image to-be-segmented is selected from a video frame image in video. Segmentation region is determined corresponding to the identified target object in the image to-be-segmented. A segmented video image of the image to-be-segmented is determined according to segmentation region. A terminal is controlled to display the segmented video image. A target site on the target object is identified. Resolution information of the image to-be-segmented is determined. Cutting size information of the image to-be-segmented is determined.
   USE - Video image cutting method.
   ADVANTAGE - The method enables realizing segmentation video images for different target objects or different scenes by utilizing the image to-be-segmented, and satisfies different viewing requirements, and reducing resource requirements for shooting and editing process.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a video image cutting device
   (2) a computer readable storage medium for storing set of instructions for a video image cutting method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a video image cutting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W04 (Audio/Video Recording and Systems)
MC T01-J05B2A; T01-J10B2; T01-J10B3A; T01-J10D; T01-J16C2; T01-J30A; T04-J01; W04-M01D
IP G06T-007/11; H04N-005/232
PD CN108986117-A   11 Dec 2018   G06T-007/11   201909   Pages: 42   Chinese
AD CN108986117-A    CN10802302    18 Jul 2018
PI CN10802302    18 Jul 2018
UT DIIDW:2018A1946V
ER

PT P
PN CN108989666-A
TI Method for shooting image by mobile terminal, involves obtaining optimal shooting position of current picture based on convolutional neural network, and obtaining guide information to move mobile terminal to optimal shooting position.
AU ZHANG G
AE OPPO CHONGQING INTELLIGENT TECHNOLOGY CO (OPPO-Non-standard)
GA 2018A1872Q
AB    NOVELTY - The method involves obtaining an optimal shooting position of a current picture based on a convolutional neural network. Guide information is obtained to move a mobile terminal to the optimal shooting position according to the optimal shooting position. Composition type of the current picture is obtained based on the convolutional neural network. Similar probability between composition of the current picture and preset composition is determined based on the convolutional neural network. Judgment is made to check whether the similarity probability of the current picture is greater than a preset threshold value.
   USE - Method for shooting a picture by a mobile terminal (claimed).
   ADVANTAGE - The method enables training the convolutional neural network by collecting common shooting positions as a sample set to output the optimal shooting position corresponding to the current picture by the trained convolutional neural network when the user collects the picture so as to move the mobile terminal to the optimal shooting position, thus improving user picture shooting experience.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for shooting a picture by a mobile terminal
   (2) a computer readable storage medium for storing a set of instructions for shooting a picture by a mobile terminal.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for shooting a picture by a mobile terminal. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-M06A1; W04-M01D
IP H04N-005/232; G06N-003/04
PD CN108989666-A   11 Dec 2018   H04N-005/232   201909   Pages: 19   Chinese
AD CN108989666-A    CN10673339    26 Jun 2018
PI CN10673339    26 Jun 2018
UT DIIDW:2018A1872Q
ER

PT P
PN CN108985348-A
TI Convolutional neural network based calligraphy style recognizing method, involves continuously verifying model classifier, and utilizing classifier training sample input model for performing calligraphy style recognition operation.
AU ZHANG J
   ZHANG F
   QU X
AE UNIV XIAN TECHNOLOGY (UYXT-C)
GA 2018A19648
AB    NOVELTY - The method involves obtaining and pre-processing calligraphy handwriting sample. The handwriting sample is divided into a training sample set and a validation sample set. The training sample set is input to a model classifier. The model classifier is continuously verified using the training sample set and the validation sample set. A classifier training sample input model is utilized for performing calligraphy style recognition operation. Minimal bounding is applied to calligraphy works to obtain a single calligraphy character image without distortion. Model classifier weight parameter is determined.
   USE - Convolutional neural network based calligraphy style recognizing method.
   ADVANTAGE - The method enables increasing identification speed, identification accuracy, and convergence speed.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a convolutional neural network based calligraphy style recognizing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B2A; T01-N01B3
IP G06K-009/62; G06N-003/04; G06N-003/08
PD CN108985348-A   11 Dec 2018   G06K-009/62   201909   Pages: 9   Chinese
AD CN108985348-A    CN10662708    25 Jun 2018
PI CN10662708    25 Jun 2018
CP CN108985348-A
      CN106599941-A   UNIV XIDIAN (UYXN)   LI Y, ZHOU L, JIAO L, LIU F, SHANG R, MA W, MA J, GOU S
      CN106709486-A   UNIV NANJING SCI & TECHNOLOGY (UNSC)   PENG S, LI Y, LI D, WANG Q, ZHOU R
      CN106919942-A   UNIV SOUTH CHINA TECHNOLOGY (UYSC)   XIAO X, JIN L, YANG Y, LIANG K, CHANG T
UT DIIDW:2018A19648
ER

PT P
PN CN108984932-A
TI Building structure characteristics quickly extracting method, involves training street view image for rapidly extracting deep learning based on building structure characteristic, and generating characteristic rapid extracting model.
AU ZHOU Y
   CHEN S
   LI X
   DAI Z
   XIONG Z
   ZHENG J
AE CHINA EARTHQUAKE ADMINISTRATION INST (CHEA-Non-standard)
GA 2018A1973T
AB    NOVELTY - The method involves obtaining a street view image corresponding to building structure characteristic (S1), where building structure characteristics comprises structure-type, a building number, building age, building height and a building area. The street view image is trained (S2) for rapidly extracting deep learning based on the building structure characteristic. A building structure characteristic rapid extracting model is generated (S3). The street view image is input into the deep learning model. Characteristic map label and feature diagram are output. Error of characteristic pattern with desired tag is calculated.
   USE - Building structure characteristics quickly extracting method.
   ADVANTAGE - The method enables quickly and accurately extracting building structure characteristics to reduce labor intensity, material resources and financial resources.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a building structure characteristics quickly extracting method. '(Drawing includes non-English language text)'
   Step for obtaining a street view image corresponding to building structure (S1)
   Step for training street view image for rapidly extracting deep learning based on the building structure characteristic (S2)
   Step for generating building structure characteristic rapid extracting model (S3)
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J15X; T01-J30A; W04-W05A
IP G06F-017/50
PD CN108984932-A   11 Dec 2018   G06F-017/50   201909   Pages: 13   Chinese
AD CN108984932-A    CN10829058    25 Jul 2018
PI CN10829058    25 Jul 2018
UT DIIDW:2018A1973T
ER

PT P
PN CN108959794-A
TI Depth learning based structure response dynamics model correcting method, involves establishing deep learning network, and obtaining to-be-measured frequency response data of correction structure according to result of correction parameter.
AU DENG Z
   ZHANG X
AE UNIV BEIHANG (UNBA-C)
GA 2018A0252F
AB    NOVELTY - The method involves generating a training set of a deep learning network. Number and range of a to-be-corrected parameter sample are determined to obtain a structure multi-point from an experimental database. Normalization processing for frequency response data is performed. An image of a training set is converted into a multi-channel image. A deep learning network is established to initialize trellis parameters to select a proper network layer depth. To-be-measured frequency response data of a correction structure is obtained according to a correction result of a correction parameter.
   USE - Depth learning based structure response dynamics model correcting method.
   ADVANTAGE - The method enables effectively avoiding problems of poor capability of manual characteristic extraction model, improving noise expansion sample accuracy, and reducing parameter correction error.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a depth learning based structure response dynamics model correcting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-D03; T01-G01A; T01-J05B2B; T01-J05B4F; T01-J15X; T01-N01B3; W04-P01F3; W04-W05A
IP G06F-017/50
PD CN108959794-A   07 Dec 2018   G06F-017/50   201909   Pages: 11   Chinese
AD CN108959794-A    CN10776660    13 Jul 2018
PI CN10776660    13 Jul 2018
UT DIIDW:2018A0252F
ER

PT P
PN CN108960340-A
TI Convolutional neural network compression method, involves determining weight value concentration of convolutional layer of convolutional neural network structure, and re-training neural network to realize neural network converge processing.
AU DUAN H
   FU M
   ZOU H
   MIN G
   ZHU Y
AE UNIV ELECTRONIC SCI & TECHNOLOGY (UEST-C)
GA 2018A0239R
AB    NOVELTY - The method involves determining weight value concentration of a convolutional layer of a convolutional neural network structure in statistics by using specified formula, where the weight value concentration exceeds threshold value for realizing a binarization processing. A neural network re-training process is performed to realize a neural network converge processing, where the binarization processing comprises a convolution kernel weight value binarization and convolution layer input characteristic binarization. Instruction of an original convolution operation is obtained by a XOR operation.
   USE - Convolutional neural network compression method.
   ADVANTAGE - The method enables increasing precision of a network, realizing non-maximum suppression based on confidence penalty of IOU and avoiding softening and certain positive influence for detecting scene of a dense target.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram illustrating a convolutional neural network compression method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J03; T01-J04B2; T01-J10B2
IP G06K-009/62; G06N-003/08; G06K-009/00
PD CN108960340-A   07 Dec 2018   G06K-009/62   201909   Pages: 14   Chinese
AD CN108960340-A    CN10812355    23 Jul 2018
PI CN10812355    23 Jul 2018
UT DIIDW:2018A0239R
ER

PT P
PN CN108961429-A
TI Method for segmenting and splicing antiquity fragment model, involves reconstructing cultural into three-dimensional model, performing error removal process on fragment model, and obtaining ICP algorithm to register section.
AU LIU B
   WANG M
AE UNIV DALIAN TECHNOLOGY (UYDA-C)
GA 2018A0214U
AB    NOVELTY - The method involves reconstructing fragments of a cultural into a three-dimensional model. The three-dimensional model is established with a grid of multiple triangular structures. A characteristic mapping image of each triangular structure is obtained to perform normal projection process. Triangular patches of a section edge portion and a section flat portion are marked on the three-dimensional model. A convolutional neural network model is predicted to a section edge part of the three-dimensional model. Prediction result is marked on the three-dimensional model. A fragment model is established to a rough mark. Error removal process is performed on the fragment model. An ICP algorithm is obtained to register the section to realize splicing process of the section.
   USE - Method for segmenting and splicing an antiquity fragment model.
   ADVANTAGE - The method enables utilizing characteristic of the convolutional neural network, obtaining better dividing effect so as to realize accurate antiquity fragment of the splicing.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for segmenting and splicing an antiquity fragment model. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J12B
IP G06T-019/20; G06N-003/04; G06N-003/08
PD CN108961429-A   07 Dec 2018   G06T-019/20   201909   Pages: 21   Chinese
AD CN108961429-A    CN10583240    08 Jun 2018
PI CN10583240    08 Jun 2018
UT DIIDW:2018A0214U
ER

PT P
PN CN108961369-A
TI Method for generating three-dimensional animation by electronic device, involves driving bound vertex in three-dimensional model to move for generating three-dimensional animation according to preset movement track of skeleton point.
AU WU S
   CHEN J
AE XIAMEN HUANSHI NETWORK TECHNOLOGY CO LTD (XIAM-Non-standard)
GA 2018A0216A
AB    NOVELTY - The method involves obtaining a photograph comprising a face image. The face image in the photograph is identified. A three-dimensional model is reconstructed according to the face image. A vertex in the three-dimensional model is bound with a preset bone point. The bound vertex in the three-dimensional model is driven to move for generating three-dimensional animation according to a preset movement track of the skeleton point. Category of the face image in the photograph is detected by a deep neural network. Key points of the face image are identified by a decision tree.
   USE - Method for generating three-dimensional animation by an electronic device (claimed).
   ADVANTAGE - The method enables dynamically displaying photos in three-dimensional animation and realizing expression of the photos in an effective manner.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) an electronic device
   (2) a computer readable storage medium for storing a set of instructions for generating three-dimensional animation by an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for generating three-dimensional animation by an electronic device. '(Drawing includes non-English language text)'
DC T04 (Computer Peripheral Equipment)
MC T04-D07F1
IP G06T-013/40
PD CN108961369-A   07 Dec 2018   G06T-013/40   201909   Pages: 15   Chinese
AD CN108961369-A    CN10756050    11 Jul 2018
PI CN10756050    11 Jul 2018
UT DIIDW:2018A0216A
ER

PT P
PN CN108961447-A
TI Method for judging employee present in seat system, involves judging whether measured pressure data is obtained by employee to determine whether seat is present by using measured samples and shaking model.
AU ZHANG L
AE BOE TECHNOLOGY GROUP CO LTD (BOEG-C)
GA 2018A0214C
AB    NOVELTY - The method involves obtaining actually measured pressure data of a seat to obtain multiple measured samples. Training samples are input into a deep neural network to obtain a shaking model, where the shaking model is established by using deep neural network algorithm. Euclidean distance between the samples is calculated. Judgment is made to check whether normalized Euclidean distance exceeds threshold. Judgment is made to check whether the measured pressure data is obtained by an employee to determine whether the seat is present by using the measured samples and the shaking model.
   USE - Method for judging employee present in a seat system (claimed).
   ADVANTAGE - The method enables determining employee attendance accurately.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for an employee attendance checking method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for judging employee present in a seat system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T05 (Counting, Checking, Vending, ATM and POS Systems)
MC T01-J10B2; T01-N01B3; T05-G03
IP G07C-001/10; G06K-009/00; G06K-009/62; G01L-005/00
PD CN108961447-A   07 Dec 2018   G07C-001/10   201909   Pages: 10   Chinese
AD CN108961447-A    CN10580935    07 Jun 2018
PI CN10580935    07 Jun 2018
UT DIIDW:2018A0214C
ER

PT P
PN CN108932499-A
TI Local binary pattern and deep belief network based rolling bearing prediction method, involves obtaining vibration signal, and classifying obtained completion trained deep belief network to determine actual rolling bearing fault type.
AU JIANG L
   XU C
   LI Y
   XU Z
   ZHOU M
   NIE W
AE UNIV WUHAN SCI & TECHNOLOGY (UWSC-C)
GA 201899430X
AB    NOVELTY - The method involves obtaining a vibration signal of a one-dimensional rolling bearing in known state pre-processing. A gray image is divided into regions based on a uniform local binary mode operator. A feature extraction process is performed to obtain a statistical histogram of each divided region. Statistic histogram normalization processing is performed. A model parameter of a deep belief network (DBN) is adjusted to obtain a completion trained DBN network. The obtained completion trained DBN network is classified to determine an actual rolling bearing fault type.
   USE - Local binary pattern and deep belief network based rolling bearing prediction method.
   ADVANTAGE - The method enables automatically extracting a DBN deep feature, determining forward self-learning and gradient descent based on counter-propagation by the DBN network, reflecting high characteristics of extrinsic information by DBN network extracting layer training completion, obtaining characteristic extracting result to realize top layer classification and identifying rolling bearing fault load under strong noise conditions.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a local binary pattern and deep belief network based rolling bearing prediction system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a local binary pattern and deep belief network based rolling bearing prediction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J03; T01-J05B2; T01-J10B2; T04-D03A; T04-D04
IP G06K-009/00; G06K-009/46; G06K-009/62
PD CN108932499-A   04 Dec 2018   G06K-009/00   201909   Pages: 22   Chinese
AD CN108932499-A    CN10742624    09 Jul 2018
PI CN10742624    09 Jul 2018
UT DIIDW:201899430X
ER

PT P
PN CN108932725-A
TI Method for estimating scene stream based on convolutional neural network, involves using scene stream network obtained by training for forward calculation of test image pair, where output is scene stream obtained by prediction.
AU XIANG X
   ZHAI M
   ZHANG R
   LV N
   GUO X
   YU Z
   WANG S
   ZHANG Y
AE UNIV HARBIN ENGINEERING (UHEG-C)
GA 201899425V
AB    NOVELTY - The method involves preparing a stereo image pair for scene stream network training. A fusion sub-network which combines some feature maps in the optical sub-network and some feature maps in the parallax sub-network is constructed to use the unsupervised learning scene flow loss function to guide the network training. The overall network of the scene stream is built (S5) to train fusion sub-network to obtain the overall network of the scene flow estimation. The scene stream network obtained by the training is used (S6) for forward calculation of the test image pair, where the output is the scene stream obtained by the prediction.
   USE - Method for estimating scene stream based on convolutional neural network.
   ADVANTAGE - By using the pre-trained network model, the scene stream is obtained reliably by forward calculation.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart of a method for estimating scene stream based on convolutional neural network. (Drawing includes non-English language text)
   Step for organizing training data set in the form of a network training input image (S1)
   Step for providing the optical subnet input as the image of the left eye camera (S2)
   Step for dividing the parallax sub-network into a respective time sub-network (S3)
   Step for building overall network of the scene stream to train fusion sub-network to obtain the overall network of the scene flow estimation (S5)
   Step for using scene stream network obtained by the training for forward calculation of the test image pair, where the output is the scene stream obtained by the prediction (S6)
DC T01 (Digital Computers)
MC T01-J10B2; T01-L02; T01-N01B3A
IP G06N-003/04; G06N-003/08; G06T-007/207
PD CN108932725-A   04 Dec 2018   G06T-007/207   201909   Pages: 13   Chinese
AD CN108932725-A    CN10589261    08 Jun 2018
PI CN10589261    08 Jun 2018
UT DIIDW:201899425V
ER

PT P
PN CN108932500-A
TI Sample data and deep neural network based dynamic gesture recognition method, involves performing gesture characteristic vector fusion by classification identification networks to identify class output sample corresponding to gesture type.
AU XIAO D
   WAN L
   ZHAN Y
   LI B
AE GUANGZHOU INTELLIGENT EQUIP RES INST CO (GUAN-Non-standard)
GA 201899430W
AB    NOVELTY - The method involves collecting dynamic gesture video segment for collecting different gestures. Data expansion processing is performed to generate a training sample data set, where the sample data set is a RGB-D format that comprises a RGB image. Collected dynamic gesture recognition is performed. Sample characteristic extracting is performed by a characteristic extraction network based on different gestures. A sample characteristic vector of each gesture is obtained. Gesture characteristic vector fusion is performed by classification identification networks to identify a class output sample corresponding to gesture type.
   USE - Sample data and deep neural network based dynamic gesture recognition method.
   ADVANTAGE - The method enables selecting a network model as a bidirectional LSTM model so as to determine correlation between continuous gesture postures and improve recognition rate of dynamic gesture.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a sample data and deep neural network based dynamic gesture recognition system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a sample data and deep neural network based dynamic gesture recognition method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J05B2; T01-J10B2A; T01-N01B3; T04-D04; T04-D08
IP G06K-009/00; G06K-009/62; G06N-003/08; G06N-003/04
PD CN108932500-A   04 Dec 2018   G06K-009/00   201909   Pages: 14   Chinese
AD CN108932500-A    CN10745350    09 Jul 2018
PI CN10745350    09 Jul 2018
CP CN108932500-A
      CN104732243-A   UNIV XIDIAN (UYXN)   CHEN B, DING J, HUANG M
      CN107219924-A   UNIV SOUTH CHINA TECHNOLOGY (UYSC)   XUE Y, XU S
      CN107451552-A   UNIV BEIJING UNION (UYBU)   YUAN J, LIU H, ZHANG H
      WO2017164478-A1   KOREA ADVANCED INST SCI & TECHNOLOGY (KOAD)   KIM D H, RO Y
UT DIIDW:201899430W
ER

PT P
PN CN108932720-A
TI Method for intelligently segmenting intracranial plaques and carotid plaques using magnetic resonance image, involves outputting segmentation image of plaque tissue region corresponding to blood vessel wall magnetic resonance image.
AU ZHENG H
   LIU X
   HU Z
   ZHANG N
   LIANG D
   YANG Y
AE SHENZHEN INST ADVANCED TECHNOLOGY (CAAT-C)
GA 2018994260
AB    NOVELTY - The method involves acquiring (S1) a magnetic resonance image of a blood vessel wall of a user. The magnetic resonance image of the blood vessel wall is preprocessed (S2) to obtain a preprocessed image. The preset plaque region in the preprocessed image is segmented (S3) by using a pre-trained convolutional neural network model. A segmentation image of the plaque tissue region corresponding to the blood vessel wall magnetic resonance image is output (S4). Multiple blood vessel wall magnetic resonance images are set to the same size. The plaque position in the magnetic resonance image of all blood vessel walls is manually outlined.
   USE - Method for intelligently segmenting intracranial plaques and carotid plaques using magnetic resonance image.
   ADVANTAGE - The accuracy of plaque segmentation of the magnetic resonance image of the blood vessel wall is improved, thus obtaining a high-precision segmentation image. The diagnosis efficiency is improved and the safety of the operation is improved.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for intelligently segmenting intracranial plaques and carotid plaques using magnetic resonance image. (Drawing includes non-English language text)
   Step for acquiring a magnetic resonance image of a blood vessel wall of a user (S1)
   Step for preprocessing magnetic resonance image of the blood vessel wall to obtain a preprocessed image (S2)
   Step for segmenting preset plaque region in the preprocessed image (S3)
   Step for outputting segmentation image of the plaque tissue region corresponding to the blood vessel wall magnetic resonance image (S4)
DC S03 (Scientific Instrumentation); T01 (Digital Computers)
MC S03-E07A; T01-J10B1; T01-J10B2
IP G06T-007/11; G06N-003/04
PD CN108932720-A   04 Dec 2018   G06T-007/11   201909   Pages: 7   Chinese
AD CN108932720-A    CN10818059    24 Jul 2018
PI CN10818059    24 Jul 2018
UT DIIDW:2018994260
ER

PT P
PN CN108898217-A
TI Method for compressing convolutional neural network, involves adjusting remaining parameters so that accuracy of compressed convolutional neural network model is not less than accuracy of original convolutional neural network model.
AU WU J
   WU H
   DING J
AE SUZHOU INST ADVANCED STUDY USTC (UCST-C)
GA 2018970380
AB    NOVELTY - The method involves extracting the activation values of the i-1th layer and the i+1th layer when compressing the i-th network layer, where ai-1 and ai+1 represent the output of the i-1th layer and the i+1th layer on the test set, respectively. A mapping relationship is fitted between ai-1 and ai+1 using a replacement model of a convolution kernel or a neuron less than the i-th network layer, and the fitted replacement model is substituted with the i-th layer of the original convolutional neural network. The remaining parameters are adjusted so that the accuracy of the compressed convolutional neural network model is not less than the accuracy of the original convolutional neural network model.
   USE - Method for compressing convolutional neural network based on automatic encoder.
   ADVANTAGE - The method for compressing convolutional neural network based on automatic encoder speeds up the calculation while reducing the size of the network.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for apparatus for compressing a convolutional neural network based on an automatic encoder.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart illustrating a method for compressing a convolutional neural network based on an automatic encoder. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-J04B2
IP G06N-003/063; G06N-003/04
PD CN108898217-A   27 Nov 2018   G06N-003/063   201909   Pages: 7   Chinese
AD CN108898217-A    CN10674697    27 Jun 2018
PI CN10674697    27 Jun 2018
UT DIIDW:2018970380
ER

PT P
PN TW570477-U
TI Computer device using full exponential operation on deep neural network.
AU WU X
   XIAO W
AE BLESSY INC (BLES-Non-standard)
GA 201911150W
DC T01 (Digital Computers)
MC T01-E03
IP G06N-003/08
PD TW570477-U   21 Nov 2018   G06N-003/08   201909   Pages: 0   Chinese
AD TW570477-U    TW206746    23 May 2018
PI TW206746    23 May 2018
UT DIIDW:201911150W
ER

PT P
PN CN108133289-A
TI Environment prediction based tunnel ventilation controlling method, involves predicting predicted value of each index according to detection value, and adjusting ventilation air quantity of tunnel based on predicted value and target value.
AU CAI Z
   ZHANG P
   HOU X
   LI Y
   KUANG J
   SU L
   CAO J
   QIAO J
   LV J
   ZHU Y
AE CHINA RAILWAY CONSTR ELECTRIFICATION BUR (CRCC-C)
   BEIJING CREC DESIGN & RES INST CO LTD (CRCC-C)
   UNIV JILIN ZHUHAI COLLEGE (UNIV-Non-standard)
GA 201846352M
AB    NOVELTY - The method involves setting target value of multiple indexes associated with tunnel environment. Multiple detecting points are set in a tunnel, where the tunnel environment includes nitrogen oxide concentration, carbon dioxide concentration, visibility and temperature in the tunnel. Detection value of each index is collected at current time. A predicting model is established by deep learning according to each index of the detection value. Predicted value of each index is predicted according to the detection value of each index at next time. Ventilation air quantity of the tunnel is adjusted based on the predicted value and the target value.
   USE - Environment prediction based tunnel ventilation controlling method.
   ADVANTAGE - The method enables reducing hysteresis of air amount feedback control, and improving control precision of the ventilating air quantity.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for an environment prediction based tunnel ventilation controlling system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an environment prediction based tunnel ventilation controlling method. '(Drawing includes non-English language text)'
DC Q49 (Mining (E21)); T01 (Digital Computers)
MC T01-J05A2; T01-J30A
IP E21F-001/00; G06N-003/08; G06Q-010/04
PD CN108133289-A   08 Jun 2018   G06Q-010/04   201842   Pages: 13   Chinese
AD CN108133289-A    CN11394301    21 Dec 2017
PI CN11394301    21 Dec 2017
UT DIIDW:201846352M
ER

PT P
PN CN108089147-A
TI Method of positioning improved shortwave unit, involves performing deep learning, and self-adjusting positioning accuracy of short-wave single station using eigenvector of number of signal sources.
AU LI T
AE SOUTHWEST ELECTRONIC TECHNOLOGY INST CHI (CETC-C)
GA 2018432918
AB    NOVELTY - The method involves sampling the antenna array received signals continuously at a chip rate to form an input matrix. A spatial-temporal DOA matrix is constructed in conjunction with the spatial sample data. The measured data of the direction of arrival of the signal source is accumulated. The direction of arrival of the external radiation signal source is estimated. The deep learning is performed and the positioning accuracy of the short-wave single station is self-adjusted using the eigenvector of the number of signal sources.
   USE - Method of positioning improved shortwave unit.
   ADVANTAGE - The resolution positioning performance of shortwave unit is improved, the calculation amount is reduced, and the positioning estimation accuracy is improved.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a processing structure of a short-wave single-station positioning system. (Drawing includes non-English language text)
DC W04 (Audio/Video Recording and Systems); W06 (Aviation, Marine and Radar Systems)
MC W04-W05A; W06-A02A
IP G01S-003/14
PD CN108089147-A   29 May 2018   G01S-003/14   201842   Pages: 12   Chinese
AD CN108089147-A    CN11287763    07 Dec 2017
PI CN11287763    07 Dec 2017
UT DIIDW:2018432918
ER

PT P
PN CN106203417-A
TI RMB crown word merged character segmentation identifying method, involves performing horizontal projection analysis, sending identification by trained convolutional neural network, and combining dividing order to obtain crown size.
AU ZHOU H
   PENG Y
   ZHU G
AE UNIV BEIJING SCI & TECHNOLOGY (UNBS-C)
GA 201678190N
AB    NOVELTY - The method involves dividing characters. Horizontal character rough divide input image is collected by a sensor. Vertical projection analysis is performed. Width of character image obtained by coarse segmentation is detected. Abnormal vertical projection curve of the character image is detected. A merged character segmenting point vertically cutting the abnormal character image is obtained. Horizontal projection analysis is performed. Identification is sent by a trained convolutional neural network. Dividing orders are combined to obtain crown size.
   USE - RMB crown word merged character segmentation identifying method.
   ADVANTAGE - The method enables segmenting the merged character with high accuracy and less error recognition rate.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a RMB crown word merged character segmentation identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E01C; T01-J07B; T01-J10B2A; T01-J16C1; T01-N01D1B; T04-D02
IP G06K-009/20; G06N-003/02
PD CN106203417-A   07 Dec 2016   G06K-009/20   201705   Pages: 8   Chinese
AD CN106203417-A    CN10544250    12 Jul 2016
PI CN10544250    12 Jul 2016
CP CN106203417-A
      CN104408814-A   TIANJIN YUANMU TECHNOLOGY CO LTD (TIAN-Non-standard)   
      CN105046252-A   UNIV HUAZHONG SCI & TECHNOLOGY (UYHZ)   CHEN S, LI J, LIU H, LIU J
      JP2008250754-A   NIDEC SANKYO CORP (DNSA)   NAKAMURA H
CR CN106203417-A
      : "", ,relevantClaims[1-2],relevantPassages[2.53]
      : "", ,relevantClaims[1-2],relevantPassages[3]
UT DIIDW:201678190N
ER

PT P
PN KR2018137851-A
TI Artificial intelligent electric lamp system for use in indoor and outdoor, comprises deep learning-based flashing determination system determines whether flashing is based on data received from sensing module through lighting system unit.
AU SON S H
   WOO L J
   SEO J W
   KIM H Y
   PARK J H
   KON L H
   YUN W J
   MIN O J
AE SON S H (SONS-Individual)
   WOO L J (WOOL-Individual)
   SEO J W (SEOJ-Individual)
   KIM H Y (KIMH-Individual)
   PARK J H (PARK-Individual)
   KON L H (KONL-Individual)
   YUN W J (YUNW-Individual)
   MIN O J (MINO-Individual)
GA 2019033090
AB    NOVELTY - The electric lamp system comprises a detection module which is composed of a sensor module and a data transmission module, which detects the visual information about a situation requiring human body detection and transmits data to the server. A data receiving unit and an electric flash control unit which can receive signals from the automatic lighting system unit and control the blinking of the electric lamp. A deep learning-based flashing determination system determines whether the flashing is based on data received from the sensing module through the automatic lighting system unit.
   USE - Artificial intelligent electric lamp system for use in an indoor and outdoor.
   ADVANTAGE - The durability of the lamp is increased, and also the cost for the maintenance or replacement of the lamp is reduced.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block representation of an electric lamp system. (Drawing includes non-English language text).
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-N01B3; T01-N01D3; T01-N03B1; W01-A06
IP H05B-037/02; G06N-003/08; H04L-012/28
PD KR2018137851-A   28 Dec 2018   H05B-037/02   201908   Pages: 5   
AD KR2018137851-A    KR077656    20 Jun 2017
PI KR077656    20 Jun 2017
UT DIIDW:2019033090
ER

PT P
PN CN208283943-U
TI CNN-based FPGA acceleration optimizing device, has main control module connected with external memory module, DRAM directly connected to memory interface of FPGA system, and accelerator connected with data transmission engine.
AU GE H
   PAN W
   XU S
   LIU H
AE UNIV NANJING INFORMATION SCI & TECHNOLOG (UNAI-C)
GA 201901790N
AB    NOVELTY - The utility model claims a CNN of FPGA-based acceleration optimizing device, comprising a main control module and an external memory module; the main control module is FPGA system-on-chip, external memory module is specifically a DDR3 DRAM, DDR3 DRAM directly connecting to the memory interface of the system BANK37, BANK38, and BANK39 on the FPGA. high efficiency of the utility model can use fast parallel processing and extremely low power consumption calculation of FPGA characteristic to realize the deep convolutional neural network model with the highest complexity in convolution calculating part, under the premise of ensuring the correct rate of the algorithm, greatly improve the algorithm efficiency and reduce the power consumption.
DC T01 (Digital Computers); U14 (Memories, Film and Hybrid Circuits)
MC T01-E01A; T01-F06; T01-H01B3; T01-J04B2; T01-M01; T01-M02C; T01-M05; T01-N01D; U14-A03B4
IP G06F-015/78; G06N-003/04
PD CN208283943-U   25 Dec 2018   G06F-015/78   201908   Pages: 9   Chinese
AD CN208283943-U    CN20882227    08 Jun 2018
PI CN20882227    08 Jun 2018
UT DIIDW:201901790N
ER

PT P
PN CN109002537-A
TI Deep learning based information processing system, has keyword search module connected with internet, and feedback module for sending image information to user when image information of object is matched with common image information.
AU FAN T
   ZHAO J
   LIU B
   LV L
   FAN F
   LUAN H
   YAO Z
AE NANCHANG INST TECHNOLOGY (NANH-C)
GA 2018A3455Q
AB    NOVELTY - The system has a storage unit for storing characteristic points transmitted by a processor. A processing chip identifies characteristic point content and image information collected by an image collecting module. A comparison unit compares the image information with characteristic points. A memory stores searched information. A keyword search module is connected with an internet. The keyword search module receives the characteristic point sent by the processor. A feedback module sends the image information to a user when image information of an object is matched with common image information.
   USE - Deep learning based information processing system.
   ADVANTAGE - The system has high humanization effect, and reduces time consumption, increases information processing accuracy, realizes information processing operation by utilizing multiple sorting paths in a simple manner, filters and removes multiple useless files, holds a search result effective manner, and performs image information screening process by a user in an effective manner.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based information processing method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a deep learning based information processing system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-E01C; T01-H01A; T01-J05B4P; T01-N01B3; T01-N01D1B; T01-N01D2; T01-N03A2; W04-W05A
IP G06F-017/30
PD CN109002537-A   14 Dec 2018   G06F-017/30   201908   Pages: 8   Chinese
AD CN109002537-A    CN10799283    19 Jul 2018
PI CN10799283    19 Jul 2018
UT DIIDW:2018A3455Q
ER

PT P
PN CN109003689-A
TI Convolutional neural network based nuclear monitoring method, involves displaying corrosion type on interaction interface to realize nuclear component surface corrosion type identification and early warning by monitoring and warning module.
AU GAO H
   SUN Y
   HONG X
   SONG H
   CAI C
   YOU Z
   ZHANG Y
   GAO Z
   WANG Y
   JIN L
AE UNIV SOUTHWEST JIAOTONG (UYSJ-C)
   JIANGSU AIGESEN CNC EQUIP MFG CO LTD (JIAN-Non-standard)
GA 2018A3429B
AB    NOVELTY - The method involves collecting nuclear component surface video data by an image collecting module (S1). The nuclear component surface video data is sent (S2) to a video data monitoring and pre-warning module. Image data is obtained (S3) by the nuclear component surface video data, where the image data is divided into training data set and test data set. The training data set is sent (S4) to a convolutional neural network for training a feature identification model and outputs primary distinguishing characteristic. The primary distinguishing characteristic is classified (S5) to obtain corrosion type. The testing data set is sent (S6) to the feature identification model. Condition of the distinguishing characteristic is satisfied (S7) by the corrosion type. The corrosion type is displayed (S8) on a human-computer interaction interface to realize a nuclear component surface corrosion type identification and early warning process by the video data monitoring and pre-warning module.
   USE - Convolutional neural network based nuclear monitoring method.
   ADVANTAGE - The method enables solving problem that manual monitoring, reducing labor investment and low efficiency and satisfying timely surface corrosion monitoring of material property and continuity requirements.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a convolutional neural network training method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a convolutional neural network based nuclear monitoring method. '(Drawing includes non-English language text)'
   Step for collecting nuclear component surface video data by a image collecting module (S1)
   Step for sending nuclear component surface video data to a video data monitoring and pre-warning module (S2)
   Step for obtaining image data by the nuclear component surface video data, where the image data is divided into training data set and test data set (S3)
   Step for sending training data set to a convolutional neural network for training a feature identification model and outputs primary distinguishing characteristic (S4)
   Step for classifying training data set to obtain corrosion type (S5)
   Step for sending testing data set to the feature identification model (S6)
   Step for satisfying testing data set by the corrosion type (S7)
   Step for displaying corrosion type on a human-computer interaction interface to realize a nuclear component surface corrosion type identification and early warning process by the video data monitoring and pre-warning module (S8)
DC K05 (Nuclear reactors and simulators - including reactor processes, components and accessories, but excluding power plant (G21B, C).); T01 (Digital Computers)
MC K05-B06D; K05-B07J; T01-N01B3A; T01-N02B2
IP G21C-017/08
PD CN109003689-A   14 Dec 2018   G21C-017/08   201908   Pages: 13   Chinese
AD CN109003689-A    CN10524745    28 May 2018
PI CN10524745    28 May 2018
UT DIIDW:2018A3429B
ER

PT P
PN CN109000622-A
TI Deep learning based underwater target object locating method, involves obtaining reference image of reference object, and determining distance information between reference object and target object to obtain position information of object.
AU HAO W
   LI Y
   WU H
   LI D
   CUI M
   ZHANG Y
AE ACAD OPTO ELECTRONICS CHINESE ACAD SCI (CPGD-C)
GA 2018A35015
AB    NOVELTY - The method involves obtaining a reference image of a reference object around a target object (S1), where the reference object is selected as a predetermined beacon or a marine organism. Depth position information of underwater is obtained (S2) according to the reference image. Distance information between the reference object and the target object is determined by using by a depth sensor and a multi-sensor to obtain the position information of the target object in underwater. The reference object in the reference image is identified by using deep learning algorithm.
   USE - Deep learning based underwater target object locating method.
   ADVANTAGE - The method enables improving hidden property locating efficiency based on satellite positioning system.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a deep learning based underwater target object locating system
   (2) a deep learning based underwater target object locating device
   (3) a non-transitory computer-readable storage medium for storing a set of instructions for locating underwater target object based on deep learning.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based underwater target object locating method. '(Drawing includes non-English language text)'
   Step for obtaining a reference image of a reference object around a target object (S1)
   Step for obtaining depth position information of underwater according to reference image (S2)
DC S02 (Engineering Instrumentation); T01 (Digital Computers)
MC S02-B04; T01-J16C2; T01-J30A; T01-S03
IP G01C-011/04
PD CN109000622-A   14 Dec 2018   G01C-011/04   201908   Pages: 7   Chinese
AD CN109000622-A    CN10479354    18 May 2018
PI CN10479354    18 May 2018
UT DIIDW:2018A35015
ER

PT P
PN CN109001211-A
TI Convolutional neural network based long-distance pipeline welding line detecting system, has layer feature map module for filtering first characteristic map layer of second layer feature map module to obtain second characteristic map layer.
AU LI J
   ZHANG F
   HE C
   XU J
   HUO Z
   ZHAO J
   YANG L
AE SUZHOU SAIKEAN INFORMATION TECHNOLOGY CO LTD (SUZH-Non-standard)
GA 2018A3762X
AB    NOVELTY - The system has a first layer feature map module for performing convolution process to an input image with three training filters. The first layer feature map module generates three first characteristic map layer. A second feature map module weights and biases characteristic map of the first layer feature map module to obtain second characteristic map layer of the second feature map module by a sigmoid. A third layer feature map module filters the second characteristic map layer of the second layer feature map module to obtain a third characteristic map layer of the third feature map module.
   USE - Convolutional neural network based long-distance pipeline welding line detecting system.
   ADVANTAGE - The system utilizes the convolutional neural network and improves judging accuracy of welding gap, and detects weld of long-distance pipeline to avoid risk of manual detection d.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of a convolutional neural network based long-distance pipeline welding line detecting system. '(Drawing includes non-English language text)'
DC S03 (Scientific Instrumentation); T01 (Digital Computers)
MC S03-E04F; T01-J04B2; T01-J10B1; T01-N01B3
IP G01N-021/88; G06N-003/04
PD CN109001211-A   14 Dec 2018   G01N-021/88   201908   Pages: 6   Chinese
AD CN109001211-A    CN10585115    08 Jun 2018
PI CN10585115    08 Jun 2018
UT DIIDW:2018A3762X
ER

PT P
PN CN109001557-A
TI Method for identifying aircraft electromechanical system fault based on random convolutional neural network, involves using trained random convolutional neural network to identify fault of aircraft electromechanical system.
AU LIANG T
   JIANG H
   WANG Z
   LI H
   TIAN H
AE UNIV NORTHWESTERN POLYTECHNICAL (UNWP-C)
GA 2018A4004V
AB    NOVELTY - The method involves extracting vibration acceleration signals of specified bearings and rotors in an aircraft electromechanical system into training samples and test samples. The training samples and the test samples are respectively subjected to short-time Fourier transform and decibel transformation normalization to obtain a training two-dimensional time-frequency map and a test two-dimensional time-frequency map. The two-dimensional time-frequency diagram is trained to input the initialized random convolutional neural network. The weight parameter of the random convolutional neural network is trained layer by layer according to the mean square error. The training of the random convolutional neural network is completed. The trained random convolutional neural network is used to identify the fault of the aircraft electromechanical system by testing two-dimensional time-frequency map.
   USE - Method for identifying aircraft electromechanical system fault based on random convolutional neural network.
   ADVANTAGE - The model over-fitting is suppressed, and the generalization ability is enhanced. The process has good recognition effect, strong practicability, simple and easy operation.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart illustrating the process for identifying aircraft electromechanical system fault. (Drawing includes non-English language text)
DC S01 (Electrical Instruments); T01 (Digital Computers); W06 (Aviation, Marine and Radar Systems)
MC S01-G; S01-H07A; T01-J04B1; T01-J07D3; T01-N01B3A; W06-B01B8; W06-B05
IP G01R-031/00; G06N-003/04
PD CN109001557-A   14 Dec 2018   G01R-031/00   201908   Pages: 18   Chinese
AD CN109001557-A    CN10592166    11 Jun 2018
PI CN10592166    11 Jun 2018
UT DIIDW:2018A4004V
ER

PT P
PN IN201741036556-A; WO2019073312-A1
TI Method for integrating image channels in deep learning model for classification of objects in sample, involves providing image channels to deep learning model to integrate image channels with deep learning model.
AU PANDE H
   AZIZ A
   CHELUVARAJU B
   DASTIDAR T R
   APURV A
   PANDEY R K
   ANAND A
AE SIGTUPLE TECHNOLOGIES PRIVATE LTD (SIGT-Non-standard)
   SIGTUPLE TECHNOLOGIES PRIVATE LTD (SIGT-Non-standard)
GA 2018A27754
AB    NOVELTY - The method involves receiving (401) a microscopic image of a sample comprising objects by an integration unit. Multiple image channels for the microscopic image are generated (402) using an image operator. The image channels comprise color image channel and hand-crafted image channel. The image channels are provided (403) to a deep learning model to integrate the image channels with the deep learning model for classification of the objects.
   USE - Method for integrating image channels in deep learning model for classification of objects in sample.
   ADVANTAGE - The deep learning model is enabled to classify objects even with usage of minimal data of objects. The higher precision and higher sensitivity can be provided in the deep learning model for the classification.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for an integration unit for integrating image channels in a deep learning model for classification of objects in a sample.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the method for integrating image channels in a deep learning model for classification of objects in a sample.
   Step for receiving a microscopic image of a sample comprising objects (401)
   Step for generating the image channels for the microscopic image (402)
   Step for providing the image channels (403)
   Step for training the deep learning model (404)
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-F03; T01-F05G3; T01-J05B2; T01-J05B4P; T01-J30A; W04-W05A
IP G06F-017/30; G06F-009/44; G06T-007/00; G06K-009/62
PD IN201741036556-A   14 Dec 2018   G06F-017/30   201908   Pages: 40   English
   WO2019073312-A1   18 Apr 2019   G06T-007/00   201930      English
AD IN201741036556-A    IN41036556    13 Oct 2017
   WO2019073312-A1    WOIB056266    20 Aug 2018
PI IN41036556    13 Oct 2017
DS WO2019073312-A1: 
		      (National): AE; AG; AL; AM; AO; AT; AU; AZ; BA; BB; BG; BH; BN; BR; BW; BY; BZ; CA; CH; CL; CN; CO; CR; CU; CZ; DE; DJ; DK; DM; DO; DZ; EC; EE; EG; ES; FI; GB; GD; GE; GH; GM; GT; HN; HR; HU; ID; IL; IN; IR; IS; JO; JP; KE; KG; KH; KN; KP; KR; KW; KZ; LA; LC; LK; LR; LS; LU; LY; MA; MD; ME; MG; MK; MN; MW; MX; MY; MZ; NA; NG; NI; NO; NZ; OM; PA; PE; PG; PH; PL; PT; QA; RO; RS; RU; RW; SA; SC; SD; SE; SG; SK; SL; SM; ST; SV; SY; TH; TJ; TM; TN; TR; TT; TZ; UA; UG; US; UZ; VC; VN; ZA; ZM; ZW
      (Regional): BW; GH; GM; KE; LR; LS; MW; MZ; NA; RW; SD; SL; ST; SZ; TZ; UG; ZM; ZW; EA; AL; AT; BE; BG; CH; CY; CZ; DE; DK; EE; ES; FI; FR; GB; GR; HR; HU; IE; IS; IT; LT; LU; LV; MC; MK; MT; NL; NO; PL; PT; RO; RS; SE; SI; SK; SM; TR; OA
UT DIIDW:2018A27754
ER

PT P
PN CN109002831-A
TI Method for classifying breast density in medical field based on convolutional neural network, involves inputting sample to network model, and acquiring probability of classification of breast density to obtain classified result of sample.
AU QIN G
   XU Z
   CHEN W
   MA L
   HE Z
AE UNIV SOUTHERN MEDICAL NANFANG HOSPITAL (UNSM-C)
GA 2018A3448B
AB    NOVELTY - The method involves collecting and classifying a mammary molybdenum target image to obtain a marked mammary molybdenum target image. The marked mammary molybdenum target image is pre-processed to obtain a molybdenum target training image. The molybdenum target training image is input to a convolutional neural network model for training. The trained predictive network model is obtained. A to-be-predicted testing sample is input to a breast classification forecasting network model to process. Probability of classification of breast density is acquired to obtain a classified result of the testing sample.
   USE - Method for classifying breast density in medical field based on convolutional neural network.
   ADVANTAGE - The method enables realize training of end-to-end through a convolution neural network model so as to automatically learn image features from a large number of mammary molybdenum target images and effectively improve adaptability of medical data and improve accuracy of classification forecast.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a convolutional neural network-based breast density classification device
   (2) a convolutional neural network-based breast density classification system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for classifying breast density in medical field based on convolutional neural network. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J05B2; T01-J10B2; T01-J16C2; T01-N01B3A; T01-N01E1; T04-D04
IP G06K-009/62; G06K-009/66; G06N-003/04
PD CN109002831-A   14 Dec 2018   G06K-009/62   201908   Pages: 8   Chinese
AD CN109002831-A    CN10582349    05 Jun 2018
PI CN10582349    05 Jun 2018
UT DIIDW:2018A3448B
ER

PT P
PN CN109002798-A
TI Convolutional neural network based clinical medicine single guide visual evoked potential waveform extracting method, involves pre-processing visual evoked potential signal, and obtaining evoked potential waveform by using neural network.
AU QIU T
   CHOU Y
AE UNIV DALIAN TECHNOLOGY (UYDA-C)
GA 2018A34497
AB    NOVELTY - The method involves obtaining an observation signal and a visual evoked potential signal under visual stimulation. An EEG signal is obtained through scalp under visual stimulation. Data of the observation signal and the visual evoked potential is obtained by using Fourier transform and inverse Fourier transform. Zero-mean data of the observation signal is processed. A deep learning network is established to extract the visual evoked potential signals. The observation signal and the visual evoked potential signal are pre-processed and utilized as input signals and supervisory signal. Evoked potential waveform is obtained by using a convolutional neural network.
   USE - Convolutional neural network based clinical medicine single guide visual evoked potential waveform extracting method.
   ADVANTAGE - The method enables realizing dynamic tracking process of change of the evoked potential under different time stimulation to complete extraction of the evoked potential waveform so as to provide basis for analysis and research of the evoked potential clinical medicine.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network based clinical medicine single guide visual evoked potential waveform extracting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B1; T01-J10B2; T01-N01B3
IP G06K-009/00; G06K-009/62; G06N-003/04
PD CN109002798-A   14 Dec 2018   G06K-009/00   201908   Pages: 8   Chinese
AD CN109002798-A    CN10795005    19 Jul 2018
PI CN10795005    19 Jul 2018
UT DIIDW:2018A34497
ER

PT P
PN CN109003659-A
TI Stomach pylorus helicobacter pylori infection pathological diagnosis support system, has convolutional neural network model training unit for adjusting parameter of convolution neural network model to train convolution neural network model.
AU WAN X
AE WAN X (WANX-Individual)
   CHEN H (CHEN-Individual)
   FAN X (FANX-Individual)
   WANG L (WANG-Individual)
   LIN H (LINH-Individual)
   FENG L (FENG-Individual)
   DOU Q (DOUQ-Individual)
   WANG P (WANG-Individual)
   ZHU Y (ZHUY-Individual)
   HUANG Y (HUAN-Individual)
   UNIV SUN YAT-SEN SIXTH AFFILIATED (UYSY-C)
   SHENZHEN IMSIGHT MEDICAL TECHNOLOGY CO (SHEN-Non-standard)
GA 2018A37550
AB    NOVELTY - The system has an image data obtaining unit for obtaining a pathology slice image and a stomach normal slice image. An image data marking unit marks input image data. An image data classifying unit classifies the input image data. An image database constructing unit is used for constructing a pathological image database. A convolutional neural network constructing unit is used for constructing a first convolution neural network model. A convolutional neural network model training unit adjusts parameter of the first convolution neural network model to train the first convolution neural network model to establish a second convolution neural network model.
   USE - Stomach pylorus helicobacter pylori infection pathological diagnosis support system.
   ADVANTAGE - The system can perform diagnosis operation inn an accurate and efficient manner, and has high working efficiency.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a stomach pylorus helicobacter pylori infection pathological diagnosis supporting method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a stomach pylorus helicobacter pylori infection pathological diagnosis support system. '(Drawing includes non-English language text)'
DC S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S05-D06; S05-D08A; S05-G02G; T01-J04B2; T01-J05B4F; T01-N01B3; T01-N01E1
IP G16H-030/20; G16H-050/20; G16H-040/67
PD CN109003659-A   14 Dec 2018   G16H-030/20   201908   Pages: 15   Chinese
AD CN109003659-A    CN10423850    07 Jun 2017
PI CN10423850    07 Jun 2017
UT DIIDW:2018A37550
ER

PT P
PN CN109001631-A
TI Online automobile battery performance evaluating system, has intelligent depth learning unit fixed on cloud terminal for optimizing learning model, and battery pack whose front end is connected to depth learning unit.
AU XIONG X
AE ZHANGJIAGANG MOTOPU DATA TECHNOLOGY CO (ZHAN-Non-standard)
GA 2018A37641
AB    NOVELTY - The system has an instant comprehensive evaluating unit fixed on a front end of a battery pack for evaluating comprehensive performance of a battery by an artificial intelligent depth learning model, where the depth learning model comprises an electrochemical model and a depth neural network model and the depth neural network model comprises a CNN, a LSTM layer, a tank layer, a connecting layer and an activation function layer. A large data storage unit is connected with the depth learning unit that is fixed on a cloud terminal for optimizing the learning model. The front end of the battery pack is connected with the intelligent depth learning unit to update. The comprehensive evaluation unit determines electric characteristic parameters and environmental parameters of the battery through a Controller Area Network (CAN) bus. The instant comprehensive evaluation unit utilizes a multi-core ARM (RTM: 32 bit reduced instruction set computer processor) system.
   USE - Online automobile battery performance evaluating system.
   ADVANTAGE - The system realizes on-line battery performance evaluating process, and can fully utilize a data cell to train height of automobile local intelligent depth of learning model for adapting a complex actual real work scene, and has high cloud storage and cloud computing ability. The system continuously optimizes local manual front end of the intelligent depth learning model so as to improve maturity of the battery and reduce incidence of failure and risk in battery charging and discharging, improve safety performance and prolong service life.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for an online automobile battery performance evaluating method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of an online automobile battery performance evaluating system. '(Drawing includes non-English language text)'
DC S01 (Electrical Instruments); T01 (Digital Computers); X16 (Electrochemical Storage)
MC S01-G06; T01-J07D1; T01-N01B3; T01-N01D3A; X16-F06A; X16-H09
IP G01R-031/36
PD CN109001631-A   14 Dec 2018   G01R-031/36   201908   Pages: 8   Chinese
AD CN109001631-A    CN10392331    27 Apr 2018
PI CN10392331    27 Apr 2018
UT DIIDW:2018A37641
ER

PT P
PN CN109001833-A
TI Deep learning based terahertz dangerous goods detecting method, involves detecting CNN neural network model to terahertz image of to-be-detected object, and adding terahertz image of to-be-detected object into dangerous image database.
AU ZHANG K
   GONG Y
   ZHAO G
   LI S
   WANG H
AE TIANHE DEFENSE TECHNOLOGY BEIJING CO LTD (TIAN-Non-standard)
GA 2018A3770R
AB    NOVELTY - The method involves establishing database of a dangerous sample image and goods classification. Detecting dangerous goods is obtained by a terahertz image. A negative sample image is added. A CNN neural network model is established. Cross-validation experiment result is obtained. A final network model is established. A terahertz image of a to-be-detected object is collected by a terahertz device. The CNN neural network model is detected to the terahertz image of the to-be-detected object. Detection result is obtained. The terahertz image of the to-be-detected object is added into a dangerous sample image database.
   USE - Deep learning based terahertz dangerous goods detecting method.
   ADVANTAGE - The method enables reducing complexity of selected network parameters, learning sample image data of a character, ensuring image classification and pattern recognition and improving working efficiency of inspection personnel. The method enables reducing workload of a worker, and ensuring inspection of larger people.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning based terahertz dangerous goods detecting method. '(Drawing includes non-English language text)'
DC S03 (Scientific Instrumentation); T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC S03-C04A; S03-C08; T01-J05B2; T01-J05B4F; T01-J10B2A; T01-J10B3A; T01-N01B3; T04-D04
IP G01V-008/10; G06F-017/30; G06K-009/62; G06N-003/04; G06N-003/08
PD CN109001833-A   14 Dec 2018   G01V-008/10   201908   Pages: 9   Chinese
AD CN109001833-A    CN10654761    22 Jun 2018
PI CN10654761    22 Jun 2018
UT DIIDW:2018A3770R
ER

PT P
PN CN109001834-A
TI Deep learning based terahertz dangerous goods detecting method, involves identifying spectrum information feature, adding spectrum characteristic of goods into goods database when goods is recognized as dangerous goods, and processing alarm.
AU ZHANG K
   GONG Y
   ZHAO G
   LI S
   WANG H
AE TIANHE DEFENSE TECHNOLOGY BEIJING CO LTD (TIAN-Non-standard)
GA 2018A3770Q
AB    NOVELTY - The method involves obtaining a classifier for detecting dangerous goods. Human terahertz image is collected to obtain a human body area by adopting a passive terahertz inspection instrument. Target detection and positioning is performed on the locating human body area to obtain position and size of the dangerous goods carried by human and active terahertz spectrum analysis is performed on the dangerous goods. Spectral information characteristic of dangerous goods carrying by the human is extracted. Spectrum information feature is identified and judged through the classifier. The spectrum characteristic of the dangerous goods is added into goods database when the goods is recognized as dangerous goods. An alarm is processed.
   USE - Deep learning based terahertz dangerous goods detecting method.
   ADVANTAGE - The method enables improving inspection efficiency, and saving inspection cost, quickly locating and identifying dangerous goods carried by human with safe and non-radiation to realize human carrying dangerous goods of metal and non-metal to non-contact type inspection.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based terahertz dangerous goods detecting method. '(Drawing includes non-English language text)'
DC S03 (Scientific Instrumentation); S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S03-C04A; S03-C08; S05-G02G3; T01-J05B4P; T01-J30A
IP G01V-008/10
PD CN109001834-A   14 Dec 2018   G01V-008/10   201908   Pages: 9   Chinese
AD CN109001834-A    CN10654764    22 Jun 2018
PI CN10654764    22 Jun 2018
UT DIIDW:2018A3770Q
ER

PT P
PN CN109002845-A
TI Deep convolutional neural network based fine-grained image classifying method, involves calculating classification accuracy of label or test data set during test image classification by using trained deep convolutional neural network model.
AU ZHANG Y
   GONG Y
   SHI W
   CHENG D
   TAO X
AE UNIV XIAN JIAOTONG (UYXJ-C)
GA 2018A3447Y
AB    NOVELTY - The method involves establishing a fine-grained image classification data set. Training data is divided into a training data set and a validation data set. A deep convolutional neural network (DCNN) model is established for classifying the fine-grained image. The DCNN model is trained by using the training data set. Network model parameters are stored when the trained DCNN model reaches set accuracy on the validation data set. Classification accuracy of a label or test data set is calculated during test image classification by using the trained DCNN model.
   USE - DCNN based fine-grained image classifying method.
   ADVANTAGE - The method enables classifying fine-grained image with better portability.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of a deep convolutional neural network model. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04A; T01-J05B2; T01-J10B2; T01-N01B3A
IP G06K-009/62; G06N-003/04; G06N-003/08
PD CN109002845-A   14 Dec 2018   G06K-009/62   201908   Pages: 17   Chinese
AD CN109002845-A    CN10715090    29 Jun 2018
PI CN10715090    29 Jun 2018
UT DIIDW:2018A3447Y
ER

PT P
PN CN109002562-A
TI Apparatus recognition model training method, involves storing and establishing characteristic database in depth convolutional neural network model and as instrument recognition model corresponding to each category tag.
AU ZHOU L
   TONG H
   NIE Z
   FENG L
   LI Y
AE BEIJING XINLIFANG TECHNOLOGIES INC (BEIJ-Non-standard)
GA 2018A3454X
AB    NOVELTY - The method involves obtaining multiple instrument sample images with a category tag and a name tag. The category tag is divided into multiple classes according to visual similarity attribute of multiple instruments. A depth convolutional neural network (CNN) model is established to obtain a wheel training model. Characteristic vector of each instrument sample image is determined by a class label based on the depth CNN model. Characteristic database is obtained corresponding to the class label. The characteristic database is stored in the depth CNN model and established as an instrument recognition model corresponding to each category tag.
   USE - Apparatus recognition model training method.
   ADVANTAGE - The method enables sorting and searching an apparatus recognition model during an instrument identification process so as to avoid problem of low recognition rate caused by dividing-type multi-low identifying precision or by directly traversing the characteristic database to search a result, thus improving identification precision and identification efficiency in an effective manner.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) an instrument identification method
   (2) an apparatus recognition model training device
   (3) an instrument identification device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an apparatus recognition model training method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B4P; T01-J10B2A; T01-N01B3; T01-N03A2; T04-D04; T04-D07D3; T04-K03B
IP G06F-017/30; G06K-009/62; G06N-003/04; G06N-003/08
PD CN109002562-A   14 Dec 2018   G06F-017/30   201908   Pages: 21   Chinese
AD CN109002562-A    CN11001676    30 Aug 2018
PI CN11001676    30 Aug 2018
UT DIIDW:2018A3454X
ER

PT P
PN CN108985337-A
TI Method for detecting surface scratch of product based on image depth learning, involves performing online detection and detection of scratch defects on highly reflective surfaces by using multi-layer convolutional neural networks.
AU CHEN B
   LI W
   LI J
   DU H
   JIANG Z
   XU H
   QIAN J
AE CHINESE ACAD SCI GUANGZHOU ELECTRONIC TE (CHSC-Non-standard)
GA 2018A1964J
AB    NOVELTY - The method involves collecting an image by an image collecting module. A collected image is divided into equal-sized image blocks. Multiple types of scratched and scratch-free image blocks are selected from the equal-sized image block as a training set sample. Offline training of a deep convolutional neural network is performed by using training set samples. A multi-layer convolutional neural network is selected by the deep convolutional neural network based on a metal surface defect detection network MSDDNet. Online detection and detection of scratch defects are performed on highly reflective surfaces by using multi-layer convolutional neural networks.
   USE - Method for detecting a surface scratch of a product based on image depth learning.
   ADVANTAGE - The method enables detecting and identifying the scratches on a high reflective surface by using trained a network model so as to identify scratch defects in a light and shadow area in image recognition.
   DESCRIPTION OF DRAWING(S) - The drawing shows a perspective view of a multi-layer convolutional neural network.
DC T01 (Digital Computers)
MC T01-J10B1; T01-J10B2A; T01-N01B3
IP G06K-009/62; G06N-003/04
PD CN108985337-A   11 Dec 2018   G06K-009/62   201908   Pages: 10   Chinese
AD CN108985337-A    CN10637934    20 Jun 2018
PI CN10637934    20 Jun 2018
UT DIIDW:2018A1964J
ER

PT P
PN CN108985169-A
TI Deep learning target detection and dynamic background modeling based store cross door management detection method, involves establishing storefront detection model and object detection model to obtain learning network of VGG network.
AU CHEN J
   GONG X
   LI Y
   PAN A
AE UNIV ZHEJIANG TECHNOLOGY (UYZT-C)
GA 2018A28382
AB    NOVELTY - The method involves obtaining a road monitoring video and cutting a road monitoring video into a frame image. A storefront detection model is established to obtain a location of a storefront in the frame image. An image of an outer road plate area of the storefront is divided into the frame image. Vi-Be process is performed on background modeling and differential process. The frame image is detected by an object detection model when viewing angle of a video is not fixed. A cross door management alarm is performed. An object store classification model is trained to obtain a VGG network. The storefront detection model and the object detection model are established to obtain a learning network of the VGG network and a Faster R-CNN network.
   USE - Deep learning target detection and dynamic background modeling based store cross door management detection method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning target detection and dynamic background modeling based store cross door management detection method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W04 (Audio/Video Recording and Systems); W05 (Alarms, Signalling, Telemetry and Telecontrol)
MC T01-J05B2; T01-J10B2; T01-J10B3; T01-J10E; T01-J21; T01-N01B3; T01-N02B2; T04-D04; W04-P01C; W04-W05A; W05-A03C
IP G06K-009/00; G06K-009/62
PD CN108985169-A   11 Dec 2018   G06K-009/00   201908   Pages: 13   Chinese
AD CN108985169-A    CN10619324    15 Jun 2018
PI CN10619324    15 Jun 2018
UT DIIDW:2018A28382
ER

PT P
PN CN108985342-A
TI Depth enhanced learning based unbalanced classification method, involves constructing classification task and interaction rules of intelligent body, and determining neural network model learned Q function.
AU CHEN Q
   QI X
   LIN E
AE UNIV SOUTH CHINA TECHNOLOGY (UYSC-C)
GA 2018A1964D
AB    NOVELTY - The method involves constructing classification task and interaction rules of an intelligent body. An action space of the intelligent body is formed. An external environment is created. A deep neural network model is established. Reinforcement learning is trained based on depth of an unbalanced classification model. Neural network model learned Q function is determined. Training sample in the external environment is obtained. Positive return value or negative return value is obtained from the external environment when classification is correct. Target of the intelligent body is obtained in the classification task accumulated reward at unbalanced classification task. Unbalanced data classification policy is obtained.
   USE - Depth enhanced learning based unbalanced classification method.
   ADVANTAGE - The method enables providing higher value of rewards and penalties of samples classified action by responding function to improve minority sample features in the classification model, and obtaining different unbalanced degree of data to learn correct classification policy, so that actual application value can be obtained, thus ensuring learning popularization.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a depth enhanced learning based unbalanced classification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2; T01-J05B4P; T01-J10B2; T01-N01B3; T04-D03; T04-D04
IP G06K-009/62; G06F-017/30
PD CN108985342-A   11 Dec 2018   G06K-009/62   201908   Pages: 15   Chinese
AD CN108985342-A    CN10652374    22 Jun 2018
PI CN10652374    22 Jun 2018
UT DIIDW:2018A1964D
ER

PT P
PN CN108985153-A
TI Face recognition method, involves obtaining two characteristic vectors according to pre-established convolutional neural network, and calculating facial similarity between two facial images according to characteristic vector group.
AU CHEN Z
   XU Y
   CHEN R
AE CHENGDU TONGJIA YOUBO TECHNOLOGY CO LTD (CHEN-Non-standard)
GA 2018A1968X
AB    NOVELTY - The method involves receiving two facial images. Two characteristic vectors are obtained according to a pre-established convolutional neural network. Relationship is established between two characteristic vectors, where the second characteristic vector is provided with a characteristic vector group. Facial similarity between two facial images is calculated according to the characteristic vector group. A recognition fragment corresponding to the pre-established convolutional neural network is obtained. A similarity group is formed according to determined similarity.
   USE - Face recognition method.
   ADVANTAGE - The method enables avoiding characteristic error caused by interference and increasing robustness of a facial recognition system. The method enables reducing face recognition model training cost.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a face recognition device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart of a face recognition method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E01A; T01-E03; T01-E04; T01-J04C; T01-J10B2A; T04-D07F1
IP G06K-009/00
PD CN108985153-A   11 Dec 2018   G06K-009/00   201908   Pages: 13   Chinese
AD CN108985153-A    CN10566589    05 Jun 2018
PI CN10566589    05 Jun 2018
UT DIIDW:2018A1968X
ER

PT P
PN CN108985147-A
TI Method for detecting target object in target candidate area, involves determining whether area that satisfies preset condition from each of input image is defined as target candidate area, and outputting target candidate area.
AU CHEN Z
   LONG X
   CHEN R
AE CHENGDU TONGJIA YOUBO TECHNOLOGY CO LTD (CHEN-Non-standard)
GA 2018A19690
AB    NOVELTY - The method involves obtaining multi input images with different sizes. A target probability distribution map of each of the input images is obtained based on pre-established convolutional neural networks. Determination is made to check whether an area that satisfies a preset condition from each of the input image is defined as a target candidate area based on the target probability distribution map. A target candidate area is outputted. A first probability distribution of the input image is obtained based on a pre-established first convolutional neural network. A second convolutional neural network is screened from each of the input images based on the first probability distribution.
   USE - Method for detecting a target object in a target candidate area.
   ADVANTAGE - The method enables sieving the input image by the convolutional neural network so as to reduce a number of target candidate areas, thus obtaining a final output of the target candidate area containing an object in an effective manner, hence improving detection precision and detection efficiency of the target.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a device for detecting a target object in a target candidate area.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for detecting a target object in a target candidate area. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B2; T01-J10B3A; T01-N01D1B
IP G06K-009/00; G06N-003/04
PD CN108985147-A   11 Dec 2018   G06K-009/00   201908   Pages: 14   Chinese
AD CN108985147-A    CN10552844    31 May 2018
PI CN10552844    31 May 2018
UT DIIDW:2018A19690
ER

PT P
PN CN108985170-A
TI Three-frame difference and deep learning based transmission suspender identification method, involves screening suspender according to threshold of classification, and outputting image to determine suspender region rectangular label.
AU CHEN Z
   CAI F
   HAN J
   LV C
AE SHANDONG CENT ELECTRONIC CO LTD (SHAN-Non-standard)
GA 2018A1968M
AB    NOVELTY - The method involves inputting an image. The image is preprocessed. Three frames of the image are matched with each other by utilizing an enhanced HOG feature algorithm. Difference between the frames is determined after matching process. ROI area extracting and detecting process is performed on an original suspected suspender. A classification model is trained by utilizing a yolov2 deep learning algorithm. Changed ROI region is classified by the training model to determine whether suspension exists. The suspender is screened according to threshold of classification. The image is outputted to determine a suspender region rectangular label.
   USE - Three-frame difference and deep learning based transmission suspender identification method.
   ADVANTAGE - The method enables effectively avoiding effects of illumination, camera shake and scene change, and reducing false alarm rate to satisfy requirements of detecting processing speed.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a three-frame difference and deep learning based transmission suspender identification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2; T01-J10B2; T01-J10B3A; T01-J16C2; T01-J30A; T04-D04; T04-D07B1
IP G06K-009/00; G06K-009/62
PD CN108985170-A   11 Dec 2018   G06K-009/00   201908   Pages: 9   Chinese
AD CN108985170-A    CN10621571    15 Jun 2018
PI CN10621571    15 Jun 2018
UT DIIDW:2018A1968M
ER

PT P
PN CN108985148-A
TI Hand key point detecting method, involves extracting hand feature image, predicting key point and field based on convolution neural network and hand feature image, and matching key point with field to determine position of hand key point.
AU CHEN Z
   LONG X
   CHEN R
AE CHENGDU TONGJIA YOUBO TECHNOLOGY CO LTD (CHEN-Non-standard)
GA 2018A1968Y
AB    NOVELTY - The method involves sampling an original image along downward direction to obtain image pyramid, where the original image is an RGB image. A hand position region is obtained based on a first pre-established convolution neural network and the image pyramid. A hand feature image is extracted based on the pre-established depth learning model and the hand position region. A key point and a field are predicted based on a second convolution neural network and the hand feature image. The key point is matched with the field to determine a position of the hand key point.
   USE - Hand key point detecting method.
   ADVANTAGE - The method enables determining the position of the hand key point by estimating hand gesture through the RGB image, screening an image pyramid by the first convolution neural network so as to increase hand key point detection accuracy, and improving hand key point detection efficiency.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a hand key point detection device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a hand key point detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J10B2; T01-N01B3; T04-D02; T04-D07D5; T04-D08
IP G06K-009/00; G06K-009/32
PD CN108985148-A   11 Dec 2018   G06K-009/00   201908   Pages: 17   Chinese
AD CN108985148-A    CN10553717    31 May 2018
PI CN10553717    31 May 2018
UT DIIDW:2018A1968Y
ER

PT P
PN CN108972593-A
TI Method for controlling industrial robot system, involves training neural network model to extract position and attitude of operating object by using deep learning algorithm, and displaying key frame image by processor based on touch screen.
AU CHENG W
   LI L
   YANG Q
   LUO H
   KE M
   YANG G
   QIU L
AE SHUNDE POLYTECHNIC (SHUN-Non-standard)
GA 2018A27052
AB    NOVELTY - The method involves sending a control command to a visual controller by a control system based on a PLC module. The visual controller is triggered to operate according to the control command. A video stream of an industrial robot operating object is shoot by the visual controller based on the control command. A neural network model is trained to extract position and attitude of the operating object by using a deep learning algorithm. A key frame image with motion difference is sent to a processor in the control system based on an Ethernet module. The key frame image is displayed by the processor based on a touch screen.
   USE - Method for controlling industrial robot system (claimed).
   ADVANTAGE - The method enables sending a fast key frame image content to the touch screen so as to realize targeted error analysis process, and storing differential images in the control system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for controlling industrial robot system. '(Drawing includes non-English language text)'
DC P62 (Hand tools, cutting (B25, B26).); T01 (Digital Computers); T04 (Computer Peripheral Equipment); X25 (Industrial Electric Equipment)
MC T01-F06; T01-F07; T01-J07B; T01-J10B2; T01-J16C2; T01-N01B3; T01-N01D1B; T04-F02A2; T04-H04; X25-A03E; X25-A03F
IP B25J-013/06; B25J-009/16
PD CN108972593-A   11 Dec 2018   B25J-013/06   201908   Pages: 10   Chinese
AD CN108972593-A    CN11050532    07 Sep 2018
PI CN11050532    07 Sep 2018
UT DIIDW:2018A27052
ER

PT P
PN CN108984481-A
TI Convolutional neural network-based homography matrix estimating method, involves generating data set, forming convolution layer with normalization layer, and inputting output of full connection layer to dropout layer.
AU DAI S
   LIN C
   WEI Z
   GAO J
AE UNIV HUAQIAO (UYHQ-C)
GA 2018A1984Q
AB    NOVELTY - The method involves generating data set. Data set is input to a first convolutional layer of a convolutional neural network. The first convolutional layer is output to a normalization layer. A second convolutional layer is output to the first convolutional layer. The second convolutional layer is output to the normalization layer. A third convolution layer is output to a first pool layer of the convolutional neural network. A fourth convolution layer is formed with the normalization layer. Output of a full connection layer is input to a dropout layer. Transformation matrix front quadrilateral vertices and perturbation are calculated by using direct linear conversion process.
   USE - Convolutional neural network-based homography matrix estimating method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a convolutional neural network-based homography matrix estimating method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J04C
IP G06F-017/16; G06N-003/04; G06N-003/08
PD CN108984481-A   11 Dec 2018   G06F-017/16   201908   Pages: 11   Chinese
AD CN108984481-A    CN10671660    26 Jun 2018
PI CN10671660    26 Jun 2018
UT DIIDW:2018A1984Q
ER

PT P
PN CN108985475-A
TI Depth neural network based car-hailing service calling requirement prediction method, involves training area getting requirement prediction model based on historical data using trained model to car hailing of each area control vehicle.
AU FAN X
   XIAO L
   WANG C
   CHEN L
AE UNIV XIAMEN (UYXI-C)
GA 2018A19614
AB    NOVELTY - The method involves performing city street grid division to form a grid area. Getting demand quantity counting in each area is calculated with respect to order data according to car hailing. A car-hailing service calling requirement prediction model is designed. Space time characteristic is obtained based on deep neural network. Weather influence factor is combined to a taxi car hailing user. Getting demand of a region is predicted. An area getting requirement prediction model is trained based on historical data using a trained model to car hailing of each area control vehicle to predicted demand.
   USE - Depth neural network based car-hailing service calling requirement prediction method.
   ADVANTAGE - The method enables expressing car hailing call requirement of complex nonlinear spatial correlation characteristic and obtaining high prediction precision.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a depth neural network based car-hailing service calling requirement prediction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E01A; T01-J04B2; T01-J07D1; T01-N01A2; T01-N01B3
IP G06Q-010/02; G06Q-010/04; G06Q-010/06; G06N-003/04
PD CN108985475-A   11 Dec 2018   G06Q-010/02   201908   Pages: 12   Chinese
AD CN108985475-A    CN10609232    13 Jun 2018
PI CN10609232    13 Jun 2018
UT DIIDW:2018A19614
ER

PT P
PN CN108985381-A
TI Nitrogen oxide emissions prediction model determining method, involves predicting discharge space and variable sample space, obtaining reconstructed sample by partial least squares to determine nitrogen oxide emissions prediction model.
AU FU J
   XIAO H
   ZHANG R
   ZHANG C
   WANG L
AE UNIV GUANGDONG TECHNOLOGY (UGTE-C)
GA 2018A19639
AB    NOVELTY - The method involves obtaining an independent sub sample space. Coal burning boiler parameter of the sub sample space is determined. The sub sample space is processed by using significant offset convolutional neural network. A sub-space prediction model of the sub sample space is determined. Predicted amount of nitrogen is calculated by using the sub-space prediction model corresponding to the coal burning boiler parameter. A discharge space and a variable sample space are predicted. A reconstructed sample is obtained by using partial least squares to determine final nitrogen oxide emissions prediction model.
   USE - Nitrogen oxide emissions prediction model determining method.
   ADVANTAGE - The method enables improving nitrogen oxide emissions prediction model determining precision.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a nitrogen oxide emissions prediction model determining device
   (2) a computer-readable storage medium for storing set of instructions for determining a nitrogen oxide emissions prediction model.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a nitrogen oxide emissions prediction model determining method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B2; T01-N01A2; T01-S03
IP G06K-009/62; G06N-003/04; G06N-003/08; G06Q-010/04; G06Q-050/26
PD CN108985381-A   11 Dec 2018   G06K-009/62   201908   Pages: 17   Chinese
AD CN108985381-A    CN10825985    25 Jul 2018
PI CN10825985    25 Jul 2018
UT DIIDW:2018A19639
ER

PT P
PN CN108985293-A
TI Depth learning based automatic image marking method, involves performing automatic manual checking function on image marking result, and storing marking result in database for performing subsequent model training and optimization function.
AU GAO H
AE DEEPFINCH HENGJI TECHNOLOGY CO LTD (DEEP-Non-standard)
GA 2018A1965K
AB    NOVELTY - The method involves collecting label data in a distributed file system. A data creation task is marked based on marking requirement. Judgment is made to check whether an automatically tagging model is constructed. Portion of marking data is transmitted to manual annotation function if the automatically tagging model is un-constructed. Automated image marking function is performed by using a marking task if the automatically tagging model is constructed. Automatic manual checking function is performed on an image marking result after completing marking function. The marking result is stored in a database for performing subsequent model training and optimization function.
   USE - Depth learning based automatic image marking method.
   ADVANTAGE - The method enables executing an automated auxiliary labeling task after pre-constructing the tagging model, and changing a marking transition from a marking executor according to a marked result so as to reduce labor intensity and improve image marking speed.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a depth learning based automatic image marking system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a depth learning based automatic image marking method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W04 (Audio/Video Recording and Systems)
MC T01-F05E; T01-J05B4P; T01-J10B1; T01-J10B2; T01-J10B3A; T01-J10E; T01-J30A; T01-N01D2; T04-D02; T04-D04; W04-W05A
IP G06K-009/32; G06K-009/62; G06T-007/00; G06F-017/30
PD CN108985293-A   11 Dec 2018   G06K-009/32   201908   Pages: 9   Chinese
AD CN108985293-A    CN10653276    22 Jun 2018
PI CN10653276    22 Jun 2018
UT DIIDW:2018A1965K
ER

PT P
PN CN108984526-A
TI Deep learning based subject vector document extracting method, involves obtaining relevant definition for defining word window, obtaining document theme information prediction target word to determine prediction probability of target word.
AU GAO Y
   HUANG H
   LU C
AE BEIJING INST TECHNOLOGY (BEIT-C)
GA 2018A1983M
AB    NOVELTY - The method involves obtaining relevant definition for defining a word window. Judgment is made to check whether the word window exists based on hidden internal association. Context phrases are obtained. Context phrase length is defined five. A document subject mapping matrix is obtained by adopting LDA learning algorithm. Hidden layer vector is obtained by using a long-term memory network model. The hidden layer vector is output. An average value of context phrase semantic vector is obtained. Document theme information prediction target word is obtained to determine prediction probability of target word.
   USE - Deep learning based subject vector document extracting method.
   ADVANTAGE - The method enables using a convolutional neural network extracted with local deep semantic information to judge whether semantic vector is more comprehensive, determining co-occurrence relationship context phrases and document subject, avoiding sentence based on subject vector model by using attention mechanism, learning deep semantic context and obvious information and making timing information more effective for constructing a model of subject vector.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning based subject vector document extracting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J11A1; T01-J16C2; T01-J16C3; T01-N01B3; T01-N01D2
IP G06F-017/27; G06N-003/04
PD CN108984526-A   11 Dec 2018   G06F-017/27   201908   Pages: 11   Chinese
AD CN108984526-A    CN10748564    10 Jul 2018
PI CN10748564    10 Jul 2018
UT DIIDW:2018A1983M
ER

PT P
PN CN108985331-A
TI Resistance generation network based target counting method, involves optimizing identification model and generation model by using resistance generation network, and counting target quantity by using each image block.
AU GUO D
   WANG J
   CUI Y
   WANG Z
   ZHANG J
   CHEN S
AE UNIV ZHEJIANG TECHNOLOGY (UYZT-C)
GA 2018A1964P
AB    NOVELTY - The method involves preprocessing an image. Multiple image blocks in the preprocessed image are randomly extracted. An identification model is established. A pixel value of the processed image is determined by using a convolutional neural network. A density map is generated by using the convolutional neural network. The identification model and a generation model are optimized by using a resistance generation network. Target quantity is counted by using each image block. Training set sequence of the resistance generation network is obtained and recorded. A probability value of the image is obtained from a real database.
   USE - Resistance generation network based target counting method.
   ADVANTAGE - The method enables optimizing the resistance generation model and the identification model in a game manner so as to generate a density map with high precision.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a resistance generation network. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B4P; T01-J10B2; T01-N01B3
IP G06K-009/62; G06N-003/04
PD CN108985331-A   11 Dec 2018   G06K-009/62   201908   Pages: 8   Chinese
AD CN108985331-A    CN10610806    14 Jun 2018
PI CN10610806    14 Jun 2018
UT DIIDW:2018A1964P
ER

PT P
PN CN108985449-A
TI Method for controlling convolutional neural network processor, involves calculating convolution calculation result by convolution calculation unit to obtain output characteristic graph of final convolution.
AU HAN Y
   XU H
   WANG Y
AE INST COMPUTING TECH CHINESE ACAD SCI (CCEC-C)
GA 2018A1961U
AB    NOVELTY - The method involves determining to-be-performed convolution operation with convolution kernel size. Convolution calculating unit is selected to input the value of the convolution kernel corresponding to the size. Size of an input feature map is determined to perform convolution calculation operation. Convolution calculation process is performed according to number of cycles. A value of an input characteristic image is loaded into the convolution calculation unit. Convolution calculation result is calculated by the convolution calculation unit to obtain an output characteristic graph of final convolution.
   USE - Method for controlling a convolutional neural network processor.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a convolutional neural network processor. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04A; T01-J04B2
IP G06N-003/063
PD CN108985449-A   11 Dec 2018   G06N-003/063   201908   Pages: 16   Chinese
AD CN108985449-A    CN10685546    28 Jun 2018
PI CN10685546    28 Jun 2018
UT DIIDW:2018A1961U
ER

PT P
PN CN108986453-A
TI Contextual information based traffic state prediction method, involves constructing feature vector by generating contextual information, and predicting traffic condition of road by deep learning technique according to feature vector.
AU HUANG C
   ZHU J
   ZHAO M
   WANG Y
AE UNIV SOUTH CHINA NORMAL (USCN-C)
   PCI-SUNTEK TECHNOLOGY CO LTD (PCIS-Non-standard)
GA 2018A3341X
AB    NOVELTY - The method involves obtaining vehicle GPS raw data, where vehicle GPS raw data is pre-processed to obtain road track data. Obtained track data is classified by utilizing clustering algorithm. Adjacent road of a road to-be-tested is generated according to classification result of track data. Feature vector is constructed by generating contextual information of the road to-be-tested according to generated adjacent road, where contextual information comprises historical traffic conditions. Traffic condition of the road is predicted by utilizing deep learning technique according to constructed feature vector.
   USE - Contextual information based traffic state prediction method.
   ADVANTAGE - The method enables realizing wide application range and high accuracy of traffic condition prediction.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a contextual information based traffic state prediction system
   (2) a contextual information based traffic state prediction device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a contextual information based traffic state prediction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T07 (Traffic Control Systems); W01 (Telephone and Data Transmission Systems)
MC T01-J05A2; T01-J05B2; T01-J05B3; T01-J07D3A; T01-J30A; T07-A01; W01-A06C4
IP G08G-001/01; H04W-004/02; G06Q-010/04
PD CN108986453-A   11 Dec 2018   G08G-001/01   201908   Pages: 16   Chinese
AD CN108986453-A    CN10621814    15 Jun 2018
PI CN10621814    15 Jun 2018
UT DIIDW:2018A3341X
ER

PT P
PN CN108986063-A
TI Method for realizing gradient fusion of tensor in deep learning distributed training, involves processing input tensor in fused buffer by allreduce algorithm if number of input tensors is greater than tensor quantity to form output tensor.
AU HUANG X
   LIU S
AE INSPUR BEIJING ELECTRONIC INFORMATION IN (INEI-C)
GA 2018A19488
AB    NOVELTY - The method involves predetermining an input tensor on a node in a deep learning distributed training framework. The input tensor is transferred to a fused buffer. Determination is made to check whether number of input tensors in the fused buffer is greater than a preset tensor amount. The input tensor in the fused buffer is processed by allreduce algorithm if the number of input tensors is greater than preset tensor quantity to form an output tensor. The fusion buffer is initialized. The output tensor is transferred to a node corresponding to the fused buffer.
   USE - Method for realizing gradient fusion of tensor in deep learning distributed training.
   ADVANTAGE - The method enables easily selecting threshold due to large difference in tensor size so as to effectively perform calculating the tensor size and accumulating in the fusion buffer, thus simplifying gradient fusion process and improving working efficiency.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a computer-readable storage medium for storing set of instructions for realizing gradient fusion of tensor in deep learning distributed training
   (2) a device for realizing gradient fusion of tensor in deep learning distributed training.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for realizing gradient fusion of tensor in deep learning distributed training. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B1; T01-J30A; T01-S03
IP G06T-005/50
PD CN108986063-A   11 Dec 2018   G06T-005/50   201908   Pages: 10   Chinese
AD CN108986063-A    CN10826851    25 Jul 2018
PI CN10826851    25 Jul 2018
UT DIIDW:2018A19488
ER

PT P
PN CN108985268-A
TI Depth migration learning based induction type radar high resolution distance image identifying method, involves preprocessing real target signal and auxiliary simulation data, and determining learning induction type of migration policy.
AU HUANG Y
   DING X
   YU X
   WANG J
   WEN Y
AE UNIV XIAMEN (UYXI-C)
GA 2018A19666
AB    NOVELTY - The method involves preprocessing a real target signal and auxiliary simulation data. A depth model is selected and optimized. Depth migration learning induction type of migration policy is determined. Radar high resolution distance image signal data is normalized. Five maximum value and minimum value are used as normalized signal data. Statistic edge portion of the real signal is performed. Pieced noise is generated around target simulation data according to distribution characteristics. Dimension consistent is realized with the real radar high resolution distance image. Classical and effective standard normal distribution initialization process is performed.
   USE - Depth migration learning based induction type radar high resolution distance image identifying method.
   ADVANTAGE - The method enables avoiding actual problem of depth transfer learning-based target identification frame with radar high-resolution distance image signal data so as to effectively increase sample quantity and radar high resolution identification performance of distance image establishing a transfer learning on the depth learning and machine learning with high practicability so as to satisfy majority of small sample and non perfect conditions such as weak supervised learning requirements.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of a depth migration learning based induction type radar high resolution distance image identifying system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-D03; T01-E01B; T01-J03; T01-J10B2; T01-J10D; W04-W05A; W04-W07A
IP G06K-009/00; G06N-003/04; G06N-003/08
PD CN108985268-A   11 Dec 2018   G06K-009/00   201908   Pages: 9   Chinese
AD CN108985268-A    CN10932269    16 Aug 2018
PI CN10932269    16 Aug 2018
UT DIIDW:2018A19666
ER

PT P
PN CN108985314-A
TI Method for detecting target object of electronic device, involves obtaining detected image of first-type characteristic pattern, and determining position coordinates of target object in image according to second characteristic pattern.
AU HUANG Z
   DONG Y
   BAI H
   XIONG F
AE BEIJING FACEALL TECHNOLOGY CO LTD (BEIJ-Non-standard)
GA 2018A19653
AB    NOVELTY - The method involves obtaining a detected image of a first-type characteristic pattern. The first-type characteristic pattern is processed by a feature model to obtain a second-type characteristic pattern. A feature map is established according to the first type of characteristic pattern to generate third type characteristic pattern. Position coordinates of a target object are determined in an image according to the third characteristic pattern. The image is obtained to detect the first type characteristic pattern by using a preset convolution layer of a deep neural network model.
   USE - Method for detecting a target object of an electronic device (claimed).
   ADVANTAGE - The method enables determining small target object feature information in a feature map by using a feature model so as to improve small target object detection effect and accuracy.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for detecting a target object of an electronic device
   (2) a computer readable storage medium for comprising a set of instruction for detecting a target object of an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for detecting a target object of an electronic device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J07B; T01-J10B2; T01-J10B3
IP G06K-009/62; G06N-003/02
PD CN108985314-A   11 Dec 2018   G06K-009/62   201908   Pages: 14   Chinese
AD CN108985314-A    CN10506339    24 May 2018
PI CN10506339    24 May 2018
UT DIIDW:2018A19653
ER

PT P
PN CN108985221-A
TI Video segment detecting method, involves determining image classification output result in active video segment, and determining valid video segment according to target starting point and target end point.
AU LEI Y
AE GUANGZHOU SHIYUAN ELECTRONICS TECHNOLOGY (GUAZ-C)
GA 2018A1967A
AB    NOVELTY - The method involves applying a pre-trained convolutional neural network model to process a target image in a target video segment. A target starting point and a target end point of the target video segment are determined. A current image and a background image are determined according to the target image. An image classification output result is determined in an active video segment by using the pre-trained convolutional neural network model. A valid video segment is determined according to the target starting point and the target end point. Pixel value difference of the background image is determined.
   USE - Video segment detecting method.
   ADVANTAGE - The method enables accurately performing effective video segment endpoint detection and increasing video segment detecting accuracy.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a video segment detecting device
   (2) a computer device
   (3) a computer readable storage medium for storing computer program to perform video segment detecting process.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a video segment detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B2; T01-S03
IP G06K-009/00; G06K-009/62
PD CN108985221-A   11 Dec 2018   G06K-009/00   201908   Pages: 12   Chinese
AD CN108985221-A    CN10763568    12 Jul 2018
PI CN10763568    12 Jul 2018
UT DIIDW:2018A1967A
ER

PT P
PN CN108985055-A
TI Malicious software detection method, involves determining whether accuracy of convolutional neural network reaches preset value, and detecting to-be-detected software when accuracy of convolutional neural network reaches preset value.
AU LI D
   SHI W
   ZHAO L
   ZHAO H
   ZHENG G
AE UNIV NORTHEASTERN QINHUANGDAO (UYDB-C)
GA 2018A1970Y
AB    NOVELTY - The method involves obtaining a training sample. Decompiling and numbering process is performed on multiple training samples to obtain a source code. Weights are assigned to a processed source code by using particle swarm algorithm to obtain a weighted source code. The weighted source code is entered into an input matrix to train a convolutional neural network. Weight of code is adjusted by using particle swarm algorithm to obtain output data of the convolutional neural network. Determination is made to check whether accuracy of the convolutional neural network reaches a preset value. To-be-detected software is detected by using trained software when accuracy of the convolutional neural network reaches the preset value.
   USE - Malicious software detection method.
   ADVANTAGE - The method enables increasing characteristic detection accuracy.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a malicious software detection system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a malicious software detection method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J12C; T01-N01B3; T01-N02B1B; T01-N02B3; T01-N03; T01-S03
IP G06F-021/56
PD CN108985055-A   11 Dec 2018   G06F-021/56   201908   Pages: 10   Chinese
AD CN108985055-A    CN10670997    26 Jun 2018
PI CN10670997    26 Jun 2018
UT DIIDW:2018A1970Y
ER

PT P
PN CN108985237-A
TI Mixed depth based wheat fusarium head light detecting method, involves analyzing depth accuracy and loss rate convolution cycle mixing classification effect of neural network model based on training obtained model.
AU LI S
   JIN X
   XU G
   FU Y
   WANG S
   ZHU J
   FANG X
AE UNIV ANHUI AGRIC (UYAH-C)
GA 2018A1966X
AB    NOVELTY - The method involves collecting a wheat spike hyper spectral image pixel (S1). A high spectrum image pixel sample is sampled to solve problem of unbalanced data. A target data deep convolutional neural network model is established. Target data is extracted (S2) from a two-dimensional image to obtain a gray image. Mean removal process is pre-processed based on a gray image. A convolution circulating mixed neural network model is trained (S3) based on data. Depth accuracy and loss rate convolution cycle mixing classification effect of the neural network model are analyzed (S4) based on a training obtained model.
   USE - Mixed depth based wheat fusarium head light detecting method.
   ADVANTAGE - The method enables quickly and non-destructive detecting head light so as to improve accuracy of a tested wheat area classifying result.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a mixed depth based wheat fusarium head light detecting system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a mixed depth based wheat fusarium head light detecting method. '(Drawing includes non-English language text)'
   Step for collecting a wheat spike hyperspectral image pixel (S1)
   Step for extracting target data from a two-dimensional image to obtain a gray image (S2)
   Step for training a convolution circulating mixed neural network model based on data (S3)
   Step for analyzing depth accuracy and loss rate convolution cycle mixing classification effect of the neural network model based on a training obtained model (S4)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J05B2; T01-J10B2; T01-N01B3; T04-D04
IP G06K-009/00; G06K-009/62; G06N-003/04
PD CN108985237-A   11 Dec 2018   G06K-009/00   201908   Pages: 12   Chinese
AD CN108985237-A    CN10805095    20 Jul 2018
PI CN10805095    20 Jul 2018
UT DIIDW:2018A1966X
ER

PT P
PN CN108985941-A
TI Combined stock news text intelligent predicting method, involves determining target output value of established ELM neural network model, and optimizing ELM neural network model parameter for obtaining final prediction model.
AU LI X
   GONG C
   FENG J
AE UNIV HOHAI (UYHO-C)
GA 2018A19512
AB    NOVELTY - The method involves pre-processing text for filtering Chinese word segments and stop words. The text without a time label is deleted. Predicted duration stock is determined according to the time label of the text. A self-encoder deep learning network is established to input feature representation vector. Feature extraction process is performed to obtain a low-dimensional feature vector. An ELM neural network model is established to change degree of stock quote quantitative. A target output value of the established ELM neural network model is determined. An ELM neural network model parameter is optimized to obtain a final prediction model.
   USE - Combined stock news text intelligent predicting method.
   ADVANTAGE - The method enables effectively combining event and historical market data, and avoiding technical problem of low stock prediction accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a combined stock news text intelligent predicting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J07B; T01-J10B2; T01-J11A1; T01-N01A1; T01-N01B3; T01-N01B4; T04-D04
IP G06Q-040/04; G06F-017/27; G06K-009/62; G06N-003/02
PD CN108985941-A   11 Dec 2018   G06Q-040/04   201908   Pages: 13   Chinese
AD CN108985941-A    CN10791693    18 Jul 2018
PI CN10791693    18 Jul 2018
UT DIIDW:2018A19512
ER

PT P
PN CN108984426-A
TI Method for processing data involves reselecting channel group as target channel group from unselected channel groups in at least one channel group to continue performing loading step.
AU LI Z
AE BEIJING ZIJIETIAODONG NETWORK TECHNOLOGY (BEIJ-Non-standard)
GA 2018A19863
AB    NOVELTY - The method (S200) for processing data involves selecting (S201) a target channel group from the preset at least one channel group, The channel group is obtained (S202) by grouping channels included in the target layer in the preset convolutional neural network in advance. The target channel group data is loaded into the target cache. The determination is made (S203) whether the data included in target channel group is processed or not. The responding to the determining process is completed, and the channel group is reselected as the target channel group from the unselected channel groups in at least one channel group to continue performing loading step. The channel group is reselected from the unselected channel group in the at least one channel group as target channel group, including the data included in target channel group is deleted from the target cache, and from unselected channel groups in the at least one channel group, channel group is reselected as target channel group.
   USE - Method for processing data using data processing device (claimed).
   ADVANTAGE - The method can reduce the number of times of loading the data of convolutional neural network, and helps to improve the computational efficiency of convolutional neural network.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a data processing device.
   DESCRIPTION OF DRAWING(S) - The drawing shows the flowchart illustrating the method for processing data. (Drawing includes non-English language text)
   Step for processing data (200)
   Step for selecting target channel group from the preset (201)
   Step for obtaining channel group by grouping channels (202)
   Step for determining whether the data included in the target channel group is processed or not (203)
DC T01 (Digital Computers)
MC T01-E01A; T01-E01B
IP G06F-012/0802; G06F-012/0895
PD CN108984426-A   11 Dec 2018   G06F-012/0802   201908   Pages: 18   Chinese
AD CN108984426-A    CN10878625    03 Aug 2018
PI CN10878625    03 Aug 2018
UT DIIDW:2018A19863
ER

PT P
PN CN108985457-A
TI Heuristic optimization algorithm based deep neural network structure designing method, involves minimizing main function by using heavy ball process or Nesterov acceleration algorithm, and establishing acceleration algorithm network.
AU LIN Z
   LI H
   YANG Y
AE UNIV PEKING (UYPK-C)
GA 2018A1961L
AB    NOVELTY - The method involves minimizing iterative process of main function by using heavier convergence process. Linear transformation process is performed in a feed-forward neural network. Different activation functions are searched by using gradient descent process. Forward process is performed in the feed-forward neural network. Main function is minimized by using heavy ball process or Nesterov acceleration algorithm to obtain structure of a deep neural network. An acceleration algorithm network is established. Fully connected linear transform is relaxed to convolution operation.
   USE - Heuristic optimization algorithm based deep neural network structure designing method.
   ADVANTAGE - The method enables designing a neural network structure from an optimization algorithm so as to improve experience and experiment attempting search and obtaining efficient neural network structure, thus saving large amount of time and computing resources.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a heuristic optimization algorithm based deep neural network structure designing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-N03A2
IP G06N-003/08
PD CN108985457-A   11 Dec 2018   G06N-003/08   201908   Pages: 11   Chinese
AD CN108985457-A    CN10958553    22 Aug 2018
PI CN10958553    22 Aug 2018
UT DIIDW:2018A1961L
ER

PT P
PN CN108985450-A
TI Vector processor based convolutional neural network operation vectorization method, involves adding core data to array of memory, and transmitting input feature data to buffer until convolution operation of input feature data is completed.
AU LIU Z
   TIAN X
   CHEN H
   GUO Y
   HU X
   SUN Y
   CHEN Y
   WANG L
AE UNIV PLA NAT DEFENCE TECHNOLOGY (UNDT-C)
GA 2018A1961T
AB    NOVELTY - The method involves adding convolution core data to a vector array of a vector memory for storage. Each buffer is calculated by selecting a moving convolution operation window from the buffer. A convolution operation is performed on the convolution core data stored in the vector array. A removing convolution operation window is operated to sequentially read input feature data. An obtained convolution calculation result is transmitted by a vector processing unit to an outer storage. The input feature data is transmitted to the buffer until a convolution operation of the input feature data is completed.
   USE - Vector processor based convolutional neural network operation vectorization method.
   ADVANTAGE - The method enables ensuring simple realizing mode and high calculation efficiency.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a vector processor based convolutional neural network operation vectorization method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E03; T01-J04B2; T01-J04C; T01-N01D
IP G06N-003/063; G06F-017/15; G06F-017/16
PD CN108985450-A   11 Dec 2018   G06N-003/063   201908   Pages: 13   Chinese
AD CN108985450-A    CN10687639    28 Jun 2018
PI CN10687639    28 Jun 2018
UT DIIDW:2018A1961T
ER

PT P
PN CN108986050-A
TI Method for enhancing image and video based multi-branch convolutional neural network, involves splicing enhanced video sequence, and averaging overlapping parts in video sequence to obtain video processing result.
AU LU F
   LV F
   ZHAO Q
AE UNIV BEIHANG (UNBA-C)
GA 2018A1948M
AB    NOVELTY - The method involves training a multi-branch convolutional neural network model by using training data set to obtain convergent multi-branch convolutional neural network model parameters. Block processing is performed on a to-be-processed image according to input size defined by the multi-branch convolutional neural network. Short video sequences are input into the trained multi-branch convolutional neural network model. Enhanced video sequence is spliced according to inverse segmentation process. Overlapping parts in the video sequence is averaged to obtain video processing result.
   USE - Method for enhancing image and video based multi-branch convolutional neural network. Uses include but are not limited to video call, automatic navigation, video monitoring, short video entertainment, social media and image restoration fields.
   ADVANTAGE - The method enables reducing image or video quality degradation caused by noise and other factors, improving accuracy and stability of the neural network, enhancing processing of a video sensor due to change of surrounding environment or image quality caused by interferences, and providing high quality image and video information for a decision system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a multi-branch convolutional neural network model. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B1; T01-J10B3A; T01-J21; T01-N01B3; T01-N02B2
IP G06T-005/00; G06N-003/04
PD CN108986050-A   11 Dec 2018   G06T-005/00   201908   Pages: 12   Chinese
AD CN108986050-A    CN10804618    20 Jul 2018
PI CN10804618    20 Jul 2018
UT DIIDW:2018A1948M
ER

PT P
PN CN108985446-A
TI Method for providing alarm signal by server, involves calculating data sequence flow amount, calculating difference value of actual flow rate data, and sending alarm signal when predicted traffic data is greater than set threshold value.
AU LU Y
   LUO R
AE BAIDU ONLINE NETWORK TECHNOLOGY BEIJING (BIDU-C)
GA 2018A1961W
AB    NOVELTY - The method involves importing a real-time collected traffic data sequence into a pre-trained traffic prediction model to obtain predicted traffic data. A data sequence flow amount is calculated by the traffic prediction model. A difference value of actual flow rate data is calculated. An alarm signal is sent when the predicted traffic data is greater than a set threshold value, where the traffic prediction model includes a convolutional neural network, a residual network and a connecting layer. The real-time traffic data sequence is input to the convolutional neural network. A characteristic vector of the traffic data sequence is generated.
   USE - Method for providing alarm signal by server.
   ADVANTAGE - The method enables improving alarm accuracy.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for providing alarm signal by server
   (2) a computer readable medium for storing set of instructions to provide alarm signal by server.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for providing alarm signal by server. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04A; T01-N01A2; T01-N01D3; T01-S03
IP G06N-003/04; G06N-003/08; G06Q-010/04
PD CN108985446-A   11 Dec 2018   G06N-003/04   201908   Pages: 22   Chinese
AD CN108985446-A    CN10817136    24 Jul 2018
PI CN10817136    24 Jul 2018
UT DIIDW:2018A1961W
ER

PT P
PN CN108984303-A
TI Incremental data set accelerating generation method for convolutional neural network, involves invoking threads in thread pool to generate corresponding intermediate data according to tasks in task list.
AU LUO P
AE SHANGHAI PHICOMM COMMUNICATION CO LTD (SHFX-C)
GA 2018A19893
AB    NOVELTY - The method involves reading (S003) all the progress record files when the category label file is checked to be not changed, and obtaining the original file information corresponding to all intermediate data in each intermediate data set. A task list of all current original files out of order is generated (S004). A target task to be deleted is obtained (S005) according to the task list and the progress record file, and the target task in the task list is deleted. A final task list is obtained, and the threads in the thread pool are invoked (S006) to generate corresponding intermediate data according to the tasks in the task list.
   USE - Incremental data set accelerating generation method for convolutional neural network.
   ADVANTAGE - The need for completely deleting and regenerating the existing generated intermediate data set is eliminated when the original file is added, modified, or deleted, thus reducing the workload and speeding up the processing. The data processing speed is accelerated and the processing efficiency is improved.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for incremental data set accelerating generation system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating the incremental data set accelerating generation method. (Drawing includes non-English language text)
   Step for loading class label file and recording all schedule files (S001)
   Step for reading all the progress record files (S003)
   Step for generating a task list of all current original files (S004)
   Step for obtaining the target task to be deleted (S005)
   Step for invoking the threads in the thread pool (S006)
DC T01 (Digital Computers)
MC T01-E01A; T01-F02A; T01-F02C1; T01-F02C2; T01-F03; T01-N01D2
IP G06F-009/50; G06F-009/48
PD CN108984303-A   11 Dec 2018   G06F-009/50   201908   Pages: 21   Chinese
AD CN108984303-A    CN10746066    09 Jul 2018
PI CN10746066    09 Jul 2018
UT DIIDW:2018A19893
ER

PT P
PN CN108985131-A
TI Method for identifying target in video frame image processed by image processing device, involves establishing relationship between pre-stored characteristics and identity, and utilizing determined identity as target identification result.
AU MA L
   XIE D
   PU S
AE HANGZHOU HIKVISION DIGITAL TECHNOLOGY CO (CETC-C)
GA 2018A19699
AB    NOVELTY - The method involves detecting a target in a video frame image by utilizing image detection algorithm or matching the video frame image with a preset target model. An image area of the target is inputted into a depth characteristic network to obtain characteristics of the target. Images are inputted into a deep convolutional neural network by the depth characteristic network for training the deep convolutional neural network. Corresponding relationship between pre-stored characteristics and an identity is established. Characteristics matching identity is determined. A determined identity is utilized as a target identification result.
   USE - Method for identifying a target in a video frame image processed by an image processing device (claimed).
   ADVANTAGE - The method enables identifying characteristics of the target in the video frame image, identifying the identity of the target by combining with the corresponding relationship between the pre-stored characteristics and the identity, eliminating need to utilize calibration information between cameras if positions of the cameras are changed so as to avoid influence on accuracy of target identification process, and identifying the target based the depth characteristic network, where the depth characteristic network is based on number of image training process, thus providing calibration information in a better manner and improving target recognition accuracy.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for an image processing device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for identifying a target in a video frame image processed by an image processing device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2A; T01-N01B3; T04-D04
IP G06K-009/00; G06K-009/62
PD CN108985131-A   11 Dec 2018   G06K-009/00   201908   Pages: 19   Chinese
AD CN108985131-A    CN10400035    31 May 2017
PI CN10400035    31 May 2017
UT DIIDW:2018A19699
ER

PT P
PN CN108985200-A
TI Terminal device based non-fit type living body detection method, involves inputting processed human face image to test network to obtain classification probability and determine human face image true and false states.
AU NING X
   LI W
   SUN L
   XU J
AE INST SEMICONDUCTORS CHINESE ACAD SCI (CBDT-C)
GA 2018A1967W
AB    NOVELTY - The method involves detecting a fake human face image and an original human face image. A human face frame is determined. Cutting and normalization processing is performed on the human face image. The normalized human face image and a corresponding truth value tag are input to a convolutional neural network model for training. A test network is constructed by utilizing the convolutional neural network model. A to-be-detected human face image is obtained. Normalization processing is performed on the to-be-detected human face image. The processed human face image is input to the test network of the convolutional neural network model to obtain classification probability and determine human face image true and false states.
   USE - Terminal device based non-fit type living body detection method.
   ADVANTAGE - The method enables compensating problem of insufficient supervision signals in classification problem by adding soft target tag, and reducing search space, and improving regularization, and extracting useful knowledge of the large model during training the small model, and ensuring generalization ability to obtain a simple model with similar performance.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a terminal device based non-fit type living body detection method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2; T01-J10B2; T01-N01B3A; T01-N03A2; T04-D04; T04-D07F1; T04-K03B
IP G06K-009/00; G06K-009/62; G06N-003/04; G06N-003/08
PD CN108985200-A   11 Dec 2018   G06K-009/00   201908   Pages: 18   Chinese
AD CN108985200-A    CN10710629    02 Jul 2018
PI CN10710629    02 Jul 2018
UT DIIDW:2018A1967W
ER

PT P
PN CN108986476-A
TI Motor vehicle based deep learning beam intelligent identification method, involves performing perspective transformation operation to obtain target area of ground coordinate position, and judging whether number plate of vehicle is detected.
AU NIU J
   CHEN L
   ZHONG L
AE ANHUI TI-SAFT INFORMATION TECHNOLOGY CO (ANHU-Non-standard)
GA 2018A1938Y
AB    NOVELTY - The method involves detecting object by an image pickup device. Two image pickup device calibration operations are performed. Perspective transform coefficients of the image pickup device are calculated. Video stream is collected by the image pickup device, where the video stream comprising multiple frames of images. A light suppressing video is collected by using a light suppressing camera. A pre-trained identifying neural network model is established. A perspective transformation operation is performed to obtain target area of ground coordinate position. Judgment is made to check whether a number plate of a motor vehicle is detected.
   USE - Motor vehicle based deep learning beam intelligent identification method.
   ADVANTAGE - The method enables identifying the vehicle by using a headlight in a convenient manner, and improving beam identification safety and reliable efficiency.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a motor vehicle based deep learning beam intelligent identification system
   (2) a storage medium for storing set of instructions for identifying a deep learning beam based motor vehicle.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a motor vehicle based deep learning beam intelligent identification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T07 (Traffic Control Systems)
MC T01-J07D1; T01-J10B2; T01-J10B3; T01-N01B3; T07-A01; T07-A03C5A; T07-A05
IP G08G-001/017; G08G-001/04; G06K-009/00; G06K-009/32
PD CN108986476-A   11 Dec 2018   G08G-001/017   201908   Pages: 12   Chinese
AD CN108986476-A    CN10889659    07 Aug 2018
PI CN10889659    07 Aug 2018
UT DIIDW:2018A1938Y
ER

PT P
PN CN108968811-A
TI Sweeping robot object recognizing method, involves preprocessing acquired images, inputting preprocessed images into object recognition model, obtaining object information from input image, and identifying object in image.
AU NIU Y
AE SICHUAN FEIXUN INFORMATION TECHNOLOGY CO (SICH-Non-standard)
GA 2018A1793A
AB    NOVELTY - The method involves transplanting an object recognition model onto an embedded platform of a sweeping robot through deep learning. Image information is collected around the sweeping robot. The acquired images are preprocessed. The preprocessed images are into the object recognition model. Object information is obtained from an input image. An object is identified in the image. A model structure and a training parameter are determined. A model structure file is generated. The model structure file is read. A model parameter is initialized. Training samples are randomly selected from a training sample set.
   USE - Sweeping robot object recognizing method.
   ADVANTAGE - The method enables obtaining classification information and position information of a surrounding object in real time, so that sweeping robot realizes precise semantic map building and navigation obstacle avoiding function.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a sweeping robot object recognizing system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a sweeping robot object recognizing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2; T01-J10B2A; T01-J10B3; T01-J16C3; T01-J30A; T04-D03; T04-D04
IP A47L-011/24; A47L-011/40; G06K-009/00; G06K-009/62
PD CN108968811-A   11 Dec 2018   A47L-011/24   201908   Pages: 19   Chinese
AD CN108968811-A    CN10636074    20 Jun 2018
PI CN10636074    20 Jun 2018
UT DIIDW:2018A1793A
ER

PT P
PN CN108984706-A
TI Deep learning based web page text and structure combined characteristics classifying method, involves inputting vector to long term memory network, and classifying web page structure characteristic and text characteristic by neural network.
AU SHEN J
   DENG L
   DU X
AE UNIV ZHEJIANG (UYZH-C)
GA 2018A1979N
AB    NOVELTY - The method involves obtaining a HTML document of a web page by reptiles. A keyword is extracted from text information by a HTML tag. A vocabulary in the text information is converted into a vector for representing text characteristics. The HTML tag is traversed and converted to the vector for representing web page structure characteristics. The vector is input to a long term memory network. The web page structure characteristic and the text characteristic are classified by a neural network based on a heterogeneous fusion training model. A web page of an URL is input to a scrappy reptile based on the HTML document.
   USE - Deep learning based web page text and structure combined characteristics classifying method.
   ADVANTAGE - The method enables completely dividing characteristics of a comprehensive area in a web page so as to improve classification accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based web page text and structure combined characteristics classifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J05B4P; T01-N01B3; T01-N01D2; T01-N02A1A; T01-N03B2
IP G06F-017/30
PD CN108984706-A   11 Dec 2018   G06F-017/30   201908   Pages: 9   Chinese
AD CN108984706-A    CN10737086    06 Jul 2018
PI CN10737086    06 Jul 2018
UT DIIDW:2018A1979N
ER

PT P
PN CN108986090-A
TI Deep convolutional neural network case surface scratch image detecting method, involves sending profile query to minimum outer rectangular outline, and finishing case surface scratch detection on image for identifying case surface scratch.
AU SONG L
   LIN W
   GUO Q
AE UNIV TIANJIN POLYTECHNIC (UYTI-Non-standard)
GA 2018A1947G
AB    NOVELTY - The method involves obtaining a case surface scratch image data set. The case surface scratch image data set is contained with an input image, a tag image and a test image. A deep convolutional neural network model is established. A case surface image is inputted to the deep convolutional neural network model for performed image processing operation. A profile query is sent to a minimum outer rectangular outline. A case surface scratch detection is finished on the case surface image for identifying a case surface scratch.
   USE - Deep convolutional neural network case surface scratch image detecting method.
   ADVANTAGE - The method enables collecting the case surface image by optimizing depth of the convolutional neural network model so as to avoid problem of the case surface scratch detection with lighting environment variables.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep convolutional neural network case surface scratch image detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-J10B3A; T01-N01D1B; T01-N03A2; T04-D04; T04-K03B
IP G06T-007/00; G06K-009/62; G06T-003/40
PD CN108986090-A   11 Dec 2018   G06T-007/00   201908   Pages: 14   Chinese
AD CN108986090-A    CN10761940    11 Jul 2018
PI CN10761940    11 Jul 2018
UT DIIDW:2018A1947G
ER

PT P
PN CN108986091-A
TI Depth hash network based casting defect image detecting method, involves performing max-pooling operation based on output result of convolutional layer, entering output result of upper layer, and obtaining image classification result.
AU SUN Z
   YANG K
   WANG A
   LIU R
   WU H
AE UNIV TAIYUAN SCI & TECHNOLOGY (UYTL-C)
GA 2018A1947F
AB    NOVELTY - The method involves pre-training a convolutional neural network. An image is input. The input image is pre-processed. Max-pooling operation is performed based on an output result of a first convolutional layer and a second convolutional layer. The output result of a third convolutional layer is input into a fourth convolutional layer for performing convolution operation. The output result of a fifth convolutional layer is subjected to perform the max-pooling operation. The output result of an upper layer is entered into a hash layer of a deep hash network. An image classification result is obtained.
   USE - Depth hash network based casting defect image detecting method.
   ADVANTAGE - The method enables improving extraction ability of image features and image classification accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a depth hash network based casting defect image detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E04; T01-J04B2; T01-J05B2B; T01-J10B1; T01-J10B2; T01-N02B1A; T04-D04; T04-D07A
IP G06T-007/00; G06K-009/62
PD CN108986091-A   11 Dec 2018   G06T-007/00   201908   Pages: 11   Chinese
AD CN108986091-A    CN10766116    12 Jul 2018
PI CN10766116    12 Jul 2018
UT DIIDW:2018A1947F
ER

PT P
PN CN108985328-A
TI Construction method of deep learning model for discriminating corneal ulceration, involves identifying corneal processed image by third depth learning model before and after adjustment.
AU TANG X
   ZHOU J
AE UNIV SUN YAT-SEN FOSHAN SHUNDE RES INST (UYSY-C)
   SYSU-CMU SHUNDE INT JOINT RES INST (SYSU-Non-standard)
   UNIV SUN YAT-SEN (UYSY-C)
GA 2018A3348N
AB    NOVELTY - The method involves processing the corneal test image to obtain a cornea processed image. The two deep learning models are obtained and the two deep learning models are used to identify the corneal processed images based on AlexNet and VGGNet training. The number of convolution layers of the first deep learning model is adjusted and the corneal processed image is identified by the first depth learning model before and after adjustment. The corneal processed image is identified by the second depth learning model before and after the adjustment, and the higher recognition rate is used as the third deep learning model. The corneal processed image is identified by the third depth learning model before and after the adjustment, and the higher recognition rate is used as the final discriminant model.
   USE - Construction method of deep learning model for discriminating corneal ulceration.
   ADVANTAGE - The method can replace human eye discrimination and has a high recognition rate, which is convenient for medical personnel and researchers to use.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a deep learning model building system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the construction method of deep learning model for discriminating corneal ulceration. (Drawing includes non-English language text)
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J04B2; T01-J10B2A; T01-J30A; W04-W05A
IP G06K-009/62; G06N-003/08
PD CN108985328-A   11 Dec 2018   G06K-009/62   201908   Pages: 13   Chinese
AD CN108985328-A    CN10586987    08 Jun 2018
PI CN10586987    08 Jun 2018
UT DIIDW:2018A3348N
ER

PT P
PN CN108968991-A
TI Method for assessing bone age of hand bone X-ray, involves obtaining calculation result of output of bone age evaluation model and result is bone of hand bone.
AU WANG J
   WU T
   LIU X
   LIU L
   MA J
   XIAO J
AE PINGAN TECHNOLOGY SHENZHEN CO LTD (PING-Non-standard)
GA 2018A3372D
AB    NOVELTY - The method involves processing (S1) hand bone x-ray film of the bone age to predict into a photo of the hand bone required by the specified pixel. The hand bone photograph is input (S3) into a preset bone age assessment model based on a convolutional neural network for calculation. A calculation result of the output of the bone age evaluation model is obtained (S3) and the result is a bone of the hand bone.
   USE - Method for assessing bone age of hand bone X-ray.
   ADVANTAGE - The bone age assessment model of the neural network automatically performs bone age assessment and has high evaluation accuracy.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) a hand X ray photograph of bone age evaluation device;
   (2) a computer device; and
   (3) a computer readable storage medium storing program for assessing bone age of hand bone X-ray.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for assessing bone age of hand bone X-ray. (Drawing includes non-English language text)
   Step for processing hand bone x ray film of the bone age (S1)
   Step for inputting hand bone photograph (S2)
   Step for obtaining calculation result of the output of the bone age evaluation model (S3)
DC P31 (Diagnosis, surgery (A61B).); S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S05-D02A; T01-J04A; T01-J10B2; T01-N01E
IP A61B-006/00; G06T-007/00
PD CN108968991-A   11 Dec 2018   A61B-006/00   201908   Pages: 21   Chinese
AD CN108968991-A    CN10433116    08 May 2018
PI CN10433116    08 May 2018
UT DIIDW:2018A3372D
ER

PT P
PN CN108986159-A
TI Method for reconstructing and measuring three-dimensional human body model for custom clothing, involves determining size of actual human body surface preset key feature based on feature point of each preset part in actual human body.
AU WANG J
   JIN X
   SHI X
   SUN X
   LIU C
AE ZHEJIANG SEMIR GARMENT CO LTD (ZHEJ-Non-standard)
   SHANGHAI LINGDI DIGITAL TECHNOLOGY CO (SHAN-Non-standard)
GA 2018A3343W
AB    NOVELTY - The method involves acquiring (101) a model contour image of a first three-dimensional human body model in a shape completion and animation of people (SCAPE) model. A deep learning training is performed (102) based on contour image of model to obtain a deep learning network model after training. A human body contour image of an actual human body is obtained (103), and the human body contour image is introduced into the deep learning network model to acquire a second three-dimensional human body model corresponding to the actual human body. Multiple preset skeleton joint points of the second three-dimensional human body model are obtained (104) as preset processing feature points. The feature points of each preset part in the actual human body are determined (105) based on multiple preset processing feature points. A size of the actual human body surface preset key feature is determined based on the feature point.
   USE - Method for reconstructing and measuring three-dimensional human body model, applied to ordinary people for body size measurement for custom clothing.
   ADVANTAGE - The accurate measurement of the human body in a simple and convenient manner is achieved. The measurement result is accurate. The body size measurement is convenient and fast. The excessive measuring equipment is not required.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a device for reconstructing and measuring a three-dimensional human body model.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart illustrating the method for reconstructing and measuring a three-dimensional human body model. (Drawing includes non-English language text)
   Step for acquiring a model contour image of a first three-dimensional human body model (101)
   Step for performing deep learning training based on the contour image of the model (102)
   Step for obtaining a human body contour image of an actual human body (103)
   Step for obtaining multiple preset skeleton joint points of the second three-dimensional human body model (104)
   Step for determining feature points of each preset part in the actual human body (105)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-J10C4; T01-N01B3; T04-D04
IP G06T-007/62; G06T-017/00; G06K-009/62
PD CN108986159-A   11 Dec 2018   G06T-007/62   201908   Pages: 18   Chinese
AD CN108986159-A    CN10378666    25 Apr 2018
PI CN10378666    25 Apr 2018
UT DIIDW:2018A3343W
ER

PT P
PN CN108985173-A
TI Marking noise apparent age database depth migration network learning method, involves re-labeling sample data set after stopping circulation process, and recombining data into database after sample data is re-labeled with sub-training set.
AU WANG J
AE ETONE INFORMATION TECHNOLOGY SHANGHAI CO (ETON-Non-standard)
GA 2018A1968K
AB    NOVELTY - The method involves dividing apparent age database into two parts. Training set data is randomly extracted to obtain multiple sub-training sets. Remaining set of data is recorded as a data set. Depth learning is performed on each sub-training set to obtain multiple classification models. The data set is de-identified. Correct sample data removed from the data set is identified. Circulating process is stopped when the data of identification accuracy and fluctuation range is within range. A sample data set is re-labeled after stopping the circulation process. The data is recombined into a database after the sample data is re-labeled with each sub-training set model according to voting process.
   USE - Marking noise apparent age database depth migration network learning method.
   ADVANTAGE - The method enables obtaining higher precision of apparent age database based on the apparent age database weakening mark noise to effectively reduce mark noise influence for experiment result, thus realizing high reliability of learning result.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a noise apparent age database depth migration network learning method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W04 (Audio/Video Recording and Systems)
MC T01-J05B2; T01-J05B4P; T01-J10B2; T01-N01A3; T01-N01B3; T04-D03A; T04-D04; W04-W05A
IP G06K-009/00; G06K-009/62
PD CN108985173-A   11 Dec 2018   G06K-009/00   201908   Pages: 11   Chinese
AD CN108985173-A    CN10630406    19 Jun 2018
PI CN10630406    19 Jun 2018
UT DIIDW:2018A1968K
ER

PT P
PN CN108985295-A
TI Deep learning based car label target image detecting method, involves butting feature extraction layer to fully-connecting layer, and forming output end of multi-scale characteristic fusion layer as end of convolutional neural network.
AU WANG K
   HUANG X
   WANG M
   CUI H
AE NANJING STARRYSKY TELECOM TECHNOLOGIES (NANJ-Non-standard)
GA 2018A1965H
AB    NOVELTY - The method involves training a convolutional neural network, where the convolutional neural network comprises a multi-scale characteristic fusion layer, three fully-connecting layers and three group of a feature extraction layer. Each group of the feature extraction layer is formed with a convolution layer and a down-sampling layer in series order. Output end of three group of the feature extraction layer are butted to corresponding input end of the fully-connecting layer. An output end of the multi-scale characteristic fusion layer is formed as an output end of the convolutional neural network.
   USE - Deep learning based car label target image detecting method.
   ADVANTAGE - The method enables realizing end-to-end detection and an identification structure, and avoiding manual characteristic extraction operation so as to ensure feature mode strong subjectivity and improve extraction efficiency with less redundancy. The method enables forming an image detection network structure based on the convolutional neural network with self-learning ability, and improving detection accuracy with better robustness according to image input and output label network learning image features based on rotated image translation and zooming function. The method enables improving performance under complex natural environment background.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning based car label target image detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J07D1; T01-J10B2; T01-J10B3A; T01-N01B3; T04-D02
IP G06K-009/32; G06N-003/04
PD CN108985295-A   11 Dec 2018   G06K-009/32   201908   Pages: 10   Chinese
AD CN108985295-A    CN10826443    25 Jul 2018
PI CN10826443    25 Jul 2018
UT DIIDW:2018A1965H
ER

PT P
PN CN108985175-A
TI Standard peripheral outline and depth learning based handwritten Chinese characters set recognizing method, involves converting channel value into binarization picture, and obtaining identification result by invoking identification module.
AU WANG Q
   YIN C
   WANG Y
   YANG G
   XU S
AE UNIV TIANJIN SCI & TECHNOLOGY (UYTC-C)
GA 2018A1968H
AB    NOVELTY - The method involves writing to-be-recognized Chinese sentence on a paper. Scanning process is performed for standard peripheral contour. A picture is cut after the scanning process is performed by using minimum bounding rectangle-part. A standard outer outline of a handwritten Chinese character sentence set cutting picture is converted into a standard peripheral outline of a single character picture. A peripheral profile of a single word picture is removed by adjusting red-green-blue (RGB) color channel threshold. A color channel value is converted into a binarization picture. An identification result is obtained by invoking a character identification module.
   USE - Standard peripheral outline and depth learning based handwritten Chinese characters set recognizing method.
   ADVANTAGE - The method enables effectively avoiding error cutting character, and improving accuracy of character recognition.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a standard peripheral outline and depth learning based handwritten chinese characters set recognizing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J10B2A; T01-J10B3B; T01-J30A; W04-W05A
IP G06K-009/00; G06K-009/34; G06N-003/04
PD CN108985175-A   11 Dec 2018   G06K-009/00   201908   Pages: 7   Chinese
AD CN108985175-A    CN10634249    20 Jun 2018
PI CN10634249    20 Jun 2018
UT DIIDW:2018A1968H
ER

PT P
PN CN108985244-A
TI TV program type identifying method, involves obtaining program type output by convolutional neural network, and performing current TV program type counting process corresponding to obtained program type and pre-set strategy.
AU WANG Y
   HUANG L
AE HISENSE GROUP CO LTD (HISG-C)
GA 2018A1966Q
AB    NOVELTY - The method involves obtaining continuous frames in video images of a current TV program. The continuous frame in the video image is input to a pre-trained convolutional neural network. A program type output by the convolutional neural network is obtained corresponding to the continuous frame in the video image. A current TV program type counting process is performed corresponding to the obtained program type, the continuous frame in the video image and a pre-set strategy. A TV program dividing process is performed. A video sample is obtained corresponding to the each program type. Image characteristic data in the video sample is determined as training data.
   USE - TV program type identifying method.
   ADVANTAGE - The method enables reducing minority video image recognition error so as to improve TV program identification accuracy.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a TV program type identifying device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a TV program type identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W03 (TV and Broadcast Radio Receivers)
MC T01-J10B2A; T01-J10B3A; T01-N01B3; T01-S03; T04-D02; T04-D04; T04-D07A; W03-A13E1
IP G06K-009/00; G06K-009/62; G06K-009/32
PD CN108985244-A   11 Dec 2018   G06K-009/00   201908   Pages: 15   Chinese
AD CN108985244-A    CN10821306    24 Jul 2018
PI CN10821306    24 Jul 2018
UT DIIDW:2018A1966Q
ER

PT P
PN CN108986092-A
TI Self-adapting visual field based computer vision depth learning method, involves locating visual field, object and domain information, and carrying out locally adaptive experimental evaluation process by local adaptive framework.
AU XIA C
AE SHENZHEN VISION TECHNOLOGY CO LTD (SHEN-Non-standard)
GA 2018A1947E
AB    NOVELTY - The method involves locating visual field, object and domain information. A locally adaptive experimental evaluation process is carried out by a local adaptive framework. Training data is marked based on target domain and source domain. Probability of the source domain and the target domain is calculated under different specific conditions. A source image and a target image are inputted in a convolutional neural network (CNN). A network pre-training process is performed on an image screen. A fine adjustment process is performed on a single S-shaped unit to perform a binary classification process.
   USE - Self-adapting visual field based computer vision depth learning method.
   ADVANTAGE - The method enables adopting locally adaptive architecture so as to occupy less storage space of computer vision experiment result to display local characteristic information in the source image in an effective manner.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a local adaptive framework. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B2; T01-J10B3A; T01-N01B3
IP G06T-003/40; G06T-007/00
PD CN108986092-A   11 Dec 2018   G06T-007/00   201908   Pages: 9   Chinese
AD CN108986092-A    CN10776763    14 Jul 2018
PI CN10776763    14 Jul 2018
CP CN108986092-A
      CN106251344-A   BEIJING INST TECHNOLOGY (BEIT)   SONG Y, ZHAO S, ZHAO Y, LI Y, HAO Q
      CN108197564-A   UNIV FUDAN ZHONGSHAN HOSPITAL (UYFU);  UNIV FUDAN (UYFU)   WANG X, SHI C, DING J, WANG Q, MAO L, DUAN M, WANG L
CR CN108986092-A
      GABRIELE ANGELETTI ET AL: "Adaptive Deep Learning through Visual Domain Localization", HTTPS://ARXIV.ORG/PDF/1802.08833.PDF,relevantClaims[1-10],relevantPassages[1-4]
UT DIIDW:2018A1947E
ER

PT P
PN CN108985183-A
TI Real-time end-to-end dual network based human behavior detecting framework, has framework body provided with detection architecture, and dual network for realizing pre-fusion, and detection architecture trained to evaluate performance.
AU XIA C
AE SHENZHEN VISION TECHNOLOGY CO LTD (SHEN-Non-standard)
GA 2018A1968A
AB    NOVELTY - The framework has a framework main body provided with an optical flow calculation architecture and a detection architecture. A dual network realizes pre-fusion and end-to-end training process. The detection architecture is trained for evaluating detection performance. The dual network is provided with a space network and a time network. The space network is simulated and transmits red-green-blue (RGB) frame signals. A foreground object moves in a scene to generate optical flow. An optical flow network calculates capacity of a graphics processor (GPU). The optical flow network is connected with a deep convolutional neural network for flow calculation.
   USE - Real-time end-to-end dual network based human behavior detecting framework.
   ADVANTAGE - The framework had high detecting efficiency and high accuracy result, and can carry out real time detection, and improves calculation capability of the GPU.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a real-time end-to-end dual network based human behavior detecting framework. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-M02; T01-N01B3; T01-N01D; T04-D02A
IP G06K-009/00; G06N-003/08; G06T-001/20
PD CN108985183-A   11 Dec 2018   G06K-009/00   201908   Pages: 8   Chinese
AD CN108985183-A    CN10665396    26 Jun 2018
PI CN10665396    26 Jun 2018
CP CN108985183-A
      CN101271527-A   BEIJING INST TECHNOLOGY (BEIT)   CHEN Y, LI F, HUANG T, ZHANG Y, LI L
      CN104123544-A   CRSC COMMUNICATION INFORMATION GROUP CO (CSCN)   AN G, GUO N, LI H, LIU Y
CR CN108985183-A
      ALAAELDIN EL-NOUBY ET.AL: "Real-Time End-to-End Action Detection with Two-Stream Networks", ARXIV:1802.08362V1 [CS.CV],relevantClaims[1-10],relevantPassages[1-6]
UT DIIDW:2018A1968A
ER

PT P
PN CN108986075-A
TI Method for judging preferred image, involves determining image to-be-evaluated as preferred images if evaluation value satisfies preset condition, and performing attribute analysis on target object.
AU XU H
   PENG X
AE ZHEJIANG DAHUA TECHNOLOGY CO LTD (ZJDH-C)
GA 2018A33446
AB    NOVELTY - The method involves inputting (S101) the image to be evaluated in the pre-trained evaluation model based on convolutional neural network-, and based on the evaluation model. The evaluation value corresponding to the target parameter of the to-be-evaluated image is obtained. The target parameter comprises the incomplete degree of the area of target object, the angle between the axis of the target object, vertical angle of the image in which the angle is located, ratio of the area of the target object to the image, the definition of the image, and the darkness and brightness of image. The evaluation value corresponding to the target parameter of the to-be-evaluated image is judged (S102) to be whether evaluation value satisfies the preset condition, and image to-be-evaluated is determined as preferred images if the evaluation value satisfies the preset condition, and performs attribute analysis on the target object.
   USE - Method for judging preferred image.
   ADVANTAGE - The image quality is improved by multiple dimensions. The line evaluation has higher accuracy. The better quality images are accurately identified for subsequent attribute analysis. The utilization of image data is greatly improved.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a device for judging preferred image.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the method for judging preferred image. (Drawing includes non-English language text)
   Step for inputting the image to be evaluated in the pre-trained evaluation model based on convolutional neural network-, and based on the evaluation model, and obtaining evaluation value corresponding to the target parameter of the to-be-evaluated image, and target parameter comprises the incomplete degree of the area of target object, the angle between the axis of the target object, vertical angle of the image in which the angle is located, ratio of the area of the target object to the image, the definition of the image, and the darkness and brightness of image (S101)
   Step for judging whether evaluation value corresponding to the target parameter of the to-be-evaluated image satisfies the preset condition, and determining image to-be-evaluated as preferred images if the evaluation value satisfies the preset condition, and performing attribute analysis on the target object (S102)
DC T01 (Digital Computers)
MC T01-J10B1; T01-J10B2; T01-J10B3
IP G06T-007/00
PD CN108986075-A   11 Dec 2018   G06T-007/00   201908   Pages: 30   Chinese
AD CN108986075-A    CN10607487    13 Jun 2018
PI CN10607487    13 Jun 2018
UT DIIDW:2018A33446
ER

PT P
PN CN108984530-A
TI Method for detecting network-sensitive content, involves determining whether to-be-distributed text is sensitive content, and determining whether text is normal text content when sensitive content of output result is detected as zero.
AU XU Y
   MENG X
AE UNIV BEIJING INFORMATION SCI & TECHNOLOG (UYBX-C)
GA 2018A1983H
AB    NOVELTY - The method involves constructing a convolutional neural network model based on multi-task learning when a judgment result indicates that semantic distance is greater than a set threshold value, where a multi-task includes sensitive content detection and text emotion polarity identification. A participle result is converted into a word vector matrix. The word vector matrix is input into the multi-task learning-based convolutional neural network model to obtain an output result. Determination is made to check whether the to-be-distributed text is sensitive content when sensitive content detection of the output result is greater than zero. Determination is made to check whether the to-be-distributed text is normal text content when the sensitive content of the output result is detected as zero.
   USE - Method for detecting network-sensitive content.
   ADVANTAGE - The method enables avoiding complicated process of sensitive content detection by the multi-task convolutional neural network model with comprehensive sensitive content and text emotion tendency so as to effectively improve accuracy of detection, thus greatly improving accuracy and rapid and ensuring real time detection.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a system for detecting network-sensitive content.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for detecting network-sensitive content. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-F02; T01-J11A1; T01-J16C3; T01-N01A2; T01-N01B3; T01-N01D2
IP G06F-017/27; G06N-003/04; G06N-003/08; G06Q-050/00
PD CN108984530-A   11 Dec 2018   G06F-017/27   201908   Pages: 15   Chinese
AD CN108984530-A    CN10809775    23 Jul 2018
PI CN10809775    23 Jul 2018
UT DIIDW:2018A1983H
ER

PT P
PN CN108986094-A
TI Automatic human face identification training image library data updating method, involves subjecting image data to posture correction to align human face, and adding aligned human face image data to training image library.
AU YANG T
   PENG R
   DU X
AE NANJING KIWI NETWORK TECHNOLOGY CO LTD (NANJ-Non-standard)
GA 2018A1947C
AB    NOVELTY - The method involves acquiring image data using crawler technology to automatically obtain face image data on a network according to preset rule. The face image data is filtered by using MTCNN algorithm to extract left eye, right eye, and nose. Distance between midpoint of the eyes to midpoint of a mouth is calculated. Affine transformation equation is established between five feature points extracted in image data. The image data is subjected to posture correction according to the affine transformation equation to align a human face. Aligned human face image data is added to a training image library.
   USE - Automatic human face identification training image library data updating method.
   ADVANTAGE - The method enables improving face recognition training richness in training process, guaranteeing depth neural network model training accuracy and training speed, and reducing training period of deep neural network model.
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B4F; T01-J10B1; T01-J10B2A; T01-N01B3; T04-D07F1
IP G06T-007/00; G06K-009/00; G06F-017/30
PD CN108986094-A   11 Dec 2018   G06T-007/00   201908   Pages: 7   Chinese
AD CN108986094-A    CN10805051    20 Jul 2018
PI CN10805051    20 Jul 2018
UT DIIDW:2018A1947C
ER

PT P
PN CN108989207-A
TI Method for realizing decision-making function of route in SDN device, involves generating routing information according to network state information, where network state information is included with traffic state information.
AU YAO H
   ZHANG P
   MAI T
   JI Z
AE UNIV BEIJING POSTS & TELECOM (UBPT-C)
GA 2018A3332U
AB    NOVELTY - The method involves obtaining network state information of a global network. Routing information is generated by a deep neural network according to the network state information. The routing information is sent to a router such that the router transfers a service stream according to the routing information, where the network state information is included with device state information and traffic state information. The network device state information of a current network is obtained based on in-band remote monitoring technology. A monitoring instruction is sent to the global network by the router.
   USE - Method for realizing decision-making function of a route in an SDN device (claimed).
   ADVANTAGE - The method enables realizing network resource allocating process in a flexible manner so as to generate different routing decision information under different network state information in an effective manner, and satisfying technical effect of a complex large scale network environment by setting the deep neural network.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a route decision-making device
   (2) a computer-readable medium for storing a set of instructions for realizing decision-making function of a route in an SDN device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for realizing decision-making function of a route in an SDN device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-N01D; T01-N02B2; T01-S03; W01-A06A3; W01-A06E1J; W01-A06E1L
IP H04L-012/721; H04L-012/741; G06N-003/04
PD CN108989207-A   11 Dec 2018   H04L-012/721   201908   Pages: 12   Chinese
AD CN108989207-A    CN11265948    26 Oct 2018
PI CN11265948    26 Oct 2018
CP CN108989207-A
      CN101860938-A   UNIV BEIJING POSTS&TELECOM (UBPT)   WANG W, CHEN S, GONG X, QUE X, ZHENG Y
      CN107124287-A   ZHONGYI SUZHOU SOFTWARE TECHNOLOGY CO (ZHON-Non-standard);  CHINA MOBILE COMMUNICATION CORP (CNMO)   GUI Y
      CN108199924-A   UNIV BEIJING POSTS & TELECOM (UBPT)   PAN T, HUANG T, LIN X, BIAN Z, E X, PENG X, LIU Y
      CN108667734-A   UNIV NANJING POSTS & TELECOM (UNPT)   ZHU X, CHEN B, WANG S, HAN S
UT DIIDW:2018A3332U
ER

PT P
PN CN108986044-A
TI Image rain mist removing method, involves training deep learning CGAN network with obtained data set, and processing rain image for performing fog processing operation by utilizing deep learning CGAN network.
AU YE W
   JIANG Q
   LIU Y
   WENG S
   ZHANG Z
AE UNIV GUANGDONG TECHNOLOGY (UGTE-C)
GA 2018A1948S
AB    NOVELTY - The method involves obtaining data set, where the data set comprises a clear map, a rain map and a fog map that is matched with the clear map. Deep learning CGAN network is trained with the obtained data set. Rain image is processed for performing fog processing operation by the deep learning CGAN network. The collected data sets are classified into training sets and verification sets. Parameters of a generator and discriminator are automatically adjusted in the deep learning CGAN network. Output result of the deep learning CGAN network is observed during training process through verification set.
   USE - Image rain mist removing method.
   ADVANTAGE - The method enables ensuring better sharpening effect, high reliability and veracity, convenient image sharpening effect.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a computer readable storage medium for storing a set of instructions for removing image rain mist
   (2) an image rain mist removing device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an image rain mist removing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B1; T01-N01B3
IP G06T-005/00
PD CN108986044-A   11 Dec 2018   G06T-005/00   201908   Pages: 10   Chinese
AD CN108986044-A    CN10688056    28 Jun 2018
PI CN10688056    28 Jun 2018
UT DIIDW:2018A1948S
ER

PT P
PN CN108984813-A
TI Recurrent neural network and angle preference based aluminum electrolysis modeling and optimizing method, involves controlling selected aluminum electrolysis industry site according to control parameters.
AU YI J
   BAI J
   CHEN X
   ZHOU W
   WU L
   CHEN S
AE UNIV CHONGQING SCI & TECHNOLOGY (UYNQ-C)
GA 2018A19773
AB    NOVELTY - The method involves selecting control parameters of current efficiency, tank voltage and total-fluoride emission to form a decision variable. An aluminum electrolysis industry site is selected. Multiple groups of decision variables are collected. A sample is tested and trained by using a recursive neural network. Four aluminum electrolytic cell production processing models are established. Strict partial order relationship is established between the aluminum electrolytic cell production processing models by using preference multi-target quantum particle swarm algorithm according to a pre-set desired value. The selected aluminum electrolysis industry site is controlled according to the control parameters.
   USE - Recurrent neural network and angle preference based aluminum electrolysis modeling and optimizing method.
   ADVANTAGE - The method enables avoiding need of cross and variation operations by MQPSO algorithm, simplifying position updating process and encoding process, achieving strong global searching capability, easily integrating preferred optimal values during population evolution process, satisfying decision maker requirements, determining process parameters during aluminum electrolysis production process, which effectively improves current efficiency, and reducing tank voltage and greenhouse gas emission to achieve energy saving and emission reduction effect.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a recurrent neural network and angle preference based aluminum electrolysis modeling and optimizing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); X25 (Industrial Electric Equipment)
MC T01-J15X; T01-M06Q; T01-N03A2; X25-R01D
IP G06F-017/50; G06N-003/00; G06N-003/04
PD CN108984813-A   11 Dec 2018   G06F-017/50   201908   Pages: 18   Chinese
AD CN108984813-A    CN10193126    09 Mar 2018
PI CN10193126    09 Mar 2018
UT DIIDW:2018A19773
ER

PT P
PN CN108968892-A
TI System for monitoring blind area under colonoscopy, has web service module which is provided to receive requests from clients using received colonoscopy image as parameter to call convolutional neural network model.
AU YU H
   WU L
   HU S
   DING Q
   WAN X
   MU G
   YU T
AE UNIV WUHAN RENMIN HOSPITAL (UYWU-C)
GA 2018A28463
AB    NOVELTY - The system has communication module which is configured to send request to server, and obtain analysis result from server. Image presentation module is configured to perform real-time prompting according to obtained analysis result. A convolutional neural network model is provided as trained model to determine whether sliding mirror is occurred during colonoscopy. Perceptual hash algorithm module is used, when the sliding mirror is encountered and mirror is re-posed to find the position before the sliding mirror to detect similarities between images, and analyze whether the picture after mirror overlaps with front of sliding mirror. Web service module is provided to receive requests from clients using received colonoscopy image as parameter to call the convolutional neural network model to determine whether the mirror is sliding mirror. The analysis results are fed back to client through sensing hash algorithm module to determine whether the mirror is successfully analyzed.
   USE - System for monitoring blind area under colonoscopy.
   ADVANTAGE - The reliable reference is provided for operators to improve the comprehensiveness and effectiveness of the test so as to avoid the patient's second pain because of lack of inspection. The blind area monitoring system is used easily.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a method for monitoring blind area under colonoscopy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of the system for monitoring blind area. (Drawing includes non-English language text)
DC P31 (Diagnosis, surgery (A61B).); S05 (Electrical Medical Equipment); T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC S05-D; T01-E04; T01-J05B2B; T01-J10B2; T01-J11E; T01-N01D1B; T01-N01D3; T01-N01E; T01-N02B1A; T01-N02B2B; W01-A06A3
IP A61B-001/04; A61B-001/31
PD CN108968892-A   11 Dec 2018   A61B-001/04   201908   Pages: 9   Chinese
AD CN108968892-A    CN10834804    26 Jul 2018
PI CN10834804    26 Jul 2018
UT DIIDW:2018A28463
ER

PT P
PN CN108985222-A
TI Deep learning network model based answering call identifying method, involves establishing optimized network by using number of convolution kernels in ten convolution layers, and replacing third convolution layer by fusion detection network.
AU ZHANG D
   SHI Y
AE TIANJIN ISECURE TECHNOLOGY CO LTD (TIAN-Non-standard)
GA 2018A19679
AB    NOVELTY - The method involves establishing an optimized network by using number of convolution kernels in ten convolution layers of an original VGG16 network. The third convolution layer in the original VGG16 network is replaced by a fusion detection network. The fusion detection network is provided with five detecting units. Range of preselected frame size required in feature extraction process is determined by using each detecting unit based on clustering algorithm. An image set is input into the optimized network for performing image enhancement process. Chromo, brightness, saturation and contrast of the image set are modified.
   USE - Deep learning network model based answering call identifying method.
   ADVANTAGE - The method enables effectively extracting learning feature of a network layer in a depth learning network, realizing high processing accuracy and reducing occupancy rate of a memory.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning network model based answering call identifying system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning network model based answering call identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J05B3; T01-J10B1; T01-J10B2; T01-N01B3; T01-N03A2
IP G06K-009/00; G06K-009/62
PD CN108985222-A   11 Dec 2018   G06K-009/00   201908   Pages: 7   Chinese
AD CN108985222-A    CN10765537    12 Jul 2018
PI CN10765537    12 Jul 2018
UT DIIDW:2018A19679
ER

PT P
PN CN108985223-A
TI Human-body movement state identifying method, involves connecting sequence feature extraction module with deep learning network, dividing action video into component frame pictures, and generating sequence optical flow picture sample.
AU ZHANG D
   SHI Y
AE TIANJIN ISECURE TECHNOLOGY CO LTD (TIAN-Non-standard)
GA 2018A19678
AB    NOVELTY - The method involves connecting a sequence feature extraction module with a color map deep learning network, where an optical flow deep learning network includes LSTM layers. Action video is obtained and divided into multiple component frame pictures. A sequence optical flow picture sample and a label of a video sequence picture are generated. A feature extraction model is trained by using sequence optical flow picture sample and the label. The sequence optical flow picture sample and label are input into a color map deep learning network. The sequence optical stream picture sample is sent to the optical flow deep learning network to perform feature extraction process.
   USE - Human-body movement state identifying method.
   ADVANTAGE - The method enables obtaining timing information of sequence video to perform human movement state identifying process by using a four-layer convolution network and the deep learning network so as to increase human movement state identifying accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a human-body movement state identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J04B2; T01-J10B2; T01-J10B3B; T01-N01B3; W04-W05A
IP G06K-009/00; G06N-003/04
PD CN108985223-A   11 Dec 2018   G06K-009/00   201908   Pages: 10   Chinese
AD CN108985223-A    CN10766185    12 Jul 2018
PI CN10766185    12 Jul 2018
UT DIIDW:2018A19678
ER

PT P
PN CN108968941-A
TI Method for detecting arrhythmia, involves carrying out feature learning and classification of heartbeat waveforms and RR intervals in training set, based on deep neural networks to determine arrhythmia category.
AU ZHANG H
   LI Q
   LIU Y
   HE R
   ZHAO N
   WANG K
AE SHENZHEN NANFANG ACAD AEROSPACE SCI (SHEN-Non-standard)
GA 2018A3375R
AB    NOVELTY - The method involves intercepting (S101) a heartbeat waveform list in an ECG signal to reconstruct a training set. The number of heartbeat waveform lists in the training set is amplified (S102). A feature learning and a classification of heartbeat waveforms and RR intervals in the training set are carried out (S103) based on deep neural networks to determine the arrhythmia category.
   USE - Method for detecting arrhythmia.
   ADVANTAGE - The learning and classification of the heartbeat signal are able to be carried out conveniently, thus ensuring an automatic detection of the arrhythmia, and the detection efficiency of arrhythmia is also improved. The human interference is reduced, and the accuracy of arrhythmia detection is increased.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) device for detecting arrhythmia; and
   (2) computer-readable storage medium storing a program for detecting arrhythmia.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating the method for detecting arrhythmia. (Drawing includes non-English language text)
   Step for intercepting a heartbeat waveform list in an ECG signal (S101)
   Step for amplifying the number of heartbeat waveform lists in the training set (S102)
   Step for carrying out a feature learning and a classification of the heartbeat waveforms and RR intervals in the training set (S103)
DC P31 (Diagnosis, surgery (A61B).); S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S05-D01A1; S05-D01B5; T01-J05B2; T01-N01B3; T01-N01E; T01-S03
IP A61B-005/0245; A61B-005/024
PD CN108968941-A   11 Dec 2018   A61B-005/0245   201908   Pages: 19   Chinese
AD CN108968941-A    CN10512612    25 May 2018
PI CN10512612    25 May 2018
UT DIIDW:2018A3375R
ER

PT P
PN CN108986197-A
TI 3D framework line constructing method, involves obtaining original image collected by image pickup device, rendering 3D framework line by combining 2D framework line and depth map, and correcting original image.
AU ZHANG J
   MAO H
   LONG X
   ZHOU J
AE CHENGDU TONGJIA YOUBO TECHNOLOGY CO LTD (CHEN-Non-standard)
GA 2018A19454
AB    NOVELTY - The method involves obtaining an original image collected by an image pickup device, where the original image comprises a first image and a second image. The first image is obtained by using a first lens. The second image is obtained by using a second lens. An original image input pre-trained convolutional neural network is constructed to obtain a2D skeleton line. The original image is corrected by using calibration data. Distortion of the original image is reduced. A depth map is constructed based on a corrected first image and a corrected second image. A 3D framework line is rendered by combining the 2D framework line and the depth map.
   USE - 3D framework line constructing method.
   ADVANTAGE - The method enables achieving simple operation with high requirement of device, low cost, and better practicability.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a 3D framework line constructing device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a 3D framework line constructing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J10B1; T01-J10C4; T01-L02; W04-N05C3E; W04-N05C7
IP G06T-015/20; G06T-005/50; G06T-005/00; G06T-017/00
PD CN108986197-A   11 Dec 2018   G06T-015/20   201908   Pages: 20   Chinese
AD CN108986197-A    CN11244255    30 Nov 2017
PI CN11244255    30 Nov 2017
UT DIIDW:2018A19454
ER

PT P
PN CN108985515-A
TI Independent circulation neural network-based energy output predicting method, involves training depth learning prediction model, and outputting energy of planning year typical force curve prediction result to data output module.
AU ZHANG X
   RAO Y
   ZHANG Z
   QIN K
   GUO C
   HAO Y
   CUI W
   WANG J
   GAO Z
   ZHU X
   WANG X
AE STATE GRID SICHUAN ELECTRIC POWER CO ELE (SGCC-C)
   UNIV WUHAN (UYWU-C)
   STATE GRID CORP CHINA (SGCC-C)
GA 2018A19607
AB    NOVELTY - The method involves determining annual output history data curve by a data input module in a planning area. Force curve clustering is performed by using fuzzy C-type clustering algorithm according to a clustering center. An optimal clustering scenario number and a desired scene number are determined. Scene cut algorithm is utilized for obtaining annual probability in weight typical force curve. An independent circulating neural network is determined according to probability weight of typical output characteristic data of curve in a training model. Depth learning prediction model is trained based on the independent circulation neural network. Energy of planning year typical force curve prediction result is output to a data output module.
   USE - Independent circulation neural network-based energy output predicting method.
   ADVANTAGE - The method enables improving predicted annual output curve typical energy plan construction and scheduling accuracy.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for an independent circulation neural network-based energy output predicting system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an independent circulation neural network-based energy output predicting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B3; T01-J10B2; T01-N01A2; T01-N01B3; T01-N03A2
IP G06Q-010/04; G06Q-050/06; G06K-009/62; G06N-003/08; G06N-003/04
PD CN108985515-A   11 Dec 2018   G06Q-010/04   201908   Pages: 21   Chinese
AD CN108985515-A    CN10817775    24 Jul 2018
PI CN10817775    24 Jul 2018
UT DIIDW:2018A19607
ER

PT P
PN CN108984275-A
TI Method for training intelligent unmanned agricultural driving based on Unity3D and deep enhancement learning, involves increasing frequency of random environment parameters and repeatedly training enhanced agent, in dynamic farmland scene.
AU ZHANG Y
   WAN Z
   HU X
   LI Y
AE LUOYANG ZHONGKE LONGWANG INNOVATION TECH (LUOY-Non-standard)
GA 2018A1989V
AB    NOVELTY - The method involves establishing a classic farmland scene in Unity3D. The classic farmland scene includes multiple environmental parameters. The driver performs a simulation operation based on the classic farmland scene, and quantifies the operation process to obtain an operation parameter. A convolutional neural network is constructed based on the environmental parameters and operational parameters. The convolutional neural network is pre-trained to obtain a pre-training agent. A dynamic farmland scene is randomly generated, and a random environment parameter is added in the dynamic farmland scene. The pre-training agent is put into the dynamic farmland scene, and the depth-enhanced learning algorithm is used to self-train and obtain the enhanced agent. The frequency of the partially random environment parameter is increased, and the enhanced agent is repeatedly trained, in the dynamic farmland scene.
   USE - Method for training intelligent unmanned agricultural driving based on Unity3D and deep enhancement learning.
   ADVANTAGE - The driving ability of the driver can be improved quickly and efficiently. The stability of the system is increased.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart illustrating the intelligent unmanned agricultural driving training. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-F03; T01-F05G3; T01-J16C2; T01-N01B3
IP G06F-009/455; G06N-003/04
PD CN108984275-A   11 Dec 2018   G06F-009/455   201908   Pages: 9   Chinese
AD CN108984275-A    CN10980718    27 Aug 2018
PI CN10980718    27 Aug 2018
UT DIIDW:2018A1989V
ER

PT P
PN CN108970119-A
TI Method for planning difficulty adaptive gaming system policy of processor by computer device based on value iterative network, involves changing game environment image information to improve precision of antagonism policy by game system.
AU ZHANG Z
   CHEN Z
   PAN Z
   CHEN Y
   FAN C
AE UNIV SOOCHOW (USWZ-C)
   NETEASE HANGZHOU NETWORK CO LTD (NTHZ-C)
GA 2018A3000B
AB    NOVELTY - The method involves storing multiple-game image information of a game system in a server database, where image information includes player strategy information and game environment information. Original game environment information is obtained corresponding to player strategy information. Initial feature information is extracted by a convolutional neural network filter. Characteristic information is obtained to obtain initial mapping function by convolution of reward information. An initial value of state function is calculated through a filter in the convolutional neural network. Game environment image information is changed to improve precision of antagonism policy by the game system.
   USE - Method for planning difficulty adaptive gaming system policy of a processor by a computer device (all claimed) based on a priority value iterative network.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a computer readable storage medium for storing program instructions to plan difficulty adaptive gaming system policy of a processor by a computer device based on a priority value iterative network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for planning difficulty adaptive gaming system policy of a processor by a computer device based on a priority value iterative network. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J04B2; T01-J05B4F; T01-J10B1; T01-J10E; T01-N01B1; T01-N02A3C; T01-S03; W04-X02C
IP A63F-013/67; G06N-003/04; G06N-003/08
PD CN108970119-A   11 Dec 2018   A63F-013/67   201908   Pages: 17   Chinese
AD CN108970119-A    CN10778924    16 Jul 2018
PI CN10778924    16 Jul 2018
UT DIIDW:2018A3000B
ER

PT P
PN CN108985349-A
TI Convolutional neural network stone texture image identifying method for determining image set complexity, involves selecting stone types according to output result of convolutional neural network model, and ranking types of stones.
AU ZHONG S
   DAI P
   CHEN K
AE UNIV FUZHOU (UFZU-C)
GA 2018A19647
AB    NOVELTY - The method involves loading a stone image set. Complexity of the stone image set is quantified to calculate intrinsic dimension of the stone image set. A stone image in the stone image set is processed by using wavelet image denoising process to reduce complexity of the stone image set. A convolutional neural network (CNN) is constructed. The stone image is identified by using a trained convolutional neural network model. Stone types are selected according to an output result of the convolutional neural network model. The types of stones are ranked in descending manner.
   USE - CNN stone texture image identifying method for determining image set complexity.
   ADVANTAGE - The method enables utilizing wavelet image denoising process combined with the CNN to identify the stone texture image, thus effectively improving recognition accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram of a CNN stone texture image identifying method for determining image set complexity. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B1; T01-J10B2A; T01-J10B3A
IP G06K-009/62; G06N-003/04
PD CN108985349-A   11 Dec 2018   G06K-009/62   201908   Pages: 10   Chinese
AD CN108985349-A    CN10673021    26 Jun 2018
PI CN10673021    26 Jun 2018
UT DIIDW:2018A19647
ER

PT P
PN CN108985134-A
TI Binocular camera based on human body face detecting method, involves correcting face area of human face according to face key point, and correcting depth characteristic of human face region using deep neural network.
AU ZHOU X
   JIAO B
AE CHONGQING ZHONGKE CLOUDWALK TECHNOLOGY (CHON-Non-standard)
GA 2018A19697
AB    NOVELTY - The method involves collecting (S1) video image of an object under visible light and infrared light using a binocular camera. Video image is pre-processed (S2) to obtain a noise-removing image. Face detection is performed (S3) in the noise-removing image to acquire face region. The two lights in the face area are extracted (S4) corresponding to a human face key point. Face area of a human face is corrected (S5) according to the face key point. A depth characteristic of the human face region is corrected (S6) using a deep neural network. Judgment is made to check whether the object is a forged face.
   USE - Binocular camera based on human face living body detecting method.
   ADVANTAGE - The method enables improving user experience and increasing application range of living body detection.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a binocular camera based human face living body detecting system
   (2) a binocular camera based brush face transaction system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a binocular camera based on human body face detecting method. '(Drawing includes non-English language text)'
   Step for collecting video image of an object under visible light and infrared light using a binocular camera (S1)
   Step for pre-processing video image to obtain a noise-removing image (S2)
   Step for performing face detection in the noise-removing image to acquire face region (S3)
   Step for extracting two lights in the face area corresponding to a human face key point (S4)
   Step for correcting Face area of a human face according to the face key point (S5)
   Step for correcting depth characteristic of the human face region using a deep neural network (S6)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-J10B3; T01-N01A1; T04-D07F1; T04-D07K
IP G06K-009/00; G06Q-020/40
PD CN108985134-A   11 Dec 2018   G06K-009/00   201908   Pages: 15   Chinese
AD CN108985134-A    CN10404541    01 Jun 2017
PI CN10404541    01 Jun 2017
UT DIIDW:2018A19697
ER

PT P
PN CN108985456-A
TI Method for training number-level increase and decrease depth learning neural network, involves outputting current deep learning neural network when quantity of output data and real result data are different from preset condition.
AU ZHU D
AE DAGUO INNOVATIVE INTELLIGENT TECHNOLOGY (DAGU-Non-standard)
GA 2018A1961M
AB    NOVELTY - The method involves training a current deep learning neural network through a sample, where the current deep learning neural network is provided with an input layer, a hidden layer, a classifier and an output layer. Training input data is input into the current deep learning neural network. First output data is calculated by the current deep learning neural network. Determination is made to check whether expected output data corresponding to the first output data is same as the training input data or not. The current deep learning neural network is output when quantity of second output data and real result data corresponding to the test input data are different from a preset condition.
   USE - Method for training a number-level increase and decrease depth learning neural network by using a computing device (claimed).
   ADVANTAGE - The method enables fully fitting the output data.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a computer readable storage medium storing a set of instructions for training a number-level increase and decrease depth learning neural network by using a computing device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for training number-level increase and decrease depth learning neural network. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-N01B3A
IP G06N-003/08; G06N-003/04
PD CN108985456-A   11 Dec 2018   G06N-003/08   201908   Pages: 17   Chinese
AD CN108985456-A    CN10823422    25 Jul 2018
PI CN10823422    25 Jul 2018
UT DIIDW:2018A1961M
ER

PT P
PN CN108985463-A
TI Method for implementing automatic competition of fighter robot system, involves establishing supervised learning model by using operational case sample, and obtaining real combat case samples to establish fighting depth learning model.
AU ZHU D
AE DAGUO INNOVATIVE INTELLIGENT TECHNOLOGY (DAGU-Non-standard)
GA 2018A1961F
AB    NOVELTY - The method involves initializing a depth learning model. A sample unsupervised learning step is generated by using a first operational case sample to establish an unsupervised learning model. A supervised learning model is established by using a second operational case sample. Real combat case samples are obtained to establish a fighting depth learning model. The obtained real combat case samples are selected to establish a fighting depth supervised learning model when a condition of the real combat case samples satisfies a preset condition.
   USE - Method for implementing automatic competition of a fighter robot system (claimed) based on knowledge base and deep learning.
   ADVANTAGE - The method enables avoiding auxiliary decision-making problem, improving processing efficiency and auxiliary decision-making capability and increasing subjective initiative precision.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a system for implementing automatic competition of a fighter robot system based on knowledge base and deep learning.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for implementing automatic competition of a fighter robot system based on knowledge base and deep learning. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J16A; T01-J30A
IP G06N-099/00
PD CN108985463-A   11 Dec 2018   G06N-099/00   201908   Pages: 20   Chinese
AD CN108985463-A    CN10774081    15 Jul 2018
PI CN10774081    15 Jul 2018
UT DIIDW:2018A1961F
ER

PT P
PN CN108986132-A
TI Method for generating document picture in Trimap FIG format by full-convolutional neural network, involves storing picture in PNG format, and dividing picture into three parts that comprise transition, background and foreground areas.
AU ZOU X
   LI G
AE UNIV SOUTH CHINA TECHNOLOGY (UYSC-C)
GA 2018A1946G
AB    NOVELTY - The method involves inputting a piece of document data to a picture in a stored format at different resolutions, where the stored format is selected as a JPG format. The picture of the jpg format is input to a network. A full-convolution neural network model is trained by a picture data set, where the picture data set comprises a human face area and a human head comprises a shoulder. The input picture is divided by the trained model. Feature extraction of the input picture is performed by a full-convolution neural network. A document picture is divided. The divided picture is stored in a PNG format. The picture is divided into three parts that comprise a transition area, a background area and a foreground area.
   USE - Method for generating a document picture in a Trimap FIG format by a full-convolutional neural network.
   ADVANTAGE - The method enables ensuring better generating precision, better noise resistance, better generating efficiency and high generating speed, and realizing certificate Trimap graph partitioning process for providing a matting input so as to achieve shoulder and clothes recognition and segmentation effect.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for generating a document picture in a Trimap FIG format by a full-convolutional neural network. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2A; T01-J10D; T01-N01D2; T04-E
IP G06T-007/194; G06T-007/11
PD CN108986132-A   11 Dec 2018   G06T-007/194   201908   Pages: 14   Chinese
AD CN108986132-A    CN10722763    04 Jul 2018
PI CN10722763    04 Jul 2018
UT DIIDW:2018A1946G
ER

PT P
PN CN108960534-A
TI Method for predicting quality of food processing waste water based on convolution extreme learning machine, involves calculating parameter of extreme learning machine, and training quality prediction model to predict quality of waste water.
AU BAI Y
   YU T
   YU Q
   LI X
   YANG S
AE UNIV CHONGQING TECHNOLOGY & BUSINESS (UYSS-C)
GA 2018A0235F
AB    NOVELTY - The method involves constructing a three-layer structure of a convolutional neural network (S1), where the three-layer structure of the convolutional neural network comprises an input layer, a convolution layer and a sampling layer. Parameter of the convolutional neural network is trained by utilizing gradient descent process. An output parameter of the convolutional neural network is input (S2) to an extreme learning machine. Parameter of the extreme learning machine is calculated (S3) to form a food processing waste water quality forecasting network. A quality prediction model is trained to predict quality of food processing waste water.
   USE - Method for predicting quality of food processing waste water based on a convolution extreme learning machine.
   ADVANTAGE - The method enables utilizing the convolutional neural network, and extracting feature of the extreme learning machine by the convolutional neural network so as to predict quality of food processing waste water in an effective manner with high popularization value.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for predicting water quality of food waste water based on a convolution extreme learning machine. '(Drawing includes non-English language text)'
   Step for constructing three-layer structure of convolutional neural network (S1)
   Step for inputting output parameter of convolutional neural network to extreme learning machine (S2)
   Step for calculating parameter of extreme learning machine (S3)
DC T01 (Digital Computers)
MC T01-J04A; T01-J04B2; T01-N01A2; T01-N01B3
IP G06Q-010/04; G06N-003/08
PD CN108960534-A   07 Dec 2018   G06Q-010/04   201908   Pages: 6   Chinese
AD CN108960534-A    CN10916787    13 Aug 2018
PI CN10916787    13 Aug 2018
UT DIIDW:2018A0235F
ER

PT P
PN CN108960119-A
TI Unmanned vending cabinet multi-angle video fusion commodity recognition algorithm, has set of rules for inputting video data into deep convolutional neural network model to obtain identified product type and number of product.
AU CAI D
   FANG W
   TANG K
   LIU Y
   ZHANG Y
AE WUHAN HAHA CONVENIENT TECHNOLOGY CO LTD (WUHA-Non-standard)
GA 2018A02452
AB    NOVELTY - The algorithm has set of rules for pre-processing video data. Dynamic area detection operation is performed on the video data to obtain a dynamic area of a video frame in the video data. Key frame sampling operation is performed on the video frame in the video data. A deep convolutional neural network model is established. Training and accuracy testing operations are performed on the deep convolutional neural network model by utilizing the sampled key frame. The video data of the unmanned vending cabinet is input into the deep convolutional neural network model after pre-processing the key frame to obtain identified product type and corresponding number of the product.
   USE - Unmanned vending cabinet multi-angle video fusion commodity recognition algorithm.
   ADVANTAGE - The algorithm enables effectively shielding commodity data so as to increase merchandise identification precision.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an unmanned vending cabinet multi-angle video fusion commodity recognition algorithm. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2A; T01-N01A2F; T01-N01B3A; T04-D04
IP G06K-009/00; G06K-009/62; G06N-003/08
PD CN108960119-A   07 Dec 2018   G06K-009/00   201908   Pages: 8   Chinese
AD CN108960119-A    CN10686023    28 Jun 2018
PI CN10686023    28 Jun 2018
UT DIIDW:2018A02452
ER

PT P
PN CN108960245-A
TI Tire mold character detecting and identifying method, involves outputting identification result of large character or small character string in character area by character identification model.
AU CAI N
   DING P
   LI J
   MO Z
   CHEN X
   WANG H
AE UNIV GUANGDONG TECHNOLOGY (UGTE-C)
GA 2018A02424
AB    NOVELTY - The method involves inputting collected tire mold picture data set sample into an enhanced SSD detection network for establishing character detection model. Character vector of character area image detected by the character detection model is extracted by using a convolutional neural network. The extracted character vector is input into long and short time memory network for establishing a character identification model. Target detection process is performed on a tire mold image by the character detection model. Position information of large character or small character string in character area is obtained. Identification result of the large character or small character string in the character area is output by the character identification model.
   USE - Tire mold character detecting and identifying method.
   ADVANTAGE - The method enables realizing mold patterns with high detection precision during character detection stage and utilizing the long and short time memory network for quickly identifying large character string and indefinite character length during character recognition stage.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a tire mold character detecting and identifying device
   (2) a computer-readable storage medium for storing a set of instructions for detecting and identifying character of a tire mold.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a tire mold character detecting and identifying method. '(Drawing includes non-English language text)'
DC A85 (Electrical applications.); T01 (Digital Computers)
MC A12-E; A12-H05; T01-J10B2A; T01-S03
IP G06K-009/34; G06K-009/20; G06K-009/62
PD CN108960245-A   07 Dec 2018   G06K-009/34   201908   Pages: 16   Chinese
AD CN108960245-A    CN10768887    13 Jul 2018
PI CN10768887    13 Jul 2018
UT DIIDW:2018A02424
ER

PT P
PN CN108935413-A
TI Device for spraying foliar medicine based on plant space prescription map, has mechanical motion system that moves plant space physiological and pathological information collection system and plant.
AU CEN H
   MA Z
   ZHU Y
   LIU F
   HE Y
AE UNIV ZHEJIANG (UYZH-C)
GA 2018A0815E
AB    NOVELTY - The device has a plant spatial physiological and pathological information collection system. An industrial computer (16) obtains physiological and pathological spectral information and sequence images. The convolutional neural network is combined to perform pixel point grading and spatial geometric topological relations are combined to cluster points. An effective spray classification section is established to generate a space prescription map. The instructions are sent to the mechanical motion system and the spray system. The mechanical motion system moves the plant space physiological and pathological information collection system and the plant according to the instructions of the industrial computer. The spraying system grades and partitions the plant according to the received space prescription map.
   USE - Device for spraying foliar medicine based on plant space prescription map.
   ADVANTAGE - The waste caused is reduced by the spraying of the medicine, the efficiency is improved and the accuracy of the target is improved.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a method for spraying foliar medicine based on a plant space prescription map.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic diagram of device for spraying foliar medicine based on plant space prescription map.
   Belt (1)
   Rotating platform (2)
   Lifting shaft (3)
   Light source generator (7)
   Industrial computer (16)
DC C07 (Apparatus, formulation, general. including veterinary syringes, general formulations where the active compound is not central to the invention (e.g. wettable powders) and analysis.); P13 (Plant culture, dairy products (A01G, H, J).); P14 (Animal management and care (A01K, L, M).); T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC C11-C11; C12-M01; C12-M13; T01-J05B2; T01-J10B2; T01-J10C4; T04-D04
IP A01M-007/00; G06K-009/62; G06T-015/00; G06T-017/00
PD CN108935413-A   07 Dec 2018   A01M-007/00   201908   Pages: 12   Chinese
AD CN108935413-A    CN10972652    24 Aug 2018
PI CN10972652    24 Aug 2018
UT DIIDW:2018A0815E
ER

PT P
PN CN108960337-A
TI Method for recognizing multimodal complex activity based on depth learning model for use in medical care area, involves utilizing label as complex active label corresponding to maximum value of complex probability distribution.
AU CHEN L
   LIU X
AE UNIV ZHEJIANG (UYZH-C)
GA 2018A0239U
AB    NOVELTY - The method involves collecting time series data of different modalities by using an intelligent devices and a wearable device when complex activities are performed. The collected time series data is cleaned and normalized to obtain complex sample. Data features are extracted by using a constructed convolution sub network. Feature matrices output by three convolution sub-networks is spliced by using a vertical splicing layer to obtain a splicing matrix. Feature extraction process is performed on a splice matrix. The fusion matrix is sequentially processed by using a dual-layer LSTM network. Representation of the complex sample is classified by using a trained classifier. A label is utilized as complex active label corresponding to a maximum value of complex probability distribution.
   USE - Method for recognizing a multimodal complex activity based on a depth learning model for use in medical care, industrial auxiliary and skill evaluation areas.
   ADVANTAGE - The method enables utilizing the deep learning model to identify complex activities to realize broad application prospects in fields of health care, industrial assistance, skill evaluation and the like.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for recognizing a multimodal complex activity based on a depth learning model for use in medical care, industrial auxiliary and skill evaluation areas. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-D03; T01-J04B2; T01-J10B2A; T01-N01B3; T01-N01D; T01-N01E; W04-W05A
IP G06K-009/62; G06N-003/04
PD CN108960337-A   07 Dec 2018   G06K-009/62   201908   Pages: 13   Chinese
AD CN108960337-A    CN10790511    18 Jul 2018
PI CN10790511    18 Jul 2018
UT DIIDW:2018A0239U
ER

PT P
PN CN108960301-A
TI Convolutional neural network based ancient thymopctidum text recognition method, involves re-calibrating output characteristic of inception structure by utilizing SEBlock, and adding recalibrated output characteristic to original input.
AU CHEN S
   WANG M
   WANG X
   MA H
   LIU Y
   ZHANG S
AE UNIV SOUTHWEST (UYSW-Non-standard)
   UNIV GUIZHOU ENG SCI (UYGU-Non-standard)
GA 2018A0240V
AB    NOVELTY - The method involves constructing a convolutional neural network with a convolutional layer, a connecting layer and softmax layer. An extra convolution layer is added in front of the convolution layer. A ResBlock is connected with an inception structure and a SEBlock structure to form a mixing structure. The SEBlock is added to the weight layer in an original ResBlock. A hybrid structure is added to a front of the convolution layer to obtain an altered convolutional neural network. An output characteristic of the inception structure is re-calibrated by utilizing the SEBlock. The recalibrated output characteristic is added to an original input.
   USE - Convolutional neural network based ancient thymopctidum text recognition method.
   ADVANTAGE - The method enables ensuring reasonable design and better identifying effect and reducing problem of performance degradation in recognition.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network based ancient thymopctidum text recognition method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J10B2A; T04-D04
IP G06K-009/62; G06N-003/04
PD CN108960301-A   07 Dec 2018   G06K-009/62   201908   Pages: 16   Chinese
AD CN108960301-A    CN10638037    20 Jun 2018
PI CN10638037    20 Jun 2018
UT DIIDW:2018A0240V
ER

PT P
PN CN108960138-A
TI Convolutional neural network based device authentication feature identification method, involves performing legal identity judgment operation in unknown identity information by utilizing wireless emitting device.
AU CHEN S
   WEN H
   JIANG Y
   XU A
   LI P
   XIE F
   CAO Y
   LIU W
   LEI W
   TANG J
AE SOUTHERN POWER GRID INT CO LTD (CSPG-C)
   UNIV ELECTRONIC SCI & TECHNOLOGY (UEST-C)
GA 2018A13181
AB    NOVELTY - The method involves performing radio frequency fingerprint signal collection operation in a legal wireless equipment and an illegal wireless device. A signal sample set is generated. Radio frequency signal characteristics is determined. Time-frequency transformation operation is performed. A multi-dimensional radio frequency fingerprint characteristic sample set is generated by utilizing a convolutional neural network. The multi-dimensional radio frequency fingerprint characteristic sample set is divided. Legal identity judgment operation is performed in unknown identity information by utilizing a wireless emitting device.
   USE - Convolutional neural network based device authentication feature identification method.
   ADVANTAGE - The method enables automatically extracting fingerprint features and increasing identification rate of a wireless transmitting device by adopting a reuse identification algorithm.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a convolutional neural network based device authentication feature identification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-C03C; T01-J10B2; T04-D04; T04-D07F2
IP G06K-009/00; G06K-009/62; G06K-017/00; G06N-003/04; G06N-003/08
PD CN108960138-A   07 Dec 2018   G06K-009/00   201908   Pages: 9   Chinese
AD CN108960138-A    CN10717590    03 Jul 2018
PI CN10717590    03 Jul 2018
UT DIIDW:2018A13181
ER

PT P
PN CN108960414-A
TI Deep learning accelerator based single broadcast multi-operation realizing method, involves storing operation result of input characteristic value and corresponding weight value, ad finishing calculation of output characteristic value.
AU CHEN S
   YANG C
   LI B
   CHEN H
   HU X
   ZHANG J
   CHEN W
AE UNIV PLA NAT DEFENCE TECHNOLOGY (UNDT-C)
GA 2018A02382
AB    NOVELTY - The method involves configuring multiple intermediate value registers for storing an intermediate result for a specified multiplier in a multiplier array of accelerator. Deep learning process is performed during calculation process. An operation result of input characteristic value and corresponding weight value is stored in the corresponding intermediate value registers to multiply the input characteristic value with the corresponding weight value to perform multiplication operation. Calculation of output characteristic value is finished.
   USE - Deep learning accelerator based single broadcast multi-operation realizing method.
   ADVANTAGE - The method enables realizing single broadcast multi-operation in a simple manner with low cost and facilitating high utilization rate of data and low energy consumption.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning accelerator based single broadcast multi-operation realizing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-E01; T01-E02A; T01-E02B; T01-J04A; T01-J30A; W04-W05A
IP G06N-003/04; G06N-003/08; G06F-007/523; G06F-007/50
PD CN108960414-A   07 Dec 2018   G06N-003/04   201908   Pages: 10   Chinese
AD CN108960414-A    CN10804165    20 Jul 2018
PI CN10804165    20 Jul 2018
UT DIIDW:2018A02382
ER

PT P
PN CN108960345-A
TI Method for merging remote sensing image by electronic device, involves constructing deep neural network model by feature fusion neural network, and performing remote sensing image fusion operation by utilizing deep neural network model.
AU CHENG L
   LIU S
   ZHAO G
AE UNIV GUANGDONG TECHNOLOGY (UGTE-C)
GA 2018A0239L
AB    NOVELTY - The method involves converting a fusion feature and a coding feature map into an image reconstruction neural network. A reconstruction operation is performed by utilizing a deconvolution layer of the image reconstruction neural network to obtain a high-resolution multi-spectral image to train the image reconstruction neural network. A neural network is extracted according to a characteristic after training is completed. A deep neural network model is constructed by utilizing a feature fusion neural network and the image reconstruction neural network. A remote sensing image fusion operation is performed by utilizing the deep neural network model.
   USE - Method for merging a remote sensing image by an electronic device (claimed).
   ADVANTAGE - The method enables improving the quality of the fusion panchromatic image and multi-spectral image.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a system for merging a remote sensing image by an electronic device
   (2) a computer-readable storage medium for storing a set of computer programs for merging a remote sensing image by an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for merging a remote sensing image by an electronic device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B1; T01-J10B2; T01-L02; T01-N01B3; T01-S03; T04-D03; T04-D04
IP G06K-009/62; G06K-009/46; G06N-003/04; G06N-003/08
PD CN108960345-A   07 Dec 2018   G06K-009/62   201908   Pages: 19   Chinese
AD CN108960345-A    CN10896255    08 Aug 2018
PI CN10896255    08 Aug 2018
UT DIIDW:2018A0239L
ER

PT P
PN CN108960411-A
TI Convolutional neural network adjusting method, involves forming convolution layer on current neural network model, and establishing neural network model according to first adjustment result and second adjustment result.
AU CHENG Y
   ZHAO Y
   DONG G
   LI X
   LIU X
AE ZHENGZHOU YUNHAI INFORMATION TECHNOLOGY (INEI-C)
GA 2018A02385
AB    NOVELTY - The method involves forming a first convolution layer on a current neural network model. Convolution kernel parameters of the first convolutional layer are obtained. Channel convolution kernel number is determined. A first adjusting result is obtained. Input data parameter of the convolution layer is adjusted. Channel number of the input data is received. A second adjusted result is received. A neural network model is established according to the first adjustment result and the second adjustment result. Size of the convolution kernel is matched with size of the convolutional layer. Channel number of the convolution kernel is increased.
   USE - Convolutional neural network adjusting method.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a convolutional neural network adjusting system
   (2) a computer-readable storage medium has a set of instructions for adjusting the convolutional neural network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network adjusting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-N02A2D; T01-S03
IP G06N-003/04; G06N-003/08
PD CN108960411-A   07 Dec 2018   G06N-003/04   201908   Pages: 13   Chinese
AD CN108960411-A    CN10677993    27 Jun 2018
PI CN10677993    27 Jun 2018
UT DIIDW:2018A02385
ER

PT P
PN CN108960347-A
TI Convolutional neural network stability handwriting recognition ordering effect evaluation system, has uncertainty calculation module for determining handwriting recognition sequence stability of convolutional neural network.
AU CUI T
   SI L
   LIAO M
AE INST SOFTWARE CHINESE ACAD SCI (CAIS-C)
GA 2018A0239J
AB    NOVELTY - The system has a main unit provided with a handwriting recognition module, a parameter estimation module and a uncertainty calculation module, where original image characteristics are extracted and handwriting recognition feature data is obtained. The parameter estimation module obtains probability statistics. The uncertainty calculation module obtains uncertainty data by using the parameter estimation module. The uncertainty calculation module determines handwriting recognition sequence stability of a convolutional neural network. A handwriting script recognition module outputs the prediction probability value.
   USE - Convolutional neural network stability handwriting recognition ordering effect evaluation system.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a convolutional neural network stability handwriting recognition ordering effect evaluation method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network stability handwriting recognition ordering effect evaluation system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J03; T01-J04D; T01-J10B2A; T04-D04; T04-D07E
IP G06K-009/68; G06N-003/04
PD CN108960347-A   07 Dec 2018   G06K-009/68   201908   Pages: 9   Chinese
AD CN108960347-A    CN10261698    28 Mar 2018
PI CN10261698    28 Mar 2018
UT DIIDW:2018A0239J
ER

PT P
PN CN108961245-A
TI Dual-channel deep convolutional network based parallel image quality classifying method, involves calculating network output image quality category of classifying result by using trained dual-channel deep parallel convolution network.
AU GAO X
   LI H
   LU W
   YU Y
   HE L
AE UNIV XIDIAN (UYXN-C)
GA 2018A02199
AB    NOVELTY - The method involves selecting an image sample. Image data of image quality evaluating process is selected as experimental data in a related field. The image sample is determined as M-types of images in a database. The image sample is included with high quality and low quality image samples. A training data set is constructed from the image sample. Sampled samples are consisted with M-type image samples in the training data set. Image quality classifying result is provided. A preprocessed image is utilized as an input of a dual-channel deep parallel convolution network. Network output image quality category of the classifying result is calculated by using a trained dual-channel deep parallel convolution network in parallel to an input image.
   USE - Dual-channel deep convolutional network based parallel image quality classifying method.
   ADVANTAGE - The method enables improving application range of computer vision and image quality classifying performance, reducing manual constructing difficulties and influence of image semantic information on image quality classifying process and realizing construction quality characteristic and convolutional neural network input normalized lost image detail information obtaining process and parallel convolution structure designing process.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a dual-channel deep convolutional network based parallel image quality classifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E01B; T01-J04A; T01-J04B2; T01-J05B1; T01-J05B4F; T01-J10B1; T01-J10B2; T01-J10B3A; T01-J16C3; T01-L02; T01-N01B3
IP G06T-007/00; G06N-003/04
PD CN108961245-A   07 Dec 2018   G06T-007/00   201908   Pages: 18   Chinese
AD CN108961245-A    CN10737250    06 Jul 2018
PI CN10737250    06 Jul 2018
UT DIIDW:2018A02199
ER

PT P
PN CN108960107-A
TI Men small minibus identifying method, involves extracting small minibus image by using pre-trained convolutional neural network, judging whether front row number is greater than or equal to two, and detecting small minibus overload.
AU GUO D
   ZHU W
   JIN L
   WANG X
AE ANHUI BCHT TECHNOLOGY CO LTD (ANHU-Non-standard)
GA 2018A0245D
AB    NOVELTY - The method involves collecting a picture of a vehicle using by using a crossing road electronic monitoring device. The picture of the vehicle is identified by using a rapid-convolution neural network (R-CNN). A small minibus image is extracted by using a pre-trained convolutional neural network. A small minibus front row number is counted. Judgment is made to check whether the front row number is greater than or equal to two. Small minibus overload is detected. A characteristic pattern is generated by using the R-CNN. A suggestion window is generated.
   USE - Men small minibus identifying method.
   ADVANTAGE - The method enables adopting the RCNN algorithm for performing a head detection counting operation, improving head detection precision and micro microbus overload limiting efficiency, and effectively identifying a men small minibus by an automatic warning operation.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a men small minibus identifying device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a men small minibus identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T07 (Traffic Control Systems)
MC T01-J07D1; T01-J10B2; T01-N02B2; T07-A03
IP G06K-009/00; G06K-009/62; G08G-001/017
PD CN108960107-A   07 Dec 2018   G06K-009/00   201908   Pages: 12   Chinese
AD CN108960107-A    CN10663647    25 Jun 2018
PI CN10663647    25 Jun 2018
UT DIIDW:2018A0245D
ER

PT P
PN CN108960141-A
TI Enhanced deep convolutional neural network-based pedestrian recognition method, involves classifying input images, and training network with goal of minimizing joint loss to make network more discriminative pedestrian image features.
AU GUO T
   GUO X
   WANG Q
   JIANG Z
   MEN A
AE ACAD BROADCASTING SCI SARFT (BROA-Non-standard)
   UNIV BEIJING POSTS & TELECOM (UBPT-C)
GA 2018A1317Y
AB    NOVELTY - The method involves extracting base depth feature of a pedestrian image by using a basic deep learning convolutional neural network model. Manual features of the pedestrian image are extracted during conventional manual features extraction process to reduce dimension. The base depth feature and the manual feature are fused into enhanced depth feature by an application feature reconstruction module. Input images are classified by using classification loss function and verification loss function to verify similarities and differences. A network is trained with goal of minimizing joint loss to make the network more discriminative pedestrian image features.
   USE - Enhanced deep convolutional neural network-based pedestrian recognition method.
   ADVANTAGE - The method enables utilizing complementary manual feature and depth characteristic combined using classification loss function for supervising network training strategy to obtain better performance so as to effectively improve pedestrian recognition accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an enhanced deep convolutional neural network-based pedestrian recognition method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B1; T01-J10B2A; T01-J10B3A; T01-N01B3
IP G06K-009/00; G06K-009/62
PD CN108960141-A   07 Dec 2018   G06K-009/00   201908   Pages: 8   Chinese
AD CN108960141-A    CN10721706    04 Jul 2018
PI CN10721706    04 Jul 2018
UT DIIDW:2018A1317Y
ER

PT P
PN CN108960074-A
TI Deep learning based small-size passenger area target detecting method, involves iteratively updating weights of VGG convolutional neural network, and gradually reducing value of final loss function to obtain accurate detection results.
AU HAN B
   WANG Y
   YANG Z
   QIU W
   ZHANG J
   LI K
AE UNIV XIDIAN (UYXN-C)
GA 2018A02463
AB    NOVELTY - The method involves utilizing a loss function to train a VGG convolutional neural network to obtain a final detection result according to final boundary regression and classification probability. Loss functions of the regression boundary and the classification probability are calculated. A final loss function is obtained according to values of the loss-function of the classification probability and the loss function of the regression boundary. Weights of the VGG convolutional neural network are iteratively updated by reverse propagation. A value of the final loss function is gradually reduced to obtain accurate final detection results.
   USE - Deep learning based small-size passenger area target detecting method.
   ADVANTAGE - The method enables realizing accurate detection of small-size targets, thus facilitating unmanned driving or driving assistance.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based small-size passenger area target detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B2; T01-N01B3
IP G06K-009/00; G06N-003/04; G06N-003/08
PD CN108960074-A   07 Dec 2018   G06K-009/00   201908   Pages: 10   Chinese
AD CN108960074-A    CN10577466    07 Jun 2018
PI CN10577466    07 Jun 2018
UT DIIDW:2018A02463
ER

PT P
PN CN108960190-A
TI Convolutional neural network based FCN image sequence model synthetic aperture radar video target detecting method, involves setting reference coordinate value as synthetic aperture radar image sequence of target motor vehicle.
AU HOU B
   ZHANG R
   JIAO L
   MA J
   MA W
   BAI J
AE UNIV XIDIAN (UYXN-C)
GA 2018A0243F
AB    NOVELTY - The method involves determining a geometrical center of motor vehicle objects in a test sample. Judgment is made to check whether a coordinate value of a plane coordinate system is compared with a coordinate value set. Euclidean distance of the coordinate value and a reference coordinate value in the coordinate value set is calculated. Judgment is made to check whether a coordinate number of the Euclidean distance is less than 500 of the reference coordinate value. The reference coordinate value is set as a synthetic aperture radar (SAR) image sequence in the plane coordinate system of a target motor vehicle corresponding to a coordinates value output.
   USE - Convolutional neural network based FCN image sequence model SAR video target detecting method.
   ADVANTAGE - The method enables fully utilizing synthesis information of a SAR video so as to improve detection accuracy of the SAR in a video target motor vehicle and target detection efficiency.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network based FCN image sequence model SAR video target detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J07D3A; T01-J10B2; T04-D02
IP G06K-009/00; G06K-009/32; G06N-003/04
PD CN108960190-A   07 Dec 2018   G06K-009/00   201908   Pages: 12   Chinese
AD CN108960190-A    CN10811807    23 Jul 2018
PI CN10811807    23 Jul 2018
UT DIIDW:2018A0243F
ER

PT P
PN CN108960284-A
TI Method for performing single-sense identification and localization of microspheres, involves obtaining information of row to corresponding area of image, and determining pixel coordinates of microsphere center by center of square-circle.
AU HU C
   HAN M
   LIN Z
   HU X
   LI H
AE UNIV TIANJIN (UTIJ-C)
GA 2018A02419
AB    NOVELTY - The method involves testing an optical tweezers or a magnetic tweezers system to obtain multiple microscopic images. A microsphere region in the microscopic image is manually extracted to obtain an image set from a microsphere region group. A convolutional neural network is established and trained. Single sense identification and localization of microspheres for microscopic images are performed to set number of rows of the microscopic image. Number information of a row is obtained to a corresponding area of the microscopic image. Pixel coordinates of the microsphere center is determined by a center of the square-circle.
   USE - Method for performing single-sense identification and localization of microspheres based on microscopic images and deep learning.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for performing single-sense identification and localization of microspheres based on microscopic images and deep learning. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-N01B3A; T04-D03; T04-D04
IP G06K-009/62; G06K-009/46; G06N-003/04
PD CN108960284-A   07 Dec 2018   G06K-009/62   201908   Pages: 9   Chinese
AD CN108960284-A    CN10547963    31 May 2018
PI CN10547963    31 May 2018
UT DIIDW:2018A02419
ER

PT P
PN CN108961088-A
TI Behavior mode multidimensional matching-pushing software based parameter pushing method, involves increasing validity of trained model, and evaluating combination of user active performance by trained model to realize team combination.
AU HU Q
AE SUZHOU ZHIXIAN ZHIXI INFORMATION TECHNOL (SUZH-Non-standard)
GA 2018A1316J
AB    NOVELTY - The method involves extracting characteristic variable according to user basic characteristic information. User psychological characteristic variable is extracted by a user psychological feature information unit. User policy is developed by a support vector machine unit, a random forest unit and a depth learning unit. Tools are dynamically combined to realize an integrated learning unit. Validity of a trained model is increased based on integrated technology. Combination of user active performance is evaluated by the trained model to realize correct team combination, where the user basic characteristic information includes sex, age, height, weight, appearance features, educational background, game preferences, personal experience and social network and the characteristic variable includes demographic characteristic, individual behavior mode characteristic and individual social network characteristics.
   USE - Behavior mode multidimensional matching-pushing software based parameter pushing method.
   ADVANTAGE - The method enables effectively analyzing and estimating parameter relationship and parameter index so as to increase social effectiveness.
DC T01 (Digital Computers)
MC T01-N01A2D; T01-N01B3; T01-N03
IP G06Q-050/00; G06Q-010/06
PD CN108961088-A   07 Dec 2018   G06Q-050/00   201908   Pages: 5   Chinese
AD CN108961088-A    CN10926612    15 Aug 2018
PI CN10926612    15 Aug 2018
UT DIIDW:2018A1316J
ER

PT P
PN CN108960331-A
TI Pedestrian human body local character clustering and identification method, involves establishing training neural network model and obtaining better performance parameter based on cluster depth of learning and recognition model.
AU HUANG J
   YU Z
   XU E
   LIU W
AE UNIV CHONGQING POSTS & TELECOM (UCPT-C)
GA 2018A02401
AB    NOVELTY - The method involves converting pedestrian image characteristic into a column vector of a three-dimensional number. A similarity value of multiple pedestrian images is calculated according to automatic pedestrian characteristic matching algorithm. A Euclidean distance value of similarity of a single-dimensional column vector is calculated. A vector and loss of function of convolutional neural network (CNN) are obtained. A training neural network model is established. A better performance parameter is obtained based on pedestrian image feature cluster depth of a learning and recognition model.
   USE - Pedestrian human body local character clustering and identification method.
   ADVANTAGE - The method enables reducing semantic characteristic matching loss during clustering operation so as to ensure character clustering and identification efficiency.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a training neural network model. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E03; T01-E04; T01-J04C; T01-J05B3; T01-J10B2A; T01-J10D; T01-J16C3; T01-N01B3; T01-N03A2; T04-D04
IP G06K-009/62; G06N-003/04
PD CN108960331-A   07 Dec 2018   G06K-009/62   201908   Pages: 5   Chinese
AD CN108960331-A    CN10751316    10 Jul 2018
PI CN10751316    10 Jul 2018
UT DIIDW:2018A02401
ER

PT P
PN CN108960067-A
TI Depth-learning based real-time train driver motion recognition system, has monitoring-recording module stores operation of driver, driver key position detection module and object detection module perform offline depth learning process.
AU HUANG J
   ZHANG S
   HU Z
   HU Y
   LIU Y
   ZHANG E
AE BEIJING HOTZONE TECHNOLOGY CO LTD (BEIJ-Non-standard)
   UNIV TSINGHUA (UYQI-C)
GA 2018A1318F
AB    NOVELTY - The system has a motion matching module provided with a human action identifying module and a human-environment interaction action identifying module. A driver key position detecting module detects a head, a face and hand position of a driver in the image. The human action identifying module identifies action of the driver. The human-environment interaction action identifying module identifies interaction of the driver with environment. A monitoring-recording module stores monitored operation of the driver in a real-time manner. A driver key position detection module and an object detection module perform offline depth learning and training process, where the action of the driver comprises sitting, standing or hitting posture, and the interaction of the driver with the environment comprises making a call or operating a screen.
   USE - Depth-learning based real-time train driver motion recognition system.
   ADVANTAGE - The system utilizes a deep convolutional neural network for object and human body detection with strong generalization ability, identifies an object and the driver in a cab in an accurate manner, analyzes movement templates by offline data and captures specific rule and movement range in a precise manner so as to match the action of the driver with movement range in an accurate manner.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a depth-learning based real-time train driver motion recognizing method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a depth-learning based real-time train driver motion recognition system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2A; T01-N01B3; T01-N02B2B; T04-D04; T04-D07D5
IP G06K-009/00; G06K-009/62
PD CN108960067-A   07 Dec 2018   G06K-009/00   201908   Pages: 9   Chinese
AD CN108960067-A    CN10567349    05 Jun 2018
PI CN10567349    05 Jun 2018
UT DIIDW:2018A1318F
ER

PT P
PN CN108960496-A
TI Learning rate based depth learning traffic flow prediction method, involves establishing predicting-radial basis function combined model by using deep belief network model, and predicting traffic flow by using training model.
AU JIAN C
   ZHANG M
   KUANG X
   SUN C
AE UNIV ZHEJIANG TECHNOLOGY (UYZT-C)
GA 2018A0236B
AB    NOVELTY - The method involves training a deep belief network model during learning rate and training time. A predicting-radial basis function combined model is established by using the deep belief network model and radial basis function. Traffic flow data is obtained. Traffic flow is predicted by using a training model. Learning rate and transformation mapping rule are obtained in the training time. Current reconstruction error err is detected if the current reconstruction error is greater than preset reconstruction error. A candidate learning rate value is obtained.
   USE - Learning rate based depth learning traffic flow prediction method.
   ADVANTAGE - The method enables reducing error, and improving error prediction stability, precision and convergence speed.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a learning rate based depth learning traffic flow prediction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J07B; T01-N01A2; T01-N01B3
IP G06Q-010/04; G06Q-050/26; G08G-001/01; G06N-003/02
PD CN108960496-A   07 Dec 2018   G06Q-010/04   201908   Pages: 15   Chinese
AD CN108960496-A    CN10673067    26 Jun 2018
PI CN10673067    26 Jun 2018
UT DIIDW:2018A0236B
ER

PT P
PN CN108960304-A
TI Network transaction fraud behavior depth learning detecting method, involves performing model storing function, and inputting real-time transaction feature data into trained model to determine whether transaction is fraudulent transaction.
AU JIANG C
   ZHANG Z
   WANG P
   ZHOU X
   ZHANG X
   WANG L
AE UNIV DONGHUA (UYDG-C)
GA 2018A0240S
AB    NOVELTY - The method involves setting a current character sequence as a target feature sequence. Pooled result of a pooling layer is selected as current input data. The pooled result of the pooling layer is optimized in an optimal arrangement order. The optimal arrangement order is selected as a current character order of an alignment layer. Data of the pooling layer is transmitted to a classification part. Judgment is made to check whether result obtained from the classification part is matched with real result corresponding to historical transaction characteristic data. Model storing function is performed when classification precision reaches desired precision. Real-time transaction feature data is inputted into a trained model to determine whether current transaction is fraudulent transaction.
   USE - Network transaction fraud behavior depth learning detecting method.
   ADVANTAGE - The method enables detecting network transaction fraud behavior of a deep learning detection system, combining the alignment layer with a convolution and polling layers to realize cyclic convolution process, and obtaining convolution information without distortion during convolution of a ring structure.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a network transaction fraud behavior depth learning detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E01A; T01-E01B; T01-J04B2; T01-J05B2; T01-J10B2; T01-N01B3; T01-N01D; T04-D04
IP G06K-009/62; G06N-003/04
PD CN108960304-A   07 Dec 2018   G06K-009/62   201908   Pages: 19   Chinese
AD CN108960304-A    CN10640209    20 Jun 2018
PI CN10640209    20 Jun 2018
UT DIIDW:2018A0240S
ER

PT P
PN CN108960939-A
TI Method for predicting revenue decline of public customers based on deep learning in bank, involves obtaining preset prediction model for decline of public customer income by training sampled feature set of public client.
AU JIANG P
   ZHAO Z
   ZHOU Q
   KANG M
   LIU Z
AE AGRIC BANK CHINA LTD (AGRI-Non-standard)
GA 2018A1317J
AB    NOVELTY - The method involves acquiring original data of an account of a public client. A feature set of the public client is generated according to the original data. The feature set of the public client is pre-processed. The feature set of the public client is input into a preset prediction model for revenue decline of the public client. A probability value of the public client is obtained. The preset prediction model for decline of the public customer income is obtained by training the sampled feature set of the public client and sampled customer income decline identification information.
   USE - Method for predicting revenue decline of public customers based on deep learning in a bank.
   ADVANTAGE - The method enables allowing banks to make pre-warning measure in a convenient manner and ensuring pertinence and accurate marketing strategy.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a device for predicting revenue decline of public customers based on deep learning.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for predicting revenue decline of public customers based on deep learning. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05A1; T01-J30A
IP G06Q-030/02; G06Q-040/02; G06N-003/08
PD CN108960939-A   07 Dec 2018   G06Q-030/02   201908   Pages: 14   Chinese
AD CN108960939-A    CN10928729    15 Aug 2018
PI CN10928729    15 Aug 2018
UT DIIDW:2018A1317J
ER

PT P
PN CN108961237-A
TI Convolutional neural network based low-dose CT image decomposition method, involves processing low-dose CT image to achieve decomposition of anatomical components and noise artifacts in selected low-dose CT image.
AU KANG Y
   LIU J
   LIU T
   ZHANG P
   ZHU J
   ZHANG K
AE UNIV ANHUI POLYTECHNIC (UYAP-C)
GA 2018A0219F
AB    NOVELTY - The method involves respectively obtaining low-dose CT projection data and conventional doses CT projection data. Corresponding training images are reconstructed to collect a low-dose CT image and a conventional dose CT image. The low-dose CT image and the conventional dose CT image are subtracted to collect a noise artifact image. Convolutional neural network is trained with certain amount of low-dose CT image and the noise artifact image. The selected low-dose CT image is processed to achieve decomposition of anatomical components and noise artifacts in the selected low-dose CT image by utilizing the trained convolutional neural network.
   USE - Convolutional neural network based low-dose CT image decomposition method.
   ADVANTAGE - The method enables effectively separating star-shaped artifact noise and structural features in the low-dose CT image.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a convolutional neural network based low-dose CT image decomposition method.
DC T01 (Digital Computers)
MC T01-J10B1; T01-J10B2; T01-J10C; T01-N01B3
IP G06T-007/00; G06T-005/00; G06T-011/00
PD CN108961237-A   07 Dec 2018   G06T-007/00   201908   Pages: 16   Chinese
AD CN108961237-A    CN10706749    28 Jun 2018
PI CN10706749    28 Jun 2018
UT DIIDW:2018A0219F
ER

PT P
PN CN108961229-A
TI Deep learning based cardiovascular OCT image plaque detection method, involves storing detection data system for outputting detecting result, processing cardiovascular OCT images, and obtaining marked image.
AU LI L
   JIA T
   YUAN Z
   CHEN H
AE UNIV CHINESE NORTHEASTERN (UYDB-C)
GA 2018A0219P
AB    NOVELTY - The method involves obtaining cardiovascular OCT images from an OCT imaging device (step 1), where data augmentation mode includes appropriate local expansion, contraction and corolla-shaped twisting. Region of interest is extracted by using a full convolution neural network (step 2). Easy loss of plaque is located and identified by using a Faster R-CNN target (step 3). Detection area is extracted by using an area suggesting network. A highest score candidate frame is selected. Detection data is stored by a system for outputting a detecting result (step 4). The cardiovascular OCT images is processed. A marked image is obtained.
   USE - Deep learning based cardiovascular OCT image plaque detection method.
   ADVANTAGE - The method enables ensuring high locating precision, strong robustness, high clinical application value, stable performance and quick detecting speed.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based cardiovascular OCT image plaque detection system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based cardiovascular OCT image plaque detection method. '(Drawing includes non-English language text)'
   Step for obtaining cardiovascular OCT images from OCT imaging device (step1)
   Step for extracting region of interest by using full convolution neural network (step2)
   Step for locating and identifying easy loss of plaque by using Faster R-CNN target (step3)
   Step for storing detection data by system for outputting detecting result (step4)
DC T01 (Digital Computers)
MC T01-E01B; T01-J04B2; T01-J10B1; T01-J10B2; T01-N01B3
IP G06T-005/00; G06T-007/00
PD CN108961229-A   07 Dec 2018   G06T-007/00   201908   Pages: 19   Chinese
AD CN108961229-A    CN10678850    27 Jun 2018
PI CN10678850    27 Jun 2018
UT DIIDW:2018A0219P
ER

PT P
PN CN108964672-A
TI Depth neural network based polar code decoding method, involves inputting likelihood ratio into deep neural network model corresponding to Rate-R node, and executing simplified continuous elimination decoding algorithm.
AU LI S
   LU L
   PAN L
   LIU J
   HUANG T
   CHEN H
   DENG Y
AE UNIV CHINA PETROLEUM HUADONG (UYPE-C)
GA 2018A0144M
AB    NOVELTY - The method involves obtaining sample data. The sample data is preprocessed by using normalization process. A deep neural network model is built. The deep neural network model is trained. Likelihood ratio is input into the deep neural network model corresponding to a Rate-R node in a polarization code decoding stage to obtain zero or one. A simplified continuous elimination decoding algorithm is executed according to the zero or one state. 80% of samples are randomly selected as training samples. Remaining 20% is used as a test sample. Layers are connected together in a full connection manner.
   USE - Depth neural network based polar code decoding method.
   ADVANTAGE - The method combining the deep neural network technology with the polar code decoding technology so as to reduce traversal operation to the Rate-R node, improve decoding speed and reduce decoding delay.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a depth neural network based polar code decoding method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-D02; T01-D03; T01-G01A; T01-N01B3A
IP H03M-013/13; G06N-003/04; G06N-003/08
PD CN108964672-A   07 Dec 2018   H03M-013/13   201908   Pages: 6   Chinese
AD CN108964672-A    CN10736700    06 Jul 2018
PI CN10736700    06 Jul 2018
UT DIIDW:2018A0144M
ER

PT P
PN CN108961137-A
TI Convolutional neural network based image steganography analyzing method, involves designing image database required for experiment, and analyzing image of test set based on convolutional neural network.
AU LI X
AE UNIV SUN YAT-SEN (UYSY-C)
GA 2018A0221W
AB    NOVELTY - The method involves designing an image database required for experiment. An information hiding, compressing and cropping process are performed. A cipher image is obtained. An original image and a dense image are separated. Training set, validation set and test set are obtained. A network model is established according to convolutional neural network design. The network model comprises a pre-treatment layer and a feature extraction layer. A experiment result pre-layer filter designing process is performed according to initialization parameter. An image of the training set is enhanced by data trained into the network model. A convolutional neural network is trained. Image of the test set is analyzed based on convolutional neural network.
   USE - Convolutional neural network based image steganography analyzing method.
   ADVANTAGE - The method enables implementing design in an easy manner, extracting image of a residual network in an effective manner, obtaining better detecting effect and grasping two content adaptive steganography algorithm.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a convolutional neural network based image steganography analyzing system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network based image steganography analyzing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B4F; T01-J10B2; T01-J15A4; T01-N01B3A; T01-N01D2; T04-D04
IP G06K-009/62; G06T-001/00
PD CN108961137-A   07 Dec 2018   G06T-001/00   201908   Pages: 11   Chinese
AD CN108961137-A    CN10432764    12 Jul 2018
PI CN10432764    12 Jul 2018
UT DIIDW:2018A0221W
ER

PT P
PN CN108961180-A
TI Infrared image enhancing method, involves updating convolutional neural network parameter, and determining whether high definition visible light image satisfies predetermined condition.
AU LI X
   LIU D
   ZHANG G
   FU W
   YANG G
   LI Z
AE RICOH SOFTWARE RES CENT BEIJING CO LTD (RICO-C)
GA 2018A0220X
AB    NOVELTY - The method involves extracting a low resolution infrared image by using a convolutional neural network (S1). A low-resolution infrared image is processed by using an ultra-pixel division neural network (S2). A high definition infrared image information is obtained (S3). The high definition infrared image information is processed. Difference between high definition infrared image information and outline information is obtained Convolutional neural network parameter is updated. Determination is made to check whether the high definition visible light image satisfies predetermined condition.
   USE - Infrared image enhancing method.
   ADVANTAGE - The method enables obtaining the super-resolution reconstruction network, which effectively recovers the object information from the infrared image.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for an infrared image enhancing system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an infrared image enhancing method. '(Drawing includes non-English language text)'
   Step for extracting low resolution infrared image by using convolutional neural network (S1)
   Step for processing low-resolution infrared image by using ultra-pixel division neural network (S2)
   Step for obtaining high definition infrared image information (S3)
DC T01 (Digital Computers)
MC T01-J10B1; T01-J10B3A; T01-J10D
IP G06T-005/00; G06N-003/04; G06T-003/40
PD CN108961180-A   07 Dec 2018   G06T-005/00   201908   Pages: 14   Chinese
AD CN108961180-A    CN10650982    22 Jun 2018
PI CN10650982    22 Jun 2018
UT DIIDW:2018A0220X
ER

PT P
PN CN108960076-A
TI Convolutional neural network based ear recognition and tracking method, involves testing ear region in output image, building convolutional neural network for ear data and ear characteristic point tag, and marking ear characteristic points.
AU LIN Y
   WANG Y
AE UNIV SOUTHEAST (UYSE-C)
GA 2018A02461
AB    NOVELTY - The method involves building a first layer convolutional neural network for face data and face frame tag. A human head in an image is detected to obtain a human face image included with an ear region. A second layer convolutional neural network is built for the ear data set and ear frame tag. The ear region in an output image is tested through training. A third convolutional neural network is built for the ear data and the ear characteristic point tag. The ear characteristic points are automatically marked in the output image by the training. Data and extended data set are obtained by a training portion.
   USE - Convolutional neural network based ear recognition and tracking method.
   ADVANTAGE - The method enables adopting three-layer cascade structure to effectively avoid problem of marking detection and feature points under the condition of relatively small data set of existing ear, and significantly compressing network size by multi-network, and reducing training phase of the memory with easy training convergence and better performance under complex condition.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic illustration of a convolutional neural network based ear recognition and tracking method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2A; T01-N01B3A; T04-K03B
IP G06K-009/00; G06N-003/04
PD CN108960076-A   07 Dec 2018   G06K-009/00   201908   Pages: 9   Chinese
AD CN108960076-A    CN10586771    08 Jun 2018
PI CN10586771    08 Jun 2018
UT DIIDW:2018A02461
ER

PT P
PN CN108957502-A
TI GNSS based depth learning LSTM multi-system multi-path real-time error correcting method, involves establishing depth learning LSTM network, and correcting multi-path training sample error based on original coordinate sequence.
AU LIU C
   ZHANG C
   ZHAO X
   ZHANG A
AE UNIV ANHUI SCI & TECHNOLOGY (UYLG-C)
GA 2018A0303N
AB    NOVELTY - The method involves performing GNSS multi-system short baseline locating single-epoch observation data calculation process to obtain a multi-path error of an original coordinate sequence. A depth learning LSTM network is established. Original coordinate sequence median filtering process is performed. Multi-path training sample error is obtained after performing the original coordinate sequence median filtering process. The obtained multi-path training sample error is corrected based on the original coordinate sequence.
   USE - GNSS based depth learning LSTM multi-system multi-path real-time error correcting method.
   ADVANTAGE - The method enables improving multi-path error correction precision.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a GNSS based depth learning LSTM multi-system multi-path real-time error correcting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W06 (Aviation, Marine and Radar Systems)
MC T01-N01B3; W06-A03A5C
IP G01S-019/42
PD CN108957502-A   07 Dec 2018   G01S-019/42   201908   Pages: 14   Chinese
AD CN108957502-A    CN10563621    04 Jun 2018
PI CN10563621    04 Jun 2018
UT DIIDW:2018A0303N
ER

PT P
PN CN108960122-A
TI Space-time convolutional feature based face classification method, involves extracting face depth feature by using convolutional neural network, and forming network training structure based on Deep-Res-Bi-LSTM network number.
AU LIU Q
   YU Z
   LIU G
AE UNIV NANJING INFORMATION SCI & TECHNOLOG (UNAI-C)
GA 2018A0244Y
AB    NOVELTY - The method involves extracting a face depth feature by using a convolutional neural network. Enlarged training data is obtained to determine an expression sequence by using a face detection algorithm. Face depth feature detail is transmitted to a Deep-Res-Bi-LSTM classification unit. A network training structure is formed based on a Deep-Res-Bi-LSTM network number, where distance between two eyes are not changed.
   USE - Space-time convolutional feature based face classification method.
   ADVANTAGE - The method enables saving time and space, utilizing number of network layers in deep manner, reducing parameter when extracting spatial information, and time information, and improving space dimension.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a space-time convolutional feature based face classification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B2; T01-N01B3; T01-N01D
IP G06K-009/00; G06K-009/62; G06N-003/04
PD CN108960122-A   07 Dec 2018   G06K-009/00   201908   Pages: 9   Chinese
AD CN108960122-A    CN10691249    28 Jun 2018
PI CN10691249    28 Jun 2018
UT DIIDW:2018A0244Y
ER

PT P
PN CN108960071-A
TI Eyes-closed state detecting method, involves calculating area of eye by utilizing detected face position and landmark coordinates, classifying eye image by utilizing pre-trained neural network model, and identifying eye closing state.
AU LIU R
   YAO Q
AE WUHAN MAGICISION INTELLIGENT TECHNOLOGY (WUHA-Non-standard)
GA 2018A02466
AB    NOVELTY - The method involves performing face detection on a current frame image to obtain a position of face landmark. An area of an eye is calculated by utilizing a detected face position and landmark coordinates. An eye image is classified by utilizing a pre-trained neural network model. An eye closing state is identified, where the neural network model is a classification model based on deep learning network MobileNet training. Eye images under different illumination conditions are collected during training. An artificial classification is performed according to the eye closing state to form a training set. A deep learning network MobileNet is trained.
   USE - Eyes-closed state detecting method.
   ADVANTAGE - The method enables realizing accurate distinction between blinking eyes and closed eyes.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an eyes-closed state detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04A; T01-J05B2; T01-J10B2; T01-N01B3; T04-D07D5; T04-D07F1A
IP G06K-009/00
PD CN108960071-A   07 Dec 2018   G06K-009/00   201908   Pages: 5   Chinese
AD CN108960071-A    CN10572216    06 Jun 2018
PI CN10572216    06 Jun 2018
UT DIIDW:2018A02466
ER

PT P
PN CN108960310-A
TI Artificial intelligence based method for identifying agricultural pests and diseases, involves subjecting multi-scale features obtained by deep network model to MLP feature fusion, and performing identification process by using classifier.
AU LIU X
   MEI S
   DAI Q
AE BEIJING PUHUI SANNONG TECHNOLOGY CO LTD (BEIJ-Non-standard)
GA 2018A13317
AB    NOVELTY - The method involves pre-processing a collected leaf image. The leaf image is transformed into a frequency domain by using a fast Fourier transform. A high frequency part is removed and recovered into airspace images (S1). Multi-scale process on the airspace images is performed (S2) to obtain image slices with different sizes to form training data sets. A deep neural network model for parameter initialization and optimization is constructed (S3). Multi-scale features obtained by the deep network model are subjected (S4) to MLP feature fusion. Identification process is performed by using a fused feature training classifier.
   USE - Artificial intelligence based method for identifying agricultural pests and diseases.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an artificial intelligence based method for identifying agricultural pests and diseases. '(Drawing includes non-English language text)'
   Step for pre-processing collected leaf image (S1)
   Step for performing multi-scale process on airspace images (S2)
   Step for constructing deep neural network model for parameter initialization and optimization (S3)
   Step for subjecting multi-scale features obtained by deep network model to MLP feature fusion (S4)
DC T01 (Digital Computers)
MC T01-J04B1; T01-J10B2; T01-N01B3
IP G06K-009/62; G06K-009/40; G06N-003/04
PD CN108960310-A   07 Dec 2018   G06K-009/62   201908   Pages: 8   Chinese
AD CN108960310-A    CN10660699    25 Jun 2018
PI CN10660699    25 Jun 2018
UT DIIDW:2018A13317
ER

PT P
PN CN108960211-A
TI Multi-target human body posture detecting method, involves extracting node information of target image, obtaining matching information of switch node, and finishing multi-target human body posture detecting process.
AU LIU X
   CAI G
   ZHANG X
   SU S
AE ROPEOK XIAMEN SCI & TECHNOLOGY GROUP CO (ROPE-Non-standard)
GA 2018A0242X
AB    NOVELTY - The method involves obtaining a target image. Node information of the target image is extracted, where the node information comprises node confidence degree, vector field pattern direction, an articulation state and distance constraint. Matching information of a switch node is obtained. Multi-target human body posture detecting process is finished. Target image scaling process is performed. An image pyramid is constructed by setting number and zoom scale to obtain a zoomed image under different scales. The node information is processed by constructing a convolutional neural network.
   USE - Multi-target human body posture detecting method.
   ADVANTAGE - The method enables adding distance constraint conditions between articulation points and reducing articulation matching problem between different targets in an effective manner.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a multi-target human body posture detecting system
   (2) a multi-target human body posture detecting device
   (3) a computer-readable storage medium for storing computer program to perform multi-target human body posture detecting process.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a multi-target human body posture detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B2; T01-J10B3A; T01-L02; T01-S03
IP G06K-009/00; G06N-003/04
PD CN108960211-A   07 Dec 2018   G06K-009/00   201908   Pages: 15   Chinese
AD CN108960211-A    CN10909302    10 Aug 2018
PI CN10909302    10 Aug 2018
UT DIIDW:2018A0242X
ER

PT P
PN CN108960432-A
TI Decision planning method, involves transmitting cloud receiving detection information by in-vehicle system in in-vehicle system group, and transmitting decision planning information to corresponding in-vehicle system through cloud.
AU LIU X
   SONG C
AE SHENZHEN ECHIEV AUTOMATIC DRIVING TECHNO (SHEN-Non-standard)
GA 2018A0237Q
AB    NOVELTY - The method involves transmitting cloud receiving detection information by in-vehicle system in an in-vehicle system group. Detection information is pre-processed by a cloud pre-processing for obtaining processed detection information. The processed detection information is inputted into a trained first deep learning model for generating decision planning information. The first deep learning model is trained based on the labeled detection information and corresponding labeled decision planning information. The decision planning information is transmitted to corresponding in-vehicle system through cloud.
   USE - Decision planning method.
   ADVANTAGE - The method enables expanding range according to environment detection for strategy planning for a wider range of environment information and obtaining perfect and rational decision planning result.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a decision planning device
   (2) a computer-readable storage medium for storing a set of instructions for executing a decision planning method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a decision planning method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J30A; T01-S03
IP G06N-099/00
PD CN108960432-A   07 Dec 2018   G06N-099/00   201908   Pages: 13   Chinese
AD CN108960432-A    CN10657294    22 Jun 2018
PI CN10657294    22 Jun 2018
UT DIIDW:2018A0237Q
ER

PT P
PN CN108960257-A
TI Deep learning based scintillation substance diabetic retinopathy grading method, involves inputting to-be-detected sample to trained initial depth learning network model for performing diabetic retinopathy grading function.
AU LIU Y
   LIU S
   GONG J
AE UNIV CHINESE NORTHEASTERN (UYDB-C)
GA 2018A0241T
AB    NOVELTY - The method involves constructing a sample base. Background and noise in an eye bottom mirror image of the sample base is removed. Different sample images are normalized to an equal range by subtracting local mean intensity of the different brightness in the sample images. A training set and a testing set are constructed. An initial depth learning network model is trained. An input part building structure, multi-branch feature transformation part architecture and a frame output portion are constructed. A to-be-detected sample is input to the trained initial depth learning network model for performing diabetic retinopathy grading function.
   USE - Deep learning based scintillation substance diabetic retinopathy grading method.
   ADVANTAGE - The method enables realizing substance diabetic retinopathy grading function on prior knowledge of dependency with better generalization ability, adopting multi-layer design to design small-sized convolution kernel by extracting small focus characteristics, thus ensuring substance diabetic retinopathy grading result in a reliable manner.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a Deep learning based scintillation substance diabetic retinopathy grading system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based scintillation substance diabetic retinopathy grading method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W04 (Audio/Video Recording and Systems)
MC T01-J04B2; T01-J10B2; T01-N01B3A; T04-D03A; T04-D04; W04-W05A
IP G06K-009/46; G06K-009/62
PD CN108960257-A   07 Dec 2018   G06K-009/46   201908   Pages: 13   Chinese
AD CN108960257-A    CN10733502    06 Jul 2018
PI CN10733502    06 Jul 2018
UT DIIDW:2018A0241T
ER

PT P
PN CN108962231-A
TI Speech classification method, involves extracting characteristic of target image based on deep learning model, inputting target image characteristic to speech classifier, and outputting type of target short voice.
AU LV Z
   ZHANG W
   CHEN S
AE WUHAN DOUYU NETWORK TECHNOLOGY CO LTD (DOYU-C)
GA 2018A0196Y
AB    NOVELTY - The method involves obtaining Mel frequency cepstral coefficient (MFCC) feature matrix of a target short voice by using MFCC algorithm. The MFCC feature matrix is converted as a target image. A characteristic of the target image is extracted based on a deep learning model. A target image characteristic is input to a speech classifier. Type of target short voice is output. Row ratio of the MFCC characteristic matrix is adjusted according to preset rule and preset aspect ratio. A gray value of a gray scale image is determined. An element of the MFCC characteristic matrix is adjusted.
   USE - Speech classification method.
   ADVANTAGE - The method enables evaluating difference voice, and classifying and processing voice data.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a speech classification device
   (2) a speech classification server
   (3) a computer-readable storage medium for storing set of instructions for classifying speech.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a speech classification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J05B2; T01-J30A; T01-N02A3C; T01-S03; W04-V01; W04-V05
IP G10L-015/08; G10L-015/30; G10L-015/02; G10L-015/04; G10L-025/18; G10L-025/24; G10L-025/45; G06N-003/08
PD CN108962231-A   07 Dec 2018   G10L-015/08   201908   Pages: 17   Chinese
AD CN108962231-A    CN10726469    04 Jul 2018
PI CN10726469    04 Jul 2018
UT DIIDW:2018A0196Y
ER

PT P
PN CN108960336-A
TI Method for classifying image by using server based on dropout algorithm, involves obtaining image training set by pre-processing image set to classify images to obtain classification results according to neural network classification model.
AU MA Y
   YU S
AE UNIV GUANGDONG TECHNOLOGY (UGTE-C)
GA 2018A0239V
AB    NOVELTY - The method involves transforming state equation of chaotic system to obtain a chaotic system differential equation. Preset parameters are obtained into the chaotic system differential equation to perform iterative calculation processing to obtain a chaotic matrix. The chaotic matrix is normalized to obtain the normalized chaotic matrix. The normalized chaotic matrix is deployed into a standard convolutional neural network to obtain a dropout algorithm convolutional neural network. The dropout algorithm convolutional neural network is trained according to an image training set to establish a convolutional neural network classification model. The image training set is obtained by pre-processing the image set. Images are classified to obtain classification results according to the convolutional neural network classification model.
   USE - Method for classifying image by using a server (claimed) based on a dropout algorithm.
   ADVANTAGE - The method enables obtaining the chaotic matrix by the chaotic system with intrinsic randomness so as to improve randomness of a closed neural unit in the dropout algorithm, thus improving accuracy of neural network classification.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a computer-readable storage medium for storing set of instructions for classifying image by using server based on dropout algorithm
   (2) a device for classifying image by using server based on dropout algorithm.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for classifying image by using server based on dropout algorithm. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B2; T01-N01B3; T01-N02A3C; T01-S03
IP G06K-009/62; G06N-003/04
PD CN108960336-A   07 Dec 2018   G06K-009/62   201908   Pages: 13   Chinese
AD CN108960336-A    CN10777166    16 Jul 2018
PI CN10777166    16 Jul 2018
UT DIIDW:2018A0239V
ER

PT P
PN CN108960065-A
TI Vision based driving behavior detecting method, involves performing fatigue driving detection and distracted driving application detection operation, and displaying and judging driving fatigue level and driving attention level.
AU MIAO Q
   CHEN S
   SU Z
   ZHENG H
   WANG J
   XU W
AE ZHEJIANG LINGPAO TECHNOLOGY CO LTD (ZHEJ-Non-standard)
GA 2018A0246A
AB    NOVELTY - The method involves collecting a cab image. Face information is extracted for performing a face detection and identity verification operation by using a deep convolutional neural network. Face key point position and a face feature map are output. Key point and a face feature pattern are output based on a human face. A fatigue driving detection and distracted driving application detection operation is performed based on a fatigue driving and distracted driving application detecting result. Driving fatigue level and driving attention level are displayed and judged.
   USE - Vision based driving behavior detecting method.
   ADVANTAGE - The method enables improving driver behavior performance efficiency.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a vision. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J07D3A; T01-J10B2
IP G06K-009/00; B60W-040/08
PD CN108960065-A   07 Dec 2018   G06K-009/00   201908   Pages: 15   Chinese
AD CN108960065-A    CN10560951    01 Jun 2018
PI CN10560951    01 Jun 2018
UT DIIDW:2018A0246A
ER

PT P
PN CN108942409-A
TI Residual convolutional neural network based method for modeling and online monitoring of tool wear amount in machine tool processing, involves selecting optimal model before over-fitting as final model if over-fitting occurs.
AU MO R
   ZHANG J
   SUN H
   CAO D
   PAN J
   DU H
AE UNIV NORTHWESTERN POLYTECHNICAL (UNWP-C)
GA 2018A0653Y
AB    NOVELTY - The method involves using a three-axis force sensor, a three-axis acceleration sensor and an acoustic emission sensor. The force and acceleration sensors are placed on the workpiece or fixture. The triaxial force sensor detects the three-axis vibration force signal during processing and converts force signal into an electrical signal. The multi-blade tool cuts the workpiece to collect total of seven signals collected by the triaxial force, the triaxial acceleration and the acoustic emission sensor during processing. The residual convolutional neural network model is built. The previously obtained samples are divided into a training set and a verification set. The optimal model before the over-fitting is selected as the final model if over-fitting occurs. The optimal model is selected as the final model, if no fitting has occurred and the mean square error (MSE) is lower than the threshold. The signal tensor is input to the final model to obtain the amount of wear at the current moment.
   USE - Residual convolutional neural network based method for modeling and online monitoring of tool wear amount in machine tool processing.
   ADVANTAGE - The problem that the method can't extract the features in the signal, the process is complicated and requires skill are solved. The neural network theory provides convenience for different working conditions, and thus stronger generalization performance is achieved.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block flow diagram of the residual convolutional neural network. (Drawing includes non-English language text)
DC P56 (Machine tools (B23P,Q).); T01 (Digital Computers); T05 (Counting, Checking, Vending, ATM and POS Systems); X25 (Industrial Electric Equipment)
MC T01-N01B3; T01-N02B2; T05-G02A; T05-G03; X25-A03
IP B23Q-017/09; G06N-003/04; G06N-003/08; G07C-003/00
PD CN108942409-A   07 Dec 2018   B23Q-017/09   201908   Pages: 12   Chinese
AD CN108942409-A    CN10977274    26 Aug 2018
PI CN10977274    26 Aug 2018
UT DIIDW:2018A0653Y
ER

PT P
PN CN108958000-A
TI Classification learning and dichotomy based optical scanning holography self-focusing method, involves re-obtaining holograms, and obtaining focusing distance of reconstructed hologram by dichotomy.
AU OU H
   WU Y
   SHAO W
   WANG B
AE UNIV ELECTRONIC SCI & TECHNOLOGY (UEST-C)
GA 2018A1443C
AB    NOVELTY - The method involves emitting a laser beam by a laser. The laser beam is divided into two light beams by a first beam splitter. One of the light beams is passed through a first reflector, a first pupil and a first convex lens. Another light beam is passed through a second reflector, a second pupil and a second convex lens. The light beams are transmitted through a second beam splitter to form a Fresnel zone plate. An X-Y scanning vibration mirror is utilized to reflect a scanned object. Multiple holograms are obtained. A focusing distance of the holograms is determined based on rebuilding operation. Relationship is recorded between a reconstructing distance and the focusing distance of the holograms. The holograms are re-obtained. Relationship is determined between the reconstructing distance and the focusing distance of the reconstructed holograms. A focusing distance of the reconstructed hologram is obtained by dichotomy.
   USE - Classification learning and dichotomy based optical scanning holography self-focusing method.
   ADVANTAGE - The method enables utilizing depth learning operation to classify phase maps of the reconstructed holograms, determining a focus position of the hologram by using dichotomy, and effectively and intelligently realizing self-focusing operation in optical scanning holography.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a beam splitter.
DC P84 (Other photographic (G03D-H).); V07 (Fibre-optics and Light Control)
MC V07-F02A; V07-F02C; V07-K05; V07-M
IP G03H-001/04
PD CN108958000-A   07 Dec 2018   G03H-001/04   201908   Pages: 12   Chinese
AD CN108958000-A    CN11079497    17 Sep 2018
PI CN11079497    17 Sep 2018
CP CN108958000-A
      CN103713097-A   UNIV SHANDONG JIANZHU (SDSJ)   SUN C, WANG M, ZHANG Z, ZHU Y, ZHANG Y, WANG W
      CN105023016-A   UNIV CHINA JILIANG (UYJA)   PAN C
      CN105204311-A   UNIV ELECTRONIC SCI & TECHNOLOGY (UEST)   WANG B, WU Y, OU H, SHAO W
      CN106303481-A   TCL GROUP CO LTD (TCLC)   WANG C
      CN108089425-A   UNIV ELECTRONIC SCI & TECHNOLOGY (UEST)   OU H, WU Y, SHAO W, WANG B
      US20060282275-A1      
CR CN108958000-A
      : "", .,relevantClaims[1-7],relevantPassages[]
      : "", ,relevantClaims[1-7],relevantPassages[]
UT DIIDW:2018A1443C
ER

PT P
PN CN108960230-A
TI Rotating rectangular frame based lightweight target identification method, involves performing characteristic extraction on candidate area, and performing target classifying on extracted characteristic to obtain object type of input image.
AU PAN C
   WANG H
   LIU Z
   WENG L
   XIANG S
AE CHINESE ACAD SCI AUTOMATION INST (CAZD-C)
GA 2018A0242H
AB    NOVELTY - The method involves performing target identification on an input image based on a pre-built target recognition network model to obtain an object-type of the input image. A target identification network model is constructed based on a convolutional neural network, where the target identification network model comprises a target extracting module and a target identification module. A candidate area of the input image is extracted by the target extracting module based on a pre-built rotating rectangular frame. A characteristic pattern of the input image is extracted based on a pre-constructed lightweight neural network. Characteristic extraction is performed on the candidate area and the characteristic pattern by the target identification module. Coordinate and target classifying is performed on the extracted characteristic to obtain a object type of the input image.
   USE - Rotating rectangular frame based lightweight target identification method.
   ADVANTAGE - The method enables reducing complexity of target identification algorithm and difficult recognition problem of multi-angle target.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a rotating rectangular frame based lightweight target identification device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a rotating rectangular frame based lightweight target identification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2A; T01-J10B3A; T04-D02; T04-D04
IP G06K-009/32; G06K-009/62
PD CN108960230-A   07 Dec 2018   G06K-009/32   201908   Pages: 18   Chinese
AD CN108960230-A    CN10549254    31 May 2018
PI CN10549254    31 May 2018
UT DIIDW:2018A0242H
ER

PT P
PN CN108961675-A
TI Convolutional neural network-based method for detecting foreground image of person by using processor in computer device, involves obtaining background difference processing image result after processing mixed Gaussian model image.
AU PENG L
   WANG Y
AE UNIV JIANGNAN (UYJN-C)
GA 2018A0209E
AB    NOVELTY - The method involves training a convolutional neural network. A frame image is pre-processed. A foreground extraction and normalization operation on is performed. Image net data is set to a reset network for obtaining a pre-training model. Model parameter is obtained after processing a processed picture into the pre- training model. Test set is input to the pre-training model. Precision of the test set is detected. A detection picture is captured after training the convolutional neural network. A mixed Gaussian model result of a processing image is obtained. A background difference processing image result is obtained after processing a mixed Gaussian model image.
   USE - Convolutional neural network-based method for detecting a foreground image of a person by using a processor in a computer device (all claimed).
   ADVANTAGE - The method enables improving foreground detection precision, reducing calculation complexity, and processing the image into the convolutional neural network.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a computer readable storage medium for storing set of instructions for detecting a foreground image of a person by using a processor.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a convolutional neural network-based method for detecting a foreground image of a person by using a processor in a computer device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W05 (Alarms, Signalling, Telemetry and Telecontrol)
MC T01-G11B; T01-J10B2; T01-J10B3A; T01-N01B3A; W05-B07G3
IP G08B-021/04; G06K-009/00; G06N-003/04; G06N-003/08
PD CN108961675-A   07 Dec 2018   G08B-021/04   201908   Pages: 18   Chinese
AD CN108961675-A    CN10614024    14 Jun 2018
PI CN10614024    14 Jun 2018
UT DIIDW:2018A0209E
ER

PT P
PN CN108961220-A
TI Multi-layer convolution characteristics fusion based image-saliency detecting method, involves inputting cooperative image group to learning network, and obtaining final significance synergistic image by adding average value to input image.
AU REN J
   LIU Z
   ZHOU X
AE UNIV SHANGHAI (USHN-C)
GA 2018A0219Y
AB    NOVELTY - The method involves determining multiple image groups by using a piece of an input image. Three original data groups are processed to generate multiple input image groups and a cooperative image group. An end to end depth learning network is constructed to perform cooperative salient object detection function. The input image and the cooperative image group are input to the depth learning network by using multi-layer convolution characteristic extraction and collaborative characteristics extraction. Loss function is minimized by using stochastic gradient descent algorithm until converges an entire network. A final significance synergistic image is obtained by adding an average value to the input image.
   USE - Multi-layer convolution characteristics fusion based image-saliency detecting method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a multi-layer convolution characteristics fusion based image-saliency detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E01A; T01-J04B2; T01-J10B2; T01-J10B3; T01-N01B3
IP G06T-007/00; G06N-003/04
PD CN108961220-A   07 Dec 2018   G06T-007/00   201908   Pages: 10   Chinese
AD CN108961220-A    CN10619671    14 Jun 2018
PI CN10619671    14 Jun 2018
UT DIIDW:2018A0219Y
ER

PT P
PN CN108960143-A
TI Method for detecting and learning ship detection depth in high resolution visible light remote sensing image, involves transmitting spatial transformation parameter transmitted into space transformation layer, and correcting candidate area.
AU SHI Z
   ZHOU M
   HE G
   ZOU Z
   LEI S
AE UNIV BEIHANG (UNBA-C)
   BEIJING INST SATELLITE INFORMATION ENG (BEIJ-Non-standard)
GA 2018A0244H
AB    NOVELTY - The method involves reading data of an image. The image is pre-processed from earth. The image is transmitted into a shallow layer of a convolutional neural network for performing image characteristics extracting function. The image characteristics are extracted by using an abstract convolution layer. A target candidate area is screened by using an anchor mechanism and two small fully-convolution function. A target candidate area is detected by using extracted characteristic pattern corresponding to a characteristic block. A spatial transformation parameter and the image characteristics are transmitted into a space transformation layer. The target candidate area is re-classified and corrected according to characteristics of the target candidate area.
   USE - Method for detecting and learning ship detection depth in a high resolution visible light remote sensing image.
   ADVANTAGE - The method enables enhancing robustness of detection process according to target deformation so as to improve high resolution visible light remote sensing image ship target detection effect and ensure wide application prospect and value.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for detecting and learning ship detection depth in a high resolution visible light remote sensing image. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J07D1; T01-J10B2; T01-J10D; T01-N01B3; T01-N01D1B
IP G06K-009/00; G06K-009/62
PD CN108960143-A   07 Dec 2018   G06K-009/00   201908   Pages: 15   Chinese
AD CN108960143-A    CN10721881    04 Jul 2018
PI CN10721881    04 Jul 2018
UT DIIDW:2018A0244H
ER

PT P
PN CN108960413-A
TI Deep convolutional neural network screw surface flaw detecting method, involves setting regularization function of deep convolutional neural network model, and obtaining screw surface defect classification detection result by color camera.
AU SONG L
   LI X
   GUO Q
AE UNIV TIANJIN POLYTECHNIC (UYTI-Non-standard)
GA 2018A02383
AB    NOVELTY - The method involves selecting data set of a screw surface image by different colors rectangular frame, where data set comprises a training image and a test image. A deep convolutional neural network model is established to determine a first convolutional layer parameter and a second convolutional layer parameter. Depth of the convolutional neural network model is measured. Excitation function of the deep convolutional neural network model is set. Regularization function of deep convolutional neural network model is set. A screw surface defect classification detection result is obtained by a color camera.
   USE - Deep convolutional neural network screw surface flaw detecting method.
   ADVANTAGE - The method enables effectively reducing screw surface defect detection problems.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep convolutional neural network screw surface flaw detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E01B; T01-J05B2; T01-J10B2; T01-J10B3B; T01-N01B3A; T04-D08
IP G06N-003/04; G06T-007/00
PD CN108960413-A   07 Dec 2018   G06N-003/04   201908   Pages: 13   Chinese
AD CN108960413-A    CN10767126    11 Jul 2018
PI CN10767126    11 Jul 2018
UT DIIDW:2018A02383
ER

PT P
PN CN108960308-A
TI Method for identifying traffic sign by using control device of terminal in vehicle, involves determining flag type of to-be-identified traffic sign, and selecting traffic sign recognition model as image classification model.
AU TANG S
   ZHANG F
   LU J
   HUANG X
   ZHU H
   DU Q
AE CHINESE ACAD SCI AUTOMATION INST (CAZD-C)
GA 2018A0240N
AB    NOVELTY - The method involves obtaining a traffic sign image of a to-be-identified traffic sign. A traffic sign image is identified by using a pre-built traffic sign recognition model. Flag type of the to-be-identified traffic sign is determined. The traffic sign recognition model is selected as an image classification model based on a convolutional neural network, where the traffic sign recognition model is constructed by using a machine learning algorithm. Scale transformation is performed to the traffic sign image. Normalization processing on each pixel point of the traffic sign image is performed after scale conversion.
   USE - Method for identifying a traffic sign by using a control device of a terminal in a vehicle (all claimed).
   ADVANTAGE - The method enables rapidly and accurately identifying type of traffic signs to reduce risk of vehicle driving process.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a storage device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for identifying a traffic sign by using a control device of a terminal in a vehicle. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J07D3A; T01-J10B2A; T01-J16C2
IP G06K-009/62; G06K-009/00
PD CN108960308-A   07 Dec 2018   G06K-009/62   201908   Pages: 8   Chinese
AD CN108960308-A    CN10658519    25 Jun 2018
PI CN10658519    25 Jun 2018
UT DIIDW:2018A0240N
ER

PT P
PN CN108966144-A
TI Convolutional neural network-based vehicle-mounted network transmission calculation model establishing method, involves obtaining vehicle network transmission calculation result by utilizing vehicle network transmission calculation model.
AU TANG X
   JIANG H
   JIN K
   CHEN W
   CHEN X
   CHAI M
AE UNIV CAPITAL NORMAL (UYLT-C)
GA 2018A0112G
AB    NOVELTY - The method involves selecting an optimized vehicle network transmission scheme. Region range is determined. A region is divided into multiple grids with same size according to predetermined condition. A GPS grid map is established. Each grid of the GPS grid map is traversed to obtain a training set. The training set is trained by utilizing a convolutional neural network (CNN). A vehicle network transmission calculation model is established. A vehicle network transmission calculation result is obtained by utilizing the vehicle network transmission calculation model.
   USE - CNN-based vehicle-mounted network transmission calculation model establishing method.
   ADVANTAGE - The method enables improving effectiveness and applicability of the vehicle network transmission scheme so as to meet real-time requirement for data service process in a vehicular network, accelerating vehicle network establishing process and improving user experience.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a CNN-based vehicle-mounted network transmission calculating model establishing device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a CNN-based vehicle-mounted network transmission calculation model establishing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-J04A; T01-J07D3A; T01-N01B3; T01-N01D; W01-A01B2; W01-A06A; W01-A06B5A; W01-A06C4; W01-A06D
IP H04W-004/029; H04W-004/44; H04L-012/24; G06N-003/08; G06N-003/04
PD CN108966144-A   07 Dec 2018   H04W-004/029   201908   Pages: 16   Chinese
AD CN108966144-A    CN10477420    18 May 2018
PI CN10477420    18 May 2018
UT DIIDW:2018A0112G
ER

PT P
PN CN108961123-A
TI Comprehensive virtual reality teaching method, involves realizing student learning quality feedback function and self-learning optimization function, and evaluating learning quality of virtual reality teaching mode.
AU WANG F
   WEI H
   LI J
AE WANG F (WANG-Individual)
GA 2018A02226
AB    NOVELTY - The method involves realizing student learning quality feedback function and self-learning optimization function. Learning quality of a virtual reality teaching mode or an augmented reality enhanced teaching mode i.e. single teaching mode, is evaluated. A learning quality result is obtained by analyzing pattern recognition, interactive data, big data analysis mining process and heat induction recognition. Quality feedback of students is obtained in a teaching mode. Deep learning, self-learning, machine learning, big data analysis processes are performed for learning quality data, internet data and other data or single data reference.
   USE - Comprehensive virtual reality teaching method.
   ADVANTAGE - The method enables realizing strong practicability of the virtual reality teaching mode, improving students learning effects function and realizing student self-optimizing and self-learning functions.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a virtual reality teaching mode. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J40C; T01-N01A2; T01-N01B3; W04-W05A; W04-W07E
IP G06Q-050/20; G06Q-010/06; G06F-003/01
PD CN108961123-A   07 Dec 2018   G06Q-050/20   201908   Pages: 5   Chinese
AD CN108961123-A    CN11115064    25 Sep 2018
PI CN11115064    25 Sep 2018
UT DIIDW:2018A02226
ER

PT P
PN CN108960288-A
TI Convolutional neural network-based three- dimensional model classification method, involves extracting shape characteristic of three-dimensional model through network hierarchy to obtain classified result of three-dimensional model.
AU WANG J
   LI M
AE UNIV SHANDONG NORMAL (UYSN-C)
GA 2018A02415
AB    NOVELTY - The method involves obtaining a three- dimensional model to be classified. Multi-angle projection view of the three- dimension model is obtained. Input of a convolutional neural network is generated. Shape characteristic of the three-dimensional model is extracted through network hierarchy to obtain classified result of the three-dimensional model. Three-dimensional model files are obtained. The three- dimensional model is adjusted according to XYZ-coordinate axes. Extracted images in the projection view are arranged in regular rows and columns. The convolutional neural network is provided with an input layer, a hidden layer and an output layer. The hidden layer is provided with multiple convolution layers and cell layers.
   USE - Convolutional neural network-based three- dimensional model classification method.
   ADVANTAGE - The method enables avoiding model-data transforming operation, thus effectively improving classification efficiency of the three-dimensional model and improving development of computer vision and computer aided design research.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a convolutional neural network-based three- dimensional model classification system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a convolutional neural network-based three- dimensional model classification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J05B2; T01-J10B2; T01-J15X; T04-D04
IP G06K-009/62; G06N-003/04
PD CN108960288-A   07 Dec 2018   G06K-009/62   201908   Pages: 10   Chinese
AD CN108960288-A    CN10580064    07 Jun 2018
PI CN10580064    07 Jun 2018
UT DIIDW:2018A02415
ER

PT P
PN CN108959304-A
TI Label prediction method, involves counting times of occurrences of each predicted label, and setting label to image data set when frequency of occurrence of label satisfies prediction label corresponding to preset condition of image.
AU WEI X
AE ALIBABA GROUP HOLDING LTD (ABAB-C)
GA 2018A14387
AB    NOVELTY - The method involves obtaining image data set, where image in the image data set belongs to same category. Label prediction is performed to the image in the image data set within preset image tag range. Predicted label of each image is generated. Times of occurrences of each predicted label is counted. Label is set to the image data set when frequency of occurrence of label satisfies prediction label corresponding to preset condition of the image. Image samples of known image tag are obtained for deep learning process to obtain relationship between model image labels and the image.
   USE - Label prediction method.
   ADVANTAGE - The method enables improving accuracy and combining efficiency of label prediction.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a label prediction device
   (2) a computer-readable storage medium for storing a set of instructions to execute a label prediction method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a label prediction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B4F; T01-J30A; T01-S03
IP G06F-017/30
PD CN108959304-A   07 Dec 2018   G06F-017/30   201908   Pages: 23   Chinese
AD CN108959304-A    CN10363676    22 May 2017
PI CN10363676    22 May 2017
UT DIIDW:2018A14387
ER

PT P
PN CN108961238-A
TI Method for detecting quality of display screen of electronic device, involves inputting pre-processed display screen image into defect detection model, and determining quality of display screen according to defect detection result.
AU WEN Y
   LENG J
   LIU M
   XU Y
   GUO J
   LI X
AE BEIJING BAIDU NETCOM SCI & TECHNOLOGY CO (BIDU-C)
GA 2018A0219E
AB    NOVELTY - The method involves receiving quality detection request sent by a console deployed on a display production line, where the quality detection request includes display screen image collected by an image acquisition device. The display screen image is pre-processed, where the image pre-processing process includes trimming, cropping, rotating, reducing and zooming processes. The pre-processed display screen image is input into a defect detection model, where the defect detection model is established by a deep convolutional neural network and an instance segmentation algorithm. Quality of a display screen is determined according to the defect detection result.
   USE - Method for detecting quality of a display screen of an electronic device (claimed).
   ADVANTAGE - The method enables increasing display screen defect detection accuracy, performance rate and service expansion ability of display screen quality detection process.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for detecting quality of a display screen of an electronic device
   (2) a storage medium for storing a set of instructions for detecting quality of a display screen of an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for detecting quality of a display screen of an electronic device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10A; T01-J10B2; T01-J10B3A; T01-N01A2
IP G06N-003/04; G06Q-010/06; G06T-007/00
PD CN108961238-A   07 Dec 2018   G06T-007/00   201908   Pages: 19   Chinese
AD CN108961238-A    CN10709189    02 Jul 2018
PI CN10709189    02 Jul 2018
CP CN108961238-A
      CN105812746-A   BEIJING DEEPGLINT INFORMATION TECHNOLOGY (BEIJ-Non-standard)   CAI Y
      CN107561738-A   HUNAN INST SCI & TECHNOLOGY (HUNA-Non-standard)   OU X, ZHANG G, WU J, KWOH R, PENG X, TU B, ZHOU J
      CN108154508-A   BEIJING BAIDU NETCOM SCI & TECHNOLOGY CO (BIDU)   LENG J, LIU M, LIANG Y, WEN Y, ZHANG F, GUO J, TANG J, YIN S
UT DIIDW:2018A0219E
ER

PT P
PN CN108960333-A
TI Deep learning based hyperspectral image lossless compression method, involves performing arithmetic coding process on residual image to obtain stream file, and decoding stream file to obtain restored original hyperspectral image.
AU WU J
   ZHAO S
   QU T
   LI J
AE UNIV XIDIAN (UYXN-C)
GA 2018A0239Y
AB    NOVELTY - The method involves performing clustering process on multiple spectral lines in a hyperspectral image. An initial predicted image and a transition prediction image are obtained. A residual image is obtained by utilizing the predicted image and an original image. Each pixel of an initial residual image and a transition residual image are compared. A point is selected with less residual pixel value to obtain a final residual image. Arithmetic coding process is performed on the residual image to obtain a to-be-transmitted stream file. The to-be-transmitted stream file is decoded to obtain a restored original hyperspectral image.
   USE - Deep learning based hyperspectral image lossless compression method.
   ADVANTAGE - The method enables forming a unit of a memory structure in a network, and increasing generalization ability of a model to improve compression efficiency. The method enables fully utilizing spectral information, and improving model generalization capability.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning based hyperspectral image lossless compression method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W04 (Audio/Video Recording and Systems)
MC T01-J05B3; T01-J10B2; T01-J10D; T01-N01B3; T01-N01D2; T01-N03A2; T04-D04; W04-P01A4
IP G06K-009/62; G06N-003/08; H04N-019/593
PD CN108960333-A   07 Dec 2018   G06K-009/62   201908   Pages: 11   Chinese
AD CN108960333-A    CN10763677    12 Jul 2018
PI CN10763677    12 Jul 2018
UT DIIDW:2018A0239Y
ER

PT P
PN CN108960488-A
TI Deep learning and multi-source information fusion based saturated precise loading space distribution accurately predicting method, involves obtaining known saturated load density, and inputting data to regression device for load prediction.
AU WU K
   WU J
   LU Z
   SUN W
   LI K
   LI B
   FENG L
   YANG B
   LIANG R
   CUI C
   YANG Y
   WANG H
   ZHANG X
   DU P
   YANG S
   LI Z
   QI L
   LIU S
   PANG Y
   LIU Z
   WANG Y
   ZHAO R
   MA R
   HAN C
   HUANG M
   YANG L
   LIN Z
AE ECONOMIC & TECHNOLOGY RES INST HUBEI ELE (SGCC-C)
   ELECTRIC POWER RES INST STATE GRID SHAND (SGCC-C)
   UNIV ZHEJIANG (UYZH-C)
GA 2018A0236G
AB    NOVELTY - The method involves obtaining known saturated load density of cellular features with saturated load density to obtain a load cell sample library. Space load cell attribute of multi-source information is analyzed according to the cellular features. Data of a tested cell is pre-processed. Land property is substituted into load cell sample base data and cell data. Proper activation function is selected by using a stack-based noise reduction-based self-encoder network in deep learning algorithm. Data network training process and multi-attribute feature extraction process are performed. The data is input into a regression device for load feature extraction and load prediction.
   USE - Deep learning and multi-source information fusion based saturated precise loading space distribution accurately predicting method.
   ADVANTAGE - The method enables realizing saturated precise loading space distribution accurately predicting process with certain feasibility and effectiveness for forecasting the space, so that extraction algorithm performance is more better.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning and multi-source information fusion based saturated precise loading space distribution accurately predicting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E01B; T01-J05B4P; T01-J16C2; T01-N01A2; T01-N01B3; T01-N01D
IP G06N-003/04; G06N-003/08; G06Q-010/04; G06Q-010/06; G06Q-050/06
PD CN108960488-A   07 Dec 2018   G06Q-010/04   201908   Pages: 13   Chinese
AD CN108960488-A    CN10609803    13 Jun 2018
PI CN10609803    13 Jun 2018
UT DIIDW:2018A0236G
ER

PT P
PN CN108961269-A
TI Image based on pig weight measuring method, involves collecting sample image, recording pig body weight, and inputting actual area of pig body to pig weight regression model for calculating weight of pig body.
AU XIE S
AE DEEPFINCH HENGJI TECHNOLOGY CO LTD (DEEP-Non-standard)
GA 2018A0218N
AB    NOVELTY - The method involves collecting a sample image. Pig body contour and profile of the sample image is marked. The pig body weight is recorded. Normalization process is carried out to the sample image. Number of pixels in pig body contour and tag profile in the sample image. Corresponding pig weight regression model is established using the semantic of a convolutional neural network. Weight image is inputted to the semantic model to obtain semantic of the weight measurement image of segmentation image. The pig body in semantic segmentation image is calculated. Actual area of the pig body is inputted to the pig weight regression model for calculating weight of the pig body.
   USE - Image based on pig weight measuring method.
   ADVANTAGE - The method enables ensuring safety and sanitation and health of measuring staff, and improves efficiency of obtaining weight data, and reducing manufacturing cost.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for an image based on pig weight measuring system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating an image based on pig weight measuring method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-J16C3; T01-N01A1; T04-K03B
IP G06T-007/11; G06Q-040/08; G06T-007/62
PD CN108961269-A   07 Dec 2018   G06T-007/11   201908   Pages: 9   Chinese
AD CN108961269-A    CN10652648    22 Jun 2018
PI CN10652648    22 Jun 2018
UT DIIDW:2018A0218N
ER

PT P
PN CN108960174-A
TI Target detection result optimization method, involves obtaining confidence level of detection frame by deep learning network, determining reference detection frame with maximum confidence, and outputting detection frame information.
AU XIE Y
   LIU G
AE UNIV GUANGDONG TECHNOLOGY (UGTE-C)
GA 2018A0243S
AB    NOVELTY - The method involves obtaining confidence level of a detection frame by a deep learning network. Reference detection frame with maximum confidence is determined corresponding to the obtained confidence level of the detection frame. Area overlap rate of the reference detection frame and a non-reference detection frame is calculated according to coordinate information of the detection frame. Judgment is made to check whether area overlap ratio is lesser that predetermined area overlap threshold or not. The non-reference detection frame is removed when the area overlap ratio is lesser that predetermined area overlap threshold. Detection frame information is outputted.
   USE - Target detection result optimization method.
   ADVANTAGE - The method enables removing redundant detection frame of same target corresponding to a display.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a target detection result optimization device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a target detection result optimization method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W04 (Audio/Video Recording and Systems)
MC T01-J10B2; T01-N01B3; T04-D02; T04-D03; W04-W05A
IP G06K-009/00; G06K-009/32; G06K-009/46
PD CN108960174-A   07 Dec 2018   G06K-009/00   201908   Pages: 12   Chinese
AD CN108960174-A    CN10765969    12 Jul 2018
PI CN10765969    12 Jul 2018
UT DIIDW:2018A0243S
ER

PT P
PN CN108960326-A
TI Deep learning framework based rapid point cloud segmenting method, involves establishing trained convolution neural network, and evaluating network performance on test set by using trained convolution neural network.
AU XU K
   FENG L
AE SHENZHEN INST ADVANCED TECHNOLOGY (CAAT-C)
GA 2018A02406
AB    NOVELTY - The method involves selecting and inputting data set into a convolution neural network from point network deep learning framework point cloud data (S1). Data format of the data set is organized and matched (S2) with code for reading the data format to perform data processing operation. A deep convolution neural network is established (S3) according to data characteristics of the data set. The convolution neural network is tested and trained (S4) by a deep learning framework to establish a trained convolution neural network. Network performance on test set is evaluated (S5) by using the trained convolution neural network.
   USE - Deep learning framework based rapid point cloud segmenting method.
   ADVANTAGE - The method enables effectively increasing utilization rate, propagation speed and network convergence speed and reducing determination of network parameter without reducing network prediction performance so as to reduce redundancy process and studying cost.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning framework based rapid point cloud segmenting system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning framework based rapid point cloud segmenting method. '(Drawing includes non-English language text)'
   Step for selecting and inputting data set into a convolution neural network (S1)
   Step for organized and matching data format of the data set with code (S2)
   Step for establishing a deep convolution neural network (S3)
   Step for testing and training the convolution neural network (S4)
   Step for evaluating network performance on test set (S5)
DC T01 (Digital Computers)
MC T01-E01B; T01-J04B2; T01-J10B2; T01-N01B3A
IP G06K-009/62
PD CN108960326-A   07 Dec 2018   G06K-009/62   201908   Pages: 8   Chinese
AD CN108960326-A    CN10721795    04 Jul 2018
PI CN10721795    04 Jul 2018
UT DIIDW:2018A02406
ER

PT P
PN CN108961339-A
TI Depth learning based cloud point object pose estimating method, involves dividing maximum pool layer into parallel multi-layer sensing machine bodies, and optimizing multi-class loss function by using adaptive torque estimating process.
AU XU K
   FENG L
   CHEN X
AE SHENZHEN COSMOSVISION INTELLIGENT TECHNO (SHEN-Non-standard)
GA 2018A02171
AB    NOVELTY - The method involves obtaining learning data. Design of a network model is established. The network model is trained. Point cloud object pose estimation problem is detected. A designed residual structure is constructed to extract a characteristic point cloud object. The designed residual structure is formed with a maximum pool layer to collect global characteristics. Characteristic score is selected as final class prediction score. The maximum pool layer is divided into three parallel multi-layer sensing machine bodies. Multi-class loss function is optimized by using adaptive torque estimating process.
   USE - Depth learning based cloud point object pose estimating method.
   ADVANTAGE - The method enables precisely performing point cloud object pose estimation process, thus improving point-cloud object pose estimating precision.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a depth learning based cloud point object pose estimating device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a depth learning based cloud point object pose estimating method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E01B
IP G06T-007/73; G06N-003/04
PD CN108961339-A   07 Dec 2018   G06T-007/73   201908   Pages: 23   Chinese
AD CN108961339-A    CN10800385    20 Jul 2018
PI CN10800385    20 Jul 2018
UT DIIDW:2018A02171
ER

PT P
PN CN108960127-A
TI Adaptive depth metric learning based shielding pedestrian identification method, involves performing pedestrian identification process according to trained model, and obtaining output characteristic of convolutional neural network.
AU YAN Y
   YANG W
   WANG H
AE UNIV XIAMEN (UYXI-C)
GA 2018A0244T
AB    NOVELTY - The method involves extracting high-level semantic feature of a pedestrian image. Adaptive depth measurement loss is determined during designing of a convolutional neural network. High distinguishing capacity characteristic is obtained to identify a pedestrian. The convolution neural network is pre-trained by utilizing a back propagation algorithm to establish a pre-training model. A pedestrian image training sample set is obtained according to the pre-training model. Pedestrian identification process is performed according to a trained model. Output characteristic of the convolutional neural network is obtained according to the pedestrian image.
   USE - Adaptive depth metric learning based shielding pedestrian identification method.
   ADVANTAGE - The method enables finishing subsequent characteristic similarity comparison process to obtain final pedestrian recognition result so as to effectively improve robustness feature of a shielding pedestrian.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of a convolutional neural network structure. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J10B2A; T01-J16C3; T01-N01B3; T04-D04; T04-D07D3
IP G06K-009/00; G06K-009/62
PD CN108960127-A   07 Dec 2018   G06K-009/00   201908   Pages: 13   Chinese
AD CN108960127-A    CN10696880    29 Jun 2018
PI CN10696880    29 Jun 2018
UT DIIDW:2018A0244T
ER

PT P
PN CN108960319-A
TI Candidate answer selecting method, involves obtaining candidate answer passages, and outputting optimal candidate answer segment and candidate answer passages when segment of paragraph is in candidate answer passages.
AU YANG M
   ZHANG Y
   LI Y
   ZHAO T
   XU B
   ZHENG D
   CAO H
   ZHU C
   MA J
AE HARBIN INST TECHNOLOGY (HAIT-C)
GA 2018A0240D
AB    NOVELTY - The method involves obtaining paragraphs of text segments in a candidate answer segment positioning range. An optimal candidate answer segment is obtained. Features are extracted in a paragraph. Relevance scoring process is performed based on the logistic regression model. Candidate answer passages are obtained. Judgment is made to check whether a segment of the paragraph is in the candidate answer passages. An optimal candidate answer segment and the candidate answer passages are output when the segment of the paragraph is in the candidate answer passages. A depth learning model is trained.
   USE - Candidate answer selecting method.
   ADVANTAGE - The method enables improving training and prediction efficiency.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a candidate answer selecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05A2B; T01-J10B2; T01-J11A1; T04-D04; T04-D07B
IP G06K-009/62; G06F-017/27
PD CN108960319-A   07 Dec 2018   G06K-009/62   201908   Pages: 11   Chinese
AD CN108960319-A    CN10700571    29 Jun 2018
PI CN10700571    29 Jun 2018
UT DIIDW:2018A0240D
ER

PT P
PN CN108965826-A
TI Object monitoring method, involves obtaining video of monitoring object, counting number of object at predetermined position in target time period, and outputting warning information when actual number is greater than prediction number.
AU YANG Y
   SONG Y
   CHEN X
AE MEGVII TECHNOLOGY LTD (MEGV-Non-standard)
GA 2018A13112
AB    NOVELTY - The method involves obtaining video of a monitoring object at a predetermined position in target time period. Predicted number of the monitoring object is determined in the predetermined position during the target time period according to the video. Actual number of the monitored object is counted at predetermined position in the target time period. Warning information is outputted when the actual number is greater than the prediction number. The video is analyzed at a single frame image by a convolutional neural network. Video collection process is performed by a camera device with in a shooting range.
   USE - Object monitoring method.
   ADVANTAGE - The method enables outputting the warning information when the actual number is greater than the predicted number so as to automatically timely warning abnormal aggregation, improve monitoring effect of the monitored object, and reducing workload of a worker.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a processing device
   (2) an object monitoring device
   (3) a computer-readable storage medium for performing an object monitoring method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an object monitoring method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T05 (Counting, Checking, Vending, ATM and POS Systems); W02 (Broadcasting, Radio and Line Transmission Systems); W05 (Alarms, Signalling, Telemetry and Telecontrol)
MC T01-G11B; T01-J10B2; T01-N02B2; T01-S03; T05-A; T05-B01; T05-D01; T05-G03; W02-F01A5; W05-B07
IP H04N-007/18; G07C-009/00; G08B-021/02
PD CN108965826-A   07 Dec 2018   H04N-007/18   201908   Pages: 16   Chinese
AD CN108965826-A    CN10957851    21 Aug 2018
PI CN10957851    21 Aug 2018
UT DIIDW:2018A13112
ER

PT P
PN CN108962356-A
TI Deep learning based real-time enteroscope operation assisting system, has sample database provided with picture library and part library, and convolution neural network model for transmitting analysis result to client end.
AU YU H
   HU S
   MU G
   WU L
AE UNIV WUHAN RENMIN HOSPITAL (UYWU-C)
GA 2018A0194L
AB    NOVELTY - The system has a client end connected with an endoscope device for obtaining colonoscopy images collected by a current mirror device. The current mirror device uploads colonoscopy images to a server by a network. The server performs colonoscopy image process according to an enteroscope image sent by the client end. The server is provided with a sample database, a convolution neural network model and a web service module. The sample database stores samples of typical colonoscopy images and provided with a qualified picture library, a part library and a part characteristic database. The convolution neural network model transmits an analysis result to the client end.
   USE - Deep learning based real-time enteroscope operation assisting system.
   ADVANTAGE - The system is simple and easy to use, and provides reliable reference basis for an operator and improves accuracy and efficiency of detection.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based real-time enteroscope operation assisting method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a deep learning based real-time enteroscope operation assisting system. '(Drawing includes non-English language text)'
DC S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S05-D06; S05-D08A; S05-G02G3; T01-J04B2; T01-J05B4F; T01-J10B2; T01-N01B3; T01-N01D1B; T01-N01D3; T01-N01E1; T01-N02A2C
IP G16H-030/40; G16H-040/60; G16H-050/20
PD CN108962356-A   07 Dec 2018   G16H-030/40   201908   Pages: 9   Chinese
AD CN108962356-A    CN10548889    31 May 2018
PI CN10548889    31 May 2018
UT DIIDW:2018A0194L
ER

PT P
PN CN108961246-A
TI Artificial intelligence based scanning electron microscope image hole identification method, involves dividing holes from electron microscope scanning image of rock sample by using artificial intelligent mode for marking color.
AU YU Q
   LIU W
   ZHANG C
   LIU C
   WANG C
AE UNIV JILIN (UYJI-C)
GA 2018A02198
AB    NOVELTY - The method involves dismissing a portion of scanning electron microscope image that contains map information by cropping the image. The scanning electron microscope image is cut into multiple images of same size according to pixel size to reduce a single data processing workload of a depth learning model. Position and shape of pores are colored by using an image processing tool. The image is converted into a grayscale image. Pore segmentation is performed on the scanning electron microscope image by using a trained artificial intelligent model. An image segmentation Python (RTM: High-level programming language) command file infer.py is executed. Holes are divided from the electron microscope scanning image of a rock sample by using an artificial intelligent mode for marking a color.
   USE - Artificial intelligence based scanning electron microscope image hole identification method.
   ADVANTAGE - The method enables improving precision of hole identification.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an artificial intelligence based scanning electron microscope image hole identification method. '(Drawing includes non-English language text)'
DC S03 (Scientific Instrumentation); S06 (Electrophotography and Photography); T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC S03-E06B1; S06-K01A; S06-K07A4D; S06-K99D; T01-J10B2; T01-J10B3B; T01-J10D; T01-J30A; T04-D08
IP G06T-007/00; G06T-007/11
PD CN108961246-A   07 Dec 2018   G06T-007/00   201908   Pages: 6   Chinese
AD CN108961246-A    CN10750534    10 Jul 2018
PI CN10750534    10 Jul 2018
UT DIIDW:2018A02198
ER

PT P
PN CN108960084-A
TI Method for tracking current frame target position by electronic device, involves obtaining possible position of target in current frame according to established object surface model, and determining position of target current frame.
AU YUAN C
   LIN Z
AE UNIV TSINGHUA SHENZHEN GRADUATE SCHOOL (UYQI-C)
GA 2018A0245V
AB    NOVELTY - The method involves reconstructing a low resolution image to a high resolution target image. An object surface model is established according to the target image. Possible position of target in a current frame is obtained according to the established object surface model. Position of target of the current frame is determined. Interpolation operation is performed on the low resolution image to obtain an interpolated low-resolution image. The interpolated low resolution image is inputted into a convolutional neural network to convolve the low-resolution image. A target image is obtained based on the interpolated low resolution image and the convolution image.
   USE - Method for tracking current frame target position by an electronic device (claimed).
   ADVANTAGE - The method enables realizing high resolution, and reducing traditional judging type tracker under low resolution scene lacks information problem, and updating the object surface model according to determined position of the target current frame, so as to improve determining effect of target track.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a system for tracking current frame target position by an electronic device
   (2) a computer readable storage medium for storing set of instructions for a method for tracking current frame target position by an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for tracking current frame target position by an electronic device. '(Drawing includes non-English language text)'
DC S01 (Electrical Instruments); T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC S01-H09; T01-J04B2; T01-J10B2; T01-J10B3A; T01-J10D; T04-D04; T04-D07D5
IP G06K-009/00; G06K-009/62
PD CN108960084-A   07 Dec 2018   G06K-009/00   201908   Pages: 17   Chinese
AD CN108960084-A    CN10632595    19 Jun 2018
PI CN10632595    19 Jun 2018
UT DIIDW:2018A0245V
ER

PT P
PN CN108960342-A
TI Soft-Max loss function based high-speed paper counter image similarity calculation method, involves obtaining output value of sample image characteristic layer, and obtaining image characteristics of image characteristic layer.
AU ZHANG D
   LI J
AE UNIV CHINA JILIANG (UYJA-C)
GA 2018A0239P
AB    NOVELTY - The method involves preparing an image recognition training data set. The image recognition training data set is input into an image-based recognition network of a convolutional neural network, where the image-based recognition network of the convolutional neural network comprises a convolution layer, a maximum sampling layer, a connecting layer and a soft-max layer. The image-based recognition network is serially connected with a sub-structure. An output value of a sample image characteristic layer is obtained in the image-based recognition network. Image characteristics of the image characteristic layer are obtained.
   USE - Soft-Max loss function based high-speed paper counter image similarity calculation method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a soft-max loss function based high-speed paper counter image similarity calculation method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04A; T01-J04B2; T01-J10B2A; T01-N01B3; T04-D03; T04-D04
IP G06K-009/62; G06K-009/46; G06N-003/04; G06N-003/08
PD CN108960342-A   07 Dec 2018   G06K-009/62   201908   Pages: 9   Chinese
AD CN108960342-A    CN10864947    01 Aug 2018
PI CN10864947    01 Aug 2018
UT DIIDW:2018A0239P
ER

PT P
PN CN108960175-A
TI Deep learning based number plate identifying method, involves detecting whether presence of number plate for identifying character of number plate, and provided plate segmentation model with number plate letter and number recognition model.
AU ZHANG D
   SHI Y
AE TIANJIN ISECURE TECHNOLOGY CO LTD (TIAN-Non-standard)
GA 2018A0243R
AB    NOVELTY - The method involves detecting whether presence of number plate for identifying character of the number plate by using a number plate segmentation model. The number plate segmentation model is provided with a number plate character recognition model and a number plate letter and number recognition model. The number plate segmentation model is provided with four convolution layers. A first prior box layer is connected with third convolution layer. A first position prediction unit, a confidence prediction unit and a second prior box layer are connected with the fourth convolution layer. A second position prediction unit, the second prior box layer and the confidence prediction unit are connected with the first prior box layer.
   USE - Deep learning based number plate identifying method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning based number plate identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J04B2; T01-J10B2A; T01-J30A; W04-W05A
IP G06K-009/00; G06K-009/34; G06N-003/04
PD CN108960175-A   07 Dec 2018   G06K-009/00   201908   Pages: 11   Chinese
AD CN108960175-A    CN10766184    12 Jul 2018
PI CN10766184    12 Jul 2018
UT DIIDW:2018A0243R
ER

PT P
PN CN108960330-A
TI Convolutional neural network based remote sensing image generating method, involves extracting test sample image characteristic by using convolution neural network, and obtaining description image content of sentence.
AU ZHANG X
   LI X
   ZHU P
   JIAO L
   TANG X
   HOU B
   MA J
   MA W
AE UNIV XIDIAN (UYXN-C)
GA 2018A02402
AB    NOVELTY - The method involves sensing image-text data. The image-text data is selected as a training sample and a test sample. A remote sensing image in a training sample is extracted by using a quick region-convolutional neural network. Text characteristics are determined by using a bidirectional neural network. A probability- based graph-text matching model is established. A picture characteristic is matched with the text characteristic. A short-term memory network is trained. A test sample image characteristic is extracted by using the convolution neural network. A description image content of a sentence is obtained.
   USE - Convolutional neural network based remote sensing image generating method.
   ADVANTAGE - The method enables improving remote sensing image semantic result, realizing image searching or scene classification process, and increasing resolution of the remote sensing image.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network based remote sensing image generating method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E01B; T01-J04B2; T01-J05B2; T01-J10B1; T01-J10B2; T01-J10C3; T01-J10C5; T01-J10D; T01-J16C3; T01-N01B3A; T01-N01D1B; T01-N01D2; T01-N03A2
IP G06K-009/62; G06N-003/04; G06N-003/08
PD CN108960330-A   07 Dec 2018   G06K-009/62   201908   Pages: 14   Chinese
AD CN108960330-A    CN10744473    09 Jul 2018
PI CN10744473    09 Jul 2018
UT DIIDW:2018A02402
ER

PT P
PN CN108960300-A
TI Deep neural network based urban land use information analyzing method, involves inputting classification result of characteristics vector to pre-trained stack from classifier, and obtaining urban land use classification information.
AU ZHANG Y
   LI Y
   SUN G
AE UNIV BEIJING TECHNOLOGY (UYBT-C)
   NAT ASTRONOMICAL OBSERVATORIES CHINA SCI (CAAO-C)
GA 2018A0240W
AB    NOVELTY - The method involves pre-obtaining polarization synthetic aperture radar data. A pre-processed optical image is obtained. Registration is pre-processed by manually selecting a ground control point. Pre-processed registration is obtained according to complete polarimetric SAR image and an optical image. Polarization characteristics are determined. Optical characteristics are determined from the optical image after registration. Polarization characteristic and optical characteristics are combined to obtain characteristics vector. A primary classification result of the characteristics vector is input to a pre-trained stack from an encoder SAE classifier. Urban land use classification information is obtained.
   USE - Deep neural network based urban land use information analyzing method.
   ADVANTAGE - The method enables improving urban land use extraction precision.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep neural network based urban land use information analyzing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B2; T01-N01A2
IP G06K-009/62; G06K-009/00; G06N-003/04; G06Q-050/16
PD CN108960300-A   07 Dec 2018   G06K-009/62   201908   Pages: 19   Chinese
AD CN108960300-A    CN10636689    20 Jun 2018
PI CN10636689    20 Jun 2018
UT DIIDW:2018A0240W
ER

PT P
PN CN108960184-A
TI Heterogeneous component depth neural network based pedestrian recognition method, involves obtaining matching result of image to-be-queried by calculating distance between image to-be-queried and feature representation vector of image.
AU ZHANG Z
   HUANG M
   LIU S
AE UNIV TIANJIN NORMAL (UYTI-Non-standard)
GA 2018A0243K
AB    NOVELTY - The method involves aligning K part-based feature vectors according to alignment distance for two images in a batch of pedestrian images (S4). Alignment of the K-part-based feature vector is learnt to obtaining batch hard triad loss. K-cross entropy losses of the batch is obtained (S5) based on distinguishing property of partial feature vectors. Network parameters of a deep neural network is updated (S6) based on hard triplet loss and K-cross entropy loss to determine a trained deep neural network. K-part-based feature vectors of an image to-be-queried is extracted (S7) by utilizing the depth neural network. Matching result of the image to-be-queried is obtained (S8) by calculating distance between the image to-be-queried and feature representation vector of the image in an image library.
   USE - Heterogeneous component depth neural network based pedestrian recognition method.
   ADVANTAGE - The method enables improving pedestrian discrimination performance of identified matches.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a heterogeneous component depth neural network based pedestrian recognition method. '(Drawing includes non-English language text)'
   Step for aligning K part-based feature vectors according to alignment distance for two images in a batch of pedestrian images (S4)
   Step for obtaining K-cross entropy losses of the batch based on distinguishing property of partial feature vectors (S5)
   Step for updating network parameters of a deep neural network based on hard triplet loss and K-cross entropy loss to determine a trained deep neural network (S6)
   Step for extracting K-part-based feature vectors of an image to-be-queried by utilizing the depth neural network (S7)
   Step for obtaining matching result of the image to-be-queried by calculating distance between the image to-be-queried and feature representation vector of the image in a image library (S8)
DC T01 (Digital Computers)
MC T01-J04A; T01-J10B2A; T01-N01B3
IP G06K-009/00; G06N-003/04
PD CN108960184-A   07 Dec 2018   G06K-009/00   201908   Pages: 12   Chinese
AD CN108960184-A    CN10800448    20 Jul 2018
PI CN10800448    20 Jul 2018
UT DIIDW:2018A0243K
ER

PT P
PN CN108961186-A
TI Deep learning based outdated cinema repairing and reproducing method, involves training de-noise network by using corresponding de-noising network model, and selecting Char bonnier function as loss function of de-noising network.
AU ZHAO Y
   NIE K
AE ZHAO Y (ZHAO-Individual)
GA 2018A0220T
AB    NOVELTY - The method involves drawing a video frame. A training data set of a de-interlacing scanning network model is obtained. A video frame model training data set and a de-fuzzy training data set are obtained for training an ultra-resolution network model. The de-interlacing scanning network model is trained for scanning a field image block to obtain a prediction result, where the network model comprises a characteristic extraction module, a non-linear mapping module and a reconstruction module. A de-noise network is trained by using a de-noising network model. Char bonnier function is selected as loss function of the de-noising network.
   USE - Deep learning based outdated cinema repairing and reproducing method.
   ADVANTAGE - The method enables realizing video de-noising and de-blurring operations in an effective manner, and improving stability, calculation speed, image restoration accuracy and image restoration effect, and realizing convenient use of the ultra-resolution network model and reducing processing cost.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based outdated cinema repairing and reproducing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J10B1; T01-J10B3A; T01-N01B3; W04-X03G5
IP G06T-005/00; G06T-003/40
PD CN108961186-A   07 Dec 2018   G06T-005/00   201908   Pages: 16   Chinese
AD CN108961186-A    CN10699895    29 Jun 2018
PI CN10699895    29 Jun 2018
UT DIIDW:2018A0220T
ER

PT P
PN CN108960064-A
TI Method for detecting and recognizing human face based on convolutional neural network, involves filtering human face candidate frame in image to form final human face candidate frame, and comparing human face image with candidate frame.
AU ZHENG K
   ZHENG G
   TAN P
   XU L
   FAN Q
   YANG Z
   GAO S
AE CHONGQING RANADA AUTOMATION TECHNOLOGY (CHON-Non-standard)
GA 2018A1318H
AB    NOVELTY - The method involves receiving a training image to form a human face training feature library. A difference amplification layer is formed with a cluster layer. The image is input for iterative training to form a feature model. Image information is received. Determination is made to check whether the human face is detected. A human face candidate frame in the image is filtered to form a final human face candidate frame. The human face image is compared with the human face candidate frame in the feature value to realize human face verification. Continuous iteration of parameters is realized to form a final feature model.
   USE - Method for detecting and recognizing a human face based on a convolutional neural network.
   ADVANTAGE - The method enables realizing single-level fitting of the characteristic parameters and continuously performing similar clustering process by using a result of the upper layer in the fitting process so as to realize better classification effect and better fitting result and precise established feature model, thus achieving accurate human face recognition, and reducing errors.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for detecting and recognizing a human face based on a convolutional neural network. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2; T01-J05B3; T01-J10B1; T01-J10B2A; T01-N01B3; T01-N03A2; T04-D07F1
IP G06K-009/00; G06N-003/04; G06N-003/08
PD CN108960064-A   07 Dec 2018   G06K-009/00   201908   Pages: 10   Chinese
AD CN108960064-A    CN10559280    01 Jun 2018
PI CN10559280    01 Jun 2018
UT DIIDW:2018A1318H
ER

PT P
PN CN108960273-A
TI Method for identifying poor students based on deep learning, involves training deep learning neural network model by using student characteristics and student label to identify poor students by trained deep learning neural network model.
AU ZHU Q
   LI X
   HU R
   CAI B
   LIU Q
   ZHOU H
   WU S
   NI J
   PAN S
AE HUAIYIN TECHNOLOGY INST (HUIA-C)
GA 2018A0241F
AB    NOVELTY - The method involves extracting student's value from student credit consumption data, score data and library data to establish a student poverty category label. A deep learning neural network model is established. The deep learning neural network model is trained by using extracted student characteristics and student label. Poor students are identified by the trained deep learning neural network model. A student credit consumption data set is established. A student performance data set is established. A student library data set is established. The student credit consumption data set, the student performance data set and the student library data set are established to form a student feature matrix.
   USE - Method for identifying poor students based on deep learning.
   ADVANTAGE - The method enables extracting student card consumption data, the score data and characteristics of library borrowing data when necessary to identify poor students to determine student category after prediction by the neural network model so as to improve accuracy and sufficient depth of a hidden layer.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for identifying poor students based on deep learning. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B2; T01-N01A2; T01-N01B3
IP G06K-009/62; G06N-003/08; G06Q-050/20
PD CN108960273-A   07 Dec 2018   G06K-009/62   201908   Pages: 10   Chinese
AD CN108960273-A    CN10415338    03 May 2018
PI CN10415338    03 May 2018
UT DIIDW:2018A0241F
ER

PT P
PN CN108960412-A
TI Image recognition method, involves identifying depth characteristics of identified images in depth characteristic base, and matching depth characteristic library in depth characteristic image class as image category of identified images.
AU ZUO X
   LIU X
   LEE W
AE BEIJING JINGDONG SHANGKE INFORMATION TEC (JDOF-C)
   BEIJING JINGDONG CENTURY TRADING CO LTD (JDOF-C)
GA 2018A02384
AB    NOVELTY - The method involves extracting depth characteristics of identified images by using a depth learning neural network. The depth characteristics of identified images is identified in a depth characteristic base. A depth characteristic library is matched in a depth characteristic image class as image category of the identified images. Neural network layer number is obtained for about less than first and second threshold values. Low- depth characteristics of the identified image are extracted. High depth characteristics of the identified image are extracted. Lower depth characteristic is cascaded with the high depth characteristics.
   USE - Image recognition method.
   ADVANTAGE - The method enables extracting the depth characteristic of the identified images, training a depth learning neural network under classification condition, and efficiently and accurately determining image category of the identified image.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) an image recognition apparatus
   (2) a computer readable storage medium for storing set of instructions for recognizing an image.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an image recognizing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2A; T01-J10B2A; T01-N01B3; T04-D03; T04-D04
IP G06N-003/04; G06K-009/46; G06K-009/62
PD CN108960412-A   07 Dec 2018   G06N-003/04   201908   Pages: 14   Chinese
AD CN108960412-A    CN10692204    29 Jun 2018
PI CN10692204    29 Jun 2018
UT DIIDW:2018A02384
ER

PT P
PN CN108932521-A
TI Deep learning based crop classification method, involves obtaining growth characteristic map according to multi-characteristic data sequence, and obtaining classification result of crops according to classification result of pixels.
AU HUANG J
   ZHU D
   LIU D
   YANG N
   XIONG Q
   LIU W
   ZHUO W
   LIU Z
   ZHANG X
AE UNIV CHINA AGRIC (UCAG-C)
GA 201899430E
AB    NOVELTY - The method involves obtaining a multi-phase multi-characteristic data set of a sub-work area corresponding to the sub-work area according to an evaluation index of remote sensing data (S1). A growth characteristic map is obtained (S2) according to a multi-phase multi-characteristic data sequence, where the multi-phase multi-characteristic data sequence is obtained according to the multi-phase multi-characteristic data set. A classification result of crops in a to-be-classified work area is obtained (S3) according to a classification result of pixels.
   USE - Deep learning based crop classification method.
   ADVANTAGE - The method enables improving crop classifying precision.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based crop classification system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based crop classification method. '(Drawing includes non-English language text)'
   Step for obtaining multi-phase multi-characteristic data set of sub-work area (S1)
   Step for obtaining growth characteristic map according to multi-phase multi-characteristic data sequence (S2)
   Step for obtaining classification result of crops in to-be-classified work area (S3)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W04 (Audio/Video Recording and Systems)
MC T01-J05A2A; T01-J05B2; T01-J10B2; T01-J30A; T04-D04; W04-W05A
IP G06K-009/62; G06Q-010/06; G06Q-050/02
PD CN108932521-A   04 Dec 2018   G06K-009/62   201908   Pages: 12   Chinese
AD CN108932521-A    CN10387307    26 Apr 2018
PI CN10387307    26 Apr 2018
UT DIIDW:201899430E
ER

PT P
PN CN108918536-A
TI Tire mold surface character defect detecting method, involves judging whether font defect exists in single character of mold character and single character of CAD character by using enhanced Siamese similarity network.
AU CAI N
   DING P
   LI J
   FANG H
   CHEN X
   WANG H
AE UNIV GUANGDONG TECHNOLOGY (UGTE-C)
GA 201898257J
AB    NOVELTY - The method involves detecting a mold character region of a to-be-tested tire mold picture and a CAD character region of a CAD drawing. Mold character of the mold character region is matched with the CAD character of the CAD character region. The to-be-tested tire mold picture is located in a corresponding position of the CAD drawing according to a matching result. Judgment is made to check whether the mold character and the CAD character are misprinted based on a positioning result. Judgment is made to check whether font defect exists in a single character of the mold character and a single character of the CAD character by using an enhanced Siamese similarity network.
   USE - Tire mold surface character defect detecting method.
   ADVANTAGE - The method enables realizing accurate tire mold picture positioning process so as to realize defect judgment process between different mode pictures based on deep learning process, thus improving robustness of large amount of data and complex background noise interference and tire mold surface defect detecting accuracy and realizing real-time performance of a tire mold surface.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a tire mold surface character defect detecting device
   (2) a computer-readable storage medium for storing a set of instructions to detect tire mold surface character defect.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a tire mold surface character defect detecting method. '(Drawing includes non-English language text)'
DC A89 (Photographic, laboratory equipment, optical - including electrophotographic, thermographic uses.); S03 (Scientific Instrumentation); T01 (Digital Computers)
MC A09-D01; A11-B17; A12-T01A; S03-E04F; T01-J15X; T01-S03
IP G01N-021/88
PD CN108918536-A   30 Nov 2018   G01N-021/88   201908   Pages: 22   Chinese
AD CN108918536-A    CN10769419    13 Jul 2018
PI CN10769419    13 Jul 2018
UT DIIDW:201898257J
ER

PT P
PN CN108921003-A
TI Unmanned aerial vehicle obstacle detecting method, involves performing obtained image morphological process, utilizing convolution neural network to obtain assumption of target area generating and outputting image processing result.
AU LV S
   ZHOU W
   LI L
   YOU Y
AE UNIV DONGHUA (UYDG-C)
GA 201898196X
AB    NOVELTY - The method involves collecting image information by an unmanned aerial vehicle. Collected image information is pre-processed. A pre-processed image is obtained from a hypothesis generation target area. Obtained image morphological process is performed. A convolution neural network is utilized to obtain assumption of target area generating. An image processing result is outputted. Image pre-processing process is provided with gray processing and filter de-noising process. Three components of RGB image information are obtained to obtain a weighted average value.
   USE - Convolutional neural network and image morphology based unmanned aerial vehicle obstacle detecting method.
   ADVANTAGE - The method enables effectively improving real-time obstacle detection performance and accuracy, effectively avoiding limitation of manual characteristic extraction and locating position of the unmanned aerial vehicle with simple characteristic from a collected image so as to improve real-time obstacle detecting performance.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an unmanned aerial vehicle obstacle detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B2; T01-J07D1; T01-J10B1; T01-J10B2; T04-D03; T04-D08
IP G06K-009/00; G06N-003/04; G06N-003/08
PD CN108921003-A   30 Nov 2018   G06K-009/00   201908   Pages: 9   Chinese
AD CN108921003-A    CN10387696    26 Apr 2018
PI CN10387696    26 Apr 2018
UT DIIDW:201898196X
ER

PT P
PN CN108898571-A
TI Structured light vision and deep learning based V-shaped weld inspecting method, involves adjusting V-shaped weld image to uniform size to input into deep learning pre-training model, and importing deep learning model into computer vision.
AU LI D
   SONG H
AE UNIV HARBIN SCI & TECHNOLOGY (UYHS-C)
GA 201897029D
AB    NOVELTY - The method involves establishing a structured light vision model, where the structured light vision model includes a CCD camera, a linear laser emitter and an optical filter. A V-shaped weld image is collected by an image collector to saves to a memory. Image preprocessing is performed on the collected V-weld image. Characteristic extraction of the pre-processed V-weld image is performed. The V-shaped weld image is adjusted to a uniform size to input into a deep learning pre-training model after performing characteristic extraction. The trained deep learning model is imported into an Open source computer vision (OpenCV).
   USE - Structured light vision and deep learning based V-shaped weld inspecting method.
   ADVANTAGE - The method enables improving accuracy and efficiency of V-shaped welding line detection in an effective manner.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a structured light vision and deep learning based V-shaped weld inspecting method. '(Drawing includes non-English language text)'
DC S03 (Scientific Instrumentation); T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC S03-E04X; T01-J07B; T01-J10B1; T01-J10B2; T01-J30A; W04-M01B; W04-M01C; W04-W05A
IP G01D-021/00; G06T-007/00; G06T-007/13; G06T-007/136
PD CN108898571-A   27 Nov 2018   G06T-007/00   201908   Pages: 6   Chinese
AD CN108898571-A    CN10257159    27 Mar 2018
PI CN10257159    27 Mar 2018
UT DIIDW:201897029D
ER

PT P
PN AU2018101513-A4
TI Enhanced recurrent neural network gated recurrent unit model for predicting stock tendency forecasts stock tendency based on commentary polarity, Baidu search frequency index, East money commentary popularity, and past stock volatility.
AU HUI B
   LIN J
   ZHANG D
   XIE Z
   ZHUANG Y
   YU Z
AE HUI B (HUIB-Individual)
   LIN J (LINJ-Individual)
   ZHANG D (ZHAN-Individual)
   XIE Z (XIEZ-Individual)
   ZHUANG Y (ZHUA-Individual)
   YU Z (YUZZ-Individual)
GA 201909992N
AB    NOVELTY - The model forecasts stock tendency based on four inputs, namely, commentary polarity (symbolizing pessimistic or optimistic), Baidu search frequency index (frequency of stock been searched), East money commentary popularity (amount of comments on stock), and past stock volatility (stock trends). The model processes substantial amount of commentary crawled from two major websites, namely East money and Baidu, comprehending the polarity of comments and converts into values between 0 and 1 via text convolutional neural network (CNN) representing the polarity of text.
   USE - Enhanced recurrent neural network (RNN) gated recurrent unit (GRU) model for predicting stock tendency on daily basis.
   ADVANTAGE - The direction of popular opinion and stock popularity is employed and analyzed utilizing GRU model to provide a precise and thorough prediction of stock tendency. Improves predicting accuracy when making investments by adding in social economic features.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic diagram of the approximate prediction of stock tendency.
DC T01 (Digital Computers)
MC T01-J07B; T01-N01A1; T01-N03A2
IP G06Q-040/06; G06N-003/02
PD AU2018101513-A4   15 Nov 2018   G06Q-040/06   201908   Pages: 20   English
AD AU2018101513-A4    AU101513    11 Oct 2018
PI AU101513    11 Oct 2018
UT DIIDW:201909992N
ER

PT P
PN AU2018101528-A4
TI Method for facilitating camouflage image encryption, involves providing chance to show anime face of real person by putting person's picture into model, generating infinite anime faces, and transferring human face into anime face.
AU LI J
   LIAO R
   ZHANG Q
   TANG D
   XIA Z
   WANG J
AE LI J (LIJJ-Individual)
   LIAO R (LIAO-Individual)
   ZHANG Q (ZHAN-Individual)
   TANG D (TANG-Individual)
   XIA Z (XIAZ-Individual)
   WANG J (WANG-Individual)
GA 201909992D
AB    NOVELTY - The method involves providing a chance to show an anime face of a real person by putting a person's picture into a model. Infinite anime faces are generated. A human face is transferred into the anime face.
   USE - Method for facilitating a camouflage image encryption based on a variational auto-encoder (VAE) and discriminator.
   ADVANTAGE - The method enables utilizing a camouflage process which increases information safety in efficient manner.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for facilitating a camouflage image encryption based on a VAE and discriminator.
DC T01 (Digital Computers)
MC T01-D01; T01-J10
IP G06T-001/00
PD AU2018101528-A4   15 Nov 2018   G06T-001/00   201908   Pages: 16   English
AD AU2018101528-A4    AU101528    14 Oct 2018
PI AU101528    14 Oct 2018
UT DIIDW:201909992D
ER

PT P
PN AU2018101512-A4
TI Method for predicting comprehensive stock trend, involves forecasting whether investing stock will make profits in next five days.
AU WANG R
   PENG X
   PEI Y
   DONG X
   YUAN Y
   SHI Y
AE WANG R (WANG-Individual)
   PENG X (PENG-Individual)
   PEI Y (PEIY-Individual)
   DONG X (DONG-Individual)
   YUAN Y (YUAN-Individual)
   SHI Y (SHIY-Individual)
GA 201909992P
AB    NOVELTY - The method involves forecasting whether investing a stock will make profits in the next five days which is the stock prediction with not only stock-related factors, but also social economic features based on long short-term memory (LSTM), gated recurrent unit (GRU) and convolutional neural network (CNN) which belong to artificial neural network (ANN) as main algorithm.
   USE - Method for predicting comprehensive stock trend.
   ADVANTAGE - The method provide investors with a useful reference on stock trend prediction, thus investors will be more confident about their choices. The method adding in social economic features improves the predicting accuracy when making investments.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of the process for predicting comprehensive stock trend.
DC T01 (Digital Computers)
MC T01-J07B; T01-N01A1
IP G06Q-040/06; G06N-003/02
PD AU2018101512-A4   15 Nov 2018   G06Q-040/06   201908   Pages: 15   English
AD AU2018101512-A4    AU101512    11 Oct 2018
PI AU101512    11 Oct 2018
UT DIIDW:201909992P
ER

PT P
PN AU2018101529-A4
TI Device for evaluating living conditions of house scientifically and objectively provides tenants dwelling-evaluation service covering residential-environmental , traveling-convenience, living-convenience and living-safety indicators.
AU YAO X
   WANG J
   HUANG Y
   BAO T
   LIU J
   WANG D
AE YAO X (YAOX-Individual)
   WANG J (WANG-Individual)
   HUANG Y (HUAN-Individual)
   BAO T (BAOT-Individual)
   LIU J (LIUJ-Individual)
   WANG D (WANG-Individual)
GA 201909992C
AB    NOVELTY - The device uses band reflectance of recent remote sensing images to calculate the water area, green area and dump area respectively around the house based on normalized difference vegetation index (NDVI) algorithms and deep learning methods. The device carries environmental assessments surround a house reliably to supersede the subjective description in the current housing-evaluation products. The device provides tenants a dwelling-evaluation service covering four indicators. The four indicators include residential-environmental indicator, traveling-convenience indicator, living-convenience indicator and living-safety indicator that are calculated based on nine types of big data or remote sensing images.
   USE - Device for evaluating living conditions of house scientifically and objectively.
   ADVANTAGE - Provides accurate, immediate, and comprehensive information of the houses to help tenants to better choose their satisfactory houses by collecting data from nine kinds of sources and figures out four indicators to evaluate the house conditions. The device evaluates the living conditions in micro-level and improves the accuracy and efficiency of the current housing-evaluation products.
   DESCRIPTION OF DRAWING(S) - The drawings show the schematic diagram of the sources of data and four indicators to evaluate the living conditions of a house and flow diagram of the data processing of four indicators.
DC Q43 (General building constructions (E04B)); T01 (Digital Computers)
MC T01-J05A2A; T01-J30A
IP G06Q-050/16; E04B-001/00; G06F-019/00; G06N-099/00
PD AU2018101529-A4   15 Nov 2018   G06Q-050/16   201908   Pages: 27   English
AD AU2018101529-A4    AU101529    14 Oct 2018
PI AU101529    14 Oct 2018
UT DIIDW:201909992C
ER

PT P
PN AU2018101525-A4
TI Complete content based image retrieval (CBIR) system for fine-grained objects, has convolutional neural networks which make system first go through dataset adjustment and dataset enlargement.
AU ZHANG Y
   GUO Y
   YANG Z
   NIE H
   CHEN L
   QIN Z
AE ZHANG Y (ZHAN-Individual)
   GUO Y (GUOY-Individual)
   YANG Z (YANG-Individual)
   NIE H (NIEH-Individual)
   CHEN L (CHEN-Individual)
   QIN Z (QINZ-Individual)
GA 201909992F
AB    NOVELTY - The system is developed based on a convolutional neural networks model named ResNet-50. The convolutional neural networks make the system first go through dataset adjustment and dataset enlargement. ResNet-50 is capable of extracting abstract features about category information not low-level visual features to some extent in semantic level, and capable of retrieval for fine-grained products. The principle component analysis (PCA) algorithm is applied to reduce dimension such that the difference between images is calculated using cosine similarity.
   USE - Complete content based image retrieval (CBIR) system for fine-grained objects.
   ADVANTAGE - The system is efficient, accurate, and capable of extracting semantic-level features. The efficiency of calculation is improved. The whole model is built to extract high dimensional features of class information of images and to greatly reduce the dimensionality by PCA with barely accuracy loss. The problem of the gradient disappearance and the inefficiency is avoided. The dimension of our features from 1024 to 200 can be reduced thus the time needed for calculation is reduced.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram of the complete CBIR system.
DC T01 (Digital Computers)
MC T01-J05B4P; T01-J10B2; T01-J16C3; T01-N01D1B; T01-N01D2
IP G06F-017/30; G06K-009/00
PD AU2018101525-A4   15 Nov 2018   G06F-017/30   201908   Pages: 27   English
AD AU2018101525-A4    AU101525    14 Oct 2018
PI AU101525    14 Oct 2018
UT DIIDW:201909992F
ER

PT P
PN RU2667879-C1; US2018350066-A1
TI Processing and analysis of data on computer-assisted tomography images.
AU ZUEV K A
   MATYUSHIN A V
   LOBASTOV S YU
   ZUYEV K
   MATYUSHIN A
   LOBASTOV S
AE ABI PROD CO LTD (ABIA-Non-standard)
   ABBYY DEV LLC (ABBY-Non-standard)
GA 201886222G
AB    NOVELTY - Group of inventions relates to medicine, namely, systems and methods for image processing and data analysis in computer-assisted tomography, and can be used to process image data of medical imaging. Said system comprises a non-volatile computer-readable storage medium containing executable instructions for implementing the method for processing image data of medical imaging, wherein the system contains: memory; processor associated with said memory. Plurality of initial images of medical imaging of the body under examination are obtained. Then, said plurality of initial images is processed by the first convolutional neural network to obtain one or more pseudo radioisotopic emission (pseudo-RE) images of the body under examination. Using the second convolutional neural network, one or more pseudo-RE images are processed, where each of one or more pseudo-RE images illustrates a simulated distribution of the radioactive marker in one or more target organs in the body under examination, including determination of the probability of the presence in one or more of the original images from the plurality of source images diagnostically significant image attributes, associated with a specific medical diagnosis related to the body under examination. After that, the second convolutional neural network is used to classify one or more of said original images from the plurality of source images with respect to a predetermined medical diagnosis for the body under examination.
   USE - Medicine.
   ADVANTAGE - Group of inventions provides higher accuracy of medical diagnosis.
25 cl, 8 dwg
DC P31 (Diagnosis, surgery (A61B).); S03 (Scientific Instrumentation); S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S03-E06B3A; S05-D02A1; S05-D02A5; T01-J10B2; T01-J16B; T01-J16C1; T01-N01D1B; T01-N01E
IP A61B-008/13; G06T-001/40; G06T-007/00; G06T-007/11; G06T-011/60
PD RU2667879-C1   24 Sep 2018   A61B-008/13   201908   Pages: 0   Russian
   US2018350066-A1   06 Dec 2018   G06T-007/00   201908      English
AD RU2667879-C1    RU118740    30 May 2017
   US2018350066-A1    US623853    15 Jun 2017
PI RU118740    30 May 2017
UT DIIDW:201886222G
ER

PT P
PN CN108959841-A
TI DBN-algorithm based drug target protein interaction predicting method, involves performing network parameter fine tuning process by adopting rear propagation algorithm, and obtaining test data for prediction.
AU GU W
   MAO Y
   TIAN X
   LI J
AE UNIV SOUTH CHINA AGRIC (USCG-C)
GA 2018A02517
AB    NOVELTY - The method involves obtaining medicine fingerprint characteristic and protein amino acid sequence. Depth confidence parameters of a layer network are obtained from a restricted Boltzmann machine for pre-training. Network parameter fine tuning process is performed by adopting rear propagation algorithm. Test data for prediction is obtained. A drug-protein characteristic vector in a binary sequence is determined. RBM parameter is initialized. A weight value matrix is initialized. Gibbs sampling process is performed. The RBM parameter is updated. An open state of a hidden element is detected. Decoded data is obtained.
   USE - DBN-algorithm based drug target protein interaction predicting method.
   ADVANTAGE - The method enables reducing absence of manual intervention and medicine research experiment cost, and accelerating pharmaceutical function.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a DBN-algorithm based drug target protein interaction predicting method. '(Drawing includes non-English language text)'
DC B04 (Natural products and polymers. Including testing of body fluids (other than blood typing or cell counting), pharmaceuticals or veterinary compounds of unknown structure, testing of microorganisms for pathogenicity, testing of chemicals for mutagenicity or human toxicity and fermentative production of DNA or RNA. General compositions.); D16 (Fermentation industry - including fermentation equipment, brewing, yeast production, production of pharmaceuticals and other chemicals by fermentation, microbiology, production of vaccines and antibodies, cell and tissue culture and genetic engineering.); T01 (Digital Computers)
MC B04-N04; B11-C08; B11-C11; B12-K04E3; D05-H09; T01-N02B1B
IP G06F-019/00; G06F-019/18; G06F-019/24; G06N-003/04; G06N-003/08
PD CN108959841-A   07 Dec 2018   G06F-019/00   201907   Pages: 10   Chinese
AD CN108959841-A    CN10336860    16 Apr 2018
PI CN10336860    16 Apr 2018
UT DIIDW:2018A02517
ER

PT P
PN CN108958217-A
TI Method for detecting CAN bus message anomaly based on deep learning, involves optimizing parameters of belief network model by using tuning set, and testing belief network model by using test set to improve reliability of network.
AU HU H
   YANG X
   ZHAO S
AE UNIV CHANGCHUN TECHNOLOGY (UYGL-C)
GA 2018A0289T
AB    NOVELTY - The method involves performing model analysis function to analyze communication process of a CAN bus network model. A deep learning network is established according to an abnormal detection network. A message in a CAN bus is processed by using abnormal detecting process. The message in the CAN bus is divided into a training set, a tuning set and a test set. Parameters of a belief network model are initialized by using the training set. The parameters of the belief network model are optimized by using the tuning set. The belief network model is tested by using the test set to improve reliability of the network.
   USE - Method for detecting a CAN bus message anomaly based on deep learning for vehicle CAN network communication system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for detecting a CAN bus message anomaly based on deep learning for vehicle CAN network communication system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T06 (Process and Machine Control)
MC T01-J07D1; T01-N01B3A; T06-A07B; T06-A08
IP G05B-023/02; G06N-003/04; G06N-003/08
PD CN108958217-A   07 Dec 2018   G05B-023/02   201907   Pages: 14   Chinese
AD CN108958217-A    CN10641586    20 Jun 2018
PI CN10641586    20 Jun 2018
UT DIIDW:2018A0289T
ER

PT P
PN CN108959252-A
TI Deep learning based semi-supervised Chinese-named entity recognition method, involves automatically constructing trusted sample, determining minimized reserved continuous sub-sentence, and generating training data of recognition model.
AU LI D
   LI Z
   FENG D
AE UNIV PLA NAT DEFENCE TECHNOLOGY (UNDT-C)
GA 2018A02655
AB    NOVELTY - The method involves constructing a character Chinese-named entity recognition model based on deep learning. A text corpus word vector is determined. Labeled data is obtained by using a learning and scoring device. A classification machine learning model is established. A prediction confidence value tag of words is determined. Judgment is made to check whether a trusted label is selected as a noise label. A trusted sample is automatically constructed. A minimized reserved continuous sub-sentence is determined. Training data of the recognition model is generated.
   USE - Deep learning based semi-supervised Chinese-named entity recognition method.
   ADVANTAGE - The method enables realizing semi-supervised Chinese-named entity recognition and improving accuracy and recall rate of Chinese-named entity recognition.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based semi-supervised Chinese-named entity recognition method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J05B2; T01-J05B4P; T01-J11A1; T01-J30A; W04-W05A
IP G06F-017/27; G06F-017/30; G06N-099/00
PD CN108959252-A   07 Dec 2018   G06F-017/27   201907   Pages: 12   Chinese
AD CN108959252-A    CN10686249    28 Jun 2018
PI CN10686249    28 Jun 2018
UT DIIDW:2018A02655
ER

PT P
PN CN108938396-A
TI Device for recognizing ear acupoint, has acquisition module for collecting ear data, identification module, and deep learning network model built in for identifying acupuncture points of ear.
AU PAN J
   LIN J
   CHEN Z
   LI T
   XIA M
   CHEN J
AE JUDA TECHNOLOGY CO LTD (JUDA-Non-standard)
GA 2018A07478
AB    NOVELTY - The ear acupoint recognition device has an acquisition module for collecting ear data, an identification module, and a deep learning network model built in for identifying acupuncture points of an ear. An input module is internally builds an input layer of the deep learning network model, and performs data processing on the ear data collected by the collection module to obtain a coordinateized ear structure. A hidden layer module internally builds a hidden layer of a deep learning network model for identifying an acupuncture point position according to a coordinated ear structure. A visualization module internally builds a visualization layer of the deep learning network model for outputting the coordinates of the ear structure and the acupuncture point position in a visually encoded form.
   USE - Device for recognizing ear acupoint.
   ADVANTAGE - The position map of the acupoints in the quasi-ears, deep learning establishes and trains a reliable deep learning network model, which greatly improves the efficiency of acupoint recognition, and the acupoint recognition and positioning is more accurate and easy to promote.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for depth learning-based acupuncture point recognition method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of the deep learning network model of device. (Drawing includes non-English language text)
DC P33 (Medical aids, oral administration (A61G, H, J).); S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S05-A05D; T01-J10C5; T01-N01B3; T01-N01E
IP A61H-039/02; G06T-011/60; G06T-019/20
PD CN108938396-A   07 Dec 2018   A61H-039/02   201907   Pages: 10   Chinese
AD CN108938396-A    CN10880679    26 Sep 2017
PI CN10880679    26 Sep 2017
UT DIIDW:2018A07478
ER

PT P
PN CN108960023-A
TI Emotion identification device, has server provided with database unit to store data processed by data processing unit, and emotion discriminating module for identifying user emotion according to data processed by data processing unit.
AU PAN J
   LIN J
   CHEN Z
   LI T
   XIA M
   CHEN J
AE JUDA TECHNOLOGY CO LTD (JUDA-Non-standard)
GA 2018A02477
AB    NOVELTY - The device has an image collecting device for collecting facial images. A data processing unit i.e. CPU, receives a facial image collected by the image collecting device to process. A prompting unit prompts emotional results. A server is provided with a database unit to store data processed by the data processing unit. An emotion discriminating module identifies user emotion according to the data processed by the data processing unit. The data processing unit is provided with an image pre-processing unit and data analysis unit. The image collecting device and the data processing unit are connected with a communication module.
   USE - Emotion identification device.
   ADVANTAGE - The device can realize emotion identification process by using deep learning and training model so as to increase integrity and reliability of emotion identification process and emotional identification result accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of an emotion identification device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B4F; T01-J10B2; T01-N02A3C
IP G06K-009/00; G06K-009/62
PD CN108960023-A   07 Dec 2018   G06K-009/00   201907   Pages: 9   Chinese
AD CN108960023-A    CN10844889    19 Sep 2017
PI CN10844889    19 Sep 2017
UT DIIDW:2018A02477
ER

PT P
PN CN108960015-A
TI Automatic car image identifying method, involves obtaining target area image by using target area image input recognition model, and performing Residual Networks series identification process to output identification result.
AU PANG M
   LIANG D
   MAO Y
   LI W
AE YOUXINPAI BEIJING INFORMATION TECHNOLOGY (YOUX-Non-standard)
GA 2018A0247A
AB    NOVELTY - The method involves training a Single Shot multi-box Detector (SSD) target vehicle detection model by using a target vehicle detection training sample. A Residual Networks (ResNet) series identification model is trained by using a recognition training sample. A vehicle image is inputted to the SSD target vehicle detection model. A target rectangular frame is obtained. A maximum area of the target rectangular frame is intercepted with the vehicle image. A target area image is obtained by using a target area image input recognition model. ResNet series identification process is performed to output identification result. A target vehicle area is marked to obtain a label frame. The label frame is loaded in a SSD network. A characteristic pattern with a default frame is generated. The default frame is matched with the label frame.
   USE - Deep learning based automatic car image identifying method.
   ADVANTAGE - The method enables obtaining a position of a target vehicle by using the (SSD) target vehicle detection model so as to intercept a vehicle image with a target area image, and realizing simple model training, and improving recognition precision and identification efficiency.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based automatic car image identifying device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an automatic car image identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W04 (Audio/Video Recording and Systems)
MC T01-J07D1; T01-J10B2A; T01-N01B3; T04-D04; W04-W05A
IP G06K-009/00; G06K-009/62
PD CN108960015-A   07 Dec 2018   G06K-009/00   201907   Pages: 13   Chinese
AD CN108960015-A    CN10374166    24 May 2017
PI CN10374166    24 May 2017
UT DIIDW:2018A0247A
ER

PT P
PN CN108942921-A
TI Scattered grabbing device based on deep learning object recognition, has computer three dimensional (3D) camera which is connected with 3D positioning software, where 3D positioning software is connected to controller.
AU PEI L
AE JIANGSU TURBOMAN ROBOT TECHNOLOGY CO LTD (JIAN-Non-standard)
GA 2018A06428
AB    NOVELTY - The scattered grabbing device has a robot (1), a three dimensional (3D) camera (2), a computer (3). The computer includes a controller (3-1) and 3D positioning software (3-2), the 3D camera is connected with the 3D positioning software, and the 3D positioning software Connected to the controller, the controller is connected to the robot. The robot is a six-degree-of-freedom robot. The 3D camera obtains point cloud information of the portion to be grabbed, and calculates the matching degree between the point cloud and a computer aided design (CAD) model by a high-precision matching algorithm in the 3D positioning software.
   USE - Scattered grabbing device based on deep learning object recognition.
   ADVANTAGE - The discriminating and locating of the objects with different shapes and different orientations by the scattered grab robot are realized, and the optimal judgment of the robot's grasping posture is realized.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of the device. (Drawing includes non-English language text)
   Robot (1)
   Three dimensional camera (2)
   Computer (3)
   Controller (3-1)
   Three dimensional positioning software (3-2)
DC P62 (Hand tools, cutting (B25, B26).); T01 (Digital Computers); T06 (Process and Machine Control); X25 (Industrial Electric Equipment)
MC T01-J07B; T01-J10B2A; T01-J15X; T01-J30A; T06-A04A4; T06-D07B; X25-A03E
IP B25J-009/16; G06T-007/514; G06T-007/73
PD CN108942921-A   07 Dec 2018   B25J-009/16   201907   Pages: 6   Chinese
AD CN108942921-A    CN10593860    11 Jun 2018
PI CN10593860    11 Jun 2018
UT DIIDW:2018A06428
ER

PT P
PN CN108959728-A
TI Deep learning based radio frequency device parameter optimization method, involves obtaining original data, obtaining parameter optimization target value, and completing cycle selection until determining allowable error.
AU WANG G
   GUAN Z
   ZHANG Z
   ZHAO P
AE HANGZHOU FADONG TECHNOLOGY CO LTD (HANG-Non-standard)
GA 2018A02545
AB    NOVELTY - The method involves obtaining original data. The original data is pre-processed to obtain a geometric parameter. A pre-processed signal is sent to a radio frequency device. A known electromagnetic parameter is input to the radio frequency device. Normalization process is performed. Training set and testing set segmentation is performed corresponding to the geometric parameter. A trained multi-layer neural network model is established. Signal frequency is determined. A parameter optimization target value is obtained. Cycle selection is completed until determining allowable error.
   USE - Deep learning based radio frequency device parameter optimization method.
   ADVANTAGE - The method enables continuously selecting cross and variation until selecting a best optimization result.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning based radio frequency device parameter optimization method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J15X; T01-N01B3A
IP G06F-017/50; G06N-003/04; G06N-003/08
PD CN108959728-A   07 Dec 2018   G06F-017/50   201907   Pages: 11   Chinese
AD CN108959728-A    CN10602897    12 Jun 2018
PI CN10602897    12 Jun 2018
UT DIIDW:2018A02545
ER

PT P
PN CN108959482-A
TI Method for classifying single-wheel dialog data of electronic device based on deep learning, involves establishing single-wheel dialog data regression model for classifying sentence vector expression to obtain probability of tags.
AU YANG P
AE BEIJING HUIWEN TECHNOLOGY DEV CO LTD (BEIJ-Non-standard)
GA 2018A02601
AB    NOVELTY - The method involves obtaining single-wheel dialog data to determine word vector of the single-wheel dialog data. The word vector of the single wheel session data is processed by a two-way long term memory layer to obtain session data based on single wheel hidden state sequence. A weighted summation process is performed for detecting hidden state in hidden state sequence to an attention mechanism layer. A sentence vector expression obtaining process is performed corresponding to the single-wheel dialog data. A single-wheel dialog data regression model is established for classifying sentence vector expression to obtain probability distribution of tags.
   USE - Method for classifying single-wheel dialog data of an electronic device (claimed) based on deep learning.
   ADVANTAGE - The method enables extracting user characteristic in the single-wheel dialog data by a bidirectional long term memory and attention mechanism to improve classification effect of dialog scene.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for classifying single-wheel dialog data of electronic device based on deep learning
   (2) a computer-readable storage medium for storing set of instruction to execute single-wheel dialog data classifying process.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for classifying single-wheel dialog data of electronic device based on deep learning. '(Drawing includes non-English language text)'
DC B04 (Natural products and polymers. Including testing of body fluids (other than blood typing or cell counting), pharmaceuticals or veterinary compounds of unknown structure, testing of microorganisms for pathogenicity, testing of chemicals for mutagenicity or human toxicity and fermentative production of DNA or RNA. General compositions.); D16 (Fermentation industry - including fermentation equipment, brewing, yeast production, production of pharmaceuticals and other chemicals by fermentation, microbiology, production of vaccines and antibodies, cell and tissue culture and genetic engineering.); T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC B11-C08; B11-C11; B12-K04; D05-H09; T01-J05B2; T01-J05B4P; T01-J30A; T01-S03; W04-W05A
IP G06F-017/30
PD CN108959482-A   07 Dec 2018   G06F-017/30   201907   Pages: 20   Chinese
AD CN108959482-A    CN10644408    21 Jun 2018
PI CN10644408    21 Jun 2018
UT DIIDW:2018A02601
ER

PT P
PN CN108937912-A
TI Automatic arrhythmia analysis method based on deep neural network, involves learning parameters of deep neural network and automatically identifying sample.
AU ZANG M
   WEI Y
   LIU T
   ZOU H
   LIU C
   ZHOU S
   JIA S
AE UNIV LUDONG (UNLD-C)
GA 2018A07586
AB    NOVELTY - The method involves using the three sampling methods for composite sampling to generate multi-channel ECG samples. The 100 points are taken before and after re-sampling to a fixed dimension 600. The 2 cycles of R-R wave interval are taken and then 1 cycle of RR wave interval is taken and resampled to a fixed dimension 600. The signals are spliced before and after resampling, forming a 600-dimensional signal. The 600-dimensional ECG signals obtained are spliced along the second dimension. A deep neural network is built. The one-dimensional convolution is used for extracting features of a one-dimensional electrocardiographic signal. The ECG signals X of the respective channels are combined as input signals into the convolutional layer units connected in series. The output of the LSTM layer unit is connected in series with a fully connected layer of softmax. The parameters of the deep neural network are learnt. The sample is automatically identified.
   USE - Automatic arrhythmia analysis method based on deep neural network.
   ADVANTAGE - The method can meet the accuracy requirements of clinical application.
   DESCRIPTION OF DRAWING(S) - The drawing shows a method for an automatic arrhythmia analysis method. (Drawing includes non-English language text)
DC P31 (Diagnosis, surgery (A61B).); S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S05-D01A1; S05-D01B5; T01-J04B2; T01-N01B3; T01-N01E
IP A61B-005/0402; A61B-005/024
PD CN108937912-A   07 Dec 2018   A61B-005/0402   201907   Pages: 9   Chinese
AD CN108937912-A    CN10451728    12 May 2018
PI CN10451728    12 May 2018
UT DIIDW:2018A07586
ER

PT P
PN CN108944940-A
TI Neural network-based driver behavior modeling method, involves determining weights of convolutional neural network after training to establish latest convolutional neural network to complete state feature extractor.
AU ZOU Q
   LI H
   PEI B
AE UNIV DALIAN (UYDV-C)
GA 2018A0597C
AB    NOVELTY - The method involves constructing a driving environment feature extractor for extracting features of reward function. Driving video is sampled by a camera placed in a windscreen of a vehicle to obtain a picture of road conditions at different driving environments. A convolutional neural network is optimized by using Nadam optimizer-based optimization process to obtain optimal solution of mean square error loss. Weights of the convolutional neural network is determined after training to establish a latest convolutional neural network to complete state feature extractor.
   USE - Neural network-based driver behavior modeling method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a neural network-based driver behavior modeling method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J07D1; T01-N01B3
IP B60W-040/09; G06N-003/04
PD CN108944940-A   07 Dec 2018   B60W-040/09   201907   Pages: 14   Chinese
AD CN108944940-A    CN10662026    25 Jun 2018
PI CN10662026    25 Jun 2018
UT DIIDW:2018A0597C
ER

PT P
PN CN108898085-A
TI Method for intelligent detection of road diseases based on mobile phone video, involves obtaining pixel coordinates of road disease boundary, and calculating size, area, and actual position of road disease.
AU WU Y
   YANG H
   ZHU X
AE UNIV ANHUI (UANH-C)
GA 2018970410
AB    NOVELTY - The method involves collecting various road disease images, and making different types of road disease training sample sets. A convolutional neural network is constructed for road disease image recognition. The training set is introduced for training, so that effective feature layers are transmitted. The global positioning system (GPS) position information of the video is collected at different times. The video is segmented into images of different time series. The time series images of different time periods are interpolated to obtain GPS positions of different images. The captured video image is substituted into trained model to identify different types of road diseases. The target of the known actual coordinates is used to calibrate the mobile phone with same posture as the video capture. The pixel coordinates of the road disease boundary are obtained, and the size, area, and actual position of the road disease are calculated.
   USE - Method for intelligent detection of road diseases based on mobile phone video.
   ADVANTAGE - The road disease information which is safer, more efficient, and lower in cost is obtained. The process is suitable for more types of road diseases and has high accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the process for intelligent detection of road diseases based on mobile phone video. (Drawing includes non-English language text)
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems); W04 (Audio/Video Recording and Systems)
MC T01-J10B2A; T01-J21; T01-N01B3; T01-N01D1B; W01-A06C4; W01-C01D3C; W01-C01G4; W04-F01
IP G06K-009/00; G06K-009/62; H04N-005/91; H04N-005/92; H04W-004/02
PD CN108898085-A   27 Nov 2018   G06K-009/00   201907   Pages: 7   Chinese
AD CN108898085-A    CN10637986    20 Jun 2018
PI CN10637986    20 Jun 2018
UT DIIDW:2018970410
ER

PT P
PN CN208255909-U
TI Embedded depth learning face recognition device, has NPU processing unit for preloading training model file data and pre-processing current image data, and image pre-processing result display unit for identifying NPU processing unit and.
AU HU L
   GUO G
   CHEN L
AE UNIV FUJIAN (UYFJ-C)
GA 2018A4412Q
AB    NOVELTY - The utility model claims an embedded depth based on learning face recognition device, comprising USB camera acquisition unit, an image storage unit, an ARM chip control unit, a PCIE data transmission unit, NPU processing unit and image result display unit; USB camera collecting unit respectively connecting image storage unit and an ARM chip control unit, image storing unit connected to the ARM chip control unit, an ARM chip control unit via the PCIE data transmission unit connected to NPU processing unit. connecting the image result of output NPU processing unit of the display unit. The utility model is combined with the NPU chip by ARM chip, which solves the problem that the current embedded face identification accuracy is low, cannot be real-time processing. the whole of the utility model has good stability, low cost and easy to deploy.
DC T01 (Digital Computers)
MC T01-C07C4A; T01-J05B2A; T01-J10B2A; T01-J30A
IP G06K-009/00
PD CN208255909-U   18 Dec 2018   G06K-009/00   201906   Pages: 6   Chinese
AD CN208255909-U    CN20973529    22 Jun 2018
PI CN20973529    22 Jun 2018
UT DIIDW:2018A4412Q
ER

PT P
PN KR2018134213-A
TI Method for separating sound source based on variable window size, involves separating sound source corresponding to characteristic from audio signal in consideration of characteristic of learning target signal.
AU LIM W T
AE ELECTRONICS & TELECOM RES INST (ETRI-C)
GA 2018A3833T
AB    NOVELTY - The method involves determining (S301) a window size by reflecting a characteristic of the audio signal. The learning target signal of the window size unit is set (S302). The learning is performed (S303) on the neural network structure by applying the learning target signal to a neural network structure and confirming characteristics of the learning target signal. The sound source corresponding to the characteristic is separated from the audio signal in consideration of the characteristic of the learning target signal.
   USE - Method for separating sound source based on variable window size.
   ADVANTAGE - The improved method accurately separates and detects a sound source signal upon detection of a sound source signal to which a deep learning technique is applied is provided.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of the configuration of the sound source separating device. (Drawing includes non-English language text)
   Step for determining the window size (S301)
   Step for setting the learning target signal of the window size unit (S302)
   Step for performing the learning (S303)
   Step for determining the characteristics of the learning target signal (S304)
   Step for separating the sound source (S305)
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-D02; T01-J07B; T01-J16B; T01-N01B3; W04-V01
IP G10L-015/16; G06N-003/02; G10L-015/22; G10L-019/12
PD KR2018134213-A   18 Dec 2018   G10L-015/16   201906   Pages: 11   
AD KR2018134213-A    KR071795    08 Jun 2017
PI KR071795    08 Jun 2017
UT DIIDW:2018A3833T
ER

PT P
PN CN108986797-A
TI Voice subject recognizing method, involves identifying to-be-identified voice, and inputting characteristic vector of different granularities into convolutional neural network and output theme of to-be-identified voice.
AU GUO W
   SUN J
AE UNIV CHINA SCI & TECHNOLOGY (UCST-C)
GA 2018A3345R
AB    NOVELTY - The method involves identifying a to-be-identified voice. Text of different granularity is obtained corresponding to the to-be-identified voice. Text of different granularity is converted into a characteristic vector. The characteristic vector of different granularities is input into a convolutional neural network and output a theme of the to-be-identified voice. Convolutional neural network model parameters are obtained. Pool layer feature of the trained convolutional neural network model are extracted. A semantic description vector is obtained. The semantic description vector is used as a feature vector of a hierarchical clustering algorithm.
   USE - Voice subject recognizing method.
   ADVANTAGE - The method enables obtaining robust characterization of topics by using complementary of different granularity units so as to improve accuracy of subject recognition.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a voice subject recognizing system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a voice subject recognizing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J05B3; T01-J16B; T01-J16C3; T01-N03A2; W04-V01; W04-V04A6
IP G10L-015/16; G10L-015/26
PD CN108986797-A   11 Dec 2018   G10L-015/16   201906   Pages: 16   Chinese
AD CN108986797-A    CN10884203    06 Aug 2018
PI CN10884203    06 Aug 2018
UT DIIDW:2018A3345R
ER

PT P
PN CN108983800-A
TI Deep learning based aircraft attitude controlling method, involves obtaining primary airplane attitude control amount by control network, determining airplane attitude inclined corner change rate, and determining airplane posture parameter.
AU LI B
   LIANG S
   LI X
   GAO X
   GAO P
AE UNIV NORTHWESTERN POLYTECHNICAL (UNWP-C)
GA 2018A20008
AB    NOVELTY - The method involves collecting state data of an aircraft in real time (S1). Normalization processing operation of the state data of the aircraft is performed. Primary airplane attitude control amount is obtained (S2) by a normalization process control network according to airplane attitude data input. Airplane attitude inclined corner change rate is determined. Secondary airplane attitude control quantity is obtained (S3). Airplane posture parameter is determined. Survival probability of a machine is determined. Determination is made to check whether target rate is greater than stable flying speed by a radar sensor system.
   USE - Deep learning based aircraft attitude controlling method.
   ADVANTAGE - The method enables utilizing an intelligent mode to build a network for obtaining inter-contact extraction data and improving aircraft attitude controlling accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based aircraft attitude controlling method. '(Drawing includes non-English language text)'
   Step for collecting state data of aircraft in real time (S1)
   Step for obtaining primary airplane attitude control amount by normalization process control network (S2)
   Step for obtaining secondary airplane attitude control quantity (S3)
DC T06 (Process and Machine Control); W06 (Aviation, Marine and Radar Systems)
MC T06-B01B; W06-A04; W06-B01A5; W06-B01B1; W06-B01B8
IP G05D-001/08
PD CN108983800-A   11 Dec 2018   G05D-001/08   201906   Pages: 12   Chinese
AD CN108983800-A    CN10846804    27 Jul 2018
PI CN10846804    27 Jul 2018
CP CN108983800-A
      CN102607639-A   UNIV NANJING AERONAUTICS&ASTRONAUTICS (UNUA)   GUO Y, LEI T, LI R, LI S, LIU J, LU C, MA H, ZENG Q
CR CN108983800-A
      : "SAR", ,relevantClaims[3-6],relevantPassages[15-32]
UT DIIDW:2018A20008
ER

PT P
PN CN108986493-A
TI Method for distributing transit time of traffic signal lamp by utilizing electronic device, involves calculating traffic light duration corresponding to degree of each lane, and updating control system according to traffic light duration.
AU WANG J
   ZHAO Z
   LI T
   XU Y
   CHEN R
AE BEIJING SEEMMO TECHNOLOGY CO LTD (BEIJ-Non-standard)
GA 2018A1938L
AB    NOVELTY - The method involves obtaining vehicle information according to current shot content of a monitoring device, where the monitoring device comprises a lane on a crossroad in each direction. Each lane waiting time for a target number is counted according to transit time distribution algorithm. Congestion degree of each lane is calculated. Traffic light duration is calculated corresponding to the congestion degree of each lane. A traffic control system is updated according to the traffic light duration. Respective lanes of a target are detected according to depth learning and target detection algorithm.
   USE - Method for distributing transit time of a traffic signal lamp by utilizing an electronic device (claimed).
   ADVANTAGE - The method enables combining a video structuring scheme of artificial intelligent technology and computer vision for dynamically adjusting duration of crossroad traffic light, and comparing direction of congestion and lane providing passing time so as to improve passing efficiency of the traffic road junction and relieve vehicle urban traffic jam.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for distributing transit time of a traffic signal lamp by utilizing an electronic device
   (2) a processor-executable non-volatile computer readable medium for comprising set of instructions for distributing transit time of a traffic signal lamp by utilizing an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for distributing transit time of a traffic signal lamp by utilizing an electronic device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T07 (Traffic Control Systems)
MC T01-J04A; T01-J07D3A; T01-J30A; T01-S03; T07-B05A; T07-C01
IP G08G-001/08
PD CN108986493-A   11 Dec 2018   G08G-001/08   201906   Pages: 13   Chinese
AD CN108986493-A    CN10957653    21 Aug 2018
PI CN10957653    21 Aug 2018
UT DIIDW:2018A1938L
ER

PT P
PN CN108989099-A
TI Software-defined universal integrated network based joint resource allocating method, involves determining cache resource dimension, and performing distributing action corresponding to maximum output value to complete resource allocation.
AU XU F
   QIU C
   ZHAO C
   LI B
AE UNIV BEIJING POSTS & TELECOM (UBPT-C)
GA 2018A3334R
AB    NOVELTY - The method involves inputting state in a state space of a software-defined world-wide integrated network into a trained joint resource allocation model i.e. deep learning neural network model. An output value is obtained corresponding to action of the state, where the state comprises multiple actions. The state space and communication resource dimension of the software-defined world-wide integrated network are determined. Cache resource dimension is determined related to computing resource dimension. Distributing action is performed corresponding to maximum output value to complete joint resource allocation.
   USE - Software-defined universal integrated network based joint resource allocating method.
   ADVANTAGE - The method enables setting the joint resource allocation model to realize joint resource allocation based on three dimensions, and improving resource utilization rate and practicability.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a software-defined universal integrated network based joint resource allocating system
   (2) a non transitory computer-readable storage medium for storing set of instruction for allocating joint resource based on software-defined universal integrated network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a software-defined universal integrated network based joint resource allocating method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-N01B3; T01-N01D4; T01-N03; T01-S03; W01-A06A3; W01-A06D; W01-A06E1L
IP H04L-012/24
PD CN108989099-A   11 Dec 2018   H04L-012/24   201906   Pages: 14   Chinese
AD CN108989099-A    CN10707558    02 Jul 2018
PI CN10707558    02 Jul 2018
UT DIIDW:2018A3334R
ER

PT P
PN CN108986925-A
TI Voice medical order depth learning method, involves collecting voice medical order, storing text data, and performing diagram monitoring process for determining change situation of patient to obtain therapeutic regimen of patient.
AU ZHANG H
AE CHENGDU HONESTVISION TECHNOLOGY CO LTD (CHEN-Non-standard)
GA 2018A19301
AB    NOVELTY - The method involves collecting voice medical order. Text data is stored according to the voice medical order. Key words are extracted according to different periods by classifying same-type of a patient. A variable is determined for setting the key words corresponding to graph. Formulates storing and outputting process is performed corresponding to the graph. Diagram monitoring process is performed for determining change situation of the patient to obtain therapeutic regimen of the patient. Noise reduction processing operation is performed according to the voice medical order.
   USE - Voice medical order depth learning method.
   ADVANTAGE - The method enables reducing workload of a doctor.
DC S05 (Electrical Medical Equipment); T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC S05-G02G; T01-E01A; T01-J06A1; T01-J30A; W04-V04A6; W04-W05A
IP G16H-080/00; G16H-050/20; G10L-015/26
PD CN108986925-A   11 Dec 2018   G16H-080/00   201906   Pages: 4   Chinese
AD CN108986925-A    CN10735613    06 Jul 2018
PI CN10735613    06 Jul 2018
UT DIIDW:2018A19301
ER

PT P
PN CN108962393-A
TI Compression neural network based automatic arrhythmia analyzing method, involves generating single-dimensional code, determining learning parameter of deep neural network and performing automatic sample identifying process.
AU LIU T
   WEI Y
   ZANG M
   ZOU H
   JIA S
   LIU C
   ZHOU S
AE UNIV LUDONG (UNLD-C)
GA 2018A0193U
AB    NOVELTY - The method involves generating a lead ECG signal of a channel number. ECG data sampling way is obtained through composite electrical signal samples. A deep neural network model is established. Deep neural network depth neural network building process is performed. A combining layer unit is arranged with a convolution coding layer unit. A single-dimensional code is generated. A learning parameter of a deep neural network is determined. Automatic sample identifying process is performed.
   USE - Compression neural network based automatic arrhythmia analyzing method.
   ADVANTAGE - The method enables solving problem of existing arrhythmia analysis and satisfies accuracy requirements of clinical application.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a compression neural network based automatic arrhythmia analyzing method. '(Drawing includes non-English language text)'
DC P31 (Diagnosis, surgery (A61B).); S05 (Electrical Medical Equipment); T01 (Digital Computers); T04 (Computer Peripheral Equipment); W01 (Telephone and Data Transmission Systems)
MC S05-D01A1; S05-D06; S05-G02G9; T01-D02; T01-J04B2; T01-J10B2; T01-N01B3; T01-N01E1; T04-D04; W01-A01B2; W01-A06A3
IP G16H-050/70; G16H-050/20; G06K-009/00; A61B-005/0402; G06K-009/62; G06N-003/04
PD CN108962393-A   07 Dec 2018   G16H-050/70   201906   Pages: 9   Chinese
AD CN108962393-A    CN10451719    12 May 2018
PI CN10451719    12 May 2018
UT DIIDW:2018A0193U
ER

PT P
PN CN108965723-A
TI Method for processing original image by using image processor of image sensor, involves connecting connection layers with one of slice layers, and outputting data by output layer to one of connection layers as final image.
AU ZHANG Y
   WANG D
AE ECORDIA DALIAN TECHNOLOGY CO LTD (ECOR-Non-standard)
GA 2018A1311K
AB    NOVELTY - The method involves receiving initial image data by an input layer of a trained deep neural network model, where slice layers and the input layer of the trained deep neural network model are orderly connected together and where core size of each slice layer is 3 /asterisk 3. Each slice layer is formed with a convolutional layer and a pooled layer, where pool size of the pooled layer is measured as 2 /asterisk 2. Connection layers are connected with one of the slice layers, where each connection layer comprises an up-sampling layer and the convolutional layer. Data is output by an output layer to one of the connection layers as a final image.
   USE - Method for processing an original image by using an image processor of an image sensor (all claimed).
   ADVANTAGE - The method enables reducing complexity of designing and optimization, and improving designing stability, and realizing multiple functions by loading a differential neural network model.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of an image processor.
DC T01 (Digital Computers); U13 (Integrated Circuits); W04 (Audio/Video Recording and Systems)
MC T01-J10B3A; U13-A01; W04-M01D6
IP H04N-005/232; H04N-009/04
PD CN108965723-A   07 Dec 2018   H04N-005/232   201906   Pages: 6   Chinese
AD CN108965723-A    CN11161920    30 Sep 2018
PI CN11161920    30 Sep 2018
UT DIIDW:2018A1311K
ER

PT P
PN CN108932713-A
TI Deep learning based welding seam air hole defect automatic detecting method, involves establishing network model, determining boundary position of welding seam, and performing void defect identification by using YOLO network.
AU FANG L
   OUYANG C
AE CHENGDU ZHIMA TECHNOLOGY CO LTD (CHEN-Non-standard)
GA 2018A0018X
AB    NOVELTY - The method involves locating a welding seam area. Two-dimensional image is converted into a one-dimensional sequence. A network model is established using depth learning. Boundary position of the welding seam is determined. Void defect identification is performed by using YOLO network. Sequence characteristic is extracted by using LSTM network. Characteristic expression of the sequence is obtained. Dropout layer treatment is performed on the LSTM network of the extracted characteristic. The network is trained by using an Adam optimizer to minimize loss function to obtain the locating function with the welding seam region of the network model.
   USE - Deep learning based welding seam air hole defect automatic detecting method.
   ADVANTAGE - The method enables reducing depending of image quality and parameter selection to improve robustness of the algorithm, thus realizing defect of air hole of the detecting process to reaches hole accuracy of defect detection with better timeliness.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based welding seam air hole defect automatic detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B1; T01-J10B2; T01-J10B3A; T01-J10D; T01-N01B3
IP G06T-007/00; G06T-007/13
PD CN108932713-A   04 Dec 2018   G06T-007/00   201906   Pages: 13   Chinese
AD CN108932713-A    CN10800612    20 Jul 2018
PI CN10800612    20 Jul 2018
UT DIIDW:2018A0018X
ER

PT P
PN CN108932722-A
TI Method of determining target single pixel profile, involves removing pixels in third image that are not in edge point set collection, and obtaining single-pixel outline image of target.
AU GAO F
   HE Z
   YANG C
   LU S
   ZHANG Y
   XIAO G
AE UNIV ZHEJIANG TECHNOLOGY (UYZT-C)
GA 201899425X
AB    NOVELTY - The method involves reading a first image of a vehicle. The first image is input into the full convolutional neural network to obtain a contour probability map. The pixel with the largest pixel gray value is found in contour probability map as PL. The central point is found. The edge point set of the second image is denoted as E. The center point and the edge point set are connected to obtain a straight line segment. The edge point is detected, when a pixel satisfies preset equation. The set collection formed by all the edge points is expressed as collection relating number of edge points. The pixels in the third image that are not in the edge point set collection are removed. The single-pixel outline image of the target is obtained.
   USE - Method of determining target single pixel profile.
   ADVANTAGE - By performing a single pixel contour extraction operation on the target, interference of the background connected to the edge near the target is effectively avoided. The contour positioning is performed when the color of the target itself is close to the background. The enhanced target contour extraction is obtained in complex environments.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of the vehicle with determined target single pixel profile.
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J07D3A; T01-J10B2; T01-J10B3B; T04-D08
IP G06T-007/13
PD CN108932722-A   04 Dec 2018   G06T-007/13   201906   Pages: 10   Chinese
AD CN108932722-A    CN10765658    12 Jul 2018
PI CN10765658    12 Jul 2018
UT DIIDW:201899425X
ER

PT P
PN CN108932783-A
TI Two-dimensional face recognition based access control system for large traffic scenarios, has remote server that is provided with face information table which includes photo coding information of user.
AU GUI G
   HONG K
   YANG Z
   GU H
   LIU F
AE UNIV NANJING POSTS & TELECOM (UNPT-C)
GA 201899424J
AB    NOVELTY - NOVELTY B The system has an access control terminal that is connected to a remote server through a communication network. The user access management website is connected to a remote real-time monitoring terminal. The access control terminal is provided with a raspberry pie camera, a face detection module, a face recognition module and an access control module. The remote server is provided with a face information table which includes photo coding information of the user. The encoded information is adjusted by 68 key points of the user's face or side face photo. The FaceNet deep convolutional neural network is used to encode 128 parameters.
   USE - Two-dimensional face recognition based access control system for large traffic scenarios.
   ADVANTAGE - ADVANTAGE B Data mining is performed using personnel access information, and the user's living habits are analyzed by entering and leaving the recorded data so as to detect the abnormal state of the user.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the process of operation of two-dimensional face recognition based access control system. (Drawing includes non-English language text)
DC T01 (Digital Computers); T05 (Counting, Checking, Vending, ATM and POS Systems)
MC T01-D02; T01-J10B2A; T01-N02A3C; T01-N02B1E; T01-N02B2; T01-N02B5; T05-D01B
IP G07C-009/00; G06K-009/62
PD CN108932783-A   04 Dec 2018   G07C-009/00   201906   Pages: 8   Chinese
AD CN108932783-A    CN11094500    19 Sep 2018
PI CN11094500    19 Sep 2018
UT DIIDW:201899424J
ER

PT P
PN CN108932452-A
TI Multi-scale convolutional neural network based arrhythmia cardiac beat classification method, involves locating ECG signal position, and selecting heart beat from left bundle branch block and right bundle branch block.
AU WANG X
   LU H
   JIN M
   WANG K
   GONG G
   CHEN G
   MAO W
   BIAN Y
AE INST SEMICONDUCTORS CHINESE ACAD SCI (CBDT-C)
   UNIV CHINESE ACAD SCI (UYCH-Non-standard)
GA 2018994320
AB    NOVELTY - The method involves locating an ECG signal position. Wave of an ECG signal is segmented to obtain a segmentation of a heart beat signal. A cardiac beat signal is converted into normal heartbeats. Heart beat is selected from a left bundle branch block and a right bundle branch block. A position of the wave positioning ECG signal is determined. Baseline drift, an ECG signal of power frequency interference and myoelectric noise are de-noised and removed. Distance between two wave peaks is calculated.
   USE - Multi-scale convolutional neural network based arrhythmia cardiac beat classification method.
   ADVANTAGE - The method enables extracting signal characteristics on different scales in feature extraction and classification process so as to reduce error and improve classification accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a multi-scale convolutional neural network based arrhythmia cardiac beat classification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2; T01-J10B2; T04-D03A; T04-D07D5
IP G06K-009/00; G06N-003/04
PD CN108932452-A   04 Dec 2018   G06K-009/00   201906   Pages: 18   Chinese
AD CN108932452-A    CN10366249    22 May 2017
PI CN10366249    22 May 2017
UT DIIDW:2018994320
ER

PT P
PN CN108932536-A
TI Deep neural network based human face gesture reconstruction method, involves substituting cut test local image set into trained gesture reconstruction model to combine partial small blocks of human face image to generate face image.
AU YANG K
   GU Y
   YUAN Y
   REN X
   CHEN X
   ZHANG H
AE UNIV ELECTRONIC SCI & TECHNOLOGY (UEST-C)
GA 2018994303
AB    NOVELTY - The method involves pre-processing a human face image. A human face training sample is divided into multiple local blocks for forming a sample partial image set. A neural network is constructed in human gesture. The sample image set is substituted into the neural network. Reconstruction expression is determined. A gesture reconstruction model is trained after enhancement. A cut test local image set is substituted into the trained gesture reconstruction model to obtain partial small blocks of the human face image after prediction and combine the partial small blocks of the human face image to generate a face image.
   USE - Deep neural network based human face gesture reconstruction method.
   ADVANTAGE - The method enables improving accuracy of face image reconstruction in an effective manner.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep neural network based human face gesture reconstruction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B1; T01-J10B2; T01-N01B3A; T04-D03; T04-D04; T04-D07F1
IP G06K-009/62; G06K-009/00; G06K-009/40; G06N-003/04
PD CN108932536-A   04 Dec 2018   G06K-009/62   201906   Pages: 13   Chinese
AD CN108932536-A    CN10790966    18 Jul 2018
PI CN10790966    18 Jul 2018
UT DIIDW:2018994303
ER

PT P
PN CN108932289-A
TI Method for answering questions based on information extraction and deep learning, involves reading weights in weight database, respectively assigning first weight to each question and answer pair.
AU YU Y
   CHEN Q
   ZHANG C
AE BEIJING HUAJIAN LANHAI TECHNOLOGY CO LTD (BEIJ-Non-standard)
GA 2018A0017X
AB    NOVELTY - The method involves reading the weights in the weight database, respectively assigning the first weight to each question and answer pair, and assigning the second weight to each first semantic set respectively by the pair of questions and answers. The first semantic set is trained to obtain the weight in the weight database, for each question and answer pair, the initial score by the first weight to obtain a first intermediate value, and the intermediate score of the corresponding first semantic set by the second weight to obtain a second intermediate value. The sum of the first intermediate value and the second intermediate value is used as the final score of each question and answer pair, and the answer with the highest score and the answer pair is the target answer. The target answer is output, the target answer is the answer to the current question.
   USE - Method for answering questions based on information extraction and deep learning.
   ADVANTAGE - The method can effectively improve the accuracy and intelligence level of the answer to the question, and provides fast response speed and good user experience.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a system for answering questions based on information extraction and deep learning.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart illustrating the method for answering questions based on information extraction and deep learning. (Drawing includes non-English language text)
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J05B4P; T01-J11A1; T01-J16C3; T01-J30A; W04-W05A
IP G06F-017/30; G06F-017/27
PD CN108932289-A   04 Dec 2018   G06F-017/30   201906   Pages: 12   Chinese
AD CN108932289-A    CN10500603    23 May 2018
PI CN10500603    23 May 2018
UT DIIDW:2018A0017X
ER

PT P
PN CN108932314-A
TI Advanced hash learning based chrysanthemum image content retrieving method, involves establishing image retrieval system, and performing image searching process in three subsystem modules by using image retrieval system.
AU YUAN P
   CAO X
   LI M
   REN S
   GU X
   XU H
AE UNIV NANJING AGRIC (UYNA-C)
GA 2018994355
AB    NOVELTY - The method involves obtaining image data information, where the image data information comprises training data set and test data set. An image balanced mean and variance determining process is performed. An image search model is established based on a convolutional neural network, where the convolutional neural network comprised an input layer, a complete convolution layer, a connecting layer and a pooled and hash layer. An image retrieval system is established. An image searching process is performed in three subsystem modules by using the image retrieval system.
   USE - Advanced hash learning based chrysanthemum image content retrieving method.
   ADVANTAGE - The method enables obtaining chrysanthemum data set and enhancement data sets to enhance model generalization capability and improving search quality and efficiency of retrieving image.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating an advanced hash learning based chrysanthemum image content retrieving method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E04; T01-J04B2; T01-J05B2B; T01-J05B4F; T01-J10B1; T01-N01B3A; T01-N01D1B; T01-N01D2; T01-N02B1A; T01-N03A2
IP G06F-017/30; G06N-003/04; G06N-003/08
PD CN108932314-A   04 Dec 2018   G06F-017/30   201906   Pages: 16   Chinese
AD CN108932314-A    CN10640741    21 Jun 2018
PI CN10640741    21 Jun 2018
UT DIIDW:2018994355
ER

PT P
PN CN108921282-A
TI Deep neural network model establishing method, involves performing random phase encryption process, and performing training process on deep neural network model when comparison result is not satisfied with preset convergence condition.
AU HE W
   HAI H
   PENG X
   LIU X
   LIAO M
   LU D
AE UNIV SHENZHEN (UYSZ-C)
GA 2018981903
AB    NOVELTY - The method involves performing (A) random phase encryption process on multiple groups of original data for obtaining training data. A deep neural network model is trained by using the training data. An output result is compared (B) with the original data corresponding to the training data for obtaining a comparison result. A constructed deep neural network model is determined (C) when the comparison result satisfies preset convergence condition. Training process is performed (D) on the deep neural network model when the comparison result is not satisfied with the preset convergence condition.
   USE - Deep neural network model establishing method.
   ADVANTAGE - The method enables solving problem of lacking of an algorithm model that breaks random phase encryption.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep neural network model establishing device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep neural network model establishing method. '(Drawing includes non-English language text)'
   Step for performing random phase encryption process on multiple groups of original data for obtaining training data (A)
   Step for comparing an output result with the original data corresponding to the training data for obtaining a comparison result (B)
   Step for determining a constructed deep neural network model when the comparison result satisfies preset convergence condition (C)
   Step for performing training process on the deep neural network model when the comparison result is not satisfied with the preset convergence condition (D)
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-D01A; T01-E01A; T01-E01C; T01-N01B3; W01-A05A
IP G06N-003/04; G06N-003/08
PD CN108921282-A   30 Nov 2018   G06N-003/04   201906   Pages: 18   Chinese
AD CN108921282-A    CN10465595    16 May 2018
PI CN10465595    16 May 2018
UT DIIDW:2018981903
ER

PT P
PN CN108920897-A
TI Method for constructing and training silicon-based surface-enhanced Raman scattering chip DNA database, involves preparing silver nanoparticle-modified silicon-based surface-enhanced Raman scattering substrate.
AU HE Y
   WANG H
   SHI H
AE UNIV SOOCHOW (USWZ-C)
GA 201898199N
AB    NOVELTY - A silicon-based surface-enhanced Raman scattering chip DNA database constructing and training method involves preparing a silver nanoparticle-modified silicon-based surface-enhanced Raman scattering substrate by a hydrofluoric acid assisted etching method, constructing a surface-enhanced Raman scattering database of DNA and extracting the main feature values for the deep neural network and training the deep neural network.
   USE - Method for constructing and training silicon-based surface-enhanced Raman scattering chip DNA database.
   ADVANTAGE - The method enables constructing and training silicon-based surface-enhanced Raman scattering chip DNA database with better specificity and repeatability, in convenient manner.
TF TECHNOLOGY FOCUS - INORGANIC CHEMISTRY - Preferred Composition: The concentration of the silver nitrate solution in the mixed solution of silver nitrate and hydrofluoric acid is 1 M, the mass percentage concentration of the hydrofluoric acid solution is 40% and the silver nitrate solution and the hydrogen fluoride solution volume ratio is 1:0.01-100. Preferred Method: The method further involves adding a potassium iodide solution to the prepared silicon-based SERS substrate for a period of time, dividing the DNA fragment of the non-allelic gene to be detected into two or more fragments of different base lengths and dissolving in a magnesium sulfate solution to prepare a DNA detection droplet to be added on the surface of the potassium iodide-modified silicon-based surface-enhanced Raman scattering substrate and drying, performing a Raman mapping test using a confocal Raman spectrometer and sorting the collected surface-enhanced Raman scattering spectral data into a database.
DC B04 (Natural products and polymers. Including testing of body fluids (other than blood typing or cell counting), pharmaceuticals or veterinary compounds of unknown structure, testing of microorganisms for pathogenicity, testing of chemicals for mutagenicity or human toxicity and fermentative production of DNA or RNA. General compositions.); D16 (Fermentation industry - including fermentation equipment, brewing, yeast production, production of pharmaceuticals and other chemicals by fermentation, microbiology, production of vaccines and antibodies, cell and tissue culture and genetic engineering.); T01 (Digital Computers)
MC B04-E01A; B11-C07B6; B11-C07B7; B11-C08E6; B11-C11C1; B12-K04F; D05-H09; T01-J05B4P; T01-N01B3A
IP G06F-019/18; G06F-019/28; G06N-003/04
PD CN108920897-A   30 Nov 2018   G06F-019/18   201906   Pages: 19   Chinese
AD CN108920897-A    CN10817521    24 Jul 2018
PI CN10817521    24 Jul 2018
UT DIIDW:201898199N
ER

PT P
PN CN108921799-A
TI Multi-scale collaborative learning convolutional neural network based remote sensing image thin cloud removing method, involves forming network structure of scale, and inputting to-be-processed cloud image into trained network model.
AU LI Y
   CHEN D
   LI W
AE UNIV NORTHWESTERN POLYTECHNICAL (UNWP-C)
GA 201898177M
AB    NOVELTY - The method involves obtaining experimental data that is divided into actual data and simulation data. The experimental data is pre-processed to generate actual data of registration. Cloudless image blocks are combined into a training sample. Multi-scale training data is generated for a set of the training sample. A pyramid multi-scale training sample is inputted into a trained network model. Mapping relation between a scale cloud and a cloud image block is established. A network structure of a scale is formed, where the network structure includes a shallow feature integration layer. A to-be-processed cloud image is inputted into the trained network model.
   USE - Multi-scale collaborative learning convolutional neural network based remote sensing image thin cloud removing method.
   ADVANTAGE - The method enables eliminating manual trace, accurately obtaining restored image information of a cloud area, maintaining fidelity of a cloudless area for better clouds removing effect, and improving remote sensing image removing precision.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a multi-scale collaborative learning convolutional neural network based remote sensing image thin cloud removing method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B1; T01-J10B2; T01-J15H; T01-N01B3
IP G06T-005/00; G06T-005/50; G06T-007/30; G06N-003/04; G06N-003/08
PD CN108921799-A   30 Nov 2018   G06T-005/00   201906   Pages: 10   Chinese
AD CN108921799-A    CN10647393    22 Jun 2018
PI CN10647393    22 Jun 2018
UT DIIDW:201898177M
ER

PT P
PN CN108921227-A
TI Method for classifying glaucoma medical image based on gelule theory, involves performing pre-processing on image, constructing image reconstruction fully connected network, and obtaining use category capsule to restore original image.
AU LIU S
   JIA X
   GUAN L
   GAO W
   HONG J
   LI G
   ZHANG Q
   LIN Z
   CUI H
AE UNIV GUANGDONG POLYTECHNIC NORMAL TIANHE (UGTH-C)
GA 201898191B
AB    NOVELTY - The method involves performing pre-processing on an image. A capsule-based convolutional neural network is constructed. A pre-processed image is inputted to output Glaucoma recognition results. An image reconstruction fully connected network is constructed. A use category capsule is obtained to restore the original image. An existing glaucoma medical image disk detection model is established. Cup semantic segmentation map information is obtained. An activation function is obtained. A local feature extraction is realized.
   USE - Method for classifying glaucoma medical image based on gelule theory.
   ADVANTAGE - The method enables improving the generalization ability based on convolutional neural network gelule, reducing interference information, and using limited adaptive histogram of contrast enhancement so as to improve the entire or local contrast.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for classifying glaucoma medical image based on gelule theory. '(Drawing includes non-English language text)'
DC S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S05-D; T01-J10B2A; T01-J16C3; T01-N01E
IP G06K-009/62; G06K-009/34
PD CN108921227-A   30 Nov 2018   G06K-009/62   201906   Pages: 11   Chinese
AD CN108921227-A    CN10759934    11 Jul 2018
PI CN10759934    11 Jul 2018
UT DIIDW:201898191B
ER

PT P
PN CN108921007-A
TI SqueezeNet based handwritten number identification method, involves establishing SqueezeNet model, and utilizing constructed SqueezeNet model to train and test handwritten numbers to obtain number identification result.
AU MIAO H
   GU Y
   QI B
   JIA L
   XIONG T
AE UNIV HOHAI CHANGZHOU CAMPUS (UYHO-C)
GA 201898196T
AB    NOVELTY - The method involves pre-processing handwritten number samples. A SqueezeNet (RTM: deep learning software framework) model is established and initialized. The constructed SqueezeNet (RTM: deep learning software framework) model is utilized to train and test handwritten numbers to obtain a number identification result. A training set is established. A label value of the handwritten number is calculated. Testing set normalization process is performed. Single-dimensional sample data is acquired. A three-dimensional matrix of sample data is determined. A characteristic pattern of the handwriting number is determined.
   USE - SqueezeNet (RTM: deep learning software framework) based handwritten number identification method.
   ADVANTAGE - The method enables effectively reducing total amount of network parameters compared to a traditional AlexNet (RTM: Convolutional neural network) and improving accuracy of handwritten digit recognition mobile devices, distributed training and embedded hardware.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning software framework based handwritten number identification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2A; T01-N01B3A; T01-N03; T04-D04; T04-D07B1; T04-D07E
IP G06K-009/00; G06K-009/62
PD CN108921007-A   30 Nov 2018   G06K-009/00   201906   Pages: 10   Chinese
AD CN108921007-A    CN10430128    08 May 2018
PI CN10430128    08 May 2018
UT DIIDW:201898196T
ER

PT P
PN CN108921042-A
TI Deep learning based human face expression identification method, involves deriving network parameter model sequence expression and obtaining fusion classification result to predict video of human facial expression categories.
AU QING L
   ZHOU W
   WU X
   HE X
   XIONG W
   TENG Q
   XIONG S
AE UNIV SICHUAN (USCU-C)
GA 2018981960
AB    NOVELTY - The method involves obtaining training set and validation set of three different resolutions of human face. An input three channel sequence multi-scale human face expression recognition network is connected with a training network. Network parameter model predicting process is performed. Trained network parameter model sequence expression is derived by a multi-scale human face sequence expression recognition network for classifying human face video. A three-channel fusion classification result is obtained to predict video of human facial expression categories.
   USE - Deep learning based human face expression identification method.
   ADVANTAGE - The method enables improving expression identification accuracy and working efficiency, ensuring learning self-learning ability, avoiding limitation difficulties of characteristic manual extracting and ensuring expression identification adaptability.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a training network. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W04 (Audio/Video Recording and Systems)
MC T01-J05B2; T01-J10B2A; T01-N01B3; T04-D07F1; W04-W05A
IP G06K-009/00; G06N-003/04
PD CN108921042-A   30 Nov 2018   G06K-009/00   201906   Pages: 8   Chinese
AD CN108921042-A    CN10587517    06 Jun 2018
PI CN10587517    06 Jun 2018
UT DIIDW:2018981960
ER

PT P
PN CN108924483-A
TI Deep learning process field based automatic wild animal monitoring system, has multiple data collecting ends respectively provided on different collecting areas, and data transceiver connected with collecting ends through network signal.
AU SHEN D
   CAO P
   ZHONG J
   YANG X
AE NANJING PUHOU ECOLOGICAL TECHNOLOGY CO (NANJ-Non-standard)
GA 2018991978
AB    NOVELTY - The system has multiple data collecting ends respectively provided on different collecting areas. The data collecting ends are connected with a data analyzing end through wireless transmission network signal. The data collecting ends are provided with a controller module. The controller module is electrically connected with a sound collecting module, an image collecting module, a communication module, a storage module and an executing module. The execution module is electrically connected on the sound collecting module and the image collecting module. The communication module is connected with the data analyzing end. The data analyzing end is provided with a processor that is electrically connected with a video image analysis module, a voice analyzing module, the storage module, a display module, an operation module, an exchange module and a data transceiver. The data transceiver is connected with the data collecting ends through the wireless transmission network signal.
   USE - Deep learning process field based automatic wild animal monitoring system.
   ADVANTAGE - The system has high monitoring accuracy and efficiency and simple configuration, and simplifies wile animal monitoring process.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning process field based automatic wild animal monitoring method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a deep learning process field based automatic wild animal monitoring system. '(Drawing includes non-English language text)'
TF TECHNOLOGY FOCUS - INDUSTRIAL STANDARDS - A wireless transmission network is connected with a 4G transmission module, a Wi-Fi transmission module or a 3G transmission module.
DC T01 (Digital Computers); W02 (Broadcasting, Radio and Line Transmission Systems)
MC T01-J10B2; T01-N01B3; T01-N01D1; T01-N02B2B; W02-F01A5; W02-F01B; W02-F01F
IP H04N-007/18; G06K-009/00
PD CN108924483-A   30 Nov 2018   H04N-007/18   201906   Pages: 10   Chinese
AD CN108924483-A    CN10677080    27 Jun 2018
PI CN10677080    27 Jun 2018
UT DIIDW:2018991978
ER

PT P
PN CN108922515-A
TI Voice model training method, involves inputting target voice characteristic into deep neural network for training target voice characteristic, and storing target characteristic recognition model and voice recognition model in database.
AU TU H
AE PINGAN SCI & TECHNOLOGY SHENZHEN CO LTD (PING-C)
GA 2018981609
AB    NOVELTY - The method involves obtaining training voice data. Training voice characteristic is extracted based on the training voice data. A target background model is obtained based on the training voice characteristic. Target voice characteristic is extracted based on target voice data. Adaptive process is performed on the target voice characteristic by using the target background model to obtain a target voice-print characteristic recognition model. The target voice characteristic is inputted into a deep neural network to train the target voice characteristic. The target voice-print characteristic recognition model and a voice recognition model are stored in a database.
   USE - Voice model training method.
   ADVANTAGE - The method enables accurately identifying sound effect.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a voice model training device
   (2) a voice recognizing method
   (3) a voice recognition device
   (4) a computer device
   (5) a computer-readable storage medium for storing a set of instructions for training voice model.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a voice model training method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-C08A; T01-J05B4P; T01-N01B3; T01-S03; W04-V01; W04-V05
IP G10L-015/06; G10L-015/02; G10L-025/18; G10L-025/24; G10L-025/30; G10L-025/45
PD CN108922515-A   30 Nov 2018   G10L-015/06   201906   Pages: 25   Chinese
AD CN108922515-A    CN10551458    31 May 2018
PI CN10551458    31 May 2018
UT DIIDW:2018981609
ER

PT P
PN CN108921783-A
TI Mixed loss function restriction based satellite image super-resolution reconstruction method, involves selecting multiple satellite image data, and obtaining final super-resolution output image according to interpolation image.
AU WANG Z
   JIANG K
   YI P
   HAN Z
   SHAO Z
AE UNIV WUHAN (UYWU-C)
GA 2018981781
AB    NOVELTY - The method involves selecting multiple satellite image data as the training sample. Size of an input low resolution image block is obtained. Image features are extracted based on convolution kernel. Output information of a residual block is processed. Characteristic information is inputted to a reconstructed layer. Residual graph of a parameter optimization network is outputted. Interpolation amplification is performed. An interpolation image is obtained. Final super-resolution output image is obtained according to the interpolation image.
   USE - Mixed loss function restriction based satellite image super-resolution reconstruction method.
   ADVANTAGE - The method enables enhancing characteristic expression capacity of the deep learning network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view illustrating a mixed loss function restriction based satellite image super-resolution reconstruction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-E01B; T01-J04B2; T01-J10B3A; T01-J10D; T01-N01B3; T01-N02B1B; T04-E
IP G06T-003/40
PD CN108921783-A   30 Nov 2018   G06T-003/40   201906   Pages: 6   Chinese
AD CN108921783-A    CN10556589    01 Jun 2018
PI CN10556589    01 Jun 2018
UT DIIDW:2018981781
ER

PT P
PN CN108920648-A
TI Music-image semantic relationship based music content and image content matching method, involves training deep neural network model by utilizing characteristic training set, and recommending music for prediction image.
AU YANG Z
   WEI X
   YU C
   WANG Z
   ZHANG S
   LV H
AE UNIV SICHUAN (USCU-C)
GA 2018982062
AB    NOVELTY - The method involves collecting image data and music data to represent an image content. Object identifying semantic characteristic and visual emotion semantic characteristic of the image data are extracted by utilizing a VGG-16 model and a DeepSentiBank model. Characteristic extraction process is performed on the image data and the music data to generate a characteristic training set. Deep neural network model is trained by utilizing the characteristic training set to generate a cross-relation model. A music is recommended for a prediction image according to a cross-relation model.
   USE - Music-image semantic relationship based music content and image content matching method.
   ADVANTAGE - The method enables solving problem poor picture and music matching relation modeling effect and improving matching degree of a recommended music content with an image-content.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a deep neural network model. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B4F; T01-J16C3; T01-N01B3; T01-N01D1
IP G06F-017/30; G06N-003/08
PD CN108920648-A   30 Nov 2018   G06F-017/30   201906   Pages: 8   Chinese
AD CN108920648-A    CN10713873    03 Jul 2018
PI CN10713873    03 Jul 2018
UT DIIDW:2018982062
ER

PT P
PN CN108921032-A
TI Deep learning model based video semantic extraction method, involves obtaining semantic structured video data, and utilizing trained three-dimensional convolutional neural network-continuous time series classification algorithm.
AU YAO Y
AE SICHUAN TROY INFORMATION TECHNOLOGY CO (SICH-Non-standard)
GA 2018981966
AB    NOVELTY - The method involves obtaining semantic structured video data by combining and segmenting video frame sequences based on video physical structure. A semantic structured video data is processed into input data of three-dimensional convolutional neural network by using a sliding window. A three-dimensional convolutional neural network model is created. An output result based on the three-dimensional convolutional neural network is obtained. A trained three-dimensional convolutional neural network-continuous time series classification algorithm is utilized as sports video semantic extraction model for extracting video semantics.
   USE - Deep learning model based video semantic extraction method.
   ADVANTAGE - The method enables improving sports video semantic extraction accuracy by combining three dimensional convolutional neural network and continuous time classification algorithm.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram illustrating a deep learning model based video semantic extraction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B2B; T01-J10B2; T01-J16C3; T01-J30D; T01-N01B3
IP G06K-009/00; G06K-009/62
PD CN108921032-A   30 Nov 2018   G06K-009/00   201906   Pages: 11   Chinese
AD CN108921032-A    CN10564348    04 Jun 2018
PI CN10564348    04 Jun 2018
UT DIIDW:2018981966
ER

PT P
PN CN108898168-A
TI Method for detecting target of convolutional neural network model by utilizing electronic device, involves training convolutional neural network model to establish compressed convolutional neural network model for detecting target.
AU WANG S
   SHU H
AE UNIV TSINGHUA (UYQI-C)
GA 201897845S
AB    NOVELTY - The method involves establishing a convolutional neural network model. Feature in the convolutional neural network model is extracted from a network structure to simplify a network. A feature extraction network is trained to determine parameters of the simplified network according to knowledge distillation process. The feature extraction network in the convolutional neural network model is replaced with the simplified network after determining the parameters. The convolutional neural network model is trained according to sample image to establish a compressed convolutional neural network model for detecting a target.
   USE - Method for detecting a target of a compressed convolutional neural network model by utilizing an electronic device (clamed).
   ADVANTAGE - The method enables improving target detection accuracy and reducing parameters of the convolutional neural network mode so as to operate the compressed convolutional neural network model on a calculation resource-limited platform.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a system for detecting a target of a compressed convolutional neural network model by utilizing an electronic device
   (2) a non-transitory computer-readable storage medium for storing a set of instructions to detect a target of a compressed convolutional neural network model by utilizing an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for detecting a target of a compressed convolutional neural network model by utilizing an electronic device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2; T01-N01B3; T01-S03; T04-D04
IP G06K-009/00; G06K-009/62; G06N-003/04
PD CN108898168-A   27 Nov 2018   G06K-009/62   201906   Pages: 15   Chinese
AD CN108898168-A    CN10628418    19 Jun 2018
PI CN10628418    19 Jun 2018
UT DIIDW:201897845S
ER

PT P
PN VN60554-A
TI Method for detecting, classifying, measuring size and motion direction of ship from satellite imagery, involves constructing and training ship-classifying neural network model, and measuring size to determine motion direction of ship.
AU NGUYEN T T
AE MILITARY IND-TELECOMS GROUP VIETTEL (MILI-Non-standard)
GA 2019038628
AB    NOVELTY - The method involves identifying a prominent map of an input image. A threshold is applied to a prominent photo map to extract and identify candidate ships. A ship-identifying convolutional neural network model is constructed and trained. The ship-classifying neural network model is constructed and trained. Size is measured to determine a motion direction of the ship.
   USE - Method for detecting, classifying, measuring size and motion direction of the ship from satellite imagery.
DC T01 (Digital Computers)
MC T01-J07D3A; T01-J10; T01-N01B3
IP G06T-001/00
PD VN60554-A   26 Nov 2018   G06T-001/00   201906   Pages: 1   
AD VN60554-A    VN004275    26 Sep 2018
PI VN004275    26 Sep 2018
UT DIIDW:2019038628
ER

PT P
PN CN108869145-A
TI Compound characteristic index and depth extreme learning machine based pump station unit fault diagnosing method, involves substituting feature vector with fault feature into machine model to obtain final classification result.
AU TIAN Y
   LEI X
   MA X
   JIANG Y
   CHANG W
   FENG J
   LV Y
   YANG M
   CAI S
   ZHANG Y
AE CHINA INST WATER RESOURCES & HYDROPOWER (IWHR-C)
GA 201895372S
AB    NOVELTY - The method involves obtaining an original vibration signal and a swing signal on a monitoring the unit under working condition of a pump station unit. Determination is made to check whether the original vibration signal or the swing signal on the monitoring component exceeds alarm signal. Non-stationary time series decomposition of the original vibration signal of the pumping station unit is performed by using an adaptive iterative filtering. Time domain features, frequency domain features, energy features, permutation entropy and sample entropy characteristics of a non-stable signal component are calculated. A depth limit learning machine model is established. Objective function is determined. Feature vector with fault feature is substituted into a single-layer extreme learning machine model to obtain a final classification result and complete fault diagnosis process.
   USE - Compound characteristic index and depth extreme learning machine based pump station unit fault diagnosing method.
   ADVANTAGE - The method enables quickly and efficiently performing feature learning process by using a depth-depth learning machine and extracting implicit fault information of each feature to avoid limitations of manual design, extraction of features and complex tuning process based on artificial neural networks, thus achieving intelligent diagnosis of pump unit failure to improve accuracy and effectiveness of pump unit fault diagnosis.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a compound characteristic index and depth extreme learning machine based pump station unit fault diagnosing method. '(Drawing includes non-English language text)'
DC Q54 (Non-positive displacement fluid engines (i.e. driven by fluid); Miscellaneous motors and machines for producing mechanical power/thrust (F03B,D,G,H))
IP F03B-011/00
PD CN108869145-A   23 Nov 2018   F03B-011/00   201906   Pages: 10   Chinese
AD CN108869145-A    CN10385373    26 Apr 2018
PI CN10385373    26 Apr 2018
UT DIIDW:201895372S
ER

PT P
PN CN108871431-A
TI System for detecting dynamic wheel pair, has wheel set damage judging device that is configured to receive wheel set damage trend curve and wheel set information collected by track edge data collecting device.
AU ZHAO J
   REN C
   ZHANG M
   WANG Z
   HAN Y
AE BEIJING JINGTIANWEI TECHNOLOGY DEV CO (BEIJ-Non-standard)
GA 201895322L
AB    NOVELTY - The system has rail edge data collecting device (1) that is configured to collect vehicle number information and wheel set information of a vehicle. A wheel set information sorting device (2) is connected to the track edge data collecting device for using the car number information and the wheel set information of the vehicle. A deep learning engine (3) is connected to the wheel set information classification device, and is configured to train the classified historical wheel pair information to obtain a wheel set damage trend curve corresponding to the car number information. A wheel set damage judging device (4) is configured to receive the wheel set damage trend curve and the wheel set information collected by the track edge data collecting device. The damage degree of the wheel set is judged according to the wheel set damage trend curve and the wheel set information. An early warning information is issued, if the damage degree of the wheel set reaches a preset value.
   USE - System for detecting dynamic wheel pair.
   ADVANTAGE - The detection time is effectively reduced. The efficiency of checking the vehicle is improved. The labor intensity is reduced. The manpower input is reduced.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a method for detecting dynamic wheel pair.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of the system for detecting dynamic wheel pair. (Drawing includes non-English language text)
   Rail edge data collecting device (1)
   Wheel set information sorting device (2)
   Deep learning engine (3)
   Wheel set damage judging device (4)
DC S02 (Engineering Instrumentation); X23 (Electric Railways and Signalling)
MC S02-J02A; X23-A05; X23-B
IP G01D-021/02; B61K-009/12
PD CN108871431-A   23 Nov 2018   G01D-021/02   201906   Pages: 11   Chinese
AD CN108871431-A    CN10490589    21 May 2018
PI CN10490589    21 May 2018
UT DIIDW:201895322L
ER

PT P
PN CN108545021-A
TI Particular target identifying vehicle driving assisting method, involves training and recognizing deep learning model to alert driver by voice broadcasting for assisting driving to identify particular target, and collecting image.
AU ZHOU Y
   DUAN C
   YU Z
AE JINAN INSPUR HIGH & NEW TECHNOLOGY INVES (INEI-C)
GA 201875884N
AB    NOVELTY - The method involves training and recognizing a deep learning model by a target identification module of a vehicle-mounted system to alert a driver by voice broadcasting for assisting driving to identify a particular target. An actual image is collected by using a vehicular camera. An image of a neural network model is selected according to a calibration data set. A target is identified by using the target identification module for collecting a real-time image. The collected real-time image is transmitted to a vehicle processor according to an identified target type. A voice prompt is generated to control vehicle audio.
   USE - Particular target identifying vehicle driving assisting method.
   ADVANTAGE - The method enables identifying presence of a target during driving process so as to remind a driver to cause attention of a driver, thus enhancing driving safety performance.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a particular target identifying vehicle driving assisting system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a particular target identifying vehicle driving assisting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); X22 (Automotive Electrics)
MC T01-E01B; T01-J07D1; T01-J10B2A; T01-N01B3; T01-N01D1; X22-E; X22-E06; X22-E09A; X22-E99; X22-K03; X22-L; X22-X02B
IP B60Q-009/00; G06K-009/00; G06K-009/62
PD CN108545021-A   18 Sep 2018   B60Q-009/00   201906   Pages: 6   Chinese
AD CN108545021-A    CN10343108    17 Apr 2018
PI CN10343108    17 Apr 2018
UT DIIDW:201875884N
ER

PT P
PN CN108515967-A
TI Number plate recognition-based collision warning method, involves measuring distance between vehicles, measuring speed of vehicle by global positioning system speed measurer, and judging whether vehicle is operated in dangerous state.
AU WANG X
   WANG P
AE SHENZHEN KAANXING TECHNOLOGY CO LTD (SHEN-Non-standard)
GA 201873798V
AB    NOVELTY - The method involves obtaining vehicle front road condition information by a single camera. A current vehicle lane is selected. Haar feature is extracted by a multi-scale sliding window. A Haar cascade classifier is input to form a vehicle detector. A vehicle identification process is performed. An image block is extracted by using the multi-scale sliding window. The image block is input to a deep convolutional neural network. Position and size information of a number plate is obtained. Distance between two vehicles is measured. Speed of a current vehicle is measured by a global positioning system (GPS) speed measurer. Judgment is made to check whether the vehicle is operated in dangerous state.
   USE - Number plate recognition-based collision warning method.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a number plate recognition-based collision warning device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a number plate recognition-based collision warning method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W06 (Aviation, Marine and Radar Systems); X22 (Automotive Electrics)
MC T01-J07D3A; T01-J10B2A; W06-A03A5C; X22-E06; X22-E09A; X22-E13; X22-J05; X22-J14; X22-K05
IP B60W-030/08
PD CN108515967-A   11 Sep 2018   B60W-030/08   201906   Pages: 14   Chinese
AD CN108515967-A    CN10379924    25 Apr 2018
PI CN10379924    25 Apr 2018
UT DIIDW:201873798V
ER

PT P
PN CN106250840-A
TI Deep learning based mouth opening and closing state detecting method, involves obtaining closing mouth prediction result, calculating neural network output result, and testing input image to obtain detection result.
AU SUN Z
   HE R
   LI H
   CAO J
AE CHINESE ACAD SCI AUTOMATION INST (CAZD-C)
GA 201700727C
AB    NOVELTY - The method involves preprocessing an input image. Image extracting process is performed. An extracted characteristic is classified by using a neural network. A certain image is obtained through a classification result. A closing mouth prediction result is obtained. A neural network output result is calculated to adjust neural network parameter. The input image is tested to obtain a detection result. The input image is normalized. The normalized image is transformed into a grey image. Features of a maximum cell layer in a CNS are extracted.
   USE - Deep learning based mouth opening and closing state detecting method.
   ADVANTAGE - The method enables increasing operation convenience and utilizing convenience, improving detecting precision, safety and reliability. The method enables reducing error generating rate by calculating capacity of mouth opening and closing state. The method ensures required computational resources and reducing memory space consumption. The method enables reducing variation in detected image resolution so as to avoid large amplitude fluctuations.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning based mouth opening and closing state detecting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J04A; T01-J05B2; T01-J10B2; T01-J10B3A; T01-J10D; T01-J16C1; T01-N01B3A; W04-P01F3; W04-W05A
IP G06K-009/00; G06N-003/08
PD CN106250840-A   21 Dec 2016   G06K-009/00   201704   Pages: 10   Chinese
AD CN106250840-A    CN10603175    27 Jul 2016
PI CN10603175    27 Jul 2016
CP CN106250840-A
      CN104504362-A   NANJING ALCOLOESS NETWORK TECHNOLOGY CO LTD (NANJ-Non-standard)   DAI T, HAN X, HE L, LUO K, WU C
      CN105426850-A   SHENZHEN SENSETIME TECHNOLOGY CO LTD (SHEN-Non-standard)   CAO Q, MA K, YU Z, ZHOU L, ZHANG G, LIU Z, LUO Y, XIANG X
      CN105512632-A   BEIJING MEGVII TECHNOLOGY CO LTD (BEIJ-Non-standard)   GU K, YIN Q
      CN105612533-A   BEIJING MEGVII TECHNOLOGY CO LTD (BEIJ-Non-standard)   CAO Z, GU K
      CN105718874-A   BEIJING TECHSHINO TECHNOLOGY CO LTD (BEIJ-Non-standard)   WANG H
CR CN106250840-A
      : "", ,relevantClaims[8],relevantPassages[4.4]
      : "", ,relevantClaims[5-6],relevantPassages[3-41.3-1.4]
UT DIIDW:201700727C
ER

PT P
PN CN106203330-A
TI Convolutional neural network-based vehicle classification method, involves obtaining characteristic of vehicle model, and using support vector machine classification model for obtaining type of vehicle based on vehicle image.
AU ZHANG E
   LI J
   DUAN G
AE UNIV XIAN TECHNOLOGY (UYXT-C)
GA 201678192K
AB    NOVELTY - The method involves obtaining learning samples. A class label is marked on the samples. A convolutional neural network model is trained to obtain excellent network model parameter. A trained convolution neural network model is used. A support vector machine (SVM) classification model is constructed. Characteristic of a vehicle model is obtained. To-be-classified vehicle type is extracted by using the convolutional neural network model. The SVM classification model is used for obtaining type of the vehicle based on vehicle image.
   USE - Convolutional neural network-based vehicle classification method.
   ADVANTAGE - The method enables utilizing output characteristics for representation of vehicle image and using the SVM classifier to classify the vehicle so as to enhance vehicle classification accuracy.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a convolutional neural network-based vehicle classification method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J05B2; T01-J07B; T01-J07D1; T01-J10B2; T01-J16C1; T01-N01B3
IP G06K-009/00; G06K-009/62; G06N-003/02
PD CN106203330-A   07 Dec 2016   G06K-009/00   201705   Pages: 8   Chinese
AD CN106203330-A    CN10536734    08 Jul 2016
PI CN10536734    08 Jul 2016
CP CN106203330-A
      CN101794378-A   UNIV ZHEJIANG (UYZH)   XU C, CHEN Y
      CN104463241-A   BEIJING INST TECHNOLOGY (BEIT)   DONG Z, JIA Y, PEI M
      CN104537387-A   CHINESE ACAD SCI GUANGZHOU ADVANCED TECH (CAAT)   HE Q, HU H, LENG B, GUAN G, JIANG D
      CN104657748-A   UNIV CHINA PETROLEUM (UYPE)   CHEN L, LU Q, ZHANG W
      CN105117739-A   UNIV NANJING INFORMATION SCI & TECHNOLOG (UNAI)   DENG J, LIU Q, YANG J, WANG F, LI Z
      CN105184271-A   JIANGSU CHINA SCI INTELLIGENT ENG CO LTD (JIAN-Non-standard);  QINGDAO ACAD INTELLECTUAL IND (QING-Non-standard);  SUZHOU PAIRULEIER INTELLIGENT TECHNOLOGY (SUZH-Non-standard);  TIANWEN HUIKE BEIJING TECHNOLOGY CO LTD (TIAN-Non-standard)   TIAN B, WANG F, YANG L, YAO Y
      CN105224951-A   SHENZHEN HARZONE TECHNOLOGY CO LTD (SHEN-Non-standard)   LENG J, LIAO Z
      CN105335702-A   ZHEJIANG ICARE VISION TECHNOLOGY CO LTD (ZHEJ-Non-standard)   SHANG L, GAO Y, ZHENG Y, YU X, YING L, LIU J
      CN105512676-A   UNIV SOUTH CHINA TECHNOLOGY (UYSC)   GUO L, LUO C, LIAO Q
      CN105574543-A   WUHAN FIBERHOME DIGITAL TECHNOLOGY CO (WUHA)   HU T, SUN Y
CR CN106203330-A
      : "", ,relevantClaims[1-4],relevantPassages[1427-30424-2]
      : "", ,relevantClaims[1-4],relevantPassages[C034-312]
      : "", ,relevantClaims[1-4],relevantPassages[61-64]
UT DIIDW:201678192K
ER

PT P
PN IN201821046360-A
TI Design system used for designing machine learning and deep learning models for embedded platform, has implementation subsystem configured to generate tests cases and use-cases to test selected model based on generated code.
AU BHOKARE G
AE IDL VISION TECH LLP (IDLV-Non-standard)
GA 2019023557
AB    NOVELTY - The design system (100) includes a storage subsystem (110) configured to store datasets, augmented datasets, models, and frameworks. The storage subsystem includes a database module (115) and a proposal module (120). A code generation subsystem (130) is operatively coupled to the storage subsystem, and configured to generate a code in a predefined computer language for a selected model. An implementation subsystem (140) is operatively coupled to the code generation subsystem, and configured to generate tests cases and use-cases to test the selected model based on a generated code.
   USE - Design system used for designing machine learning and deep learning models for an embedded platform. Can be used in the fields of, e.g., automotive, robotics, drones, medical, and consumer electronics such as camera and mobiles.
   ADVANTAGE - Provides a design system that enables the user with basic background knowledge to design multiple models of machine learning and deep learning in an embedded platform with a predefined time. Stores multiple predesigned datasets and predesigned models, which helps a novice developer or the user for quick reference and porting the models in real-life applications. Helps designing customized models based on the requirements of the user. Generates test cases or use-cases in order to test generated code for the selected model.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a design method used for designing machine and deep learning models of an embedded platform.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram illustrating the design system used for designing machine learning and deep learning models for an embedded platform.
   Design system (100)
   Storage subsystem (110)
   Database module (115)
   Proposal module (120)
   Code generation subsystem (130)
   Implementation subsystem (140)
DC T01 (Digital Computers)
MC T01-J05B4P; T01-J06A1; T01-J17
IP G06F-011/00
PD IN201821046360-A   28 Dec 2018   G06F-011/00   201905   Pages: 20   English
AD IN201821046360-A    IN21046360    07 Dec 2018
PI IN21046360    07 Dec 2018
UT DIIDW:2019023557
ER

PT P
PN CN108983412-A
TI Non-wave front adaptive optics system, has voltage conversion module for converting zernike coefficient to deformable mirror drive voltage such that light beam is adjusted, where deformable mirror is controlled.
AU XIN X
   TIAN Q
   ZHANG Q
   LU C
   WANG Y
   TIAN F
   YIN X
   ZHU L
AE UNIV BEIJING POSTS & TELECOM (UBPT-C)
GA 2018A33597
AB    NOVELTY - The system has a deformable mirror for receiving a light beam. An imaging module for receiving the beam from the deformable mirror and obtaining a light spot image. A convolutional neural network module receives the light spot image and predicts Zernike coefficient corresponding to the light spot image. The convolutional neural network module trains the light spot image according to each sample spot image and the zernike coefficient. A voltage conversion module converts zernike coefficient to deformable mirror drive voltage such that the light beam is adjusted, where the deformable mirror is controlled according to surface shape change of the deformable mirror drive voltage.
   USE - Non-wave front adaptive optics system.
   ADVANTAGE - The system can quickly spot image into the deformable mirror and achieve real-time phase adjusting requirement.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a method for adjusting beam phase of a non-wave front adaptive optics system
   (2) a computer-readable storage medium for storing set of instructions for adjusting beam phase of a non-wave front adaptive optics system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a front view of a non-wave front adaptive optics system.
DC P81 (Optics (G02).); T01 (Digital Computers); V07 (Fibre-optics and Light Control)
MC T01-S03; V07-F02A
IP G02B-026/06
PD CN108983412-A   11 Dec 2018   G02B-026/06   201905   Pages: 16   Chinese
AD CN108983412-A    CN10746256    09 Jul 2018
PI CN10746256    09 Jul 2018
UT DIIDW:2018A33597
ER

PT P
PN CN108964046-A
TI Short time based disturbed trajectory power system transient stability evaluation method, involves realizing transient stability classification based on rapid assessment of transient stability of combined track.
AU AN J
   RHEE J
   AI S
   ZHAO G
   LI J
   YANG S
   LIU D
   LI B
   YANG H
   ZHENG H
   SHAO G
   XU X
   YIN H
   WANG Z
   LIU Y
   GAO D
   LI Z
AE UNIV NORTHEAST DIANLI (UNEE-C)
   CHINA ELECTRIC POWER RES INST (SGCC-C)
   NORTHEAST BRANCH STATE GRID CORP CHINA (SGCC-C)
GA 2018A0158F
AB    NOVELTY - The method involves determining convolutional neural network input characteristics. Voltage amplitude, disturbed track speed and angle of a large generator are obtained through off-line simulation. Trajectory sampling sequence of a convolution nerve network input sample matrix set is obtained. Local feature of the convolutional neural network is extracted for enhancing robustness of a model. Non-linear mapping relation of a track is established for seeking optimal feature space arrangement. Transient stability classification is realized based on rapid assessment of transient stability of the combined track.
   USE - Short time based disturbed trajectory power system transient stability evaluation method.
   ADVANTAGE - The method enables reducing leakage of judgment model evaluation samples in an effective manner, and evaluating disturbed track transient stability so as to take control measures by the scheduling personnel in a timely manner.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a short time based disturbed trajectory power system transient stability evaluation method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); X12 (Power Distribution/Components/Converters)
MC T01-J04B2; T01-J05B2; X12-H01
IP H02J-003/00
PD CN108964046-A   07 Dec 2018   H02J-003/00   201905   Pages: 15   Chinese
AD CN108964046-A    CN10878266    03 Aug 2018
PI CN10878266    03 Aug 2018
UT DIIDW:2018A0158F
ER

PT P
PN CN108957453-A
TI Multi-target tracking based high-precision moving target imaging and identifying method, involves extracting target features of ship by using convolutional neural network, and obtaining specific classification information of ship.
AU FENG P
   ZHAO Z
   HE G
   LI K
   WANG J
   LIU D
   GUO Y
   XIA Z
AE SPACE STAR TECHNOLOGY CO LTD (CAER-C)
GA 2018A0304V
AB    NOVELTY - The method involves continuously illuminating a designated area by a SAR platform operating in a bunching mode. Geographic information and flight parameters of the SAR platform are combined to perform imaging process. A SAR image sequence and a SAR video are obtained. Doppler parameters are corrected during SAR imaging process by using estimated target motion parameters. SAR image target detection process is performed. A suspected target is extracted. Target features of a ship are extracted by using a convolutional neural network. Specific classification information of the ship is obtained.
   USE - Multi-target tracking based high-precision moving target imaging and identifying method.
   ADVANTAGE - The method enables obtaining a SAR video motion parameter by using multi-target tracking function, correcting Doppler imaging coefficient to obtain a high precision image and providing support for high precision recognition.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a multi-target tracking based high-precision moving target imaging and identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W06 (Aviation, Marine and Radar Systems)
MC T01-J05B2; T01-J07D3A; W06-A04A2; W06-A04H3; W06-A04J; W06-C01B
IP G01S-013/90
PD CN108957453-A   07 Dec 2018   G01S-013/90   201905   Pages: 12   Chinese
AD CN108957453-A    CN10810189    23 Jul 2018
PI CN10810189    23 Jul 2018
UT DIIDW:2018A0304V
ER

PT P
PN CN108959258-A
TI Natural language processing and deep learning based particular study integration entity link method, involves linking candidate entity with highest similarity as target entity, and establishing dynamic entity link on entity reference item.
AU GUO J
   JIANG S
   YU Z
   XIAN Y
   WANG H
AE UNIV KUNMING SCI & TECHNOLOGY (UKST-C)
GA 2018A02650
AB    NOVELTY - The method involves establishing a word vector model by using encyclopedia corpus of a traveling field. A TransE model is established to obtain a candidate entity vector. Triples are trained in a domain knowledge base by using the TransE model. An entity semantic ordering process is performed after determining a candidate entity. A similarity link is established according to a target entity. Ordering of a semantic item is indicated to determine similarity of the semantic item and a candidate entity from high to low. The candidate entity with highest similarity is linked as the target entity. A dynamic entity link is established on an entity reference item. Page information is extracted from a Chinese database of Wikipedia (RTM: Web content management system).
   USE - Natural language processing and deep learning based particular study integration entity link method.
   ADVANTAGE - The method enables improving particular study integration entity link precision and efficiency.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a natural language processing and deep learning based particular study integration entity link method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J05B4M; T01-J11A1; T01-J16A; T01-J16C3; T01-J30A; T01-N03A1A; W04-W05A
IP G06F-017/27; G06F-017/30; G06N-005/02
PD CN108959258-A   07 Dec 2018   G06F-017/27   201905   Pages: 16   Chinese
AD CN108959258-A    CN10717561    02 Jul 2018
PI CN10717561    02 Jul 2018
UT DIIDW:2018A02650
ER

PT P
PN CN108959550-A
TI User interest point excavating method, involves obtaining user search action data, and performing point-of-interest enlargement process to obtain class points when topic category focus point is present in user search action data.
AU LIU H
   HE B
   XIAO X
   LV Y
   WU T
AE BEIJING BAIDU NETCOM SCI & TECHNOLOGY CO (BIDU-C)
GA 2018A0258D
AB    NOVELTY - The method involves obtaining user search action data. Point-of-interest enlargement process is performed to obtain class points when a topic category focus point is present in the user search action data. A search intention recognition model is established by utilizing a deep neural network, a convolutional neural network, a circulating neural network, a long term memory network. Search intent in the user search action data is identified, where the search intent comprises navigation type, information type and transaction type and the user search action data comprises query text, click title, show title and click link.
   USE - User interest point excavating method.
   ADVANTAGE - The method enables improving real interests of a user so as to provide an appropriate recommended content to the user.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a user interest point excavating device
   (2) a computer readable medium for storing a set of instruction for excavating user interest point.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a user interest point excavating method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B4P; T01-J11A1; T01-J21; T01-N01D2; T01-N03A2; T01-S03
IP G06F-017/27; G06F-017/30; G06N-003/04
PD CN108959550-A   07 Dec 2018   G06F-017/30   201905   Pages: 19   Chinese
AD CN108959550-A    CN10712526    29 Jun 2018
PI CN10712526    29 Jun 2018
UT DIIDW:2018A0258D
ER

PT P
PN CN108960040-A
TI Method for detecting target human eye of video image in computer, involves sending first human eye image into neural network, and determining whether matching result indicates that speculative image is not second human eye image.
AU MEI F
   DAI B
   WANG Y
   YE W
   WANG L
AE CHONGQING ELECTRIC POWER CORP INFORMATIO (SGCC-C)
GA 2018A0246S
AB    NOVELTY - The method involves acquiring images of sample human eyes from a video image (S1). The images of the sample human eyes are sent into a convolutional neural network. A target human eye in the video image is detected (S2). Determination is made to check whether a first target human eye is detected in the video image. Two sliding windows are horizontally moved (S3) along left and right sides of the first target human eye at a preset distance. The image of the first target human eye is extracted (S4). The first target human eye image and a speculative image are sent into the convolutional neural network. Determination is made (S5) to check whether a matching result indicates that the speculative image is not a second target human eye image.
   USE - Method for detecting a target human eye of a video image in a computer.
   ADVANTAGE - The method enables sending the speculative image to the convolutional neural network and a Gaussian mixture model until the matching result is judged as the second target human eye image so as to improve accuracy of the target human eye detection result.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for Method for detecting a target human eye of a video image in a computer. '(Drawing includes non-English language text)'
   Step for acquiring images of sample human eyes from video image (S1)
   Step for detecting target human eye in video image (S2)
   Step for horizontally moving two sliding windows along left and right sides of first target human eye at preset distance (S3)
   Step for extracting image of first target human eye (S4)
   Step for determining whether matching result indicates that speculative image is not second target human eye image (S5)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B1; T01-J10B2; T01-N01D1B; T04-D07F1A
IP G06K-009/00
PD CN108960040-A   07 Dec 2018   G06K-009/00   201905   Pages: 8   Chinese
AD CN108960040-A    CN10426431    07 May 2018
PI CN10426431    07 May 2018
UT DIIDW:2018A0246S
ER

PT P
PN CN108960056-A
TI Gesture-analysis and support vector data description based old people falling detection method, involves selecting motion trajectory features of joint point, and judging whether features are detected by support vector data description mode.
AU TANG P
   LI W
   JIN W
AE UNIV SOUTHWEST JIAOTONG (UYSJ-C)
GA 2018A0246F
AB    NOVELTY - The method involves obtain video data in a collection area and intercept key frames of human body action. Coordinates of a joint point of a human body are acquired through a body posture estimation model based on depth learning in each frame image. Motion trajectory features of the joint point are selected. Judgment is made to check whether motion trajectory features are detected by a support vector data description mode to detect falling function. Coordinates of the joint points of the human body are normalized to obtain normalized coordinates.
   USE - Gesture-analysis and support vector data description based old people falling detection method.
   ADVANTAGE - The method enables avoiding obtaining problem of shielding and non-balance data and tumble data, ensuring high automation processing level, high recognition rate and low error rate and reducing discovery of risk in old people falling function.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a gesture-analysis and support vector data description based old people falling detection system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2A; T01-J30A; T04-D03; T04-D04; T04-D07A
IP G06K-009/00; G06K-009/46; G06K-009/62
PD CN108960056-A   07 Dec 2018   G06K-009/00   201905   Pages: 9   Chinese
AD CN108960056-A    CN10536981    30 May 2018
PI CN10536981    30 May 2018
UT DIIDW:2018A0246F
ER

PT P
PN CN108959732-A
TI Convolutional neural network-based transmission wire fault type identifying method, involves obtaining training sample, performing fault type identifying process and performing network accuracy checking process through test sample.
AU WANG M
   ZHU L
   ZHANG G
   NIU Q
   ZHAI K
   ZHANG J
   WANG G
AE UNIV XIAN SCI & TECHNOLOGY (UYXI-Non-standard)
GA 2018A02542
AB    NOVELTY - The method involves selecting a convolutional neural network (CNN) to realize training process. An electric power system is connected with an electromagnetic transient simulation software EMTP simulation module. A double-power transmission wire model is established. Short circuit fault setting process is performed. ELU activation function selecting process is performed. A training sample is obtained. Fault type identifying process is performed. Network accuracy checking process is performed through a test sample.
   USE - Convolutional neural network-based transmission wire fault type identifying method.
   ADVANTAGE - The method enables reducing error rate of wire fault type recognition, reducing fault type identifying process and improving wire fault type identifying efficiency.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a convolutional neural network. '(Drawing includes non-English language text)'
DC S01 (Electrical Instruments); T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC S01-G05; S01-G14; S01-H07A; T01-J10B2A; T01-J15H; T01-J20C; T01-N01B3A; T01-N01D; T01-N03; T04-D04; T04-D07A
IP G06F-017/50; G06K-009/62; G01R-031/08
PD CN108959732-A   07 Dec 2018   G06F-017/50   201905   Pages: 18   Chinese
AD CN108959732-A    CN10621653    15 Jun 2018
PI CN10621653    15 Jun 2018
UT DIIDW:2018A02542
ER

PT P
PN CN108956653-A
TI Welding point quality detecting method, involves constructing welding point quality classification model by using training data set, and constructing mathematical model based on depth learning algorithm.
AU WANG Y
   WANG H
   WEI C
   XU D
   FAN B
AE GUANGDONG ZHENGYE TECHNOLOGY CO LTD (GUAN-Non-standard)
GA 2018A0323X
AB    NOVELTY - The method involves obtaining target welding point of a target X-ray image. The target X-ray image is input to a welding point quality judging model to obtain target welding point quality result. A welding point quality classification model is constructed by using training data set. A mathematical model is constructed based on depth learning algorithm, where the training data set comprises historical welding points of X-ray image and class information corresponding to each history. The mathematical model is trained by using the training data set to obtain training result. Historical welding point type information is obtained by using the training result. Training error is generated according to correction feedback.
   USE - Welding point quality detecting method.
   ADVANTAGE - The method enables generating a welding point quality judging model to judge quality of the target welding point by analyzing pattern characteristic of target in the X-ray image and improving welding spot detecting quality.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a welding point quality detecting system
   (2) a welding point quality detecting device
   (3) a computer-readable storage medium for storing set of instructions for detecting welding point quality.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a welding point quality detecting method. '(Drawing includes non-English language text)'
DC S03 (Scientific Instrumentation); T01 (Digital Computers)
MC S03-E06B; T01-J04E; T01-J05B2; T01-J10B1; T01-J16C2; T01-J30A; T01-L02; T01-S03
IP G01N-023/04
PD CN108956653-A   07 Dec 2018   G01N-023/04   201905   Pages: 11   Chinese
AD CN108956653-A    CN10550671    31 May 2018
PI CN10550671    31 May 2018
UT DIIDW:2018A0323X
ER

PT P
PN CN108940919-A
TI Radio transmission and deep learning based rubbish sorting robot, has controller and camera connected with remote terminal through wireless network, where remote terminal is provided with program for identifying different rubbish types.
AU WU Q
   CHEN L
   LI S
   CAO G
   WANG C
AE UNIV EAST CHINA SCI & TECHNOLOGY (UYEC-C)
GA 2018A0688A
AB    NOVELTY - The robot has a barrel body divided into multiple chambers by radial. An identification component is provided with a rotating box, a controller, a camera of a rubbish classification and a great steering engine. The rotary box is provided with a downwards opening and closing in a rotating bottom plate. An end of the rotary box is connected with a first rotating shaft and a steering machine by an output shaft. The first rotating shaft is located in a supporting shaft extended line of the steering machine that is connected with the controller. The controller and the camera are connected with a remote terminal communication through a wireless network. The remote terminal is provided with a program for identifying different rubbish types.
   USE - Radio transmission and deep learning based rubbish sorting robot.
   ADVANTAGE - The robot has simple and compact structure, low cost, strong function, and can automatically judge throwing rubbish type and self-learning by the machine continuously improve recognition accuracy so as to achieve intelligent rubbish classification.
   DESCRIPTION OF DRAWING(S) - The drawing shows a top view of a radio transmission and deep learning based rubbish sorting robot.
DC P41 (Crushing: centrifuging, separating solids (B02, B03, B04).); T01 (Digital Computers); T05 (Counting, Checking, Vending, ATM and POS Systems); W01 (Telephone and Data Transmission Systems); X25 (Industrial Electric Equipment)
MC T01-C03C; T01-J05B2; T01-N01D; T01-S03; T05-K05; W01-A06C4; X25-F06
IP B07C-005/34; B07C-005/36
PD CN108940919-A   07 Dec 2018   B07C-005/34   201905   Pages: 9   Chinese
AD CN108940919-A    CN10613546    14 Jun 2018
PI CN10613546    14 Jun 2018
UT DIIDW:2018A0688A
ER

PT P
PN CN108960328-A
TI Hankel matrix based automobile hub bearing failure diagnosis method, involves determining failure type of diagnose unknown failure mode, and performing automobile hub bearing failure diagnosis process.
AU XIANG J
   WANG S
   JIANG Y
   ZHONG Y
AE UNIV WENZHOU (UYWE-Non-standard)
GA 2018A02404
AB    NOVELTY - The method involves obtaining a Hankel matrix (S1). A two-dimensional matrix is obtained. Vibration signal of the two-dimensional matrix is obtained. A known failure mode of a convolutional neural network is determined (S2). An enhanced hidden Markov model is established (S3). Failure type of the diagnose unknown failure mode is determined. Automobile hub bearing failure diagnosis process is performed. Original vibration signal of the known fault is collected. The original vibration signal is included with one-dimensional signal sequence. Data length of one-dimensional signal sequence is determined.
   USE - Hankel matrix based automobile hub bearing failure diagnosis method.
   ADVANTAGE - The method enables increasing fault type dynamic sequence modeling ability and time sequence mode classification ability.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a hankel matrix based automobile hub bearing failure diagnosis method. '(Drawing includes non-English language text)'
   Step for obtaining a Hankel matrix (S1)
   Step for determining the known failure mode of the convolutional neural network (S2)
   Step for establishing the enhanced hidden Markov model (S3)
DC S02 (Engineering Instrumentation); T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC S02-J03; T01-J05B2; T01-J07D1; T01-J10B2; T04-D04; T04-D07D3
IP G06K-009/62; G01M-013/04
PD CN108960328-A   07 Dec 2018   G06K-009/62   201905   Pages: 22   Chinese
AD CN108960328-A    CN10724155    04 Jul 2018
PI CN10724155    04 Jul 2018
UT DIIDW:2018A02404
ER

PT P
PN CN108959713-A
TI Method for measuring target distance and positive position offset based on convolutional neural network, involves training identification network, and adding trained convolutional neural network to obtain test result in actual environment.
AU YANG J
   MAN J
AE UNIV TIANJIN (UTIJ-C)
GA 2018A0254H
AB    NOVELTY - The method involves constructing a training set according to actual construction requirements. An actual construction environment is simulated by using 3Dmax software. Simulated object pattern is simulated to obtain a simulation data set. 3Dmax software script system is utilized to batch production training set. An identification network is trained by using format-switched training set. An actual model target distance and positive position offset in an actual environment are adjusted to shoot a picture. A trained convolutional neural network is added to obtain test result in the actual environment.
   USE - Method for measuring target distance and positive position offset based on convolutional neural network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a photograph of a sample.
DC T01 (Digital Computers)
MC T01-J15H; T01-N01B3A; T01-N03
IP G06F-017/50; G06N-003/04
PD CN108959713-A   07 Dec 2018   G06F-017/50   201905   Pages: 5   Chinese
AD CN108959713-A    CN10567845    05 Jun 2018
PI CN10567845    05 Jun 2018
UT DIIDW:2018A0254H
ER

PT P
PN CN108937934-A
TI Deep learning based brain MRI hippocampus detecting and dividing method, involves processing model structure according to training set, and determining hyper-parameters of model structure to re-divide initial data.
AU YANG J
   WANG J
   LI Y
AE UNIV WUHAN SCI & TECHNOLOGY (UWSC-C)
GA 2018A0757L
AB    NOVELTY - The method involves pre-processing MRI data. A model structure is established. An initial data set is divided into a training set. A verification set and a test set are obtained. Model hyper-parameters of the initial data set are obtained. The model structure is processed according to the training set. A determination is made to check whether performance of the verification set satisfies standard requirement. Hyper-parameters of the model structure are determined to re-divide the initial data set. An actual size of an edited picture of a brain is calculated.
   USE - Deep learning based brain MRI hippocampus detecting and dividing method.
   ADVANTAGE - The method enables utilizing historical manually segmented result image information so as to realize efficient brain MRI hippocampus detecting and dividing operation in a precision manner.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning based brain MRI hippocampus detecting and dividing method. '(Drawing includes non-English language text)'
DC P31 (Diagnosis, surgery (A61B).); S05 (Electrical Medical Equipment)
MC S05-D02B1
IP A61B-005/055
PD CN108937934-A   07 Dec 2018   A61B-005/055   201905   Pages: 7   Chinese
AD CN108937934-A    CN10427794    07 May 2018
PI CN10427794    07 May 2018
UT DIIDW:2018A0757L
ER

PT P
PN CN108958482-A
TI Convolutional neural network-based similarity action recognition device, has accelerometer module connected to terminal, and server for storing data based on TensorFlow platform, where recognition result is returned to Android client module.
AU YANG M
   YANG S
AE UNIV FUZHOU (UFZU-C)
GA 2018A0283W
AB    NOVELTY - The device has an accelerometer module connected to a mobile terminal. The accelerometer module is placed on a subject, where collected data is transmitted to Android (RTM: Linux-based operating system) client module through a Bluetooth. The Android (RTM: Linux-based operating system) client module sends the collected data to a local storage part, where a data file is transmitted to a server through a wireless network. The server stores the data based on a TensorFlow (RTM: Open source software library) platform, where an action recognition result is returned to the Android (RTM: Linux-based operating system) client module.
   USE - Convolutional neural network-based similarity action recognition device.
   ADVANTAGE - The device can automatically extract feature values for different application scenarios without manually designing feature values for different scenes and ensure better recognition effect on similarity actions.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a convolutional neural network-based similarity action recognition method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an operation of a convolutional neural network-based similarity action recognition device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-C03C; T01-J05B4P; T01-N01D2; T01-N01D3; T01-N03; W01-A06C4
IP G06F-003/01; G06N-003/04; G06N-003/08
PD CN108958482-A   07 Dec 2018   G06F-003/01   201905   Pages: 9   Chinese
AD CN108958482-A    CN10690728    28 Jun 2018
PI CN10690728    28 Jun 2018
UT DIIDW:2018A0283W
ER

PT P
PN CN108960063-A
TI Video-oriented event relation code natural language description algorithm, has set of rules for performing descriptor decoding operation, and describing described natural language of event according to descriptor decoding operation.
AU YUAN C
   YANG D
AE UNIV TSINGHUA SHENZHEN GRADUATE SCHOOL (UYQI-C)
GA 2018A0246B
AB    NOVELTY - The algorithm has a set of rules for extracting depth characteristic using a three-dimensional (3D) convolutional neural network. A depth characteristic vector is determined based on the depth characteristic. A depth signature sequence is determined according to the depth characteristic vector. Event selecting operation is performed based on the depth signature sequence. An attention model is established. Descriptor decoding operation is performed by using an LSTM adaptive decoder. Described natural language of the event is described according to the descriptor decoding operation.
   USE - Video-oriented event relation code natural language description algorithm.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a video-oriented event relation code natural language description algorithm. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-D02; T01-E01B; T01-E03; T01-E04; T01-J10B2; T01-J16C3
IP G06K-009/00; G06N-003/04
PD CN108960063-A   07 Dec 2018   G06K-009/00   201905   Pages: 9   Chinese
AD CN108960063-A    CN10558731    01 Jun 2018
PI CN10558731    01 Jun 2018
UT DIIDW:2018A0246B
ER

PT P
PN CN108958892-A
TI Method for creating Docker container for deep learning operation, involves selecting Docker image by user from mirrored warehouse for pushing, and creating Docker container on computing node in cluster by using pushed Docker image.
AU YUAN S
AE ZHENGZHOU YUNHAI INFORMATION TECHNOLOGY (INEI-C)
GA 2018A0275B
AB    NOVELTY - The method involves receiving and storing a to-be trained Docker image by using a mirrored warehouse. Deep learning framework driving program is installed for training the to-be trained Docker image by using required frame-dependencies. Secure shell protocol service is configured. Deep learning operation is scheduled according to idle resource condition of a computing node in a cluster. The Docker image is selected by the user from the mirrored warehouse for pushing when deep learning operation is scheduled to the computing node. A Docker container is created on the computing node in the cluster by using the pushed Docker image.
   USE - Method for creating a Docker container for a deep learning operation.
   ADVANTAGE - The method enables conveniently creating the required Docker container to reduce time and energy consumption during Docker-container creation.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a device for creating a Docker container for a deep learning operation.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for creating Docker container for deep learning operation. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems); W04 (Audio/Video Recording and Systems)
MC T01-F02C1; T01-F03; T01-F05G3; T01-J30A; W01-A03B; W01-A06F3; W01-A06G2; W04-W05A
IP G06F-009/455
PD CN108958892-A   07 Dec 2018   G06F-009/455   201905   Pages: 10   Chinese
AD CN108958892-A    CN10918890    14 Aug 2018
PI CN10918890    14 Aug 2018
UT DIIDW:2018A0275B
ER

PT P
PN CN108965731-A
TI Method for processing dark image by utilizing mobile terminal, involves establishing neural network model by preset short-exposure image and preset normal image, and outputting processed picture corresponding to short-exposure image.
AU ZHANG G
AE OPPO GUANGDONG MOBILE COMMUNICATION CO (GDOP-C)
GA 2018A1311H
AB    NOVELTY - The method involves obtaining current environment information of a camera and a to-be-photographed image. The to-be-photographed image is input into a trained convolutional neural network model to obtain a processed image when the current environment information satisfies a predetermined condition. The convolutional neural network model is established by using a preset short-exposure image and a preset normal image. The processed image is output corresponding to the preset short-exposure image, where the preset short-exposure image is selected as quality information of the normal image.
   USE - Method for processing a dark image by utilizing a terminal (claimed) i.e. mobile terminal (from drawings).
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for processing a dark image by utilizing a terminal
   (2) a computer-readable storage medium for storing a set of instructions for processing a dark image by utilizing a terminal.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for processing a dark image by utilizing a terminal. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J10B1; T01-S03; W04-M01D5
IP H04N-005/235; H04N-005/243
PD CN108965731-A   07 Dec 2018   H04N-005/235   201905   Pages: 16   Chinese
AD CN108965731-A    CN10961442    22 Aug 2018
PI CN10961442    22 Aug 2018
UT DIIDW:2018A1311H
ER

PT P
PN CN108944650-A
TI High beam and low beam illumination principle based car lamp opening state judging method, involves establishing machine learning model, determining road continuously open state by using high beam and low beam identification classifiers.
AU ZHU H
   WANG D
   DU S
   HUANG Y
   XUE S
   PAN S
AE ZHEJIANG ANXIE INTELLIGENT SIC-TECH CO (ZHEJ-Non-standard)
GA 2018A0602K
AB    NOVELTY - The method involves obtaining recognition capability of an image. Frame picture display characteristics of a high light are determined. A vehicle area is extracted by performing video moving target tracking process. Light sequence is obtained. Video frame sequence length of a car light area is determined. Car video frame sequence is collected. Positive and negative samples of a training model are obtained. A machine learning model or deep learning network model is established. Road continuously open state is determined by using high beam and low beam identification classifiers.
   USE - High beam and low beam illumination principle based car lamp opening state judging method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a high beam and low beam illumination principle based car lamp. '(Drawing includes non-English language text)'
DC W04 (Audio/Video Recording and Systems); X22 (Automotive Electrics)
MC W04-W05A; X22-B01
IP B60Q-001/14
PD CN108944650-A   07 Dec 2018   B60Q-001/14   201905   Pages: 6   Chinese
AD CN108944650-A    CN10934489    14 Aug 2018
PI CN10934489    14 Aug 2018
UT DIIDW:2018A0602K
ER

PT P
PN CN108959603-A
TI Depth neural network based personal recommending system, has personalized recommending module for calculating multi-user item related degree of items, where personalized recommending module generates recommendation list of items.
AU ZI Y
   LI Y
   SUN H
   LU L
   YOU X
AE BEIJING GRAPHIC COMMUNICATION INST (BGCO-C)
GA 2018A02575
AB    NOVELTY - The system has a depth neural network fusion sequence set generating module for performing character vectorization on multi-source heterogeneous data in multi-source heterogeneous data source. The depth neural network fusion sequence set generating module obtains user character vector of a corresponding user and an item of corresponding item, where the depth neural network fusion sequence set generating module performs deep neural network learning and scoring on user character vector. A personalized recommending module calculates multi-user item related degree of items based on collaborative filtering algorithm, where the personalized recommending module generates recommendation list of items.
   USE - Depth neural network based personal recommending system.
   ADVANTAGE - The system improves accuracy of recommendation process, and realizes accurate personalized recommendation by collaborative filtering algorithm so as to improve personalized recommendation efficiency and utilization feeling of users.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a depth neural network based personal recommending method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a depth neural network based personal recommending system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-E03; T01-J04C; T01-J05B4B; T01-J07B; T01-N01B3
IP G06F-017/30; G06N-003/02
PD CN108959603-A   07 Dec 2018   G06F-017/30   201905   Pages: 23   Chinese
AD CN108959603-A    CN10769873    13 Jul 2018
PI CN10769873    13 Jul 2018
UT DIIDW:2018A02575
ER

PT P
PN CN108932715-A
TI Optimization method for segmentation of coronary artery angiography based on deep learning, involves optimizing segmentation result of coronary angiography by network structure combining cascade module and pixel recovery module.
AU XU B
   YANG R
   WANG X
   CHEN D
   YE D
AE BEIJING HONGYUN ZHISHENG TECHNOLOGY CO (BEIJ-Non-standard)
GA 2018994264
AB    NOVELTY - The method involves using a tensor object to store coronary angiograms. The calculation in the neural network is accelerated by a graphics processing unit (GPU) to obtain the segmentation result. The segmentation result of the coronary angiography is optimized by a network structure combining a cascade module and a pixel recovery module added in the neural network. A cascading module is comprised of a fixed number of cascading layer connections and is proportionally added to the neural network. A normalized layer of a first cascading layer is normalized.
   USE - Optimization method for segmentation of coronary artery angiography based on deep learning.
   ADVANTAGE - The accuracy of image segmentation is ensured. The duration is greatly shortened. The segmentation accuracy is improved.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram of the optimization method for segmentation of coronary artery angiography based on deep learning. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-J10B1; T01-J10B2; T01-N01B3
IP G06T-007/10; G06T-005/00; G06N-003/04; G06N-003/08
PD CN108932715-A   04 Dec 2018   G06T-007/10   201905   Pages: 10   Chinese
AD CN108932715-A    CN10766732    13 Jul 2018
PI CN10766732    13 Jul 2018
UT DIIDW:2018994264
ER

PT P
PN CN108932712-A
TI Rotor winding quality detecting system used widely in industrial production, has image detection module that uses trained neural network to perform quality detection on rotor winding image to detect.
AU ZHANG X
   YAN S
   JIA Y
   ZHU Y
   CHEN G
AE UNIV SOUTHEAST (UYSE-C)
GA 2018994265
AB    NOVELTY - The system has image pre-processing module for dividing the rotor winding images located by the image template to obtain an image set of the portion to detect. The image of each portion detected is qualified to mark the image collections of the portions to detect of the mark as a training set. The feature extracting module extracts texture of each portion of image to detect using LBP method, neural network training module. The texture characteristic of the detected portion image as the input of the convolutional neural network that outputs is qualified or unqualified classification mark. The convolutional neural network is obtained by training the weights and bias of the optimal convolutional neural network. The image detection module uses trained neural network to perform quality detection on rotor winding image to detect.
   USE - Rotor winding quality detecting system used widely in industrial production.
   ADVANTAGE - The weight parameter of the network system is optimized by learning the texture information of the rotor winding. The detection and recognition rate of the rotor winding qualification is greatly improved, especially for those components with poor reflection.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a quality detection method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a structure schematic diagram of a quality detecting system. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B1; T01-J10B2A; T01-N01B3
IP G06T-007/00; G06T-007/44
PD CN108932712-A   04 Dec 2018   G06T-007/00   201905   Pages: 14   Chinese
AD CN108932712-A    CN10651213    22 Jun 2018
PI CN10651213    22 Jun 2018
UT DIIDW:2018994265
ER

PT P
PN CN108921060-A
TI Deep learning based intelligent motor vehicle outline lamp position identifying method, involves obtaining video stream, and judging whether motor vehicle utilizes outline lamp corresponding to number plate according to outline lamp rule.
AU GAO Z
   CHEN L
   XU X
AE ANHUI TI-SAFT INFORMATION TECHNOLOGY CO (ANHU-Non-standard)
GA 201898195J
AB    NOVELTY - The method involves obtaining a video stream from a traffic monitoring device, where the video stream comprises multi-frame images. A number plate of a motor vehicle is identified in each frame image by utilizing a pre-trained number plate recognition neural network model. A number plate position of the motor vehicle is identified in each frame image corresponding to a recognized number plate. Tracking process of the motor vehicle is performed corresponding to an identified number plate. A neural network model is identified according to a pre-trained outline lamp. An outline lamp of the motor vehicle is identified in each frame image. The identified number plate is matched with an identified outline lamp. A state of the outline lamp is preset according to travel distance of the motor vehicle license corresponding to the number plate. Judgment is made to check whether the motor vehicle correctly utilizes the outline lamp corresponding to the number plate according to outline lamp rule.
   USE - Deep learning based intelligent motor vehicle outline lamp position identifying method.
   ADVANTAGE - The method enables intelligently identifying whether the motor vehicle correctly utilizes the outline lamp according to preset regulations so as to increase management strength of utilizing the outline lamp.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a deep learning based intelligent motor vehicle outline lamp position identifying system
   (2) a storage medium for storing a set of instructions for identifying intelligent motor vehicle outline lamp position based on deep learning.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based intelligent motor vehicle outline lamp identifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J07D3A; T01-J10B2A; T01-N01B3; T01-N02B2; T04-D07D5
IP G06K-009/00; G06N-003/04
PD CN108921060-A   30 Nov 2018   G06K-009/00   201905   Pages: 13   Chinese
AD CN108921060-A    CN10632538    20 Jun 2018
PI CN10632538    20 Jun 2018
UT DIIDW:201898195J
ER

PT P
PN CN108922548-A
TI In-depth learning based intelligent bird and frog monitoring method, involves performing image recognition and statistical analysis processes on visual language map by computer server to generate daily monitoring table.
AU ZHAO J
   SUN Y
   SU H
   CHEN X
AE SHENZHEN LANDSCAPE CO LTD (SHEN-Non-standard)
GA 2018990385
AB    NOVELTY - The method involves arranging an outdoor sound collecting device in a monitoring area, where outdoor sound collecting device comprises a wireless communication module i.e. Wireless fidelity (WiFi) Carrier Sense Multiple Access (CSMA)/CA mechanism. Collection of bird voice and frog voice is triggered by the outdoor sound collecting device through a voice triggering module. An audio file of the bird voice and frog voice is wirelessly transmitted to a computer server by the wireless communication module. The audio file is converted into a visual language map by the computer server. Image recognition and statistical analysis processes are performed on the visual language map by the computer server to generate a daily monitoring table. The audio file is stored as uncompressed Waveform Audio (WAV) format. Long-distance wireless transmission is realized by the wireless communication module based on IEEE 802.11g protocol code.
   USE - In-depth learning based intelligent bird and frog monitoring method.
   ADVANTAGE - The method enables reducing labor cost and material resources during artificial ecological monitoring operation, shortening monitoring time and limiting frequency, improving data processing efficiency, and satisfying professional skill requirements of identification staff.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating an in-depth learning based intelligent bird and frog monitoring method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W01 (Telephone and Data Transmission Systems); W04 (Audio/Video Recording and Systems)
MC T01-J03; T01-J10B2A; T01-N01B3; T01-N01D1; T01-N01D2; T01-N01D3; T01-N02B2; T04-L07; W01-A06C4E; W04-V04A3; W04-V05; W04-W05A
IP G10L-017/26; G10L-021/10
PD CN108922548-A   30 Nov 2018   G10L-017/26   201905   Pages: 13   Chinese
AD CN108922548-A    CN10948553    20 Aug 2018
PI CN10948553    20 Aug 2018
UT DIIDW:2018990385
ER

PT P
PN CN108924090-A
TI Convolutional neural network based shadowsocks flow rate detection method, involves obtaining shadowsocks flow by grasping tool, forming convolutional neural network model, and obtaining final calculation model.
AU ZOU F
   ZHU C
   XIONG Y
   LI L
   WU Y
   QI K
   YI P
AE UNIV SHANGHAI JIAOTONG (USJT-C)
GA 201898122N
AB    NOVELTY - The method involves obtaining shadowsocks flow by a grasping tool. A flow splitting unit is used to split TCP flow. Payload of the TCP flow and decimal number i.e. data parameter, are extracted. Judgment is made to check whether the TCP flow is matched with the shadowsocks flow. Convolutional neural network model is formed. A final calculation model is obtained, where the shadowsocks flow is greater than 1 GB. Actual transmission content of the payload is obtained. Parameter input of a convolutional neural network is determined. TCP stream transmission is carried out by a client end of the shadowsocks flow and a remote server.
   USE - Convolutional neural network based shadowsocks flow rate detection method.
   ADVANTAGE - The method enables extracting traffic, and detecting decisive characteristics of the shadowsocks flow.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram illustrating a convolutional neural network based shadowsocks flow rate detection method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-N01D2; T01-N01D3
IP H04L-029/06; H04L-012/26; G06N-003/04; G06N-003/08
PD CN108924090-A   30 Nov 2018   H04L-029/06   201905   Pages: 6   Chinese
AD CN108924090-A    CN10565176    04 Jun 2018
PI CN10565176    04 Jun 2018
UT DIIDW:201898122N
ER

PT P
PN CN108898157-A
TI Classification method of radar graph representation of numerical data based on convolutional neural network, involves representing numerical data as image data and inputting into convolutional neural network model for classification.
AU CHENG C
   REN J
AE UNIV ZHEJIANG SCI TECH (UZST-C)
GA 201897039C
AB    NOVELTY - The method involves drawing a radar function corresponding to the numerical data by using a polar function, and establishing the image digitized data set train by using an obtained radar chart. A basic structure of a convolutional neural network is constructed. A convolutional neural network model is obtained by using the obtained picture digitized data set train. The numerical data to be classified is represented as image data, and input into a convolutional neural network model for classification.
   USE - Classification method of radar graph representation of numerical data based on convolutional neural network.
   ADVANTAGE - The sorting accuracy of the numerical data is effectively increased compared with the existing driving data classification method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating the classification method of the radar graph representation of numerical data based on the convolutional neural network. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-J05B2; T01-J05B4F; T01-J10B2
IP G06K-009/62; G06N-003/04; G06N-003/08
PD CN108898157-A   27 Nov 2018   G06K-009/62   201905   Pages: 15   Chinese
AD CN108898157-A    CN10525151    28 May 2018
PI CN10525151    28 May 2018
UT DIIDW:201897039C
ER

PT P
PN CN108896450-A
TI Atmospheric aerosol inversion method based on multi-angle multi-channel polarization information, involves obtaining results of atmospheric aerosol inversion, establishing test data set, and inputting deep stack sparse self-encoder network.
AU FANG W
   ZHANG D
   YI W
   DU L
   HUANG H
   SUN X
AE CHINESE ACAD SCI HEFEI INST PHYS SCI (CAWZ-C)
GA 201897080W
AB    NOVELTY - The method involves unsupervised training of deep stack sparse automatic encoder with training samples without two dimensional (2D) label scores. The network parameters of the stack sparse automatic encoder are obtained. The supervised learning is provided to fine-tune the 5-layer deep stack sparse self-encoder network. Training of a 5-layer deep stack sparse self-encoder network is performed using a tag sample set. The results of atmospheric aerosol inversion are obtained, a test data set is established, and 5-layer deep stack sparse self-encoder network is inputted. The output aerosol optical thickness and the thickness of the particles are set in two-dimensional predicted values.
   USE - Atmospheric aerosol inversion method based on multi-angle multi-channel polarization information combined with deep learning technology.
   ADVANTAGE - The atmospheric aerosol inversion method adopts a deep network model of stack sparse self-encoder to realize the inversion of aerosol thickness and thickness-to-particle ratio, and improves the inversion calculation efficiency and processing speed.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the atmospheric aerosol inversion process. (Drawing includes non-English language text)
DC S03 (Scientific Instrumentation); T01 (Digital Computers)
MC S03-F05; T01-N01B3A
IP G01N-015/00; G06N-003/04; G06N-003/08
PD CN108896450-A   27 Nov 2018   G01N-015/00   201905   Pages: 15   Chinese
AD CN108896450-A    CN10454559    14 May 2018
PI CN10454559    14 May 2018
UT DIIDW:201897080W
ER

PT P
PN CN108897823-A
TI Personalized product retrieval method based on deep learning attention mechanism, involves sorting all distance values from high to low, and returning item corresponding to first n-distance value to user.
AU GUO Y
   CHENG Z
   NIE L
   WANG Y
   MA J
AE UNIV SHANDONG (USHA-C)
GA 201897047A
AB    NOVELTY - The method involves updating current user's long-term preference to obtain an updated long-term preference model based on the attention mechanism, The short-term preference model based on attention mechanism, long-term preference model based on attention mechanism and the current query are combined. The interaction is learned through the multi-layer fully connected network. The recombined query representation is obtained and distance function is adopted to define the degree of relevance of all commodities to the current query. The distance value between all the commodities and the current query is obtained after training the multi-layer fully connected network, and all distance values are sorted from high to low. The item corresponding to the first n-distance value is returned to the user.
   USE - Personalized product retrieval method based on deep learning attention mechanism.
   ADVANTAGE - The accuracy of retrieval can be improved, thus improving the retrieval experience of the user.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a personalized product retrieval device based on deep learning attention mechanism.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the personalized product retrieval method based on deep learning attention mechanism. (Drawing includes non-English language text)
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J05B4P; T01-N01A2F; T01-N01B3; W04-W05A
IP G06F-017/30; G06N-003/04
PD CN108897823-A   27 Nov 2018   G06F-017/30   201905   Pages: 11   Chinese
AD CN108897823-A    CN10645528    21 Jun 2018
PI CN10645528    21 Jun 2018
UT DIIDW:201897047A
ER

PT P
PN CN108898155-A
TI Synthetic aperture radar (SAR) image target recognition method based on wavelet threshold denoising combined with convolutional neural network, involves reconstructing SAR target and carrying out target recognition of SAR target image.
AU HUAN R
   YANG P
   BAO C
   GE L
AE UNIV ZHEJIANG TECHNOLOGY (UYZT-C)
GA 201897039E
AB    NOVELTY - The method involves reconstructing a synthetic aperture radar (SAR) target image by low-frequency coefficients of wavelet decomposition and high-frequency coefficients of threshold quantization. The target recognition of SAR target image reconstructed by wavelet transform is carried out by a convolutional neural network. The convolutional neural network is comprised of an input layer, a convolutional layer, a maximum pooling layer, a full connection layer and an output layer, and uses ReLU as activation function. The convolutional layer, the maximum pooling layer and the full connection layer are configured as hidden layers.
   USE - Synthetic aperture radar (SAR) image target recognition method based on wavelet threshold denoising combined with convolutional neural network.
   ADVANTAGE - The SAR image target recognition method reduces the influence of speckle noise on recognition precision, reduces the artificial design, and improves the SAR image target recognition effect.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating the SAR image target recognition method based on wavelet threshold denoising combined with convolutional neural network. (Drawing includes non-English language text)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J04B1; T01-J10B1; T01-J10B2A; T01-J10B3A; T04-D03A; T04-D04
IP G06K-009/62; G06K-009/40; G06N-003/04
PD CN108898155-A   27 Nov 2018   G06K-009/62   201905   Pages: 20   Chinese
AD CN108898155-A    CN10479461    18 May 2018
PI CN10479461    18 May 2018
UT DIIDW:201897039E
ER

PT P
PN CN108898137-A
TI Natural image character recognition method based on deep neural network, involves obtaining final recognition result according to weighted value ranking.
AU HUANG K
AE HUANG K (HUAN-Individual)
GA 201897039U
AB    NOVELTY - The method involves collecting a multi-frame image of a natural scene to be recognized, and framing the multi-frame image of the same target according to each pixel point. An open source character detection image library is used to train a region proposal network (RPN) network to obtain the deep neural network model as the character locator. A three-interface convolutional neural networks (CNN) network is trained using a character image database containing printed matter. A character-based long-short term memory (LSTM) prediction model is trained as a rationality determiner. The continuous Chinese in the preliminary recognition result is inputted as a character sequence to the rationality determiner. The natural language prediction result is obtained. The natural language prediction result and the preliminary recognition result are weighted according to preset weights to obtain a weighted value. The final recognition result is obtained according to the weighted value ranking.
   USE - Natural image character recognition method based on deep neural network.
   ADVANTAGE - The natural image character recognition method based on deep neural network to improve the detection speed and recognition accuracy of characters in the natural image is provided. The strong robustness is provided to occlusion and partial deletion of characters in the image. The lot of computing time for online testing is avoided.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a natural image character recognition system based on the deep neural network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic diagram of the depth neural network based natural image character recognition system. (Drawing includes non-English language text)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B4F; T01-J10B2A; T01-J16C3; T04-D02; T04-D04
IP G06K-009/34; G06K-009/62
PD CN108898137-A   27 Nov 2018   G06K-009/34   201905   Pages: 13   Chinese
AD CN108898137-A    CN10517976    25 May 2018
PI CN10517976    25 May 2018
UT DIIDW:201897039U
ER

PT P
PN CN108898087-A
TI Human face training method of key point positioning model, involves stopping training of CNN model and storing CNN model when loss function value of CNN model is less than preset threshold.
AU JIANG M
AE TENCENT TECHNOLOGY SHENZHEN CO LTD (TNCT-C)
GA 201897040X
AB    NOVELTY - The method involves constructing (201) a convolutional neural network CNN model for face key point positioning. The face key point positioning is performed (202) on the training sample by using the CNN model to obtain a predicted position of a face key point in the training sample. A loss function value is calculated (203) corresponding to each of the n types of face key points according to a predicted position and a real position of the face key points classified by each of the n types of classifications. A loss function value of the CNN model is calculated (204) according to a loss function value corresponding to each of the n classified face key points. The training of the CNN model is stopped (205) and the CNN model is stored when the loss function value of the CNN model is less than a preset threshold.
   USE - Human face training method of key point positioning model.
   ADVANTAGE - The model volume is reduced by constructing a slim and long CNN model while ensuring that the positioning accuracy is not lost as much as possible.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) a training device for human face key point positioning model;
   (2) a computer device; and
   (3) a computer readable medium storing instruction for human face training of key point positioning model.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a process of human face training of key point positioning model. (Drawing includes non-English language text)
   Step for constructing a convolutional neural network CNN model for face key point positioning (201)
   Step for performing face key point positioning on the training sample by using the CNN model to obtain a predicted position of a face key point in the training sample (202)
   Step for calculating loss function value corresponding to each of the n types of face key points according to a predicted position and a real position of the face key points classified by each of the n types of classification (203)
   Step for calculating loss function value of the CNN model according to a loss function value corresponding to each of the n classified face key points (204)
   Step for stopping training of the CNN model and saving the CNN model when the loss function value of the CNN model is less than a preset threshold (205)
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B2; T01-L02; T01-N01B3; T01-S03
IP G06K-009/00; G06N-003/04
PD CN108898087-A   27 Nov 2018   G06K-009/00   201905   Pages: 20   Chinese
AD CN108898087-A    CN10650499    22 Jun 2018
PI CN10650499    22 Jun 2018
UT DIIDW:201897040X
ER

PT P
PN CN108898059-A
TI Method for recognizing flowers for use in android system, involves collecting image of target flower, and determining flower to which Euclidean distance image satisfies threshold condition as target flower.
AU LI W
   ZHANG M
   WEI L
   CHEN J
   WEN L
   SUN Y
AE SHANGHAI INST TECHNOLOGY (SHGH-C)
GA 201897041N
AB    NOVELTY - The method involves collecting (110) images of N kinds of flowers. A flower database is constructed. The image preprocessing is performed (120) on each image in the flower database. Each image in the flower database is inputted into a deep convolutional neural network. The feature extraction is performed (130) on the deep convolution network to obtain a feature vector of each image. The deep convolutional neural network is obtained after multiple training iterations. An image of the target flower is collected (140). A Euclidean distance between a feature vector of the image of the target flower and a feature vector of each image in the flower database is collected. The flower to which the Euclidean distance image satisfies the threshold condition is determined as the target flower.
   USE - Method for recognizing flowers for use in android (RTM: mobile operating system developed by Google) system.
   ADVANTAGE - The convolutional neural network and a flower database are constructed to quickly and accurately identify flower species.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a device for recognizing flowers for use in android system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the process for recognizing flowers under android system. (Drawing includes non-English language text)
   Step for collecting images of N kinds of flowers (110)
   Step for performing image preprocessing (120)
   Step for performing feature extraction (130)
   Step for collecting image of target flower (140)
DC T01 (Digital Computers)
MC T01-F05G; T01-J04B2; T01-J05B4F; T01-J10B2A; T01-N01B3; T01-N02B1E; T01-N03A2
IP G06K-009/00
PD CN108898059-A   27 Nov 2018   G06K-009/00   201905   Pages: 14   Chinese
AD CN108898059-A    CN10538860    30 May 2018
PI CN10538860    30 May 2018
UT DIIDW:201897041N
ER

PT P
PN CN108898175-A
TI Computer-aided model construction method for gastric cancer pathological slice based on deep learning algorithm, involves saving optimal model and measuring accuracy of model classification using test set data.
AU LIU B
   ZHAO Y
AE UNIV BEIJING TECHNOLOGY (UYBT-C)
GA 201897038Y
AB    NOVELTY - The method involves performing correlation preprocessing on a gastric cancer pathological slice data set. The gastric cancer pathological slice data set is normalized using the mean and variance of the image net data set. The training algorithm of the model is adjusted to use the standard Adam optimization algorithm to train the model. The loss function is set to add a cross-entropy function. The two epochs on the gastric cancer pathological slice dataset are trained to obtain the basic ability to extract the features of pathological sections of gastric cancer. The attention module is added between the first, second, and third dense blocks of the model. The model is selected with the smallest loss of the verification set as the final result. The optimal model is saved, and the accuracy of the model classification is measured using the test set data.
   USE - Computer-aided model construction method for gastric cancer pathological slice based on deep learning algorithm.
   ADVANTAGE - The main optimization of the model during formal training is better focused on how to extract the features of the diseased area. The data utilization efficiency is improved. The model identification precision is higher. The model parameters are few, and the calculation efficiency is high when the sample identification is performed. The resource occupation is low.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating the process of dense convolution structure in recognition model. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-D03; T01-J04B2; T01-J05B2; T01-J10B2A; T01-J16C2; T01-J30A
IP G06K-009/62
PD CN108898175-A   27 Nov 2018   G06K-009/62   201905   Pages: 12   Chinese
AD CN108898175-A    CN10665639    26 Jun 2018
PI CN10665639    26 Jun 2018
UT DIIDW:201897038Y
ER

PT P
PN CN108896494-A
TI Object recognition instrument based on spectral and depth learning, has display unit which is configured to display three objects with greatest probability of discriminating and to display image.
AU NI X
   CAO C
   CUI X
AE CHINESE ACAD SCI EMOTE SENSING & DIGITAL (CAYS-C)
GA 201897079M
AB    NOVELTY - The instrument has fixed devices, spectral imagers (CCD charge coupled devices), analog-to-digital converters (ADCs), data processors, memory cells and display units. The fixing device is configured as the object identifier integrated device, integrating the spectral imaging instrument and the image processing instrument. The spectral imager CCD is configured to receive a multi-band object reflection spectrum configured in red, green, blue, near-infrared, and infrared. The data processor is configured to match the received spectral data with the spectral database of the storage unit. The storage unit is configured to store the standard spectral library, the trained convolution neural network and most of the objects of the object encountered in life. The display unit is configured to display the three objects with the greatest probability of discriminating and to display the image.
   USE - Object recognition instrument based on spectral and depth learning.
   ADVANTAGE - The instrument can identify the object by combining the spectral analysis technology with the convolutional neural network technology in deep learning.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic diagram illustrating an object recognition instrument based on spectral and depth learning. (Drawing includes non-English language text)
DC S03 (Scientific Instrumentation); T01 (Digital Computers)
MC S03-E04A1; T01-C08; T01-J04B2; T01-J05B4P; T01-J10B2A; T01-J10B3; T01-N01B3
IP G01N-021/27; G06N-003/04
PD CN108896494-A   27 Nov 2018   G01N-021/27   201905   Pages: 5   Chinese
AD CN108896494-A    CN10417233    04 May 2018
PI CN10417233    04 May 2018
UT DIIDW:201897079M
ER

PT P
PN CN108897852-A
TI Method for judging continuity of conversation content, involves inputting first and second similarity matrices into coherence discriminant model and constructing coherence discriminant model based on convolutional neural network.
AU PENG J
   MA Z
   LIAN R
   JIANG D
   HE J
AE BEIJING BAIDU NETCOM SCI & TECHNOLOGY CO (BIDU-C)
GA 201897046N
AB    NOVELTY - The method involves inputting (S100) the above sentence into a sentence in the generated model, to generate the following sentence. A similarity between each of the above sentences and the current sentence is calculated (S200) to construct a first similarity matrix. A similarity between each of the following sentences and the current sentence is calculated (S300) to construct a second similarity matrix. The first similarity matrix and the second similarity matrix are inputted (S400) into a coherence discriminant model to generate a coherent feature parameter of the current sentence. The coherence discriminant model is constructed based on a convolutional neural network.
   USE - Method for judging continuity of conversation content.
   ADVANTAGE - The coherence of two sentences are compared from the semantic dimension and push the user back to the coherent and high-quality reply by using the combination of coherent discriminant model and sentence generation model to solve the problem of coherence of dialogue content.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) a conversation content continuity judging device; and
   (2) a computer-readable storage medium storing instructions for judging continuity of conversation content.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow chart illustrating a method for judging continuity of conversation content. (Drawing includes non-English language text)
   Step for inputting the above sentence into a sentence in the generated model, to generate the following sentence (S100)
   Step for calculating a similarity between each of the above sentences and the current sentence to construct a first similarity matrix (S200)
   Step for calculating a similarity between each of the following sentences and the current sentence to construct a second similarity matrix (S300)
   Step for inputting the first similarity matrix and the second similarity matrix into a coherence discriminant model to generate a coherent feature parameter of the current sentence (S400)
DC T01 (Digital Computers)
MC T01-J05B4P; T01-J11A1; T01-J16C3; T01-N01D2; T01-S03
IP G06F-017/27; G06F-017/30
PD CN108897852-A   27 Nov 2018   G06F-017/30   201905   Pages: 14   Chinese
AD CN108897852-A    CN10694536    29 Jun 2018
PI CN10694536    29 Jun 2018
UT DIIDW:201897046N
ER

PT P
PN CN108900432-A
TI Network popularity based content-aware method involves feeding back identified network flow data to deep neural network- hidden Markov model (DNN-HMM) and updating model parameters to obtain new DNN-HMM model in model update phase.
AU TAN X
   XIE Y
   FEI X
AE UNIV SUN YAT-SEN (UYSY-C)
GA 2018969857
AB    NOVELTY - The method involves collecting the network flow data from an external network and extracting the observation features to obtain training samples in a model training phase. The deep neural network- hidden Markov model (DNN-HMM) model is utilized to model the network popularity, and the training samples are reused to train the model to obtain model parameters. The collected real-time network stream to-be detected is input into the trained DNN-HMM model, in a content recognition stage, so as to output the content category of the network stream. The identified network flow data is feedback to the DNN-HMM model, and the model parameters are updated to obtain a new DNN-HMM model in a model update phase.
   USE - Network popularity based content-aware method.
   ADVANTAGE - The dynamic modeling capability of the hidden Markov model and the powerful nonlinear representation capability of the deep neural network are utilized efficiently. The feasibility of the content-aware process is shown.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating the content-aware process. (Drawing includes non-English language text)
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems)
MC T01-N01B3; T01-N01D2; W01-A06A; W01-A06D
IP H04L-012/24; H04L-012/851
PD CN108900432-A   27 Nov 2018   H04L-012/851   201905   Pages: 19   Chinese
AD CN108900432-A    CN10728170    05 Jul 2018
PI CN10728170    05 Jul 2018
UT DIIDW:2018969857
ER

PT P
PN CN108898112-A
TI Near infrared human face detecting method, involves collecting original image of human face through near infrared camera, and judging whether collected image is detected in human-face detecting model by infrared camera.
AU WANG H
   ZHANG B
AE UNIV CHINESE NORTHEASTERN (UYDB-C)
GA 201897040E
AB    NOVELTY - The method involves collecting an original image as an original sample of a human face through a near infrared camera (S1). An original positive sample printing image is obtained. An original positive sample and an original negative sample are pre-processed (S2) by a human face region detection model. A standard human face image is screened out. A convolutional neural network is trained (S3) to obtain a training human-face detecting model. A convolutional neural network parameter is obtained for extracting facial features of a convolution layer and a neuronal zero activation function layer. Judgment is made to check whether the collected image is detected in the human-face detecting model by the infrared camera (S4).
   USE - Near infrared human face detecting method.
   ADVANTAGE - The method enables reducing parameter amount by the convolutional neural network and size of the model so as to convey the model to a mobile end, and improve wide range of applications.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a near infrared human face detecting system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a near infrared human face detecting method. '(Drawing includes non-English language text)'
   Step for collecting the original image as the original sample of the human face through the near infrared camera (S1)
   Step for pre-processing the original positive sample and the original negative sample by the human face region detection model (S2)
   Step for training the convolutional neural network to obtain the training human-face detecting model (S3)
   Step for judging whether collected image is detected in human-face detecting model by the infrared camera (S4)
DC S03 (Scientific Instrumentation); T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC S03-E04X; T01-J04B2; T01-J10B2; T01-N01B3; T04-D04; T04-D07F1; T04-D07K
IP G06K-009/00; G06K-009/62
PD CN108898112-A   27 Nov 2018   G06K-009/00   201905   Pages: 16   Chinese
AD CN108898112-A    CN10710607    03 Jul 2018
PI CN10710607    03 Jul 2018
UT DIIDW:201897040E
ER

PT P
PN CN108899037-A
TI Animal voiceprint feature extraction method, involves inputting animal speech feature vector into convolutional neural network model for training and obtaining animal voiceprint feature to identify identity of animal.
AU WANG J
   CAI Y
   CHENG N
   XIAO J
AE PINGAN SCI & TECHNOLOGY SHENZHEN CO LTD (PING-C)
GA 201897018Q
AB    NOVELTY - The method involves obtaining (S101) animal voice data. An animal speech feature vector is extracted (S102) from the animal speech data. The animal speech feature vector is inputted (S103) into a convolutional neural network model for training. An animal voiceprint feature is obtained to identify the identity of the animal. The animal voice data is pre-processed to obtain processed animal voice data. A frame-by-frame operation is performed on the processed animal voice data according to a preset time interval to obtain a multi-frame animal voice sequence.
   USE - Animal voiceprint feature extraction method.
   ADVANTAGE - The animal voiceprint features can be accurately extracted, thus improving the animal identification effect.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) a computer device;
   (2) an animal voiceprint feature extraction device; and
   (3) a computer storage medium for extracting animal voiceprint feature.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating an animal voiceprint feature extraction method. (Drawing includes non-English language text)
   Step for obtaining animal voice data (S101)
   Step for extracting animal speech feature vector from animal speech data (S102)
   Step for inputting animal speech feature vector into convolutional neural network model for training (S103)
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-N01B3; W04-V04A3A
IP G10L-017/26; G10L-017/18; G10L-017/04; G10L-017/02
PD CN108899037-A   27 Nov 2018   G10L-017/26   201905   Pages: 19   Chinese
AD CN108899037-A    CN10729268    05 Jul 2018
PI CN10729268    05 Jul 2018
UT DIIDW:201897018Q
ER

PT P
PN CN108897975-A
TI Method for predicting gas content of coalbed methane logging based on deep belief network, involves collecting coal seam logging data of other un-hearted wells, and transmitting to computer.
AU XIANG M
   ZHANG F
   ZUNU P
   SHANG Y
   QI X
   AN R
AE XINJIANG INST ENG (XINJ-Non-standard)
GA 201897043N
AB    NOVELTY - The method involves using coalbed methane logging data to predict the gas content of the coalbed methane reservoir, shallow lateral resistivity, microsphere focusing, density, acoustic time difference, Nine conventional logging data of neutron, natural potential, and natural gamma. The logging data is collected by the field logging instrument, and the logging curve is regarded as a spatial signal changing with depth, which is formed by superimposing the effective signal and the interference signal. The weight matrix of the deep belief network is basically determined After unsupervised learning. The coal seam logging data of other un-hearted wells is collected, and transmitted to the computer of coalbed methane reservoir gas content prediction model algorithm.
   USE - Method for predicting gas content of coalbed methane logging based on deep belief network.
   ADVANTAGE - The method can predict the gas content of coalbed methane logging simply.
   DESCRIPTION OF DRAWING(S) - The drawing shows the flowchart illustrating the method for predicting gas content of coalbed methane logging. (Drawing includes non-English language text)
DC T01 (Digital Computers)
MC T01-J04B1; T01-J15X; T01-N01B3; T01-N01D2; T01-N02B2
IP G06F-017/50; G06F-017/14; G06N-003/04; G06N-003/08
PD CN108897975-A   27 Nov 2018   G06F-017/50   201905   Pages: 14   Chinese
AD CN108897975-A    CN10880131    03 Aug 2018
PI CN10880131    03 Aug 2018
UT DIIDW:201897043N
ER

PT P
PN CN108898140-A
TI Network algorithm based magnetic resonance brain tumor image segmenting method, involves utilizing conditional random field model to calculate tag probability value, and predicting types of probability maps.
AU XING B
   LI Q
   GUAN X
AE UNIV TIANJIN (UTIJ-C)
GA 201897039R
AB    NOVELTY - The method involves performing grayscale normalizing process on three models of brain tumor images for image pre-processing process. Simple grayscale image fusing process is performed as convolutional nuclear energy. Different features of different modalities are learned. A pre-processed image is obtained after utilizing gray-scale fusion as algorithm training and testing data. Full convolutional neural network (FCNN) coarse segmenting algorithm is obtained based on a FCNN network. Energy function is initialized in a conditional random field (CRF) model when a pixel point is originally assigned to a tag probability value. The CRF model is utilized to calculate the tag probability value. Two types of probability maps are predicted by FCNN-4s when the FCNN are modified to obtain fine segmenting fusion result of the CRF.
   USE - FCNN algorithm based magnetic resonance (MR) brain tumor image segmenting method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a network algorithm based magnetic resonance brain tumor image segmenting method. '(Drawing includes non-English language text)'
DC S03 (Scientific Instrumentation); T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC S03-E07A; T01-J04A; T01-J10B2; T01-N01B3A; T04-D02; T04-D04; T04-K03B
IP G06K-009/34; G06K-009/62; G06N-003/04
PD CN108898140-A   27 Nov 2018   G06K-009/34   201905   Pages: 11   Chinese
AD CN108898140-A    CN10590091    08 Jun 2018
PI CN10590091    08 Jun 2018
UT DIIDW:201897039R
ER

PT P
PN CN108898063-A
TI Device for recognition of human body gesture, has identifying module that identifies to be predicted image in human articulation point position, and output module that outputs human gesture identification result information.
AU ZHANG Q
   ZHANG Z
   DONG J
   ZHOU D
   WEI X
   XIA S
   LIU Y
AE UNIV DALIAN (UYDV-C)
GA 201897041J
AB    NOVELTY - The device has an input module (101) that captures human gesture to form an input image. A pre-processing module (102) pre-processes the input image after processing convolutional neural network training predictor for three-stage. A model module (104) stores joint-predictor parameters obtained by training. A feature fusion module (105) joints point adjacent domain characteristic. An identifying module (106) identifies to be predicted image in human articulation point position. An output module (107) outputs human gesture identification result information.
   USE - Device for recognition of human body gesture based on full convolutional neural network.
   ADVANTAGE - The identification precision of node and defects of manual design feature are determined in simple and reliable manner.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a method for recognition of human body gesture based on full convolutional neural network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of the device for recognition of human body gesture based on full convolutional neural network. (Drawing includes non-English language text)
   Input module (101)
   Pre-processing module (102)
   Model module (104)
   Feature fusion module (105)
   Identifying module (106)
   Output module (107)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J10B2A; T01-N01B3; T04-D03; T04-D04; T04-D07D5
IP G06K-009/00; G06K-009/62
PD CN108898063-A   27 Nov 2018   G06K-009/00   201905   Pages: 7   Chinese
AD CN108898063-A    CN10562059    04 Jun 2018
PI CN10562059    04 Jun 2018
UT DIIDW:201897041J
ER

PT P
PN CN108877267-A
TI Vehicle monocular camera intersection detection method, involves obtaining image samples deep neural network input screening set, and establishing trained deep neural network by utilizing descent algorithm.
AU YAN F
   WANG K
   ZOU B
   TANG L
   LI W
AE UNIV WUHAN TECHNOLOGY (WUHT-C)
GA 2018959050
AB    NOVELTY - The method involves mounting a test vehicle forward-view camera with a position sensor. Front road RGB color image sample is received by a typical situation driving vehicle through a camera. The front road RGB color image sample is stored by a position sensor. Vehicle earth ground coordinate position information is collected during driving process. Earth ground coordinate is received by a Gauss plane coordinate system. Position sample set is received by the Gauss plane coordinate system. Constructed road network topological graph is received by the position sample set. Image samples deep neural network input screening set is obtained. A trained deep neural network is established by utilizing descent algorithm.
   USE - Vehicle monocular camera intersection detection method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a vehicle monocular camera intersection detection method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J07D1; T01-J10B2; T01-J10B3B; T01-J10E; T04-D04; T04-D08; T04-E
IP G08G-001/0967; G06K-009/00; G06K-009/62
PD CN108877267-A   23 Nov 2018   G08G-001/0967   201905   Pages: 18   Chinese
AD CN108877267-A    CN10883499    06 Aug 2018
PI CN10883499    06 Aug 2018
UT DIIDW:2018959050
ER

PT P
PN KR1933856-B1
TI System for processing image by using convolutional neural network, has acquisition unit for acquiring video information about given area, and image processing unit for classifying sub sampling layer according to wake up of given area.
AU TAE C S
AE SIJUNG (SIJU-Non-standard)
GA 201902118N
AB    NOVELTY - The system has an image information acquisition unit (100) for acquiring video information about a given area. An image processing unit (200) determines wake up of the given area and image-processes the obtained video information using a convolutional neural network (CNN). A weather analysis section (300) analyzes wake up of the given area based on the image control result of the video information. The image processing unit extracts specific images for video frame according to specific time period and filters the extracted specific images according to meta data. The image processing unit classifies a sub sampling layer according to the wake up of the given area.
   USE - System for processing an image by using a CNN.
   ADVANTAGE - The image processing unit classifies the sub sampling layer according to the wake up of the given area so as to measure fine dust concentration in an accurate manner and prevent generation of air pollution.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a method for processing an image by using a CNN.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a system for processing an image by using a CNN. '(Drawing includes non-English language text)'
   Image information acquisition unit (100)
   Image processing unit (200)
   Weather analysis section (300)
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2C; T01-J10B1; T01-J10B2; T01-J10B3A; T04-D04
IP G06T-003/40; G06K-009/62; G06T-005/00; G06T-007/90
PD KR1933856-B1   31 Dec 2018   G06T-003/40   201904   Pages: 14   
AD KR1933856-B1    KR084070    03 Jul 2017
PI KR084070    03 Jul 2017
UT DIIDW:201902118N
ER

PT P
PN US2019005672-A1; EP3422278-A1; CA3008863-A1; IN201814023541-A; KR2019002344-A; AU2018204033-A1; CN109215070-A; JP2019012503-A; SG10201805009-A1
TI Commercial product size determination device, has estimation unit that estimates actual size of body portion from measured value of size of body portion in photographic image.
AU MCLEAR J
   MALLICK S
   MISHRA P
AE MTG CO LTD (MTGM-Non-standard)
   MTG CO LTD (MTGM-Non-standard)
   MTG CO LTD (MTGM-Non-standard)
   MTG CO LTD (MTGM-Non-standard)
GA 2019004021
AB    NOVELTY - The device has an image acquisition unit that acquires a photographic image showing a commercial product of a known size and a body portion that should wear the commercial product. A detection unit detects a size of the product in the photographic image. A measurement unit measures a size of the body portion in the photographic image. An estimation unit estimates an actual size of the body portion from a measured value of the size of the body portion in the photographic image, based on a ratio between the known size of the product and the size of the product in the photographic image.
   USE - Commercial product size determination device.
   ADVANTAGE - The more the precision of determination by the determination algorithm is improved by machine learning. The precision of learning through deep learning is improved by reflecting feedbacks from users who purchased the ring relating to whether the ring size.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a commercial product size determination program.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic diagram of joints of the fingers detected from another image taken when the card is placed on the hand.
   Rectangular card (300)
   Second joint (310)
DC T01 (Digital Computers)
MC T01-J05A2M; T01-J10A
IP G06T-007/62; G06Q-030/06; A44C-027/00; G01B-011/00; G06T-007/00; G01B-011/02; G01C-011/02; G06T-007/194; G06T-007/60
PD US2019005672-A1   03 Jan 2019   G06T-007/62   201904   Pages: 26   English
   EP3422278-A1   02 Jan 2019   G06Q-030/06   201904      English
   CA3008863-A1   29 Dec 2018   G01B-011/00   201904      English
   IN201814023541-A   04 Jan 2019   G06T-007/00   201905      English
   KR2019002344-A   08 Jan 2019   G06Q-030/06   201906      
   AU2018204033-A1   17 Jan 2019   G01C-011/02   201908      English
   CN109215070-A   15 Jan 2019   G06T-007/60   201908      Chinese
   JP2019012503-A   24 Jan 2019   G06T-007/62   201908   Pages: 17   Japanese
   SG10201805009-A1   30 Jan 2019      201920      English
AD US2019005672-A1    US016039    22 Jun 2018
   EP3422278-A1    EP193027    25 Sep 2017
   CA3008863-A1    CA3008863    19 Jun 2018
   IN201814023541-A    IN14023541    25 Jun 2018
   KR2019002344-A    KR074123    27 Jun 2018
   AU2018204033-A1    AU204033    07 Jun 2018
   CN109215070-A    CN10884858    26 Sep 2017
   JP2019012503-A    JP187569    28 Sep 2017
   SG10201805009-A1    SG10005009    12 Jun 2018
FD  US2019005672-A1 Provisional Application US526702P
PI US526702P    29 Jun 2017
   US016039    22 Jun 2018
DS EP3422278-A1: 
		      (Regional): AL; AT; BE; BG; CH; CY; CZ; DE; DK; EE; ES; FI; FR; GB; GR; HR; HU; IE; IS; IT; LI; LT; LU; LV; MC; MK; MT; NL; NO; PL; PT; RO; RS; SE; SI; SK; SM; TR; BA; ME; MA; MD
CP    EP3422278-A1
      US20130179288-A1      
      US20130278626-A1      
      US6535223-B1   SCHMIDT LAB INC (SCHM-Non-standard)   FOLEY C
      US8908928-B1   HANSEN A S (HANS-Individual)   HANSEN A S
      US9165318-B1   AMAZON TECHNOLOGIES INC (AMAZ)   PAULEY D B, WORLEY C S B, LILJEGREN E A, LARSEN P A, YANG J S, MADER T B
      JP2015093004-A   HITACHI SYSTEMS KK (HSYS)   YAMAUCHI S, YUI T
UT DIIDW:2019004021
ER

PT P
PN WO2018236748-A1
TI Method for reconstructing an image of a subject based on the measured signals obtained by imaging device, involves performing an iterative image reconstruction method to produce intermediate images and to produce the image of the subject.
AU ANASTASIO M
   MATTHEWS T
   KELLY B
AE UNIV WASHINGTON (UNIW-C)
GA 201900095K
AB    NOVELTY - The method involves performing an iterative image reconstruction method to produce the intermediate images and to produce the image of the subject. One selected intermediate image is transformed from the intermediate images using a quasi-projection operator. The quasi- projection operator comprises a deep-learning model configured to map the selected intermediate image to a regularized intermediate image.
   USE - Method for reconstructing an image of a subject based on the measured signals obtained by an imaging device.
   ADVANTAGE - The method involves performing an iterative image reconstruction method to produce the intermediate images and to produce the image of the subject, and hence enhances the quality of images reconstructed from incomplete measurement data.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) a method for producing a quasi-projection operator;
   (2) a system for reconstructing an image of a subject based on measured signals obtained by an imaging device; and
   (3) a non-transitory computer-readable storage media.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart of a deep learning-assisted image reconstruction method.
   Receiving measured data (302)
   Initial reconstruction (304)
   Intermediate reconstruction (306)
   Deep learning projection (310)
   Final reconstruction (312)
DC P31 (Diagnosis, surgery (A61B).); S05 (Electrical Medical Equipment); T01 (Digital Computers)
MC S05-D; T01-J06A; T01-J10B; T01-J16B; T01-J16C1; T01-S03
IP A61B-006/00; G06T-001/40
PD WO2018236748-A1   27 Dec 2018   G06T-001/40   201904   Pages: 37   English
AD WO2018236748-A1    WOUS038070    18 Jun 2018
PI US521670P    19 Jun 2017
DS WO2018236748-A1: 
		      (National): AE; AG; AL; AM; AO; AT; AU; AZ; BA; BB; BG; BH; BN; BR; BW; BY; BZ; CA; CH; CL; CN; CO; CR; CU; CZ; DE; DJ; DK; DM; DO; DZ; EC; EE; EG; ES; FI; GB; GD; GE; GH; GM; GT; HN; HR; HU; ID; IL; IN; IR; IS; JO; JP; KE; KG; KH; KN; KP; KR; KW; KZ; LA; LC; LK; LR; LS; LU; LY; MA; MD; ME; MG; MK; MN; MW; MX; MY; MZ; NA; NG; NI; NO; NZ; OM; PA; PE; PG; PH; PL; PT; QA; RO; RS; RU; RW; SA; SC; SD; SE; SG; SK; SL; SM; ST; SV; SY; TH; TJ; TM; TN; TR; TT; TZ; UA; UG; US; UZ; VC; VN; ZA; ZM; ZW
      (Regional): BW; GH; GM; KE; LR; LS; MW; MZ; NA; RW; SD; SL; ST; SZ; TZ; UG; ZM; ZW; EA; AL; AT; BE; BG; CH; CY; CZ; DE; DK; EE; ES; FI; FR; GB; GR; HR; HU; IE; IS; IT; LT; LU; LV; MC; MK; MT; NL; NO; PL; PT; RO; RS; SE; SI; SK; SM; TR; OA
CP WO2018236748-A1
      US20140363067-A1      
      US20160328643-A1      
      WO2016042466-A2   KONINK PHILIPS NV (PHIG)   GRASS M, KOEHLER T, PROKSA R
UT DIIDW:201900095K
ER

PT P
PN US2018374089-A1; CA3009699-A1
TI Method for transaction analysis, involves computing distance between first and second transaction signatures and performing computer system that comprises memory and processor connected to memory.
AU DUBOUE P A
AE KASISTO INC (KASI-Non-standard)
   KASISTO INC (KASI-Non-standard)
GA 2018A4063A
AB    NOVELTY - The method involves determining (505) an inverse document frequency value for each of the statistically correlated character groups. A first transaction signature and a second transaction signature corresponding to the statistically correlated character groups are generated (507) for a first transaction and a second transaction. A distance between the first and second transaction signature is computed (509). The main portion is performed by computer system comprising memory and processor connected to the memory.
   USE - Method for transaction analysis.
   ADVANTAGE - The signature include a reduced vector of real numbers obtained by a deep learning projection of a larger vector of fixed length of character segments. The derivation component generates transaction signatures for respective transactions which are based on the statistically correlated character groups, and compute distances between the respective transaction signatures.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) a system for transaction analysis; and
   (2) an article of manufacture for transaction analysis.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating the process for transaction analysis.
   Step for extracting character group (501)
   Step for determining character group (503)
   Step for determining inverse document frequency value (505)
   Step for generating first and second transaction signature (507)
   Step for computing distance between first and second transaction signatures (509)
DC T01 (Digital Computers)
MC T01-E01A; T01-F05G3; T01-J03; T01-J04B2; T01-J05A2C; T01-J05B4P; T01-S03
IP G06Q-020/38; G06N-003/08; G06F-017/30; G06F-009/455; G06Q-040/00
PD US2018374089-A1   27 Dec 2018   G06Q-020/38   201904   Pages: 16   English
   CA3009699-A1   27 Dec 2018   G06Q-040/00   201904      English
AD US2018374089-A1    US634212    27 Jun 2017
   CA3009699-A1    CA3009699    27 Jun 2018
PI US634212    27 Jun 2017
UT DIIDW:2018A4063A
ER

PT P
PN US2018374209-A1
TI Method for using machine learning techniques e.g., deep learning, to segment e.g., bone, involves generating tissue mask using set of single-channel tissue maps, and displaying tissue mask or tissue-free volume derived using tissue mask.
AU PATIL B D
   LAMB P
   BHAGALIA R R
   DAS B
AE GENERAL ELECTRIC CO (GENE-C)
GA 2018A41313
AB    NOVELTY - The method involves obtaining multi-channel measurement data from an imaging scanner, processing all or a portion of the multi-channel measurement data using a trained neural network, in which the trained neural network (50) outputs a set of two-dimensional or higher dimensional single-channel tissue maps, generating a tissue mask using the set of single-channel tissue maps, and displaying the tissue mask or a tissue-free volume derived using the tissue mask.
   USE - Method for using machine learning techniques e.g., deep learning, to segment bone, tissue or other types of materials in derived images.
   ADVANTAGE - The deep learning aspects use multi-dimensional features, which help to effectively resolve ambiguity and, and to do so faster, than in conventional segmentation algorithms. The such non-invasive imaging technologies rely on various physical principles to acquire data and to construct images or otherwise represent the observed internal features of the patient/object and such an approach allows, in the training context, information from more than one channel to be used to learn tissue properties, thus improving tissue classification.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) an image processing system; and
   (2) a one or more non-transitory computer-readable media encoding processor-executable routines.
   DESCRIPTION OF DRAWING(S) - The drawing shows the block diagram of the convolutional neural network for bone segmentation.
   Neural network (50)
   Downsampling layers (58D)
   Corresponding unsampling layers (58E)
   Multi-channel inputs (210)
   Single channel output map (212)
DC T01 (Digital Computers)
MC T01-J05B2; T01-J10B2; T01-S03
IP G06T-007/00; G06T-007/11
PD US2018374209-A1   27 Dec 2018   G06T-007/00   201904   Pages: 13   English
AD US2018374209-A1    US634657    27 Jun 2017
PI US634657    27 Jun 2017
UT DIIDW:2018A41313
ER

PT P
PN JP2018205858-A
TI Learning apparatus for learning neural network, has learning unit that relearns neural network based on importance of each intermediate layer of learned neural network.
AU SARUTA T
   TACHI S
   KOMORI Y
AE CANON KK (CANO-C)
GA 201900271F
AB    NOVELTY - The apparatus (50) has a learning unit that is configured to learn a neural network. An evaluation unit is configured to evaluate the identification precision of an intermediate layer of the learned neural network. A determination unit (503) is configured to determine the importance of each intermediate layer based on the evaluation result with respect to the identification precision of the intermediate layer. The learning unit is configured to relearn the neural network based on the importance of each intermediate layer.
   USE - Learning apparatus for learning neural network e.g. deep neural network.
   ADVANTAGE - The learning apparatus which is configured for learning the neural network with high identification precision is provided.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following:
   (1) a method for learning; and
   (2) a program for learning a neural network.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a function structure of the learning apparatus. (Drawing includes non-English language text)
   Learning apparatus (50)
   Neural network parameter setup unit (500)
   Neural network learning control unit (501)
   Determination unit (503)
   Learning data holding unit (510)
DC T01 (Digital Computers)
MC T01-J10B2; T01-N01B3
IP G06N-003/08; G06T-007/00
PD JP2018205858-A   27 Dec 2018   G06N-003/08   201904   Pages: 23   Japanese
AD JP2018205858-A    JP107451    31 May 2017
PI JP107451    31 May 2017
UT DIIDW:201900271F
ER

PT P
PN CN108960214-A
TI Fingerprint image enhancing binarization method, involves performing characteristic statistics and detail reconstruction on texture local characteristic area by up-sampling unit to generate fingerprint binary gray image.
AU CHEN S
   BI H
AE ZKETCO TECHNOLOGY CO LTD (ZKET-Non-standard)
GA 2018A1331L
AB    NOVELTY - The method involves receiving collected fingerprint image. The fingerprint image is inputted to an enhanced binary model. Fingerprint sample image set and corresponding binary image data set is obtained based on trained convolutional neural network. Texture e part of the fingerprint image is extracted by a downsampling unit in the enhanced binary model. Characteristic statistics and detail reconstruction on the texture local characteristic area is performed by an up-sampling unit in the enhanced binary model to generate a fingerprint binary gray image.
   USE - Fingerprint image enhancing binarization method.
   ADVANTAGE - The method enables realizing better anti-interference ability and robustness and accurate detection and positioning.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a fingerprint image enhancing binarization device
   (2) a computer readable storage medium for storing a set of instructions to execute a fingerprint image enhancing binarization method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a fingerprint image enhancing binarization method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J03; T01-J10B1; T01-J10B2; T04-D03; T04-D07F2
IP G06K-009/00; G06T-007/12; G06N-003/04
PD CN108960214-A   07 Dec 2018   G06K-009/00   201904   Pages: 16   Chinese
AD CN108960214-A    CN10941045    17 Aug 2018
PI CN10941045    17 Aug 2018
UT DIIDW:2018A1331L
ER

PT P
PN CN108961302-A
TI Method for processing image by mobile terminal, involves determining background category, and replacing object to be replaced according to image data corresponding to background category when foreground object includes object to be replaced.
AU CHEN Y
AE OPPO GUANGDONG MOBILE COMMUNICATION CO (GDOP-C)
GA 2018A1332J
AB    NOVELTY - The method involves obtaining a to-be-processed image. A background category and a foreground target of the to-be-processed image are determined based on a convolutional neural network. An object to be replaced is replaced according to image data corresponding to the background category when the foreground object includes an object to be replaced. Feature extraction process is performed on the to-be-processed image by using the convolutional neural network to obtain feature data. The feature data is input to a classification network of the convolutional neural network to perform classification process the to-be-processed image.
   USE - Method for processing an image by a mobile terminal (claimed).
   ADVANTAGE - The method enables processing the image with better appreciation.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for processing an image by a mobile terminal
   (2) a computer readable storage medium for storing a set of instructions for processing an image by a mobile terminal.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for processing an image by a mobile terminal. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J05B2; T01-J10B2; T01-M06A1; W04-M01D
IP G06T-007/194; G06N-003/08; G06N-003/04; H04N-005/232
PD CN108961302-A   07 Dec 2018   G06T-007/194   201904   Pages: 21   Chinese
AD CN108961302-A    CN10779944    16 Jul 2018
PI CN10779944    16 Jul 2018
UT DIIDW:2018A1332J
ER

PT P
PN CN108959512-A
TI Image description network based attribute prediction model, has attribute prediction model unit comprising attribute word distribution information and visual features corresponding to attribute word.
AU DING G
   CHEN H
AE UNIV TSINGHUA (UYQI-C)
GA 2018A1338A
AB    NOVELTY - The model has an attribute prediction model unit for obtaining a prediction result of an attribute word by using image feature according to an attention technique. A grid area characteristic value of a convolutional neural network is extracted from an image characteristic value. A sentence generating model generates a prediction result of the attribute prediction model. A sentence is generated by attention technology. The prediction result of the attribute prediction model unit comprises attribute word distribution information and visual features corresponding to the attribute word.
   USE - Image description network based attribute prediction model.
   ADVANTAGE - The model can solves problem of irrelevant features currently present in attention model image feature redundancy and image content information so as to improve model predictive attribute and image description capability.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for an attribute prediction model based enhanced image description method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of an image description network based attribute prediction model. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J05B4P; T01-J10B1; T01-N01D1B; T01-N01D2
IP G06F-017/30
PD CN108959512-A   07 Dec 2018   G06F-017/30   201904   Pages: 12   Chinese
AD CN108959512-A    CN10684426    28 Jun 2018
PI CN10684426    28 Jun 2018
UT DIIDW:2018A1338A
ER

PT P
PN CN108966352-A
TI Dynamic beam scheduling method for multi-beam satellite communication system, involves extracting batch of data from empirical pool, and performing action decision-making process by using trained network to analyze optimal action strategy.
AU HU X
   WANG Y
   LI X
   WANG W
   LIU S
   ZHANG Y
AE UNIV BEIJING POSTS & TELECOM (UBPT-C)
GA 2018A2859N
AB    NOVELTY - The method involves modeling dynamic beam scheduling problems as a Markov decision process. An optimal action strategy is solved by using a depth enhanced learning algorithm. A data matrix and a time delay matrix are extracted by using a characteristic of a convolutional neural network. A current state is observed at time slot. A batch of data is randomly extracted from an empirical pool. An action decision-making process is performed by using a trained network to analyze the optimal action strategy. A value of an optimal action is obtained by a deep neural network.
   USE - Depth enhanced learning algorithm based dynamic beam scheduling method for a multi-beam satellite communication system.
   ADVANTAGE - The method enables adopting a self-learning algorithm to output current beam scheduling result according to moment of an environment state and unchanging a comprehensive long-term performance maximizing system to reduce transmission data packet waiting time delay.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view illustrating a depth enhanced learning algorithm based dynamic beam scheduling method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W01 (Telephone and Data Transmission Systems); W02 (Broadcasting, Radio and Line Transmission Systems)
MC T01-J16C2; T01-N01B3; W01-A03B; W01-A06C4; W01-A06G2; W02-C03B1A; W02-C03B1B; W02-C03E5; W02-C03G1
IP H04W-072/04; H04W-072/12; H04B-007/185
PD CN108966352-A   07 Dec 2018   H04W-072/04   201904   Pages: 14   Chinese
AD CN108966352-A    CN10734324    06 Jul 2018
PI CN10734324    06 Jul 2018
UT DIIDW:2018A2859N
ER

PT P
PN CN108959270-A
TI Deep learning-based entity linking method, involves obtaining attribute information of to-be-linked entity, and determining whether linked entity is linked with corresponding entity reference based on attribute information.
AU HUA J
   LIU J
   XU C
AE XINHUA ZHIYUN TECHNOLOGY CO LTD (XINH-Non-standard)
GA 2018A13442
AB    NOVELTY - The method involves acquiring a to-be-linked entity reference in a to-be-identified document and extracting a candidate entity set corresponding to an entity reference in a library (S1). A concentrating conceptual similarity between each candidate entity is calculated and extracting the candidate entity with the highest conceptual similarity (S2). Attribute information of to-be-linked entity is obtained. Determination is made to check whether a linked entity is linked with the corresponding entity reference based on attribute information (S3).
   USE - Deep learning-based entity linking method.
   ADVANTAGE - The method enables combining the attribute information of the candidate entity and the concept similarity to determine whether the candidate entity is linked with the entity reference for determining the conceptual similarity between the candidate entity and the entity reference is linked, and realizing model training process automatically learning whether the candidate entity and entity reference to link so that the judgment is more accurate.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning-based entity linking method.
   Step for acquiring an to-be-linked entity reference in a to-be-identified document and extracting a candidate entity set corresponding to an entity reference in a library (S1)
   Step for concentrating conceptual similarity between each candidate entity is calculated and extracting the candidate entity with the highest conceptual similarity (S2)
   Step for obtaining attribute information of to-be-linked entity and determining whether linked entity is linked with corresponding entity reference based on attribute information (S3)
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J11A1; T01-J30A; W04-W05A
IP G06F-017/27
PD CN108959270-A   07 Dec 2018   G06F-017/27   201904   Pages: 17   Chinese
AD CN108959270-A    CN10906886    10 Aug 2018
PI CN10906886    10 Aug 2018
UT DIIDW:2018A13442
ER

PT P
PN CN108960232-A
TI Method for training model of electronic device, involves inputting first detection information to predetermined depth learning model, and obtaining convergence result when convergence result satisfies preset convergence condition.
AU LIU Y
AE OPPO GUANGDONG MOBILE COMMUNICATION CO (GDOP-C)
GA 2018A1331H
AB    NOVELTY - The method involves inputting first detection information and image data to a predetermined depth learning model. The image data is determined by using the predetermined depth learning model. Second detection information of the first detection information is corrected. The image data and the second detection information are obtained by the deep learning model. A convergence result is obtained when the convergence result satisfies a preset convergence condition. Identified target main body type and target position information of the image data are determined in a data training unit.
   USE - Method for training a model of an electronic device (claimed).
   ADVANTAGE - The method enables reducing manual tagging data training set of workload and saving training cost of the deep learning model.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a device for training a model of an electronic device
   (2) a computer readable storage medium for comprising a set of instruction for training a model of an electronic device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a method for training a model of an electronic device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B2; T01-J30A
IP G06K-009/32; G06K-009/62; G06N-099/00
PD CN108960232-A   07 Dec 2018   G06K-009/32   201904   Pages: 17   Chinese
AD CN108960232-A    CN10590113    08 Jun 2018
PI CN10590113    08 Jun 2018
UT DIIDW:2018A1331H
ER

PT P
PN CN108960772-A
TI Deep learning based enterprise evaluation auxiliary method, involves generating market analysis report according to text related to enterprise, and sending market analysis report and competitive product analysis report to client.
AU LU F
AE BEIJING WOOTOU NETWORK TECHNOLOGY CO LTD (BEIJ-Non-standard)
GA 2018A1336W
AB    NOVELTY - The method involves obtaining an enterprise review submitted by a user terminal (S1). Network data collection process is performed (S2) to obtain multiple texts related to an enterprise according to identity identification information of the enterprise. A word vector is generated (S3) by a word2vec tool after each of the text related to the enterprise is segmented. The word vector is input (S4) into a convolution neural network model. A market analysis report is generated (S5) according to the text related to the enterprise. The market analysis report and a competitive product analysis report are sent (S6) to a client.
   USE - Deep learning based enterprise evaluation auxiliary method.
   ADVANTAGE - The method enables reviewing personnel collecting and arranging information, improving working efficiency and working quality of review personnel and reducing threshold of review personnel.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based enterprise evaluation auxiliary system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep learning based enterprise evaluation auxiliary method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J04B2; T01-J05B4P; T01-J10B2; T01-J11A1; T01-N01A2; T01-N01B3; T01-N01D
IP G06Q-010/10; G06F-017/27; G06F-017/30; G06K-009/62
PD CN108960772-A   07 Dec 2018   G06Q-010/10   201904   Pages: 9   Chinese
AD CN108960772-A    CN10680253    27 Jun 2018
PI CN10680253    27 Jun 2018
UT DIIDW:2018A1336W
ER

PT P
PN CN108960289-A
TI Medical image classifying device, has mapping vector mapping library establishing unit established image sample library in database, and training unit for realizing circular iterative training process of convolutional neural network model.
AU LV H
   ZHAO Y
   JIANG R
   ZHANG X
AE UNIV TSINGHUA (UYQI-C)
GA 2018A1331B
AB    NOVELTY - The device has a sample base establishing unit provided with a marking unit for establishing an image sample of a database and marking sort of the image sample. A model training unit trains a deep convolutional neural network model. A mapping vector mapping library establishing unit is established image sample library in the database based on an image input part. A training unit realizes a circular iterative training process of the triple deep convolutional neural network model. A vector distance difference obtaining module obtains a reference image and a similar image.
   USE - Medical image classifying device.
   ADVANTAGE - The device enables improving accuracy of medical image identification.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a medical image classifying method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a medical image classifying device. '(Drawing includes non-English language text)'
DC S05 (Electrical Medical Equipment); T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC S05-G02G3; T01-J05B4F; T01-J10B1; T01-J10B2; T01-J16C1; T01-N01B3; T01-N01E1; T04-D04
IP G06K-009/62; G06N-003/08; G06N-003/06
PD CN108960289-A   07 Dec 2018   G06K-009/62   201904   Pages: 17   Chinese
AD CN108960289-A    CN10586792    08 Jun 2018
PI CN10586792    08 Jun 2018
UT DIIDW:2018A1331B
ER

PT P
PN CN108959375-A
TI Rule and depth learning based knowledge extracting method, involves judging accuracy rate, recall rate and value of extraction result, and performing knowledge extraction continuously until evaluation standard reaches preset standard.
AU MENG T
   LI J
AE NANJING DATAINSIGHT INFORMATION TECHNOLOGY CO LTD (NANJ-Non-standard)
GA 2018A13396
AB    NOVELTY - The method involves defining a relationship between a concept and a domain concept defined by an expert. A knowledge extraction is performed according to a generated rule. A text matching the relationship between the concept and the domain concept is extracted. A deep learning mode is trained according to the text matching the relationship between the concept and the domain concept to obtain more relationships between the concept and the domain concept. An extraction result is marked. An accuracy rate, a recall rate and value of the extraction result are judged. The knowledge extraction is performed continuously until an evaluation standard reaches a preset standard.
   USE - Rule and depth learning based knowledge extracting method.
   ADVANTAGE - The method enables reducing the cold start problem of machine learning and improving the recall rate of the knowledge extraction.
   DESCRIPTION OF DRAWING(S) - The drawing shows a block diagram of a rule and depth learning based knowledge extracting device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-J05B4P; W04-W05A
IP G06F-017/30; G06N-003/04
PD CN108959375-A   07 Dec 2018   G06F-017/30   201904   Pages: 7   Chinese
AD CN108959375-A    CN10505732    24 May 2018
PI CN10505732    24 May 2018
UT DIIDW:2018A13396
ER

PT P
PN CN108961559-A
TI Intelligent goods selling system, has control unit for generating corresponding shopping order according to missing goods purchase order and sends shopping order to user terminal through background server.
AU PENG J
AE SHENZHEN ZHIYIKU TECHNOLOGY CO LTD (SHEN-Non-standard)
GA 2018A1335L
AB    NOVELTY - The system has a sale device connected with a background server. The sale device is provided with a control unit for performing data management process. The control unit determines whether user information passes verification. The control unit sends door opening command to a relay lock to unlock the relay lock and open a door if the user information passes verification. The control unit generates corresponding shopping order according to missing goods purchase order and sends the shopping order to a user terminal through the background server.
   USE - Intelligent goods selling system.
   ADVANTAGE - The system adopts intelligent depth learning technique for merchandise identification accurately.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for an intelligent goods selling method.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic block diagram of an intelligent goods selling system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T05 (Counting, Checking, Vending, ATM and POS Systems)
MC T01-N01A; T01-N01D3; T05-H04; T05-H08A; T05-H08C1
IP G07F-011/62; G06Q-030/06
PD CN108961559-A   07 Dec 2018   G07F-011/62   201904   Pages: 11   Chinese
AD CN108961559-A    CN10556513    01 Jun 2018
PI CN10556513    01 Jun 2018
UT DIIDW:2018A1335L
ER

PT P
PN CN108965805-A
TI Embedded deep learning algorithm based splicing linkage system, has lens for simultaneously acquire images and finding similar feature point of two image overlap regions, and face detection algorithm obtaining current coordinates of face.
AU SUN C
   LIU Z
AE SHENZHEN JVT TECHNOLOGY CO LTD (SHEN-Non-standard)
GA 2018A0119L
AB    NOVELTY - The linkage system has lens for simultaneously acquire images and finding similar feature point of two image overlap regions. A face detection algorithm obtains a current coordinates of the face. A snapshot machine i.e. dual lens high definition (HD) camera, for acquiring shots. An image pre-processing is performed on a distortion and low contrast of the image.
   USE - Embedded deep learning algorithm based splicing linkage system.
   ADVANTAGE - The system achieves splicing and merging of two shots, increasing scope of view and obtaining a natural picture without obvious color difference. The system is adapted to a variety of monitoring environments and operated easily in real-time.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a operation of embedded deep learning algorithm based splicing linkage system. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment); W02 (Broadcasting, Radio and Line Transmission Systems); W04 (Audio/Video Recording and Systems)
MC T01-J10B2; T01-J10B3A; T01-J10B3B; T01-J16C2; T04-D02A; T04-D07F1; T04-D08; W02-F01A5; W04-N05B1
IP H04N-007/18; H04N-005/265; G06T-003/40; G06K-009/00
PD CN108965805-A   07 Dec 2018   H04N-007/18   201904   Pages: 8   Chinese
AD CN108965805-A    CN10748645    10 Jul 2018
PI CN10748645    10 Jul 2018
UT DIIDW:2018A0119L
ER

PT P
PN CN108961218-A
TI Solar silicon sheet mettled area extracting method, involves carrying out sample image classification process, performing mettled area extracting process by image morphology, and obtaining area location information in mettled area.
AU WU Y
   CHEN W
   WU H
AE WUXI VISWIT TECHNOLOGIES CO LTD (WUXI-Non-standard)
GA 2018A1332Y
AB    NOVELTY - The method involves carrying out a sample image classification process. A sample image collecting process is performed by using a convolutional neural network. The collected sample image is processed according to a crystal and non-crystal flower. A sample image rough crystal flower location process is performed in a pattern of an overlapping window. The overlapping window is divided into multiple small windows. A mettled area extracting process is performed by an image morphology. Area location information in the mettled area is obtained.
   USE - Solar silicon sheet mettled area extracting method.
   ADVANTAGE - The method enables increasing recognition rate, realizing mettled area extracting process in an accurate manner and improving silicon plate detection efficiency.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a solar silicon sheet mettled area extracting method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B2; T01-J10B2A; T04-D04
IP G06T-007/00; G06K-009/62; G06N-003/04
PD CN108961218-A   07 Dec 2018   G06T-007/00   201904   Pages: 11   Chinese
AD CN108961218-A    CN10592654    11 Jun 2018
PI CN10592654    11 Jun 2018
UT DIIDW:2018A1332Y
ER

PT P
PN CN108962223-A
TI Method for identifying voice gender based on depth learning by utilizing computer device, involves training ResCNN neural network model corresponding to cross entropy loss function, and performing voice gender prediction.
AU YE Z
   LI X
   XIAO L
   CAI Z
   LIU X
   TAN Y
AE XIAMEN KUAISHANGTONG INFORMATION TECHNOL (XIAM-Non-standard)
GA 2018A01975
AB    NOVELTY - The method involves obtaining voice information. Voice acoustic characteristics are extracted from the voice information. A ResCNN neural network model is constructed. The voice acoustic characteristic is input to the ResCNN neural network model for obtaining gender probability. Judgment is made to check whether the gender probability is compared with authenticity for constructing a cross entropy loss function. The ResCNN neural network model is trained corresponding to the cross entropy loss function. Voice gender prediction is performed by the trained ResCNN neural network model. A time domain signal is converted into time domain-frequency domain information.
   USE - Method for identifying voice gender based on depth learning by utilizing a computer device (claimed).
   ADVANTAGE - The method enables combining the ResCNN neural network and the cross-entropy loss function by deep learning so as to improve voice recognition rate, and accurately identifying gender of section of the voice so as to reduce size of the ResCNN neural network model.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a non transitory computer-readable storage medium for storing set of instructions for identifying voice gender based on depth learning by utilizing a computer device
   (2) a device for identifying voice gender based on depth learning by utilizing a computer device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a method for identifying voice gender based on depth learning by utilizing a computer device. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); W04 (Audio/Video Recording and Systems)
MC T01-C08A; T01-J16B; T01-L02; T01-N01B3; T01-S03; W04-V01; W04-V04A3; W04-V05
IP G10L-015/02; G10L-015/06; G10L-015/16; G10L-025/30; G10L-025/51
PD CN108962223-A   07 Dec 2018   G10L-015/02   201904   Pages: 8   Chinese
AD CN108962223-A    CN10661799    25 Jun 2018
PI CN10661799    25 Jun 2018
UT DIIDW:2018A01975
ER

PT P
PN CN108957331-A
TI Electric automobile battery performance detecting method, involves obtaining to-be-detected battery corresponding relationship between two different parameters, and determining performance parameters of battery based on attenuation model.
AU ZHAO J
AE NIO AUTOMOBILE CO LTD (NIOA-Non-standard)
GA 2018A1340M
AB    NOVELTY - The method involves establishing an electric automobile battery performance attenuation model. To-be-detected battery corresponding relationship between two different parameters is obtained when a charging process is performed. Performance parameters of a to-be-detected battery are determined based on the battery performance attenuation model. A relationship curve is determined closest to a segment. A matching parameter is determined corresponding to the segment. Curves of two subsets are set by using a convolutional neural network.
   USE - Electric automobile battery performance detecting method.
   ADVANTAGE - The method enables determining electric automobile battery end actual usage at real-time so as to delay retirement of battery performance thus improving battery performance.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following:
   (1) a electric automobile battery performance detecting system
   (2) a machine readable storage medium for storing a set of instructions to perform a electric automobile battery performance detecting process
   (3) a computer device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating an electric automobile battery performance detecting method. '(Drawing includes non-English language text)'
DC S01 (Electrical Instruments); T01 (Digital Computers); X16 (Electrochemical Storage); X21 (Electric Vehicles)
MC S01-G06; T01-J07D1; T01-L01; X16-H; X21-A01F; X21-A06
IP G01R-031/36
PD CN108957331-A   07 Dec 2018   G01R-031/36   201904   Pages: 11   Chinese
AD CN108957331-A    CN10466867    16 May 2018
PI CN10466867    16 May 2018
UT DIIDW:2018A1340M
ER

PT P
PN CN108956876-A
TI Flue gas on-line continuous monitoring system measurement time delay correcting method, involves establishing neural network prediction model, and predicting current real-time concentration of pollutants in measured flue gas.
AU ZHENG C
   GAO X
   HUANG Y
   LIU S
   ZHANG Y
   WANG Y
   GUO Y
   WENG W
   WU W
   XU D
   QU R
AE UNIV ZHEJIANG (UYZH-C)
GA 2018A0318A
AB    NOVELTY - The method involves performing space and analyzing binding and time delay calculation processes. A flue gas flow rate and actual length of a sampling pipe in a smoke sampling pipe is measured. Time required for measured flue gas is calculated through the sampling device. A prediction model is established. A smoke historical sampled value is obtained for selecting corresponding quantity according to different pollutants. A neural network prediction model is established through deep learning. Current real-time concentration of pollutants in the measured flue gas is predicted by using iterative prediction process of step rolling.
   USE - Flue gas on-line continuous monitoring system measurement time delay correcting method.
   ADVANTAGE - The method enables improving continuous monitoring system for smoke discharge pollutant and monitoring performance and accuracy in real-time.
   DESCRIPTION OF DRAWING(S) - The drawing shows a front view of a flue gas on-line continuous monitoring system. '(Drawing includes non-English language text)'
DC S03 (Scientific Instrumentation); T01 (Digital Computers)
MC S03-E14N; T01-N01B3; T01-N02B2B
IP G01N-033/00; G06N-003/08
PD CN108956876-A   07 Dec 2018   G01N-033/00   201904   Pages: 12   Chinese
AD CN108956876-A    CN10763844    12 Jul 2018
PI CN10763844    12 Jul 2018
UT DIIDW:2018A0318A
ER

PT P
PN CN108926338-A
TI Deep learning based heart rate predicting method, involves obtaining output predicted ECG signal when long-short-term memory network model is included with long-short-term memory model for each moving state after completing training process.
AU GAO J
   DANG X
   RONG F
   CHEN R
AE UNIV SOUTH CENT NATIONALITIES (USOC-C)
GA 201899554T
AB    NOVELTY - The method involves obtaining a pulse signal and a motion posture signal. The pulse signal and the motion posture signal are pre-trained and inputted to a final long-short-term memory (LSTM) network model. The LSTM model is selected for predicting process in a moving state corresponding to the motion posture signal. An output predicted ECG signal is obtained when the final LSTM network model is included with corresponding LSTM model for each moving state after completing training process. Different moving states are determined corresponding to the motion posture signal of the LSTM model when the moving states are trained.
   USE - Deep learning based heart rate predicting method.
   ADVANTAGE - The method enables realizing predicted ECG signal training and predicting process to the LSTM model to predict an exact heart rate value.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a deep learning based heart rate predicting device.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a deep learning based heart rate predicting method. '(Drawing includes non-English language text)'
DC P31 (Diagnosis, surgery (A61B).); S05 (Electrical Medical Equipment); W04 (Audio/Video Recording and Systems)
MC S05-D01A1; W04-W05A
IP A61B-005/024
PD CN108926338-A   04 Dec 2018   A61B-005/024   201904   Pages: 22   Chinese
AD CN108926338-A    CN10553893    31 May 2018
PI CN10553893    31 May 2018
CP CN108926338-A
      CN105125198-A   CERVINI S (CERV-Individual)   CERVINI S
      CN105590011-A   SHENZHEN MAIDIJIA TECHNOLOGY DEV CO LTD (SHEN-Non-standard)   DAI P, SHEN J
      CN106725376-A   GAO J (GAOJ-Individual)   GAO J, ZHANG C, DANG X, WEI R, ZHENG W, RONG F
      CN107092894-A   SUN E (SUNE-Individual)   SUN E, LI Y, LI H
      CN107405091-A   LIFEQ GLOBAL LTD (LIFE-Non-standard);  OLIVIER L R (OLIV-Individual)   OLIVIER L R
      CN107463878-A   CHENGDU BRAND BIG DATA TECHNOLOGY CO LTD (CHEN-Non-standard)   KANG Q, LIU S, ZHANG X
      US9848823-B2   APPLE INC (APPY)   RAGHURAM K J, SILVA J M, KANARIS A, BHASKARAN B N
UT DIIDW:201899554T
ER

PT P
PN CN108932229-A
TI Method for analyzing financial news tendency, involves processing each tuple to update similarity matching score and base dictionary, applying Baidu search for name, and determining query update score to be greater than threshold value.
AU LV X
   DONG Z
AE UNIV BEIJING INFORMATION SCI & TECHNOLOG (UYBX-C)
GA 2018994370
AB    NOVELTY - The method involves identifying a candidate office name, classifying an extraction key sentence and adopting an LSTM model. A news text to-be processed is decomposed as multiple tuples and set as a candidate office name. A sentence containing six-bit office code and the tuple score is processed. Each tuple is processed to update similarity matching score and a base dictionary. Baidu search is applied for candidate office name. Baidu query update score is determined to be greater than threshold value. A tuple set score is initialized.
   USE - Method for analyzing office financial news tendency.
   ADVANTAGE - The method enables adopting office name dictionary and thesaurus query method to identify a office name with better expansibility. The method enables adopting a depth learning frame for extracting text similarity comprehensive characteristic attribute key sentence, improving financial news tendency analyzing accuracy and text orientation estimation accuracy and increasing recall rate.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a method for analyzing financial news tendency. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); T04 (Computer Peripheral Equipment)
MC T01-J05B1; T01-J05B3; T01-J10B2; T01-J11A1; T04-D04
IP G06F-017/27; G06F-017/30; G06N-003/04; G06N-003/08; G06K-009/62
PD CN108932229-A   04 Dec 2018   G06F-017/27   201904   Pages: 13   Chinese
AD CN108932229-A    CN10605916    13 Jun 2018
PI CN10605916    13 Jun 2018
UT DIIDW:2018994370
ER

PT P
PN CN108932484-A
TI Capsule net based human face voice and gesture expression identification method, involves periodically reporting test data set by using model prediction result, and obtaining human face voice and gesture expression identification result.
AU ZHANG J
   XIAO N
AE UNIV SOUTH CHINA TECHNOLOGY (UYSC-C)
GA 201899431A
AB    NOVELTY - The method involves selecting a data set, a database expression data sets and a CK plus expression data set. Data pre-processing operation is performed. A depth learning model is selected as an experimental model by using de-convolution of a capsule Net. The CK plus expression data set is divided into a training data set and a test data set according to model training. The training data set is read. A trained learning model of a NAO robot is established. The test data set is periodically reported by using a model prediction result. A human face voice and gesture expression identification result is obtained.
   USE - Capsule net based human face voice and gesture expression identification method.
   ADVANTAGE - The method enables reaching human face voice and gesture expression identification effect and ensuring high expression identification accuracy and reliability in a rapid manner.
   DESCRIPTION OF DRAWING(S) - The drawing shows a schematic view of a depth learning model.
DC T01 (Digital Computers)
MC T01-E01B; T01-J05B4P; T01-J10B2; T01-J30A
IP G06K-009/00; G06N-003/04
PD CN108932484-A   04 Dec 2018   G06K-009/00   201904   Pages: 12   Chinese
AD CN108932484-A    CN10633028    20 Jun 2018
PI CN10633028    20 Jun 2018
UT DIIDW:201899431A
ER

PT P
PN CN108921826-A
TI Ultra-pixel segmentation and deep learning combined transmission line intrusion detection method, involves training R-CNN model to generate detection model file, and testing to-be-tested image by using file to obtain identified result.
AU HAN J
   CAI F
   CHEN Z
   LV C
AE SHANDONG CENT ELECTRONIC CO LTD (SHAN-Non-standard)
GA 2018981772
AB    NOVELTY - The method involves obtaining a sample image. Ultra-pixel cutting of the sample image is performed by using SLIC algorithm. Edge information is obtained by using median filtering algorithm for removing noise caused by interference. Multiple pixel blocks are selected as a sample when median filtering is finished. A Faster R-CNN model is trained to generate a detection model file. A to-be-tested image is tested by using the detection model file to obtain an identified result. Pixel is classified according to pixel similarity to update a cluster center for iteratively calculating a convergence rate to form a pixel block.
   USE - Ultra-pixel segmentation and deep learning combined transmission line intrusion detection method.
   ADVANTAGE - The method enables improving identification precision of hazard type, and reducing hazard type false alarm rate, and accurately classifying hazard type, and avoiding environment factor interference of detecting effect.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a ultra-pixel segmentation and deep learning combined transmission line intrusion detection method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B2; T01-J30A; T01-N02B1D
IP G06T-007/00; G06T-007/10; G06T-007/90
PD CN108921826-A   30 Nov 2018   G06T-007/00   201904   Pages: 8   Chinese
AD CN108921826-A    CN10608811    13 Jun 2018
PI CN10608811    13 Jun 2018
UT DIIDW:2018981772
ER

PT P
PN CN108921092-A
TI Convolutional neural network model quadratic integration based melanoma skin image classifying method, involves constructing different training sets based on random masking, and performing network model secondary integration process.
AU HU H
   KONG X
   SU Y
   CHEN S
   XIAO J
   ZHOU Q
AE UNIV ZHEJIANG TECHNOLOGY (UYZT-C)
GA 201898194U
AB    NOVELTY - The method involves constructing multiple different training sets based on random masking. A convolutional neural network model is constructed by using focal loss as penalty function. Convolutional neural network model secondary integration process is performed. Original data is enhanced by performing the random masking. The original data is combined with different samples. Two original training sets are constructed to obtain original images. Softmax loss is replaced in the convolutional neural network model to obtain an adjusting parameter. An output of softmax function is obtained.
   USE - Convolutional neural network model quadratic integration based melanoma skin image classifying method.
   ADVANTAGE - The method enables improving melanoma skin image identification performance according to a voting result.
   DESCRIPTION OF DRAWING(S) - The drawing shows a sequential diagram illustrating a convolutional neural network model quadratic integration based melanoma skin image classifying method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B1; T01-J10B2; T01-N01A3; T01-N01B3
IP G06K-009/00; G06K-009/62; G06N-003/04
PD CN108921092-A   30 Nov 2018   G06K-009/00   201904   Pages: 12   Chinese
AD CN108921092-A    CN10708545    02 Jul 2018
PI CN10708545    02 Jul 2018
UT DIIDW:201898194U
ER

PT P
PN CN108921879-A
TI Convolutional neural network and Kalman filtering region selection based moving target tracking method, involves detecting posterior estimation value, and predicting frame position of target by utilizing motion estimation information.
AU WANG C
   ZHANG L
AE UNIV CHINA GEOSCIENCES WUHAN (UYCI-C)
GA 2018991684
AB    NOVELTY - The method involves establishing a moving target detection model based on convolutional neural network (CNN) to obtain image database for performing image feature extraction pre-training operation on image data in the image database. LeNet-5 convolutional neural network structure is constructed to obtain image features. Sample identification sequence of a moving target object is generated. A posterior estimation value is detected in Kalman filter with final position by a network algorithm training model. A current frame position of the target is predicted by utilizing motion estimation information of a frame.
   USE - CNN and Kalman filtering region selection based moving target tracking method.
   ADVANTAGE - The method enables reducing training period by reducing calculation amount and error rate so as to improve tracking performance of the target.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a CNN and Kalman filtering region selection based moving target tracking system.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flowchart illustrating a convolutional neural network and Kalman filtering region selection based moving target tracking method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers); U22 (Pulse Generation and Manipulation)
MC T01-J05B4F; T01-J10B2; T01-N01B3; U22-G01A1B
IP G06T-007/277; G06N-003/04; G06N-003/08
PD CN108921879-A   30 Nov 2018   G06T-007/277   201904   Pages: 12   Chinese
AD CN108921879-A    CN10470406    16 May 2018
PI CN10470406    16 May 2018
UT DIIDW:2018991684
ER

PT P
PN CN108921044-A
TI Deep convolutional neural network based driver decision feature extraction method, involves inputting actual driving data to depth convolutional neural network, and outputting driving decision characteristic.
AU ZOU Q
   LI H
AE UNIV DALIAN (UYDV-C)
GA 201898195X
AB    NOVELTY - The method involves establishing a training sample library for training of a first deep convolutional neural network. The first deep convolutional neural network is established for extracting a driving decision characteristic. Off-line training process is performed on the first deep convolutional neural network according to a training sample. The first deep convolutional neural network is optimized. A second deep convolutional neural network is established. Actual driving data is input to the second depth convolutional neural network. The driving decision characteristic is output. Weather data is obtained.
   USE - Deep convolutional neural network based driver decision feature extraction method.
   ADVANTAGE - The method enables selecting a training sample for training a deep convolutional neural network under multiple scenes in an effective manner, and avoiding testing problems.
   DESCRIPTION OF DRAWING(S) - The drawing shows a flow diagram illustrating a deep convolutional neural network based driver decision feature extraction method. '(Drawing includes non-English language text)'
DC T01 (Digital Computers)
MC T01-J10B2; T01-N01B3A
IP G06K-009/00; G06N-003/04; G06N-003/08
PD CN108921044-A   30 Nov 2018   G06K-009/00   201904   Pages: 10   Chinese
AD CN108921044-A    CN10592632    11 Jun 2018
PI CN10592632    11 Jun 2018
UT DIIDW:201898195X
ER

EF